<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F24%2FMySQL%E7%B4%A2%E5%BC%95%E4%BB%A5%E5%8F%8A%E7%B4%A2%E5%BC%95%E7%9A%84%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[MySQL索引以及索引优化分析一、索引的概念1、什么是索引？MySQL 官方对索引的定义为：索引（Index）是帮助 MySQL 高效获取数据的数据结构。可以得到索引的本质：索引是数据结构。可以简单理解为排好序的快速查找数据结构，再简单索引就类似于一本书的目录，通过目录可以快速找到需要查找对类容。 在数据之外，数据库系统还维护着满足特定查找算法的数据结构，这些数据结构以某种方式引用（指向）数据，这样就可以在这些数据结构上实现高级查找算法。这种数据结构，就是索引。下图就是一种可能的索引方式示例： 左边是数据表，一共有两列七条记录，最左边的是数据记录的物理地址 。 为了加快 Col2 的查找，可以维护一个右边所示的二叉查找树，每个节点分别包含索引键值和一个指向对应数据记录物理地址的指 针，这样就可以运用二叉查找在一定的复杂度内获取到相应数据，从而快速的检索出符合条件的记录。一般来说索引本身也很大，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。 2、索引的优缺点分析？优势 提高查询效率：提高对数据的检索效率，降低数据库的IO成本。 天生排序：通过索引对数据进行排序，降低数据的排序成本，从而降低了CPU的消耗。 劣势 降低更新表的速度：虽然索引大大提高了查询速度，同时却会降低更新表的速度，如对表进行INSERT、UPDATE和DELETE。因为更新表时，MySQL不仅要保存数据，还要保存一下索引文件每次更新添加了索引列的字段，都会调整因为更新所带来的键值变化后的索引信息。 占用额外的空间：实际上索引也是一张表，该表保存了主键与索引字段，并指向实体表的记录，所以索引列也是要占用空间的。 二、索引的数据结构索引是在MySQL的存储引擎层实现的，所以每种存储引擎支持的缩影都不一定完全相同，也不是所有的存储引擎都支持所有的索引类型，MySQL目前提供了一下4中索引： BTREE索引：最常见的索引类型，大部分存储引擎都支持BTREE索引。 HASH索引：只有Memory引擎支持，使用场景比较简单。 R-tree索引（空间索引）：空间索引是MyISAM引擎的一个特殊索引类型，通常使用较少。 Full-text索引（全文索引）：全文索引也是MyISAM支持的一种特殊索引类型，主要用于全文索引，InnoDB从MySQL5.6开始也支持全文索引。 InnoDB、MyISAM、Memory三种常用存储引擎对各种索引的支持 索引\存储引擎 InnoDB MyISAM memory BTREE索引 支持 支持 支持 Hash索引 不支持 不支持 支持 R-tree索引 不支持 支持 不支持 Full-tree全文索引 5.6以后支持 支持 不支持 我们平常所说的索引，没有特殊说明，都是指B+树（多路搜索树）结构组织组织的索引。下面我们就来详细了解一下B树索引。 1、B树结构B树又叫多路平衡搜索树，一颗m叉的B树具有如下特性： 每个节点最多有m-1个关键字。 根节点最少可以只有1个关键字。非根节点至少有m/2个关键字。 每个节点中的关键字都按照从小到大的顺序排列，每个关键字的左子树中的所有关键字都小于它，而右子树中的所有关键字都大于它。 所有叶子节点都位于同一层，或者说根节点到每个叶子节点的长度都相同。 每个非叶子节点有n个key与n+1个指针组成，其中m/2向上取整-1&lt;=n&lt;=m-1。 以5叉B树为例，key的个数范围就是：2&lt;=n&lt;=4。当n&gt;4的时候，中间节点分裂成父节点，两边结点做子节点。这里我们以插入C N G A H E K Q M F W L T Z D P R X Y S数据为例。 【插入过程】B树的插入，我们只需要记住一个规则：判断当前结点key的个数是否小于等于m-1，如果满足，直接插入即可，如果不满足，将节点的中间的key将这个节点分为左右两部分，中间的节点放到父节点中即可。并且在插入中是根据关键字大小来决定一个关键字位置的。 （1）插入前4个字母：C N G A （2）插入H ，此时n&gt;4了，中间的结点G应该分裂成为父节点，其余结点按大小分裂到两边做子节点 （3）插入E K Q 不需要分裂 （4）插入M，中间元素M分裂到父节点 （5）插入F W L T不需要分裂 （6）插入Z，中间节点T分裂到父节点 （7）插入D时，中间节点D分裂到父节点，之后接着插入P R X Y都不会导致节点分裂 （8）最后插入S，NPQR节点个数&gt;4了，中间接单Q向上分裂，但是分裂后父节点的关键字个数也大于4了，此时父节点中间元素M再次分裂 至此，B树的构建就完成了，B树相对于二叉树来说，B树的搜索效率更高，因为兑入同等两级的数量，B树的层数更少，因此比较的次数就越少。 【查找过程】如果要找数据项F，那么首先会把M节点通过一次IO从磁盘加载到内存中，通过二分查找发现F比M小，因此需要到左边的结点去找，于是先把磁盘块D，G加载到内存中，之后又通过有通过二分查找确定F是在D和G之间，于是发生第二次IO把E,F加载到内存中，同时做二分查找，找到F，结束查询。总计3次IO。 然而真实的情况是，3 层的 B+树可以表示上百万的数据，如果上百万的数据查找只需要三次 IO，性能提高将是巨大的，如果没有索引，每个数据项都要发生一次 IO，那么总共需要百万次的 IO，显然成本非常非常高。 2、B+树结构B+树是B树的变种，他与B树的区别如下： B+树有两种类型的节点：内部结点（也称索引结点）和叶子结点。内部节点就是非叶子节点，内部节点不存储数据，只存储索引，数据都存储在叶子节点。 内部结点中的key都按照从小到大的顺序排列，对于内部结点中的一个key，左树中的所有key都小于它，右子树中的key都大于等于它。叶子结点中的记录也按照key的大小排列。 每个叶子结点都存有相邻叶子结点的指针，叶子结点本身依关键字的大小自小而大顺序链接。 父节点存有右孩子的第一个元素的索引。 下图所示就是一个B+树结构，上面两层节点都不存数据的，只是一个索引，只在最后一层叶子节点存数据。 3、MySQL中的B+树MySQL索引数据结构对经典的B+树进行了优化。在原来B+树的基础上，增加了一个指向相邻叶子节点的链表指针，就形成了顺序指针的B+树，提高了区间访问性能。 MySQL中的B+树索引结构示意图： 思考：为什么B+树更适合实际操作系统的文件索引或数据库的索引?答： （1）B+树的磁盘读写代价更低。 B+树的内部结点并没有指向关键字具体信息的指针。因此其内部结点相对 B 树更小。如果把所有同一内部结点的关键字存放在同一盘块中，那么盘块所能容纳的关键字数量也越多。一次性读入内存中的需要查找的关键字也就越多。相对来说 IO 读写次数也就降低了。 （2）B+树的查询效率更稳定。 由于非终结点并不是最终指向文件内容的结点，而只是叶子结点中关键字的索引。所以任何关键字的查找必须走一条从根结点到叶子结点的路。所有关键字查询的路径长度相同，导致每一个数据的查询效率相当 三、MySQL的索引分类索引从数据存储方式上说，分成两类：聚簇索引和非聚簇索引 从功能上说，分为6种：单值索引、唯一索引、主键索引、复合索引、外键索引、全文索引 1、聚簇索引和非聚簇索引聚簇索引并不是一种单独的索引类型，而是一种数据存储方式。术语‘聚簇’表示数据行和相邻的键值聚簇的存储在一起。如下图，左侧的索引就是聚簇索引，因为数据行在磁盘的排列和索引排序保持一致。 聚簇索引的好处：按照聚簇索引排列顺序，查询显示一定范围数据的时候，由于数据都是紧密相连，数据库不不用从多个数据块中提取数据，所以节省了大量的IO操作。 聚簇索引的限制： 对于 mysql 数据库目前只有 innodb 数据引擎支持聚簇索引，而 Myisam 并不支持聚簇索引。由于数据物理存储排序方式只能有一种，所以每个 Mysql 的表只能有一个聚簇索引。一般情况下就是该表的主键。 为了充分利用聚簇索引的聚簇的特性，所以 innodb 表的主键列尽量选用有序的顺序 id，而不建议用无序的 id，比如 uuid 这种。 2、单值索引、唯一索引、主键索引、复合索引、外键索引、全文索引2.1 单值索引概念：即一个索引只包含单个列，一个表可以有多个单列索引。 语法： 创建表： CREATE TABLE customer ( id INT(10) UNSIGNED AUTO_INCREMENT , customer_no VARCHAR(200), customer_name VARCHAR(200),PRIMARY KEY(id),KEY (customer_name)); 建一个单值索引： create index idx_customer_name on customer(customer_name); 2.2 唯一索引概念： 索引列的值必须唯一，但允许有空值 语法： 创建表： CREATE TABLE customer ( id INT(10) UNSIGNED AUTO_INCREMENT , customer_no VARCHAR(200), customer_name VARCHAR(200),PRIMARY KEY(id),KEY (customer_name)); 建一个单值索引： create unique index idx_customer_no on customer(customer_no); 2.3 主键索引概念： 特殊的唯一索引，不允许有空值。设定为主键后数据库会自动建立索引，innodb为聚簇索引。主键索引会随着表的创建而创建。 2.4 复合索引概念：一个索引中包含多个列。 语法： 创建表： CREATE TABLE customer ( id INT(10) UNSIGNED AUTO_INCREMENT , customer_no VARCHAR(200), customer_name VARCHAR(200), customer_age int,PRIMARY KEY(id),KEY (customer_name)); 建一个单值索引： create index idx_customer on customer(customer_no,customer_name,customer_age); 在mysql建立复合索引时会遵循最左前缀匹配的原则，即最左优先，在检索数据时从复合索引的最左边开始匹配。比如上面这个索引语句其实就是创建了（customer_no）、（customer_no,customer_name）以及（customer_no,customer_name,customer_age）是三个索引。简单来说复合索引有以下几个好处： （1）可以减少开销。每多一个索引，都会增加写操作的开销和磁盘空间的开销。对于大量数据的表，使用联合索引会大大的减少开销！ （2）覆盖索引。MySQL可以直接通过遍历索引取得数据，而无需回表，这减少了很多的随机io操作。减少io操作，特别的随机io其实是dba主要的优化策略。所以，在真正的实际应用中，覆盖索引是主要的提升性能的优化手段之一。 （3）效率高。索引列越多，通过索引筛选出的数据越少。 四、索引的设计原则索引的设计可以遵循一些已有的原则，创建索引的时候请尽量考虑复合这些原则，便于提升索引的使用效率，更高效的使用索引。 （1）对查询频次高，且数据量适量的表建立索引。一般来说，小表使用全表扫描更快，中大表才使用索引。超级大表索引基本无效。 （2）索引字段的选择，最佳候选列应当从where子句的条件中提取，如果where子句中的组合比较多，那么应当挑选最常用。过滤效果最好的列的组合。 （3）尽量使用唯一索引，区分度越高，使用索引的效率越高。 （4）索引可以有效的提高数据查询的效率，但是事事都是物极必反的，过多的索引不仅会占用大量的磁盘空间，还会增加数据库系统维护索引的代价。 （5）使用短索引，索引的字段的内容应该尽可能少，不然索引也会占用过多的磁盘空间。 （6）利用最左前缀原则，N个列组合而成的复合索引，相当于创建了N个索引，如果查询时where子句中使用了组成该索引的前几个字段，那么查询效率会大大提升。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F24%2FMySQL%E9%80%BB%E8%BE%91%E6%9E%B6%E6%9E%84%E7%AE%80%E4%BB%8B%2F</url>
    <content type="text"><![CDATA[MySQL逻辑架构简介1、整体架构图和其它数据库相比，MySQL 有点与众不同，它的架构可以在多种不同场景中应用并发挥良好作用。主要体现在存储引擎的架构上，插件式的存储引擎架构将查询处理和其它的系统任务以及数据的存储提取相分离。这种架构可以根据业务的需求和实际需要选择合适的存储引擎。MySQL官方给出的系统逻辑架构分为4层，如下图所示： 这四层自顶向下分别是连接层，服务层（核心层），存储引擎层，系统文件层。我们自顶向下开始讲解。 1.1 连接层最上层是一些客户端和连接服务，包含本地 sock 通信和大多数基于客户端/服务端工具实现的类似于 tcp/ip 的通信。主要完成一些类似于连接处理、授权认证、及相关的安全方案。在该层上使用了线程池技术，为通过认证安全接入的客户端提供线程。同样在该层上可以实现基于 SSL 的安全链接。服务器也会为安全接入的每个客户端验证它所具有的操作权限。 1.2 服务层 第二层服务层是MySQL的核心，MySQL的核心服务层都在这一层：查询解析，SQL执行计划分析，SQL执行计划优化，查询缓存。以及跨存储引擎的功能都在这一层实现：存储过程，触发器，视图等。重要的组件的功能如下图所示： Management Serveices &amp; Utilities 系统管理和控制工具 SQL Interface SQL 接口。接受用户的 SQL 命令，并且返回用户需要查询的结果。比如select from就是调用 SQL Interface Parser 解析器。 SQL 命令传递到解析器的时候会被解析器验证和解析 Optimizer 查询优化器。 SQL 语句在查询之前会使用查询优化器对查询进行优化，比如有where 条件时，优化器来决定先投影还是先过滤。 Cache 和 Buffer 查询缓存。如果查询缓存有命中的查询结果，查询语句就可以直接去查询缓存中取数据。这个缓存机制是由一系列小缓存组成的。比如表缓存，记录缓存，key 缓存，权限缓存等 在这一层就是SQL语句被执行的一层，接下来我们分析一下SQL语句的执行过程： （1）mysql客户端通过协议和mysql服务器连接，发送查询语句，首先会检查查询缓存(query cache)，如果命中，直接返回结果，否则进行语句解析 。 查询缓存(query cache)——它存储 SELECT 语句以及相应的查询结果集。如果某个查询结果已经位于缓存中，服务器就不会再对查询进行解析、优化、以及执行。它仅仅将缓存中的结果返回给用户即可，这将大大提高系统的性能。 （2）语法解析器和预处理：首先mysql解析器会将SQL语句根据关键字进行解析，并生成一颗”解析树”。语法解析器会根据mysql语法规则对解析树进行语法检查；预处理器则根据一些 mysql 规则进一步检查解析数是否合法。 （3）当解析树被认为是合法的了，会通过查询优化器将其转化成执行计划。通常一条查询可以有很多种执行方式，最后都返回相同的结果。优化器的作用就是找到这其中最好的执行计划。 （4）在完成语法解析和优化之后，mysql会生成执行计划。查询执行引擎根据执行计划给出的指令调用存储引擎的结构得到结果。在查询到结果后除了返回给客户端外，还会将结果缓存一份到查询缓存中。 SQL语句的执行过程如下图所示： 1.3 存储引擎层存储引擎层，存储引擎真正的负责了 MySQL 中数据的存储和提取，服务器通过 API 与存储引擎进行通信。MySQL采用插件式的存储引擎。MySQL为我们提供了许多存储引擎，每种存储引擎有不同的特点。我们可以根据不同的业务特点，选择最适合的存储引擎。如果对于存储引擎的性能不满意，可以通过修改源码来得到自己想要达到的性能。 这里需要说明的是：存储引擎是针对于表的而不是针对库的（一个库中不同表可以使用不同的存储引擎），服务器通过API与存储引擎进行通信，用来屏蔽不同存储引擎之间的差异。 在MySQL中常用的存储引擎有3个：InnoDB、MyISAM以及Memory。这三种引擎就是因为很常用，所以在面试中也经常被问到，因此我们有必要详细了解一下，这里不做过多的说明，只是简单的介绍一下，详情参考 InnoDB：支持事物，适合OLTP应用，假设没有特殊的需求，使用InnoDB就可以满足需求。InnoDB支持行级锁，从MySQL5.5.8开始InnoDB就成为了MySQL的默认存储引擎。 MyISAM：不支持事务，表锁设计，支持全文索引，主要应用于OLAP应用 Memory：数据都存放在内存中，数据重启或崩溃，表中的数据都将消失，但是表的结构还是会保存下来。默认使用Hash索引。适用于OLTP应用的临时表或中间表。 1.4 系统文件层该层主要是将数据库的数据存储在文件系统之上，并完成与存储引擎的交互。 MyISAM文件格式MyISAM在磁盘存储上有三个文件，每个文件名以表名开头，扩展名指出文件类型： .frm文件：用于存储表结构的定义 .MYD文件：用于存放数据 .MYI文件用于存放表索引 MyISAM引擎还支持三种不同类型的存储格式：静态表、动态表、压缩表 InnoDB文件格式InnoDB属于索引组织表，InnoDB有两种存储方式：共享表空间和独享表空间存储。两种存储方式的表结构信息和MyISAM一样，以表名开头，扩展名是.frm。 .frm文件：与表相关的元数据信息都存放在frm文件，包括表结构的定义信息等。 .ibd/.ibdata文件：存放innodb表的数据文件。独享表空间存储方式使用.ibd文件格式。共享表空间存储方式使用.ibdata存储方式，所有的表共同使用一个ibdata文件，即所有的数据文件都存在一个文件中。决定使用哪种表的存储方式可以通过mysql的配置文件中 innodb_file_per_table选项来指定。InnoDB默认采用的是独享表空间存储数据，这种方式的好处是当数据库产生大量文件碎片的时，整理磁盘碎片对线上运行环境的影响较小。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F24%2FJAVA%E9%9B%86%E5%90%88%E6%80%BB%E7%BB%93%EF%BC%8C%E5%B0%86%E7%9F%A5%E8%AF%86%E7%82%B9%E4%B8%80%E7%BD%91%E6%89%93%E5%B0%BD%EF%BC%81%2F</url>
    <content type="text"><![CDATA[JAVA集合总结，将知识点一网打尽！一、Java集合框架体系总览 总的来说，Java集合框架以Collection接口为中心，下属是三个子接口，分别是：List（线性表）、Set、Queue（队列），以及还有一个非常重要的Map接口。下面我们分别总结一下每种类型集合下的知识点。 Collection接口首先我们来看一下Collection接口中的方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768691. 添加元素的功能：/**添加元素*/boolean add(E e);/**将整个集合添加到某个集合*/boolean addAll(Collection&lt;? extends E&gt; c);2.从集合中删除(指定)元素/**清空集合中的所有元素*/void clear();//从集合中移除指定元素boolean remove(Object o);//从此集合中移除指定集合中包含的元素boolean removeAll(Collection&lt;?&gt; c);//移除在c集合中不包含的元素boolean retainAll(Collection&lt;?&gt; c);3.判断功能/**集合中是否有元素o,如果有返回true,否则返回false*/boolean contains(Object o);/**如果在此集合中有给定集合中的全部元素那么将返回true*/boolean containsAll(Collection&lt;?&gt; c);//判断集合是否为空，如果为空返回true,否者返回falseboolean isEmpty();4.获取集合的各种信息//获得遍历集合元素的迭代器，这个方法是Collection继承Iterable接口得到的Iterator&lt;E&gt; iterator();//返回集合中元素的个数int size();/**判断两个对象是否相等*/boolean equals(Object o);//返回集合对象的hashCodeint hashCode();5. 转换//将此集合转化为数组Object[] toArray();/**=============jdk1.8新增的几个方法=============*///在jdk1.8中新增了一下几个方法，都是default方法，在Collection接口中直接给出了实现//parallelStream()返回并行的Streamdefault Stream&lt;E&gt; parallelStream() &#123; return StreamSupport.stream(spliterator(), true);&#125;//仅仅是返回集合的Streamdefault Stream&lt;E&gt; stream() &#123; return StreamSupport.stream(spliterator(), false); &#125; //删除容器中所有满足filter指定条件的元素default boolean removeIf(Predicate&lt;? super E&gt; filter) &#123; Objects.requireNonNull(filter); boolean removed = false; final Iterator&lt;E&gt; each = iterator(); while (each.hasNext()) &#123; if (filter.test(each.next())) &#123; each.remove(); removed = true; &#125; &#125; return removed; &#125; //可分割的迭代器，不同以往的iterator需要顺序迭代，Spliterator可以分割为若干个小的迭代器进行并行操//作，既可以实现多线程操作提高效率，又可以避免普通迭代器的fail-fast机制所带来的异常default Spliterator&lt;E&gt; spliterator() &#123; return Spliterators.spliterator(this, 0);&#125; Iterable接口Collection接口继承了Iterable接口，说明所有的集合元素都是可以通过Iterator迭代器来遍历，事实也确实是这样，下面是Iterable接口中的三个方法： 1234567891011121314151617//获取遍历集合的迭代器，Collection中的iterator方法就是从这里继承得到的Iterator&lt;T&gt; iterator();//JDK1.8新增的一个遍历集合的方法，采用函数式接口的方式，可以很方便的遍历所有集合类型default void forEach(Consumer&lt;? super T&gt; action) &#123; //方法内部已经判空了，所有在使用这个方法的时候没有必要的时候不用判空 Objects.requireNonNull(action); //底层实际还是增强for for (T t : this) &#123; action.accept(t); &#125; &#125; //作用和Collection中的同名方法一样default Spliterator&lt;T&gt; spliterator() &#123; return Spliterators.spliteratorUnknownSize(iterator(), 0);&#125; Iterator—迭代器使用迭代器可以任何类型的集合，Iterator也是一个接口，它有三个迭代器必备的基本方法外加jdk1.8新增了一个方便的遍历集合的方法forEachRemaining： 12345678910111213141516//判断集合是否还有下一个元素boolean hasNext();//获取集合的下一个元素E next();//移除元素default void remove() &#123; throw new UnsupportedOperationException("remove");&#125;//JDK1.8新增的一个方法，用法和作用都和Iterable接口中的forEach()方法类似default void forEachRemaining(Consumer&lt;? super E&gt; action) &#123; Objects.requireNonNull(action); //这里使用的是Iterator接口中的hasNext方法配合while循环实现遍历的 while (hasNext()) action.accept(next()); &#125; 二、List接口Java 的 List 是非常常用的数据类型。List 是有序的 Collection。Java List 一共三个实现类：分别是 ArrayList、Vector 和 LinkedList。 1、ArrayListArrayList 是最常用的 List 实现类，内部是通过Object数组实现的，它可以实现对元素进行快速随机访问。ArrayList中的Object数组的的默认初始化大小是10，并且默认构造方法中对于数组的创建是在第一次添加元素时执行的，我们可以看看源码的实现： 1234567891011121314151617181920212223242526272829303132public class ArrayList&lt;E&gt; extends AbstractList&lt;E&gt; implements List&lt;E&gt;, RandomAccess, Cloneable, java.io.Serializable&#123; //ArrayList默认容量 private static final int DEFAULT_CAPACITY = 10; //用Object[0]来代替null 很多时候我们需要传递参数的类型，而不是传null，所以用Object[0] private static final Object[] EMPTY_ELEMENTDATA = &#123;&#125;; //一个空对象，如果使用默认构造函数创建，则默认对象内容默认是该值 private static final Object[] DEFAULTCAPACITY_EMPTY_ELEMENTDATA = &#123;&#125;; //存储元素的数组 transient Object[] elementData; // non-private to simplify nested class access //数组中元素个数 private int size; //数组最大容量 private static final int MAX_ARRAY_SIZE = 2147483639; //默认构造方法，在构造方法中并没有立即初始化一个大小为10的Object数组，而是采用了懒加载，延迟到第一次添加元素的时候才初始化 public ArrayList() &#123; this.elementData = DEFAULTCAPACITY_EMPTY_ELEMENTDATA; &#125; //指定容量的ArrayList则是在构造方法中立即初始化了一个指定容量大小的Object数组 public ArrayList(int initialCapacity) &#123; if (initialCapacity &gt; 0) &#123; this.elementData = new Object[initialCapacity]; &#125; else if (initialCapacity == 0) &#123; this.elementData = EMPTY_ELEMENTDATA; &#125; else &#123; throw new IllegalArgumentException("Illegal Capacity: "+ initialCapacity); &#125; &#125;&#125; 添加元素的方法addArrayList会在添加新元素之前先检查一下数组的大小是否够用，如果不够用就会扩容，默认的扩容大小是原数组的1.5倍，如果扩容1.5的大小还是没法满足添加元素所需的容量，就会使用传入的容量大小，这样就会导致下一次添加元素的时候又触发扩容，因此在使用任何集合元素的时候请尽量给定一个初始容量，避免频繁的扩容影响性能。 但是当从 ArrayList 的中间位置插入或者删除元素时，需要对数组进行复制、移动、代价比较高。因此，它适合随机查找和遍历，不适合插入和删除。 123456789101112131415161718192021222324252627282930313233343536373839404142public boolean add(E e) &#123; //ArrayList的扩容机制在这一步实现 ensureCapacityInternal(size + 1); //确认内部容量 elementData[size++] = e; return true; &#125;private void ensureCapacityInternal(int minCapacity) &#123; // 如果elementData 指向的是 DEFAULTCAPACITY_EMPTY_ELEMENTDATA 的地址 if (elementData == DEFAULTCAPACITY_EMPTY_ELEMENTDATA) &#123; //可以看到，如果是使用了默认构造方法时，只有在第一次添加元素的时候才会构造一个大小为10的数组 // minCapacity = Math.max(DEFAULT_CAPACITY, minCapacity); &#125; //确定实际容量 ensureExplicitCapacity(minCapacity); &#125;private void ensureExplicitCapacity(int minCapacity) &#123; modCount++; // 如果超出了容量，进行扩展 if (minCapacity - elementData.length &gt; 0) grow(minCapacity); &#125;//ArrayList的扩容实现private void grow(int minCapacity) &#123; // overflow-conscious code int oldCapacity = elementData.length; //新数组的大小是旧数组大小的1.5倍 int newCapacity = oldCapacity + (oldCapacity &gt;&gt; 1); //如果1.5倍的新数组大小还是没法满足，那就使用minCapacity if (newCapacity - minCapacity &lt; 0) newCapacity = minCapacity; if (newCapacity - MAX_ARRAY_SIZE &gt; 0) //当数组容量超过自大容量限制后MAX_ARRAY_SIZE，将数组的容量设置为Integer.MAX_VALUE newCapacity = hugeCapacity(minCapacity); // minCapacity is usually close to size, so this is a win: elementData = Arrays.copyOf(elementData, newCapacity); &#125; 2、Vector （ 数组实现、 线程同步）Vector 与 ArrayList 一样，也是通过数组实现的，不同的是它支持线程的同步，即某一时刻只有一个线程能够写 Vector，避免多线程同时写而引起的不一致性，但实现同步需要很高的花费，因此，访问它比访问 ArrayList 慢。 3、LinkedList（双链表、双端队列）LinkedList即实现了List接口，同时它也实现了Deque接口。它使用链表结构存储数据，很适合数据的动态插入和删除。具体的我们看看源码就清楚了： 1234567891011121314151617181920212223//Node结点，是一个双链表private static class Node&lt;E&gt; &#123; E item; Node&lt;E&gt; next; Node&lt;E&gt; prev; Node(Node&lt;E&gt; prev, E element, Node&lt;E&gt; next) &#123; this.item = element; this.next = next; this.prev = prev; &#125; &#125;//链表的头结点transient Node&lt;E&gt; first; //链表的尾结点 transient Node&lt;E&gt; last;//链表的结点个数transient int size = 0;//默认的构造方法，啥都没干...public LinkedList() &#123;&#125; 添加元素的方法LinkedList同时具有链表和双向队列的功能，因此添加元素的方法也有两个add方法和offer方法，前者用于向链表中尾插数据，后者用于向队列尾部添加数据。其实在源码中offer方法是把add方法有包装了一下而已。我们直接来看add方法的实现即可、 1234567891011121314151617//添加新元素public boolean add(E e) &#123; linkLast(e); return true; &#125; //在链表的尾部插入新节点（尾插法）void linkLast(E e) &#123; final Node&lt;E&gt; l = last; final Node&lt;E&gt; newNode = new Node&lt;&gt;(l, e, null); last = newNode; if (l == null) first = newNode; else l.next = newNode; size++; modCount++; &#125; 三、Set接口Set 注重独一无二的性质,该体系集合用于存储无序(存入和取出的顺序不一定相同)元素，值不能重复。对象的相等性本质是对象 hashCode 值（java 是依据对象的内存地址计算出的此序号）判断的，如果想要让两个不同的对象视为相等的，就必须覆盖 Object 的 hashCode 方法和 equals 方法。 1、HashSet哈希表边存放的是哈希值。HashSet 存储元素的顺序并不是按照存入时的顺序（和 List 显然不同） 而是按照哈希值来存的所以取数据也是按照哈希值取得。元素的哈希值是通过元素的hashcode 方法来获取的, HashSet 首先判断两个元素的哈希值，如果哈希值一样，接着会比较equals 方法 如果 equls 结果为 true ，HashSet 就视为同一个元素。如果 equals 为 false 就不是同一个元素。 2、TreeSet（1）TreeSet()是使用二叉树的原理对新 add()的对象按照指定的顺序排序（升序、降序），每增加一个对象都会进行排序，将对象插入的二叉树指定的位置。 （2）Integer 和 String 对象都可以进行默认的 TreeSet 排序，而自定义类的对象是不可以的，自己定义的类必须实现 Comparable 接口，并且覆写相应的 compareTo()函数，才可以正常使用。 （3）在覆写 compare()函数时，要返回相应的值才能使 TreeSet 按照一定的规则来排序 （4）比较此对象与指定对象的顺序。如果该对象小于、等于或大于指定对象，则分别返回负整数、零或正整数。 3、LinkedHashSet对于 LinkedHashSet 而言，它继承与 HashSet、又基于 LinkedHashMap 来实现的。LinkedHashSet 底层使用 LinkedHashMap 来保存所有元素，它继承与 HashSet，其所有的方法操作上又与 HashSet 相同，因此 LinkedHashSet 的实现上非常简单，只提供了四个构造方法，并通过传递一个标识参数，调用父类的构造器，底层构造一个 LinkedHashMap 来实现，在相关操作上与父类 HashSet 的操作相同，直接调用父类 HashSet 的方法即可。 四、Map接口 1、HashtableHashtable 是遗留类，很多映射的常用功能与 HashMap 类似，不同的是它承自 Dictionary 类，并且是线程安全的，任一时间只有一个线程能写 Hashtable，并发性不如 ConcurrentHashMap，因为 ConcurrentHashMap 引入了分段锁。Hashtable 不建议在新代码中使用，不需要线程安全的场合可以用 HashMap 替换，需要线程安全的场合可以用 ConcurrentHashMap 替换。 2、HashMapHashMap 根据键的 hashCode 值存储数据，大多数情况下可以直接定位到它的值，因而具有很快的访问速度，但遍历顺序却是不确定的。 HashMap 最多只允许一条记录的键为 null，允许多条记录的值为 null。HashMap 非线程安全，即任一时刻可以有多个线程同时写 HashMap，可能会导致数据的不一致。如果需要满足线程安全，可以用 Collections 的 synchronizedMap 方法使HashMap 具有线程安全的能力，或者使用 ConcurrentHashMap。我们用下面这张图来介绍HashMap 的结构。 在JDK7中HashMap使用数组+链表实现 大方向上，HashMap 里面是一个数组，然后数组中每个元素是一个单向链表。上图中，每个绿色的实体是嵌套类 Entry 的实例，Entry 包含四个属性：key, value, hash 值和用于单向链表的 next。 capacity：当前数组容量，始终保持 2^n，可以扩容，扩容后数组大小为当前的 2 倍。 loadFactor：负载因子，默认为 0.75。 threshold：扩容的阈值，等于 capacity * loadFactor Java8 对 HashMap 进行了一些修改，最大的不同就是利用了红黑树，所以其由 数组+链表+红黑树 组成。根据 Java7 HashMap 的介绍，我们知道，查找的时候，根据 hash 值我们能够快速定位到数组的具体下标，但是之后的话，需要顺着链表一个个比较下去才能找到我们需要的，时间复杂度取决于链表的长度，为 O(n)。为了降低这部分的开销，在 Java8 中，当链表中的元素超过了 8 个以后，会将链表转换为红黑树，在这些位置进行查找的时候可以降低时间复杂度为 O(logN)。 具体的原理可以参考我的博客HashMap是如何工作的 。 3、LinkedHashMapLinkedHashMap 是 HashMap 的一个子类，保存了记录的插入顺序，在用 Iterator 遍历LinkedHashMap 时，先得到的记录肯定是先插入的，也可以在构造时带参数，按照访问次序排序。 4、TreeMapTreeMap 实现 SortedMap 接口，能够把它保存的记录根据键排序，默认是按键值的升序排序，也可以指定排序的比较器，当用 Iterator 遍历 TreeMap 时，得到的记录是排过序的。如果使用排序的映射，建议使用 TreeMap。在使用 TreeMap 时，key 必须实现 Comparable 接口或者在构造 TreeMap 传入自定义的Comparator，否则会在运行时抛出 java.lang.ClassCastException 类型的异常。 参考通过分析 JDK 源代码研究 TreeMap 红黑树算法实现]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F24%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3CopyOnWriteArrayList%E2%80%94%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%2F</url>
    <content type="text"><![CDATA[线程安全的容器之CopyOnWriteArrayList—源码剖析]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F24%2F%E9%AB%98%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8BJAVA%E4%B8%AD%E7%9A%84%E9%98%BB%E5%A1%9E%E9%98%9F%E5%88%97%2F</url>
    <content type="text"><![CDATA[高并发编程之JAVA中的阻塞队列队列是一种数据结构，它有两个基本操作：在队列尾部加入元素和从队列头部移除元素。在我们日常开发中，经常用来并发操作数据。java中有一些应用比较广泛的特殊队列：一种是以ConcurrentLinkedQueue为代表的非阻塞队列；另一种是以BlockingQueue接口为代表的阻塞队列。通过这两种队列，我们保证了多线程操作数据的安全性。 一、初识阻塞队列在J.U.C包中提供的BlockingQueue很好的解决了多线程中如何高效安全“传输”数据的问题。通过这些高效并且线程安全的队列类，为我们快速搭建高质量的多线程程序带来极大的便利。本文详细介绍了BlockingQueue家庭中的所有成员，包括他们各自的功能以及常见使用场景。 BlockingQueue核心方法： 12345678910111213141516171819202122232425262728293031323334353637public interface BlockingQueue&lt;E&gt; extends Queue&lt;E&gt; &#123; //将给定元素添加到队列中，如果设置成功返回true, 否则抛出异常。如果是往限定了长度的队列中设置值，推荐使用offer()方法。 boolean add(E e); //将给定的元素添加到队列中，如果设置成功返回true, 否则返回false. e的值不能为空，否则抛出空指针异常。 boolean offer(E e); //将元素添加到队列中，如果队列中没有多余的空间，该方法会一直阻塞，直到队列中有多余的空间。 void put(E e) throws InterruptedException; //将给定元素在给定的时间内添加到队列中，如果设置成功返回true, 否则返回false. boolean offer(E e, long timeout, TimeUnit unit) throws InterruptedException; //从队列中获取值，如果队列中没有值，线程会一直阻塞，直到队列中有值，并且该方法取得了该值。 E take() throws InterruptedException; //在给定的时间里，从队列中获取值，如果没有取到会抛出异常。 E poll(long timeout, TimeUnit unit) throws InterruptedException; //获取队列剩余的空间。 int remainingCapacity(); //从队列中移除指定的值。 boolean remove(Object o); //判断队列中是否拥有该值。 public boolean contains(Object o); //将队列中值，全部移除，并发设置到给定的集合中。 int drainTo(Collection&lt;? super E&gt; c); //指定最多数量限制将队列中值，全部移除，并发设置到给定的集合中。 int drainTo(Collection&lt;? super E&gt; c, int maxElements);&#125; 阻塞队列的线程安全是依赖ReentrantLock实现的，并且借助于Condition中的await()和signal()\signal()方法实现对线程的阻塞和唤醒。 二、阻塞队列成员详细介绍1、ArrayListBlockingQueueArrayListBlockingQueue是一个用数组实现的有界阻塞队列，此队列按照先进先出（FIFO）的原则对元素进行排序。支持公平锁和非公平锁（默认情况下是非公平锁）。 12345678910111213public ArrayBlockingQueue(int capacity) &#123; //默认使用的是非公平锁 this(capacity, false); &#125;//通过boolean类型的参数可以控制使用公平锁还是非公平锁public ArrayBlockingQueue(int capacity, boolean fair) &#123; if (capacity &lt;= 0) throw new IllegalArgumentException(); this.items = new Object[capacity]; lock = new ReentrantLock(fair); notEmpty = lock.newCondition(); notFull = lock.newCondition(); &#125; 2、LinkedBlockingQueueLinkedBlockingQueue是一个用单链表实现的有界阻塞队列。此队列的默认长度和最大长度为Integer.MAX_VALUE。此队列按照先进先出的原则对元素进行排序。 3、PriorityBlockingQueue一个支持线程优先级排序的无界队列，默认自然序进行排序，也可以自定义实现compareTo()方法来指定元素排序规则，不能保证同优先级元素的顺序。 4、DelayQueueDelayQueue是一个支持延时获取元素的无界阻塞队列。队列基于PriorityBlockingQueue实现。队列中的元素必须实现Delayed接口，在创建元素是可以指定多久才能从队列中获取当前元素。DelayQueue可以用于 缓存系统设计 和 定时任务调度 这样的应用场景。 5、SynchronousQueueSynchronousQueue是一个不存储元素的阻塞队列。每一个put操作必须等待一个take操作，否则不能继续添加元素。它支持公平访问队列。默认情况下线程采用非公共策略访问队列。当使用公平锁的时候，等待的线程会采用先进先出的顺序访问队列。 12345678//默认使用非公平锁public SynchronousQueue() &#123; this(false); &#125; //通过boolean类型的参数可以控制使用公平锁还是非公平锁public SynchronousQueue(boolean fair) &#123; transferer = fair ? new TransferQueue&lt;E&gt;() : new TransferStack&lt;E&gt;();&#125; 6、LinkedTransferQueueLinkedTransferQueue是一个由链表实现的无界阻塞Transfer队列。相对于其他阻塞队列，LinkedTransferQueue多了transfer和tryTransfer方法 7、LinkedBlockingDequeLinkedBlockingDeque是一个由双链表实现的双向阻塞队列。队列头部和尾部都可以添加和移除元素，多线程并发时，可以将锁的竞争最多降到一半。 接下来重点介绍下：ArrayListBlockingQueue、LinkedBlockingQueue以及DelayQueue 三、阻塞队列原理及应用阻塞队列的原理就是基于等待/通知机制实现的,即当生产者往满的队列里添加元素的时候会阻塞生产者，当消费者消费了队列中的一个元素后户通知生产者生产。只不过在阻塞队列中没有使用Obeject类中的wait()和notify()，而是使用了Conditon接口下的await()和signal()方法来实现了对某个具体的线程的挂起和唤醒，底层调用的是LockSupport类的静态方法prak()和unpark()方法实现的。其中Condition接口的实例是通过ReentrantLock的newCondition()方法得到的，实际的实现是在AQS中，接下来我们就以ArrayListBlockingQueue、LinkedBlockingQueue以及DelayQueue为重点来分析一下他们是如何实现的。 1、Conditon接口在AQS中的实现在AQS中有一个内部类ConditonObject，它实现了Condition接口。我们主要就来看看await()和signal()方法的实现： 1234567public class ConditionObject implements Condition, java.io.Serializable &#123; /** First node of condition queue. */ private transient Node firstWaiter; /** Last node of condition queue. */ private transient Node lastWaiter; public ConditionObject() &#123; &#125; &#125; （1）await()方法—用于阻塞当前线程 12345678910111213141516171819public final void await() throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); Node node = addConditionWaiter(); int savedState = fullyRelease(node); int interruptMode = 0; while (!isOnSyncQueue(node)) &#123; //调用了LockSupport.park(Thread)方法来阻塞当前线程 LockSupport.park(this); if ((interruptMode = checkInterruptWhileWaiting(node)) != 0) break; &#125; if (acquireQueued(node, savedState) &amp;&amp; interruptMode != THROW_IE) interruptMode = REINTERRUPT; if (node.nextWaiter != null) // clean up if cancelled unlinkCancelledWaiters(); if (interruptMode != 0) reportInterruptAfterWait(interruptMode); &#125; （2）signal()方法—用于唤醒处在AQS等待队列头部的线程 12345678910111213141516171819202122232425262728293031public final void signal() &#123; if (!isHeldExclusively()) throw new IllegalMonitorStateException(); //获取头部结点 ，结点中封装了等待中的线程 Node first = firstWaiter; if (first != null) //如果结点不为null,那就唤醒结点中处于等待中的线程 doSignal(first); &#125; private void doSignal(Node first) &#123; do &#123; if ( (firstWaiter = first.nextWaiter) == null) lastWaiter = null; first.nextWaiter = null; &#125; while (!transferForSignal(first) &amp;&amp; (first = firstWaiter) != null); &#125; final boolean transferForSignal(Node node) &#123; if (!compareAndSetWaitStatus(node, Node.CONDITION, 0)) return false; Node p = enq(node); int ws = p.waitStatus; if (ws &gt; 0 || !compareAndSetWaitStatus(p, ws, Node.SIGNAL)) //最终还是调用了LockSupport.unpark(Tread)唤醒线程 LockSupport.unpark(node.thread); return true; &#125; 2、ArrayListBlockingQueue（1）参数以及构造方法： 1234567891011121314151617181920212223242526272829303132333435363738394041public class ArrayBlockingQueue&lt;E&gt; extends AbstractQueue&lt;E&gt; implements BlockingQueue&lt;E&gt;, java.io.Serializable &#123; /** 存储数据的数组 */ final Object[] items; /** 拿数据的索引，在take()/poll()/peek()/remove()方法中使用*/ int takeIndex; /** 添加数据的索引，在put()/offer()/add()方法中使用*/ int putIndex; /** 元素个数 */ int count; /** 可重入锁*/ final ReentrantLock lock; /** Condition for waiting takes */ private final Condition notEmpty; /** Condition for waiting puts */ private final Condition notFull; public ArrayBlockingQueue(int capacity) &#123; //默认构造非公平的阻塞队列 this(capacity, false); &#125; public ArrayBlockingQueue(int capacity, boolean fair) &#123; if (capacity &lt;= 0) throw new IllegalArgumentException(); //初始化数组，容量是capacity this.items = new Object[capacity]; //锁，传入false就是非公平锁；传入true就是公平锁 lock = new ReentrantLock(fair); //初始化非空等待队列 notEmpty = lock.newCondition(); //出初始化非满等待队列 notFull = lock.newCondition(); &#125;&#125; （2）添加元素的原理—add/offer/put add方法最终调用的还是offer方法，offer方法最终调用了enqueue(E x)方法。enqueue(E x)方法内部通过putIndex索引直接将元素添加到数组items中，这里可能会疑惑的是当putIndex索引大小等于数组长度时，需要将putIndex重新设置为0，这是因为当前队列执行元素获取时总是从队列头部获取，而添加元素从中从队列尾部获取所以当队列索引（从0开始）与数组长度相等时，下次我们就需要从数组头部开始添加了 1234567891011121314151617181920212223242526272829303132333435//offer方法的实现public boolean offer(E e) &#123; checkNotNull(e); //首先获取锁 final ReentrantLock lock = this.lock; lock.lock(); try &#123; //如果队列满了之后就返回false if (count == items.length) return false; else &#123; //队列还有空间就调用enqueue()方法添加 enqueue(e); return true; &#125; &#125; finally &#123; //解锁 lock.unlock(); &#125; &#125;//enqueue方法的实现——入队操作private void enqueue(E x) &#123; final Object[] items = this.items; //putIndex索引就是下一元素应该放入的索引位置，这里直接把元素放入数组putIndex处 items[putIndex] = x; //索引自增，如果已是最后一个位置，重新设置 putIndex = 0; if (++putIndex == items.length) putIndex = 0; //容量自加 count++; //唤醒在等待取元素的线程 notEmpty.signal(); &#125; 接下来我们看一下put方法的实现： put方法是一个阻塞的方法，如果队列元素已满，那么当前线程将会被notFull条件对象挂起加到等待队列中，直到队列有空档才会唤醒执行添加操作。但如果队列没有满，那么就直接调用enqueue(e)方法将元素加入到数组队列中。 1234567891011121314151617//put方法的实现public void put(E e) throws InterruptedException &#123; checkNotNull(e); //获取锁，可以响应中断 final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; //当队列元素个数与数组长度相等时，无法添加元素 while (count == items.length) //将当前调用线程挂起，添加到notFull条件队列中等待唤醒 notFull.await(); enqueue(e); &#125; finally &#123; //解锁 lock.unlock(); &#125; &#125; offer，add在正常情况下都是无阻塞的添加，而put方法是阻塞添加。这就是阻塞队列的添加过程。说白了就是当队列满时通过条件对象Condtion来阻塞当前调用put方法的线程，直到线程又再次被唤醒执行。总得来说添加线程的执行存在以下两种情况，一是，队列已满，那么新到来的put线程将添加到notFull的条件队列中等待，二是，有移除线程执行移除操作，移除成功同时唤醒put线程，如下图所示： （3）移除元素-poll/remove poll方法，该方法获取并移除此队列的头元素，若队列为空，则返回 null 12345678910111213141516171819202122232425262728293031public E poll() &#123; //获取锁 final ReentrantLock lock = this.lock; lock.lock(); try &#123; //非阻塞获取队列头部元素，如果队列是空的就返回null return (count == 0) ? null : dequeue(); &#125; finally &#123; //解锁 lock.unlock(); &#125; &#125; //出队操作private E dequeue() &#123; // assert lock.getHoldCount() == 1; // assert items[takeIndex] != null; final Object[] items = this.items; @SuppressWarnings("unchecked") E x = (E) items[takeIndex]; //由于是数组，可以直接通过takeIndex索引获取数据 items[takeIndex] = null; //表示把元素移除了 //takeIndex索引自加，如果takeIndex跑到数组尾部了，就初始成0 if (++takeIndex == items.length) takeIndex = 0; count--; //count初始为0 if (itrs != null) //更新迭代器中的元素数据 itrs.elementDequeued(); notFull.signal(); //把添加元素的线程唤醒 return x; //返回元素 &#125; 接下来在看看remove方法，它只会移除元素而不会返回元素，移除成功返回true,否则返回false。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566//移除队列中的元素，但不返回该元素public boolean remove(Object o) &#123; if (o == null) return false; final Object[] items = this.items; //加锁 final ReentrantLock lock = this.lock; lock.lock(); try &#123; //队列不为空 if (count &gt; 0) &#123; //获取putIndex final int putIndex = this.putIndex; //获取当前要被删除元素的索引 int i = takeIndex; //执行循环查找要删除的元素 do &#123; //找到要删除的元素 if (o.equals(items[i])) &#123; removeAt(i); //删除索引i位置的元素 return true; &#125; //当前删除索引执行加1后判断是否与数组长度相等 //若为true，说明索引已到数组尽头，将i设置为0 if (++i == items.length) i = 0; &#125; while (i != putIndex); &#125; return false; &#125; finally &#123; lock.unlock(); &#125; &#125; //移除数组中指定索引位置的元素void removeAt(final int removeIndex) &#123; final Object[] items = this.items; if (removeIndex == takeIndex) &#123; items[takeIndex] = null; if (++takeIndex == items.length) takeIndex = 0; count--; if (itrs != null) itrs.elementDequeued(); &#125; else &#123; final int putIndex = this.putIndex; for (int i = removeIndex;;) &#123; int next = i + 1; if (next == items.length) next = 0; if (next != putIndex) &#123; items[i] = items[next]; i = next; &#125; else &#123; items[i] = null; this.putIndex = i; break; &#125; &#125; count--; if (itrs != null) itrs.removedAt(removeIndex); &#125; //移除时候唤醒等待添加元素的线程 notFull.signal(); &#125; 3、LinkedBlockingQueue（1）重要参数和构造方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class LinkedBlockingQueue&lt;E&gt; extends AbstractQueue&lt;E&gt; implements BlockingQueue&lt;E&gt;, java.io.Serializable &#123; //链表结点类型：单链表 static class Node&lt;E&gt; &#123; E item; //元素 Node&lt;E&gt; next; //下一个结点的引用 Node(E x) &#123; item = x; &#125; &#125; //队列的容量大小 private final int capacity; /** 统计元素个数，因为有2个锁，存在竞态条件，使用AtomicInteger保证原子性*/ private final AtomicInteger count = new AtomicInteger(); /**链表头结点*/ transient Node&lt;E&gt; head; /**链表尾结点*/ private transient Node&lt;E&gt; last; /**获取并移除元素时使用的锁，如take, poll, etc */ private final ReentrantLock takeLock = new ReentrantLock(); /** 添加元素时使用的锁如 put, offer, etc */ private final ReentrantLock putLock = new ReentrantLock(); /** notEmpty条件对象，当队列没有数据时用于挂起执行移除元素的线程 */ private final Condition notEmpty = takeLock.newCondition(); /** notFull条件对象，当队列数据已满时用于挂起执行添加元素的线程 */ private final Condition notFull = putLock.newCondition(); //LinkedBlockingQueue的默认大小是Integer.MAX_VALUE,因此在使用的时候一定要指定大小 public LinkedBlockingQueue() &#123; this(Integer.MAX_VALUE); &#125; //构造指定大小的单链表 public LinkedBlockingQueue(int capacity) &#123; if (capacity &lt;= 0) throw new IllegalArgumentException(); //此时链表的长度不能超过capacity this.capacity = capacity; last = head = new Node&lt;E&gt;(null); &#125;&#125; （2）添加元素—offer/put offer方法和put的差别就是offer方法是一个非阻塞的方法，如果添加成功返回true,添加失败了就返回false，不会阻塞的等待。take方法是一个阻塞的方法，如果添加失败了，会阻塞着等待。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public boolean offer(E e) &#123; if (e == null) throw new NullPointerException(); //队列中元素个数 final AtomicInteger count = this.count; //队列满了，没法添加了直接返回false,不会阻塞 if (count.get() == capacity) return false; //队列没有满，可以添加 int c = -1; //new一个Node Node&lt;E&gt; node = new Node&lt;E&gt;(e); //获取加入元素的锁 final ReentrantLock putLock = this.putLock; putLock.lock(); try &#123; //如果当前队列的元素个数小于指定的容量 if (count.get() &lt; capacity) &#123; //入队新元素 enqueue(node); //队列元素个数统计+1 c = count.getAndIncrement(); //如果添加新元素后队列大小小于指定容量就把其他执行添加元素的线程唤醒 if (c + 1 &lt; capacity) notFull.signal(); &#125; &#125; finally &#123; putLock.unlock(); &#125; if (c == 0) signalNotEmpty(); return c &gt;= 0;&#125;//逻辑大致和offer类似，只是当队列满了之后会阻塞当前线程public void put(E e) throws InterruptedException &#123; if (e == null) throw new NullPointerException(); // Note: convention in all put/take/etc is to preset local var // holding count negative to indicate failure unless set. int c = -1; Node&lt;E&gt; node = new Node&lt;E&gt;(e); final ReentrantLock putLock = this.putLock; final AtomicInteger count = this.count; putLock.lockInterruptibly(); try &#123; //对了满了，阻塞当前线程 while (count.get() == capacity) &#123; notFull.await(); &#125; enqueue(node); c = count.getAndIncrement(); if (c + 1 &lt; capacity) notFull.signal(); &#125; finally &#123; putLock.unlock(); &#125; if (c == 0) signalNotEmpty(); &#125;//入队private void enqueue(Node&lt;E&gt; node) &#123; //直接把新节点放到队列尾部即可 last = last.next = node;&#125; （2）元素出队—poll()/take() poll和take方法的区别主要还是前者在获取的时候如果发现队列是空的就会直接返回null不会阻塞，当时后者如果发现队列是空的就会阻塞当前线程。具体我们通过源码分析一下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768public E poll() &#123; //首先获取到当前队列的大小（元素个数） final AtomicInteger count = this.count; //如果队列是空的就直接返回null if (count.get() == 0) return null; E x = null; int c = -1; final ReentrantLock takeLock = this.takeLock; takeLock.lock(); try &#123; //队列不为空 if (count.get() &gt; 0) &#123; //从队列的头部获取到元素 x = dequeue(); //更新count c = count.getAndDecrement(); if (c &gt; 1) //如果队列不空，唤醒其他等待获取元素的线程 notEmpty.signal(); &#125; &#125; finally &#123; takeLock.unlock(); &#125; if (c == capacity) signalNotFull(); return x; &#125;/***逻辑大致和poll方法类似，只是当队列为空之后会阻塞当前线程*/public E take() throws InterruptedException &#123; E x; int c = -1; final AtomicInteger count = this.count; final ReentrantLock takeLock = this.takeLock; takeLock.lockInterruptibly(); try &#123; //队列空了，阻塞当前线程 while (count.get() == 0) &#123; notEmpty.await(); &#125; x = dequeue(); c = count.getAndDecrement(); if (c &gt; 1) notEmpty.signal(); &#125; finally &#123; takeLock.unlock(); &#125; if (c == capacity) signalNotFull(); return x; &#125;//弹出链表中的第一个元素private E dequeue() &#123; // assert takeLock.isHeldByCurrentThread(); // assert head.item == null; Node&lt;E&gt; h = head; Node&lt;E&gt; first = h.next; h.next = h; // help GC head = first; E x = first.item; first.item = null; return x; &#125; 4、DelayQueueDelayQueue的泛型参数需要实现Delayed接口，Delayed接口继承了Comparable接口，DelayQueue内部使用非线程安全的优先队列（PriorityQueue），并使用Leader/Followers模式，最小化不必要的等待时间。DelayQueue不允许包含null元素。 Leader/Followers模式： 有若干个线程(一般组成线程池)用来处理大量的事 有一个线程作为领导者，等待事件的发生；其他的线程作为追随者，仅仅是睡眠。 假如有事件需要处理，领导者会从追随者中指定一个新的领导者，自己去处理事件。 唤醒的追随者作为新的领导者等待事件的发生。 处理事件的线程处理完毕以后，就会成为追随者的一员，直到被唤醒成为领导者。 假如需要处理的事件太多，而线程数量不够(能够动态创建线程处理另当别论)，则有的事件可能会得不到处理。 所有线程会有三种身份中的一种：leader和follower，以及一个干活中的状态：proccesser。它的基本原则就是，永远最多只有一个leader。而所有follower都在等待成为leader。线程池启动时会自动产生一个Leader负责等待网络IO事件，当有一个事件产生时，Leader线程首先通知一个Follower线程将其提拔为新的Leader，然后自己就去干活了，去处理这个网络事件，处理完毕后加入Follower线程等待队列，等待下次成为Leader。这种方法可以增强CPU高速缓存相似性，及消除动态内存分配和线程间的数据交换。 （1）参数以及构造方法 1234567891011121314151617// 可重入锁private final transient ReentrantLock lock = new ReentrantLock();// 存储队列元素的队列——优先队列private final PriorityQueue&lt;E&gt; q = new PriorityQueue&lt;E&gt;();//用于优化阻塞通知的线程元素leader，Leader/Followers模式private Thread leader = null;//用于实现阻塞和通知的Condition对象private final Condition available = lock.newCondition();public DelayQueue() &#123;&#125;public DelayQueue(Collection&lt;? extends E&gt; c) &#123; this.addAll(c);&#125; （2）offer()方法 123456789101112131415161718192021public boolean offer(E e) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; q.offer(e); // 如果原来队列为空，重置leader线程，通知available条件 if (q.peek() == e) &#123; leader = null; available.signal(); &#125; return true; &#125; finally &#123; lock.unlock(); &#125; &#125; //因为DelayQueue不限制长度，因此添加元素的时候不会因为队列已满产生阻塞，因此带有超时的offer方法的超时设置是不起作用的 public boolean offer(E e, long timeout, TimeUnit unit) &#123; // 和不带timeout的offer方法一样 return offer(e); &#125; 普通的poll()方法：如果延迟时间没有耗尽的话，直接返回null 12345678910111213public E poll() &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; E first = q.peek(); if (first == null || first.getDelay(TimeUnit.NANOSECONDS) &gt; 0) return null; else return q.poll(); &#125; finally &#123; lock.unlock(); &#125; &#125; take()方法： 1234567891011121314151617181920212223242526272829303132333435363738394041public E take() throws InterruptedException &#123; final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; for (;;) &#123; // 如果队列为空，需要等待available条件被通知 E first = q.peek(); if (first == null) available.await(); else &#123; long delay = first.getDelay(TimeUnit.NANOSECONDS); // 如果延迟时间已到，直接返回第一个元素 if (delay &lt;= 0) return q.poll(); // leader线程存在表示有其他线程在等待，那么当前线程肯定需要等待 else if (leader != null) available.await(); else &#123; Thread thisThread = Thread.currentThread(); leader = thisThread; // 如果没有leader线程，设置当前线程为leader线程 // 尝试等待直到延迟时间耗尽（可能提前返回，那么下次 // 循环会继续处理） try &#123; available.awaitNanos(delay); &#125; finally &#123; // 如果leader线程还是当前线程，重置它用于下一次循环。 // 等待available条件时，锁可能被其他线程占用从而导致 // leader线程被改变，所以要检查 if (leader == thisThread) leader = null; &#125; &#125; &#125; &#125; &#125; finally &#123; // 如果没有其他线程在等待，并且队列不为空，通知available条件 if (leader == null &amp;&amp; q.peek() != null) available.signal(); lock.unlock();&#125; 5、阻塞队列的应用阻塞队列更据不同的类型适用的场景很多，比如ArrayListBlockingQueue、LinkedBlockingQueue、SynchronousQueue可以作为线程池的任务队列（线程池的任务队列应该尽量使用有界队列）；还比如DelayQueue可以用于实现缓存系统设计和定时任务调度的场景…..；除过这些，还有其他生产者消费者的应用场景都可以使用合适的阻塞队列实现业务逻辑。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F24%2F%E9%AB%98%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8BCopyOnWriteArrayList%E2%80%94%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%2F</url>
    <content type="text"><![CDATA[高并发编程之CopyOnWriteArrayList—源码剖析CopyOnWriteArrayList是J.U.C包下的一个并发容器，它是线程安全且读操作无锁的ArrayList，写操作（增删改）则通过将底层数组拷贝一份，更改操作全部在新数组上进行，是一种读写分离的并发策略，我们也可以称这种容器为”写时复制器”，Java并发包中类似的容器还有CopyOnWriteArraySet。本文会对CopyOnWriteArrayList的实现原理及源码进行分析。 一、实现原理我们都知道，集合框架中的ArrayList是非线程安全的，Vector虽是线程安全的，但由于简单粗暴的锁同步机制，性能较差。而CopyOnWriteArrayList则提供了另一种不同的并发处理策略（当然是针对特定的并发场景）。 很多时候，我们的系统应对的都是读多写少的并发场景。CopyOnWriteArrayList容器允许并发读，读操作是无锁的，性能较高。至于写操作，比如向容器中添加一个元素，则首先将当前容器复制一份，然后在新副本上执行写操作，结束之后再将原容器的引用指向新容器。 1、关键属性和构造方法在jdk1.8中CopyOnWriteArraylist的底层数据结构还是数组，它使用ReentrarntLock来保证线程安全 1234567891011121314//在jdk1.8中使用ReentrantLock来保证线程安全，在jdk11使用的是synchronized final transient ReentrantLock lock = new ReentrantLock(); //底层数据结构是Object数组private transient volatile Object[] array;//默认无参构造方法，初始化了一个长度为0的Object数组public CopyOnWriteArrayList() &#123; setArray(new Object[0]); &#125; //可以传一个数组，注意到他没有直接使用我们传入的数组，而是copy了一份，这是为啥呢？public CopyOnWriteArrayList(E[] toCopyIn) &#123; setArray(Arrays.copyOf(toCopyIn, toCopyIn.length, Object[].class)); &#125; 2、添加元素—add()add()方法的逻辑非常简单，在添加元素之前先获取当前对象的锁，之后在原数组的基础上复制一个新数组并且长度+1，之后把新元素放入新增加的数组索引位置之后在把老数组的引用改为这个新数组的引用，解锁成功后就完成了添加元素的逻辑。 12345678910111213141516171819public boolean add(E e) &#123; //ReentrantLock加锁，保证线程安全 final ReentrantLock lock = this.lock; lock.lock(); try &#123; Object[] elements = getArray(); int len = elements.length; //拷贝原容器，长度为原容器长度加一 Object[] newElements = Arrays.copyOf(elements, len + 1); //在新副本上执行添加操作 newElements[len] = e; //将原容器引用指向新副本 setArray(newElements); return true; &#125; finally &#123; //解锁 lock.unlock(); &#125; &#125; 3、删除操作看了添加操作，再来看看删除操作，和add方法逻辑大致相同，都是需要先获取锁，如果移除的数据在数组末尾免责直接复制原数组的[0-array.length-1]即可;如果要删除的元素不在数组末尾，那就会先new一个是原数组长度-1的新数组，然后使用System.arrayCopy把原数组中除要删除元素之外的其他元元素复制过去。 1234567891011121314151617181920212223242526public E remove(int index) &#123; //加锁 final ReentrantLock lock = this.lock; lock.lock(); try &#123; Object[] elements = getArray(); int len = elements.length; E oldValue = get(elements, index); int numMoved = len - index - 1; if (numMoved == 0) //如果要删除的是列表末端数据，拷贝前len-1个数据到新副本上，再切换引用 setArray(Arrays.copyOf(elements, len - 1)); else &#123; //否则，将除要删除元素之外的其他元素拷贝到新副本中，并切换引用 Object[] newElements = new Object[len - 1]; System.arraycopy(elements, 0, newElements, 0, index); System.arraycopy(elements, index + 1, newElements, index, numMoved); setArray(newElements); &#125; return oldValue; &#125; finally &#123; //解锁 lock.unlock(); &#125; &#125; 4、获取元素—get()CopyOnWriteArrayList允许并发的读，就是因为他没有加任何锁，任何线程只要来了就会可以获取数据。为啥敢这么写呢？这是因为CopyOnWriteArrayList中的Object数组是被volatile保护着，volatile可以保证共享数据在多个线程之间的可见性，即任何线程去获取值都是最新的值。 1234567public E get(int index) &#123; return get(getArray(), index);&#125;private E get(Object[] a, int index) &#123; return (E) a[index];&#125; 二、总结—CopyOnWriteArrayList优缺点分析优点： 读操作性能很高，因为无需任何同步措施，比较适用于读多写少的并发场景。Java的list在遍历时，若中途有别的线程对list容器进行修改，则会抛出ConcurrentModificationException异常。而CopyOnWriteArrayList由于其”读写分离”的思想，遍历和修改操作分别作用在不同的list容器，所以在使用迭代器进行遍历时候，也就不会抛出ConcurrentModificationException异常了，这就是一种快速失败机制（并发容器几乎都是这种机制）。 缺点： 缺点也很明显，一是内存占用问题，毕竟每次执行写操作都要将原容器拷贝一份，数据量大时，对内存压力较大，可能会引起频繁GC；二是无法保证实时性，Vector对于读写操作均加锁同步，可以保证读和写的强一致性。而CopyOnWriteArrayList由于其实现策略的原因，写和读分别作用在新老不同容器上，在写操作执行过程中，读不会阻塞但读取到的却是老容器的数据。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F24%2F%E9%AB%98%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8BConcurrentLinkedQueue%E2%80%94%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%2F</url>
    <content type="text"><![CDATA[高并发编程之ConcurrentLinkedQueue—源码剖析一、ConcurrentLinkedQueue简介在Java开发个过程中我们不可避免的会使用到一些集合类，比如ArrayList、HashMap等，这些集合类型在多线程环境下使用会有线程安全问题。虽然不同的集合类型都有他的线程安全版本，比如ArrayList不是线程安全的，Vector是线程安全。而保障Vector线程安全的方式，是非常粗暴的在方法上用synchronized独占锁，将多线程执行变成串行化。要想将ArrayList变成线程安全的也可以使用Collections.synchronizedList(List list)方法ArrayList转换成线程安全的，但这种转换方式依然是通过synchronized修饰方法实现的，很显然这不是一种高效的方式，同时，队列也是我们常用的一种数据结构，为了解决线程安全的问题，Doug Lea大师为我们准备了ConcurrentLinkedQueue这个线程安全的队列。从类名就可以看的出来实现队列的数据结构是链式。 ConrrentLinkedQueue是一个单向链式结构的无界并发队列。它遵循队列的先进先出规则（FIFO），当我们添加一个元素的时候会添加到队列的尾部，当我们获取一个队列的时候会从队列头部获取。它采用CAS机制保证了对元素操作的线程安全性。 ConcurrentLinkedQueue适用于”单生产，多消费”的场景，同一时刻，允许两个线程（一个消费者一个或多个生产者）同时执行。 二、ConcurrentLinkedQueue的结构1、ConcurrentLinkedQueue的类图首先对ConcurrentLinkedQueue在类的继承关系上先有个整体认知： ConcurrentLinkedQueued由head结点和tail结点组成，每个节点（Node）由结点元素（item）和指向下一个结点（next）的引用组成，节点与节点之间通过next引用关联起来，从而组成了一张链表结构的队列。默认情况下head结点存储的元素内容为空，tail结点等于head节点（） 12345678//头节点private transient volatile Node&lt;E&gt; head;//尾结点private transient volatile Node&lt;E&gt; tail;//构造方法初始化的时候head=tail，并且节点的内容是空的public ConcurrentLinkedQueue() &#123; head = tail = new Node&lt;E&gt;(null);&#125; 2、内部类NodeNode中有两个属性：(1)元素item，类型有泛型参数决定；(2)下一个节点的引用next。值的注意的是，他们都被volatile修饰了，这可以保证在多线程环境下的内存可见性。另外在Node的构造参数中我们可以看到，它调用了Umsafe类中的本地方法，这进一步保证了线程安全性。 12345678910111213private static class Node&lt;E&gt; &#123; volatile E item; volatile Node&lt;E&gt; next; /** * Constructs a new node. Uses relaxed write because item can * only be seen after publication via casNext. */ Node(E item) &#123; UNSAFE.putObject(this, itemOffset, item); &#125; ......&#125; 3、操作Node的几个CAS操作在队列进行出队入队的时候免不了对节点需要进行操作，在多线程就很容易出现线程安全的问题。可以看出在处理器指令集能够支持CMPXCHG指令后，在java源码中涉及到并发处理都会使用CAS操作，那么在ConcurrentLinkedQueue对Node的CAS操作有这样几个： 1234567891011121314//使用CAS更新节点中item域 boolean casItem(E cmp, E val) &#123; return UNSAFE.compareAndSwapObject(this, itemOffset, cmp, val);&#125; //懒惰设置next指向 void lazySetNext(Node&lt;E&gt; val) &#123; UNSAFE.putOrderedObject(this, nextOffset, val); &#125; //使用CAS更新节点的next指向 boolean casNext(Node&lt;E&gt; cmp, Node&lt;E&gt; val) &#123; return UNSAFE.compareAndSwapObject(this, nextOffset, cmp, val);&#125; 上面这些方法，底层实际调用了Unsafe类的相关本地方法来实现的，具体的方法实现需要惨嚎hostpot源码了，所以就先看到这里了，目前为止我们需要知道：ConcurrentLinkedQueue是通过CAS+volatile来保证ConcurrentLinkedQueue的线程安全性的即可。 三、入队操作—offer()入队操作就是将节点添加到队列的尾部的过程。让我们通过每个节点入队的快照来观察下tail节点的变化： 入队主要就干两件事： （1）新建一个节点，并将新节点设置为当前队列尾部节点的下一个节点； （2）更新tail节点，如果tail节点的next节点不为空，则将入队节点设置为tail节点，如果tail节点的next节点为空，则将入队的结点设置为tail节点的next节点。 不过我们需要注意的是：ConcurrentLinkedQueue当前的tail不一定指向队列真正的尾节点，因为在ConcurrentLinkedQueue中tail是被延迟更新的 123456789101112131415161718192021222324252627public boolean offer(E e) &#123; checkNotNull(e); //入队前，先创建一个入队节点 final Node&lt;E&gt; newNode = new Node&lt;E&gt;(e); //死循环不断重试 for (Node&lt;E&gt; t = tail, p = t;;) &#123; //创建一个指向tail的节点引用t和p Node&lt;E&gt; q = p.next; //如果当前tail就是正真的尾结点，那就使用CAS尝试把新节点设置为tail的next并且把用CAS把tail更新 if (q == null) &#123; // CAS更新next指向 if (p.casNext(null, newNode)) &#123; if (p != t) // hop two nodes at a time //CAS更新tail,允许失败 casTail(t, newNode); // Failure is OK. return true; &#125; &#125; else if (p == q) //寻找正真的tail p = (t != (t = tail)) ? t : head; else //寻找正真的tail p = (p != t &amp;&amp; t != (t = tail)) ? t : q; &#125; &#125; 从源码角度来看，整个入队过程主要做两件事：第一是定位出尾结点；第二是使用CAS算法将入队节点设置为尾结点的后继结点，如果不成功则重试。 四、出队操作—poll()出队列的就是从队列里返回一个节点元素，并清空该节点对元素的引用。让我们通过每个节点出队的快照来观察下head节点的变化： 从图中可知，并不是每次出队的时候都会更新head节点，当head结点里有元素（item!=null）的时候，直接弹出head结点中的元素，而不会更新head节点。只有当head节点里没有元素的时候，出队操作才会更新head节点。这种做法可以减少使用CAS更新head节点带来的消耗，从而提高效率。 123456789101112131415161718192021222324252627public E poll() &#123; restartFromHead: for (;;) &#123; //p节点就是首节点，也即需要出队的结点 for (Node&lt;E&gt; h = head, p = h, q;;) &#123; E item = p.item; //如果节点的的元素不为null,则使用CAS尝试把结点的内容更新为null,表示出队 if (item != null &amp;&amp; p.casItem(item, null)) &#123; //元素出队成功，更新head节点 if (p != h) // hop two nodes at a time updateHead(h, ((q = p.next) != null) ? q : p); return item; &#125; // 如果头节点的元素为空或头节点发生了变化，这说明头节点已经被另外一个线程修改了。 // 那么获取p节点的下一个节点，如果p节点的下一节点为null，则表明队列已经空了 else if ((q = p.next) == null) &#123; updateHead(h, p); return null; &#125; // p == q，则使用新的head重新开始 else if (p == q) continue restartFromHead; else p = q; &#125; &#125;&#125; 头节点的元素，首先判断头节点元素是否为空，如果为空，表示另外一个线程已经进行了一次出队操作将该节点的元素取走，如果不为空，则使用CAS的方式将头节点的引用设置成null，如果CAS成功，则直接返回头节点的元素，如果不成功，表示另外一个线程已经进行了一次出队操作更新了head节点，导致元素发生了变化，需要重新获取头节点。 五、HOPS设计通过上面对offer和poll方法的分析，我们发现tail和head是延迟更新的，两者更新触发时机为： tail节点的更新触发时机：当tail结点的next节点不为空的时候，会执行定位队列真正的队尾节点的操作，找到队尾节点后完成插入之后才会通过casTail进行tail更新；当tail指向的节点的下一个节点为null的时候，只插入节点不更新tail。 head节点的更新触发时机：当head结点的item=null的时候，将会执行定位头结点的操作，定位到头结点头使用CAS完成对头节点的删除，并且通过updateHead进行head更新；当head指向的节点的item域不为null的时候，只删除节点不更新head。 如果让tail永远作为队列的队尾节点，实现的代码量会更少，而且逻辑更易懂。但是，这样做有一个缺点，如果大量的入队操作，每次都要执行CAS进行tail的更新，汇总起来对性能也会是大大的损耗。如果能减少CAS更新的操作，无疑可以大大提升入队的操作效率，所以doug lea大师每间隔1次（tail和队尾节点的距离为1）进行才利用CAS更新tail。 对head的更新也是同样的道理，虽然，这样设计会多出在循环中定位队尾节点，但总体来说读的操作效率要远远高于写的性能，因此，多出来的在循环中定位尾节点的操作的性能损耗相对而言是很小的。 六 、ConcurrentLinkedDeque在J.U.C包下还有一个非阻塞队列的实现就是ConcurrentLinkedDeque，它和ConcurrentLinkedQueue保证线程安全的机制是一样的，都采用CAS+volatile来实现。但是他与ConcurrentLinkedQueue的区别如下： ConcurrentLinkedQueue **是单向链表结构的无界并发队列**。元素操作按照 FIFO (first-in-first-out 先入先出) 的顺序。适合“单生产，多消费”的场景。 ConcurrentLinkedDeque **是双向链表结构的无界并发队列。与 ConcurrentLinkedQueue 的区别是该队列同时支持FIFO和FILO**两种操作方式，即可以从队列的头和尾同时操作(插入/删除)。适合“多生产，多消费”的场景。 ConcurrentLinkedDeque的Node中不仅有next引用指向下一个节点，还有一个prev引用指向前一个节点（和AQS的结构类似）。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F24%2F%E9%AB%98%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B%E4%B9%8BCnocurrentHashMap%E2%80%94%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%2F</url>
    <content type="text"><![CDATA[高并发编程之CnocurrentHashMap—源码剖析HashMap在多线程环境下有线程安全问题，因此在多线程环境下不要直接使用HashMap，而是使用下面几种不同的方式去代替： （1）使用ConcurrentHashMap （2）使用Hashtable （3）使用Collections.synchronizedMap(Map map)方法将HashMap包装成一个线程安全的集合 不过鉴于要保证多线程环境下程序的并发度，后两种方案直接Pass，因为他们保证线程安全的机制是synchronized，在并发很高的环境下效率很低，此时我们就可以使用ConcurrentHashMap。 一、jdk1.7的实现以及源码分析1、 ConcurrentHashMap的数据结构jdk1.7 的ConcurrentHashMap的底层数据结构是数组+链表，如下图所示 **ConcurrentHashMap是由Segment数组结构和HashEetry数组组成**。 Segment继承了ReentrantLock，是一个可重入的锁，它在ConcurretnHashMap中扮演锁的角色； HashEntry则用于存储键值对。它们之间的关系是：一个ConcurrentHashMap包含了一个Segment数组，一个Segment里维护了一个HashEntry数组，HashEntry数组和HashMap结构类似，是一种数组+链表的结构，当一个线程需要对HashEntry中的元素修改的时候，必须先获得Segment锁，下面是ConcutrrentHashMap的类图（借用网上的一张图）： 2、Segment内部类首先先来熟悉一下Segment，Segment是ConcurrentHashMap的内部类，它在ConcurrentMap就是扮演锁的角色，主要组成如下： 123456789101112131415161718192021static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123; private static final long serialVersionUID = 2249069246763182397L; // 和 HashMap 中的 HashEntry 作用一样，真正存放key-value的bucket transient volatile HashEntry&lt;K,V&gt;[] table; transient volatile int count; // 记得快速失败（fail—fast）么？ transient int modCount; // 大小 transient int threshold; // 负载因子 final float loadFactor; //构造方法 Segment(float lf, int threshold, HashEntry&lt;K,V&gt;[] tab) &#123; this.loadFactor = lf; this.threshold = threshold; this.table = tab; &#125; &#125; HashEntry是一个和HashMap类似的数据结构，这里值的注意的是他被volatile修饰了。这里复习一下volatile的特性： （1）可以保证共享变量在多线程之间的可见性，即一个线程修改了共享变量的值对于其他线程是这个修改后的是可见的； （2）可以禁止指令重排序； （3）volatile可以保证对单次读写操作的原子性； 3、ConcurrentHashMap的构造方法ConcurrentHashMap的构造方法中通过initialCapacity、loadFactor、concurrencyLevel三个参数完成了对Segment数组、段偏移量segmentShift、段掩码segmentMask和每一个Segment里的HashEntry数组的初始化。我们来看看源码是如何实现的： 12345678910111213141516171819202122232425262728293031public ConcurrentHashMap(int initialCapacity, //初始容量 默认是16 float loadFactor, //加载因子 默认0.75 int concurrencyLevel) &#123; //并发度 由DEFAULT_CONCURRENCY_LEVEL 决定 if (!(loadFactor &gt; 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); if (concurrencyLevel &gt; MAX_SEGMENTS) concurrencyLevel = MAX_SEGMENTS; // Find power-of-two sizes best matching arguments int sshift = 0; //计算ssize左移的次数 int ssize = 1; //计算segment的大小 while (ssize &lt; concurrencyLevel) &#123;//segment的大小为2^n ++sshift; ssize &lt;&lt;= 1; &#125; this.segmentShift = 32 - sshift; this.segmentMask = ssize - 1; if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; int c = initialCapacity / ssize;//计算每个segment的大小 if (c * ssize &lt; initialCapacity)//若是条件成立，表示c有余数，所以增加一个segment ++c; int cap = MIN_SEGMENT_TABLE_CAPACITY; while (cap &lt; c) cap &lt;&lt;= 1; Segment&lt;K,V&gt; s0 = new Segment&lt;K,V&gt;(loadFactor, (int)(cap * loadFactor), (HashEntry&lt;K,V&gt;[])new HashEntry[cap]); Segment&lt;K,V&gt;[] ss = (Segment&lt;K,V&gt;[])new Segment[ssize]; UNSAFE.putOrderedObject(ss, SBASE, s0); // ordered write of segments[0] this.segments = ss; &#125; 我们来捋捋构造方法： 首先了解几个常量： 1234567static final int DEFAULT_CONCURRENCY_LEVEL = 16; //初始的并发等级，通过并发等级来确定Segment的大小static final int MIN_SEGMENT_TABLE_CAPACITY = 2;// segment的最小值.2 static final int MAX_SEGMENTS = 1 &lt;&lt; 16; //segment数组最大长度，65535private static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; //每个HashEnty数组的最大长度 2^30 初始化Segment数组123456789101112131415if (!(loadFactor &gt; 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); if (concurrencyLevel &gt; MAX_SEGMENTS) concurrencyLevel = MAX_SEGMENTS; //Segment数组的大小必须是2的幂，比兔2，4，8.... int sshift = 0; //计算ssize左移的次数 int ssize = 1; //计算segment的大小 while (ssize &lt; concurrencyLevel) &#123;//segment的大小为2^n ++sshift; //sshift ssize &lt;&lt;= 1; &#125; //segmentShift默认值32-4=28 this.segmentShift = 32 - sshift; //segmentMask默认值是 15 即 0000 0000 0000 1111 this.segmentMask = ssize - 1; 由上面的代码可以知道，Segment数组的长度是ssize,这个参数又是通过concurrencyLevel计算出来的。我了通过按位与的散列算法来定位segment数组索引，必须保证segment数组的长度是2的幂，所以必须计算出一个大于等于concurrencyLevel的最小2个幂大小的数组长度。同时concurrencyLevel最大值是2^16,即65535个，这意味着Segment数组的大小最大也是65535。 初始化segmentShift和segmentMask这两个变量狮是在定位segment是的散列算法中用的，segmentShift用于定位参与散列计算的位数，segmentShift=32-sshift，其中sshift等于ssize从1向左移的次数，在默认情况下concurrencyLevel是16，因此ssize=16,sshift=4。，所以默认情况下是28。 segmentMask是散列运算的掩码，等于ssize-1，默认是15，掩码的二进制的各个位一般都是1.因为ssize的最大长度是65536，所以segmentShift的最大值是16，segmentMask的最大值是65536. 初始化Segment123456789101112131415161718if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY;int c = initialCapacity / ssize;//计算每个segment的大小if (c * ssize &lt; initialCapacity)//若是条件成立，表示c有余数，所以增加一个segment ++c;int cap = MIN_SEGMENT_TABLE_CAPACITY; //cap=2 while (cap &lt; c) cap &lt;&lt;= 1;//创建一个segment,并且放在 segment[ 0]Segment&lt;K,V&gt; s0 = new Segment&lt;K,V&gt;(loadFactor, (int)(cap * loadFactor), (HashEntry&lt;K,V&gt;[])new HashEntry[cap]);//创建Segment数组 大小是ssizeSegment&lt;K,V&gt;[] ss = (Segment&lt;K,V&gt;[])new Segment[ssize];//使用CAS初始化Segment数组的第一个元素segment[0]UNSAFE.putOrderedObject(ss, SBASE, s0);//Segment[] segments=ss;this.segments = ss; 上面代码中cap的值就是每个HashEntry数组的初始长度，他等于initialCapacity/ssize的倍数，如果有余数在+1。如果c大于1，就会取待遇等于c的2的幂的值，所以c只可能是1或者是2^n。 4、定位SegmentConcurrentHashMap使用了分段锁Segment来维护不同段的数据，那么在插入和获取元素的时候，必须先通过算法定位到Segment上之后才可以在具体的HashEntry用类似HashMap找元素的方法来定位一个元素。首先来看看ConcurretnHashMap使用的hash算法： 12345678private static int hash(int h)&#123; h+=(h&lt;&lt;15)^0xffffcd7d; h^=(h&gt;&gt;&gt;10); h+=(h&lt;&lt;3); h^=(h&gt;&gt;&gt;6); h+=(h&lt;&lt;2)+(h&lt;&lt;14); return h^(h&gt;&gt;&gt;16);&#125; 通过这个hash算法对hashCode在散列，目的是减少hash冲突，是元素可以均匀的分布在egment数组内，提高容器的使用率。基于这个hash(int h)计算出来的hash值，Segment通过下面这个算法定位到具体的Segment: 123final Segment&lt;K,V&gt; segmentFor(int h)&#123; return segments[(hash&gt;&gt;&gt;segmentShift)&amp;segmentMask];&#125; 默认情况下，segmentShift是28，segmentMask是15，因此hash&gt;&gt;&gt;segmentShift的意思就是让hash值的高4位参与到定位Sengmet运算中，上面说到过，segmentMask是散列运算的掩码，它等于ssize-1，ssize又是一个2的幂的数，因此segmentMask二进制的低位是连续的1，那么最终决定Segment位置索引的就是hash&gt;&gt;&gt;segmentShift的值。 5、put()操作put操作需要在定位到Segment之后，对Segment加锁。 如果value==null，空指针异常； 如果value不是null 首先，计算hash(key)，最终的hash值是hashCode(key) ^ hashSeed之后，再经过各种位操作之后的值 然后，通过（hash&gt;&gt;&gt;segmentShift）&amp; segmentMark算法得到Segment[]的下标 构造器中只初始化了Segment[]下标0处的Segment对象，在put时，确定了Segment的位置，先判断该位置上的Segment有没有初始化，没有，先初始化 最后，调用Segment对象的put方法存入键值对。 对每个Segment加锁 确定HashEntry[]的下标。index = (tab.length - 1) &amp; hash; 如果当前HashEntry没有初始化，先初始化，并将键值对插入 已经初始化，遍历HashEntry链，有重复的，新值覆盖旧值，否则，插入 插入之前，判断是否需要扩容，扩容：Segment[]是不能扩容的，只能扩容一个个Segment中的HashEntry[]的大小为原来的两倍 下面结合源码和注释来说明： 123456789101112131415public V put(K key, V value) &#123; //找到对应的segment,把key，value放入对应的segment中 Segment&lt;K,V&gt; s; //value不允许为null if (value == null) throw new NullPointerException(); int hash = hash(key); //定位Segment：(hash&gt;&gt;&gt;sengmentShift)&amp; segmentmask int j = (hash &gt;&gt;&gt; segmentShift) &amp; segmentMask; if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObject(segments, (j &lt;&lt; SSHIFT) + SBASE)) == null) //由于Segment数组在初始化的时候只初始化了segments[0]这个槽位， //在插入的时候首先需要初始化segments[j] s = ensureSegment(j); return s.put(key, hash, value, false);&#125; Segment内部的put()方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263final V put(K key, int hash, V value, boolean onlyIfAbsent) &#123; //每个segment进行put操作的时候都要进行加锁操作 tryLock()方法尝试获取锁 HashEntry&lt;K,V&gt; node = tryLock() ? null : //尝试获取锁失败，计进入 scanAndLockForPut流程，循环尝试获取锁 scanAndLockForPut(key, hash, value); //执行到这里，Segment就已经加上锁了，可以安全执行了 V oldValue; try &#123; //每个Segment中维护了一个HashEntry数组叫table HashEntry&lt;K,V&gt;[] tab = table; //定位HashEntry： hash&amp;(tab.lenght-1) int index = (tab.length - 1) &amp; hash; //找到HashEntry数组中table[index]元素（链表头结点） HashEntry&lt;K,V&gt; first = entryAt(tab, index); //遍历链表 for (HashEntry&lt;K,V&gt; e = first;;) &#123; //e就是每个从链表中取出的结点 if (e != null) &#123; //更新key-value K k; //hash值相等 并且equals方法返回true就说明这是要找的key if ((k = e.key) == key || (e.hash == hash &amp;&amp; key.equals(k))) &#123; oldValue = e.value; if (!onlyIfAbsent) &#123; //替换新值 e.value = value; ++modCount; &#125; //修改成功，退出循环 break; &#125; e = e.next; &#125; else &#123; //新增key-value if (node != null) //1)之前等待锁的时候，如果新的链表接待被创建了，那就把值设置进去，并把此结点的next指向当前链表的头结点 node.setNext(first); else //2)如果显得结点还没创建，那就直接new一个 node = new HashEntry&lt;K,V&gt;(hash, key, value, first); //c就是当前HashEntry的元素多少 size int c = count + 1; //如果错过了阈值并且当前HashEntry的长度小于最大允许长度2^30就会扩容 if (c &gt; threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY) rehash(node); else //如果没有超过阈值，那就把新新节点插入链表头部 setEntryAt(tab, index, node); ++modCount; count = c; oldValue = null; //添加成功，退出循环 break; &#125; &#125; &#125; finally &#123; unlock(); &#125; return oldValue; &#125; 获取写入锁： 前面我们看到，在往某个 segment 中 put 的时候，首先会调用 node = tryLock() ? null : scanAndLockForPut(key, hash, value)，也就是说先进行一次 tryLock() 快速获取该 segment 的独占锁，如果失败，那么进入到 scanAndLockForPut 这个方法来获取锁。 下面我们来具体分析这个方法中是怎么控制加锁的。 123456789101112131415161718192021222324252627282930313233343536373839private HashEntry&lt;K,V&gt; scanAndLockForPut(K key, int hash, V value) &#123; HashEntry&lt;K,V&gt; first = entryForHash(this, hash); HashEntry&lt;K,V&gt; e = first; HashEntry&lt;K,V&gt; node = null; int retries = -1; // negative while locating node // 循环获取锁 while (!tryLock()) &#123; HashEntry&lt;K,V&gt; f; // to recheck first below if (retries &lt; 0) &#123; if (e == null) &#123; if (node == null) // speculatively create node // 进到这里说明数组该位置的链表是空的，没有任何元素 // 当然，进到这里的另一个原因是 tryLock() 失败，所以该槽存在并发，不一定是该位置 node = new HashEntry&lt;K,V&gt;(hash, key, value, null); retries = 0; &#125; else if (key.equals(e.key)) retries = 0; else // 顺着链表往下走 e = e.next; &#125; // 重试次数如果超过 MAX_SCAN_RETRIES（单核1多核64），那么不抢了，进入到阻塞队列等待锁 // lock() 是阻塞方法，直到获取锁后返回 else if (++retries &gt; MAX_SCAN_RETRIES) &#123; lock(); break; &#125; else if ((retries &amp; 1) == 0 &amp;&amp; // 这个时候是有大问题了，那就是有新的元素进到了链表，成为了新的表头 // 所以这边的策略是，相当于重新走一遍这个 scanAndLockForPut 方法 (f = entryForHash(this, hash)) != first) &#123; e = first = f; // re-traverse if entry changed retries = -1; &#125; &#125; return node;&#125; 这个方法有两个出口，一个是 tryLock() 成功了，循环终止，另一个就是重试次数超过了 MAX_SCAN_RETRIES，进到 lock() 方法，此方法会阻塞等待，直到成功拿到独占锁。 这个方法就是看似复杂，但是其实就是做了一件事，那就是获取该 segment 的独占锁，如果需要的话顺便实例化了一下 node。 6、rehash()扩容操作Segment数组的长度一旦确定就不能改变，当一个Segment数组在插入新元素之前会先判断是否超过阈值，如果超阈值了，就会扩容，并且只是扩容当前Segment中的HashEntry[]。总的来说，Segment对扩容时机的判断比HashMap更恰当，因为HashMap的扩容是在元素添加会后判断的，如果超过阈值就会扩容，但是很有可能扩容之后就没有新元素插入了，这时HashMap就进行了一次无效的扩容。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061private void rehash(HashEntry&lt;K,V&gt; node) &#123; //因为rehash()操作是被put()调用的，pput()已经获取过锁了，这里就不需要再获取锁了 HashEntry&lt;K,V&gt;[] oldTable = table; //获取旧表的容量 int oldCapacity = oldTable.length; //新表对容量*2 int newCapacity = oldCapacity &lt;&lt; 1; //计算新的阈值 threshold = (int)(newCapacity * loadFactor); //创建新的HashEntry数组，大小是旧数组的2倍 HashEntry&lt;K,V&gt;[] newTable = (HashEntry&lt;K,V&gt;[]) new HashEntry[newCapacity]; int sizeMask = newCapacity - 1; //遍历旧的HashEntry数组 把其中的元素移动到新的HashEntry数组中 for (int i = 0; i &lt; oldCapacity ; i++) &#123; //HashEntry数组索引为i的槽位的值 HashEntry&lt;K,V&gt; e = oldTable[i]; //HashEntry数组索引为i的槽位的值如果不为空就搬移 if (e != null) &#123; //尝试获取链表头结点的下一个结点 HashEntry&lt;K,V&gt; next = e.next; int idx = e.hash &amp; sizeMask; if (next == null) // Single node on list //该槽位只有一个节点，直接搬移过去 newTable[idx] = e; else &#123; // Reuse consecutive sequence at same slot //链表上有多个结点 HashEntry&lt;K,V&gt; lastRun = e; int lastIdx = idx; //由于扩容之后有些key的索引就会改变，需要找到key发生变化的结点和新索引 for (HashEntry&lt;K,V&gt; last = next; last != null; last = last.next) &#123; int k = last.hash &amp; sizeMask; if (k != lastIdx) &#123; //新索引 lastIdx = k; //节点 lastRun = last; &#125; &#125; newTable[lastIdx] = lastRun; // Clone remaining nodes for (HashEntry&lt;K,V&gt; p = e; p != lastRun; p = p.next) &#123; V v = p.value; int h = p.hash; int k = h &amp; sizeMask; HashEntry&lt;K,V&gt; n = newTable[k]; newTable[k] = new HashEntry&lt;K,V&gt;(h, p.key, v, n); &#125; &#125; &#125; &#125; //扩容完成后插入新的结点 int nodeIndex = node.hash &amp; sizeMask; // add the new node //设置新节点为头结点 node.setNext(newTable[nodeIndex]); newTable[nodeIndex] = node; //更新table table = newTable; &#125; 7、get操作Segment的get操作实现非常简单和高效。先经过一次hash()，然后使用散列值运算定位到Segment，在定位到聚义的元素的过程。 get操作的高效是因为整个get操作不需要加锁，为什么他不需要加锁呢？是因为get方法中使用的共享变量都被定义成了volatile类型，比如：统计当前Segment大小的count，和用于存储key-value的HashEntry。定义成volatile的变量能够在多个先后餐呢个之间保证可见性，如果与多个线程读，它读取到的值一定是当前这个变量的最新值。 123456789101112131415161718192021222324public V get(Object key) &#123; Segment&lt;K,V&gt; s; // manually integrate access methods to reduce overhead HashEntry&lt;K,V&gt;[] tab; //计算key的hash值 int h = hash(key); //u为segment对象在数组中的偏移量 long u = (((h &gt;&gt;&gt; segmentShift) &amp; segmentMask) &lt;&lt; SSHIFT) + SBASE; //s就是segment对象 if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(segments, u)) != null &amp;&amp; (tab = s.table) != null) &#123; //((long)(((tab.length - 1) &amp; h)) &lt;&lt; TSHIFT) + TBASE是目标key的槽位在HashEntry的偏移量 //下面的for循环就是遍历链表的 for (HashEntry&lt;K,V&gt; e = (HashEntry&lt;K,V&gt;) UNSAFE.getObjectVolatile (tab, ((long)(((tab.length - 1) &amp; h)) &lt;&lt; TSHIFT) + TBASE); e != null; e = e.next) &#123; K k; if ((k = e.key) == key || (e.hash == h &amp;&amp; key.equals(k))) //找到目标值返回 return e.value; &#125; &#125; //没找到返回null return null; &#125; 8、size操作size()就是求当前ConcurrentHashMap中元素个数的方法，它是弱一致性的。方法的逻辑大致是：首先他会使用不加锁的模式去尝试多次计算 ConcurrentHashMap 的 size，最多三次，比较前后两次计算的结果，结果一致就认为当前没有元素加入或删除，计算的结果是准确的，然后返回此结果；如果尝试了，他就会给每个 Segment 加上锁，然后计算 ConcurrentHashMap 的 size 返回。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public int size() &#123; final Segment&lt;K,V&gt;[] segments = this.segments; //ConcurrentHashMap大小 int size; boolean overflow; // true if size overflows 32 bits //当前size最新统计的size大小 long sum; // sum of modCounts //前一次的size大小 long last = 0L; // previous sum //重试的次数 int retries = -1; // first iteration isn't retry try &#123; for (;;) &#123; //操作次数，加锁 if (retries++ == RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) //ensureSegment方法确保Segment是被初始化了的 ensureSegment(j).lock(); // force creation &#125; sum = 0L; size = 0; overflow = false; //遍历所有Segment，把所有Segment中的元素个数相加==&gt;这个值在modCount中 for (int j = 0; j &lt; segments.length; ++j) &#123; Segment&lt;K,V&gt; seg = segmentAt(segments, j); if (seg != null) &#123; sum += seg.modCount; int c = seg.count; if (c &lt; 0 || (size += c) &lt; 0) overflow = true; &#125; &#125; if (sum == last) break; last = sum; &#125; &#125; finally &#123; //结束后如果尝试的次数大于RETRIES_BEFORE_LOCK就说明加锁了，在这里需要把每个Segment解锁 if (retries &gt; RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) segmentAt(segments, j).unlock(); &#125; &#125; //返回结果 return overflow ? Integer.MAX_VALUE : size;&#125; 二、jdk1.8的实现以及源码分析1、ConcurrentHashMap的数据结构JDK1.8的实现已经摒弃了Segment的概念，而是直接使用 数组+链表+红黑树 的数据结构来实现的，并发控制使用的是CAS+synchronized,jdk1.8版本的ConcurrentHashMap看起来就像是优化过之后线程安全的HashMap,虽然在JDK1.8中还能看到Segment，但是已经简化了属性，只是为了兼容旧版本。 2、重要的属性和内部类1234567//默认为0，当初始化或它表示即将创建的哈希表的大小，//当扩容完成后表示下一次哈希表扩容的阈值private transient volatile int sizeCtl; // hash表transient volatile Node&lt;K,V&gt;[] table; //扩容时的新hash表private transient volatile Node&lt;K,V&gt;[] nextTable; 内部类Node12345678910111213static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; volatile V val; volatile Node&lt;K,V&gt; next; Node(int hash, K key, V val, Node&lt;K,V&gt; next) &#123; this.hash = hash; this.key = key; this.val = val; this.next = next; &#125; &#125; 这个Node和jdk1.8中HashMap的Node是一样的。jdk1.8中的ConcurrentHashMap保证线程安全使用的是CAS+synchronized。 内部类ForwardingNode扩容时如果某个链表转移完毕，就会用ForwardingNode作为旧哈希表这个槽位的头结点，下面是他的属性和构造方法： 1234567891011/** * A node inserted at head of bins during transfer operations. */ static final class ForwardingNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; final Node&lt;K,V&gt;[] nextTable; ForwardingNode(Node&lt;K,V&gt;[] tab) &#123; super(MOVED, null, null, null); this.nextTable = tab; &#125; &#125; 内部类ReservationNode用在compute以及cpmouteIfAbsent时用来占位，计算完成后替换为普通Node结点 123456789101112/** * A place-holder node used in computeIfAbsent and compute */ static final class ReservationNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; ReservationNode() &#123; super(RESERVED, null, null, null); &#125; Node&lt;K,V&gt; find(int h, Object k) &#123; return null; &#125; &#125; 内部类 TreeBin红黑树的头结点，存储root和first结点 12345678910static final class TreeBin&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; root; volatile TreeNode&lt;K,V&gt; first; volatile Thread waiter; volatile int lockState; // values for lockState static final int WRITER = 1; // set while holding write lock static final int WAITER = 2; // set when waiting for write lock static final int READER = 4; // increment value for setting read lock&#125; 内部类 TreeNode红黑树的结点，存储关于它的parent、left、right结点 12345678910111213141516/** * Nodes for use in TreeBins */ static final class TreeNode&lt;K,V&gt; extends Node&lt;K,V&gt; &#123; TreeNode&lt;K,V&gt; parent; // red-black tree links TreeNode&lt;K,V&gt; left; TreeNode&lt;K,V&gt; right; TreeNode&lt;K,V&gt; prev; // needed to unlink next upon deletion boolean red; TreeNode(int hash, K key, V val, Node&lt;K,V&gt; next, TreeNode&lt;K,V&gt; parent) &#123; super(hash, key, val, next); this.parent = parent; &#125; &#125; 3、ConcurrentHashMap的构造方法jdk1.8中的ConcurrentHashMap是懒惰初始化的，在构造方法中只是计算了一下哈希表的大小，只有在第一次使用到的时候才会真正创建。 12345678910111213public ConcurrentHashMap(int initialCapacity, float loadFactor, int concurrencyLevel) &#123; if (!(loadFactor &gt; 0.0f) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); if (initialCapacity &lt; concurrencyLevel) // Use at least as many bins initialCapacity = concurrencyLevel; // as estimated threads long size = (long)(1.0 + (long)initialCapacity / loadFactor); //tableSizeFor方法保证哈希表的大小是2的幂 int cap = (size &gt;= (long)MAXIMUM_CAPACITY) ? MAXIMUM_CAPACITY : tableSizeFor((int)size); //把哈希表的大小赋给成员变量sizeCtl this.sizeCtl = cap; &#125; 4、添加元素操作—put()首先我们通过源码看到，jdk1.8中ConcurrentHashMap不允许key或value为null，如果你违反了就会报NPE。 之后调用spread方法使得key的hash码更散列。 在之后会首先判断当前hash表时候被初始化了，因为jdk1.8中ConcurrentHashMap是懒惰初始化的，只有这个爱第一次使用的时候才会初始化。 如果哈希表已经初始化了，然后计算key的桶的位置，如果在这个位置还是null，那就直接把元素放到桶的这个位置即可； 在之后会判断当前hash表是否在扩容中，如果没有： 首先对链表的头结点/红黑树的root结点上锁 如果key的桶的位置还是链表，那就在链表的尾部插入新的元素，再次过程中还会统计链表的结点个数，存储在modCount中，用于在插入之后判断是否需要扩容 如果key的桶的位置已经是红黑树了，那就把新的元素插入红黑树中 插入完毕之后会判断modCount的值是否已经大于等于树化阈值（8）了，如果是，那就把链表转换为红黑树 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687public V put(K key, V value) &#123; return putVal(key, value, false); &#125;/** Implementation for put and putIfAbsent */ final V putVal(K key, V value, boolean onlyIfAbsent) &#123; //ConcurrentHashMap不允许key-value为null if (key == null || value == null) throw new NullPointerException(); //是的hash值更分布 int hash = spread(key.hashCode()); int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; //判断hash表是否存在 if (tab == null || (n = tab.length) == 0) //创建hash表，initTable方法使用CAS初始化hash表 tab = initTable(); //i=(n-1)&amp;hash 计算出桶的位置，如果在这个桶中还没有元素就直接把新元素放入桶中 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; //添加元素使用了CAS，比synchronized性能高 if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; //如果这个条件成立，说明当前hash表在扩容过程中，判断的依据是看桶的头结点是否是ForwardingNode else if ((fh = f.hash) == MOVED) //其他线程过来帮忙扩容 tab = helpTransfer(tab, f); else &#123; //如果这个条件成立，说明当前hash表存在、(n-1)&amp;hash 位子有元素了并且没有在扩容 V oldVal = null; //对（n-1）&amp;hash位置链表的头结点加锁 synchronized (f) &#123; //再次确认链表的头结点有没有被移动 if (tabAt(tab, i) == f) &#123; if (fh &gt;= 0) &#123; //槽位中的元素还是链表 binCount = 1; //使用binCount统计当前桶中的元素个数 for (Node&lt;K,V&gt; e = f;; ++binCount) &#123; K ek; //遍历链表，发现相同的key if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; //更新旧值 if (!onlyIfAbsent) e.val = value; //更新完毕之后直接退出 break; &#125; Node&lt;K,V&gt; pred = e; if ((e = e.next) == null) &#123; //这里就是新元素插入的逻辑了，可以看到还是使用了尾插法 pred.next = new Node&lt;K,V&gt;(hash, key, value, null); break; &#125; &#125; &#125; else if (f instanceof TreeBin) &#123; //槽位中的元素已经构成了红黑树了，那就把元素加入到红黑树中 Node&lt;K,V&gt; p; binCount = 2; if ((p = ((TreeBin&lt;K,V&gt;)f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) p.val = value; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; //如果桶中元素个数大于等于树化阈值（8）就将链表转化为红黑树 if (binCount &gt;= TREEIFY_THRESHOLD) //转化为红黑树的逻辑 treeifyBin(tab, i); if (oldVal != null) return oldVal; break; &#125; &#125; &#125; addCount(1L, binCount); return null; &#125; 5、初始化哈希表—initTable()在put过程中如果是第一次put，此时hash表还没有初始化，因此需要首先初始化哈希表。 我们一起来看看hash表的初始化逻辑吧！ 123456789101112131415161718192021222324252627282930private final Node&lt;K,V&gt;[] initTable() &#123; Node&lt;K,V&gt;[] tab; int sc; while ((tab = table) == null || tab.length == 0) &#123; //在构造方法中sizeCtl就是hash表的初始大小 if ((sc = sizeCtl) &lt; 0) Thread.yield(); // lost initialization race; just spin //使用CAS将sc的值设置为-1 表示初始化table,设置成功后返回true else if (U.compareAndSwapInt(this, SIZECTL, sc, -1)) &#123; //获取到锁，创建table. //此时其他线程会在while()循环中忙等待（即自旋） try &#123; //再次检查hash表没有创建 if ((tab = table) == null || tab.length == 0) &#123; int n = (sc &gt; 0) ? sc : DEFAULT_CAPACITY; @SuppressWarnings("unchecked") //创建hash表 Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n]; table = tab = nt; //计算下次hash表扩容的阈值 sc = n - (n &gt;&gt;&gt; 2); &#125; &#125; finally &#123; //之后sizeCtl就表示hash表的扩容阈值了 sizeCtl = sc; &#125; break; &#125; &#125; return tab; &#125; 6、统计链表的长度—addCount()在put操作的最后一个操作中他会调用addCount方法来统计哈希表的使用情况，如果已经超过阈值了就会扩容。具体请看注释分析。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657//check就是链表中结点个数private final void addCount(long x, int check) &#123; CounterCell[] as; //累加单元数组，这一点可以参考LongAdder类 long b, s; //初始化累加数组以及累加单元的操作，具体参考LongAdder类的设计思想 if ((as = counterCells) != null || !U.compareAndSwapLong(this, BASECOUNT, b = baseCount, s = b + x)) &#123; CounterCell a; long v; int m; boolean uncontended = true; if (as == null || (m = as.length - 1) &lt; 0 || (a = as[ThreadLocalRandom.getProbe() &amp; m]) == null || !(uncontended = U.compareAndSwapLong(a, CELLVALUE, v = a.value, v + x))) &#123; fullAddCount(x, uncontended); return; &#125; if (check &lt;= 1) return; //获取哈希表中元素的个数 s = sumCount(); &#125; if (check &gt;= 0) &#123; Node&lt;K,V&gt;[] tab, nt; int n, sc; //sizeCtl表示扩容阈值，s是当前哈希表中元素的个数如果超过阈值就会触发扩容 while (s &gt;= (long)(sc = sizeCtl) &amp;&amp; (tab = table) != null &amp;&amp; (n = tab.length) &lt; MAXIMUM_CAPACITY) &#123; int rs = resizeStamp(n); //其他线程进来之后发现sizeCtl&lt;0(因为第一个线程把这个值设置为负数了) if (sc &lt; 0) &#123; if ((sc &gt;&gt;&gt; RESIZE_STAMP_SHIFT) != rs || sc == rs + 1 || sc == rs + MAX_RESIZERS || (nt = nextTable) == null || transferIndex &lt;= 0) break; //如果新的hash表已经被创建了，就使用CAS帮助第一个线程完成扩容 if (U.compareAndSwapInt(this, SIZECTL, sc, sc + 1)) transfer(tab, nt); &#125; //正常情况下，第一个线程执行到这以后首先使用CAS把sizeCtl的值修改为一个负数，修改成功后就进入到transfer方法中扩容 else if (U.compareAndSwapInt(this, SIZECTL, sc, (rs &lt;&lt; RESIZE_STAMP_SHIFT) + 2)) //第一个线程进来后初始化一个新的hash表 transfer(tab, null); s = sumCount(); &#125; &#125; &#125; //注意累加数组的类型定义CounterCell上使用了@sun.misc.Contended注解，//这个注解可以避免缓存行伪共享问题@sun.misc.Contended static final class CounterCell &#123; //保存了每一个桶中元素的个数 volatile long value; CounterCell(long x) &#123; value = x; &#125; &#125; 7、获取元素操作—get()get方法没有加锁，这依赖于volatile带来的便利性。 123456789101112131415161718192021222324public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; //spread可以保证hash值是一个正整数 int h = spread(key.hashCode()); //hash表存在并且key的槽位不为null 还是使用了(n - 1) &amp; h)定位了key的桶的位置 if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; //头结点就是要找的值 if ((eh = e.hash) == h) &#123; if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; //hash值小于0表示hash表在扩容中，或者已经转化为红黑树了 else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; while ((e = e.next) != null) &#123; //遍历链表，查找key对应的value if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null; &#125; 8、获取元素的个数—size()1234567891011121314151617181920public int size() &#123; //直接调用sumCount()统计哈希表元素个数 long n = sumCount(); return ((n &lt; 0L) ? 0 : (n &gt; (long)Integer.MAX_VALUE) ? Integer.MAX_VALUE : (int)n); &#125; final long sumCount() &#123; CounterCell[] as = counterCells; CounterCell a; long sum = baseCount; //counterCells中保存了每一个桶中元素的个数，现在统计只需要遍历counterCells把每个桶中元素个数相加即可 if (as != null) &#123; for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) sum += a.value; &#125; &#125; return sum; 9、扩容操作—transfer()扩容的逻辑比较复杂，这里不再贴出源码了，我们来捋一下关键流程就好了： 首先扩容会传进来两个参数：老的哈希表和新的哈希表（Node&lt;K,V&gt;[] tab, Node&lt;K,V&gt;[] nextTab），在第一个线程调用这个方法的时候新的哈希表nextTab=null 当线程判断nextTab=null之后，会new一个是元hash表2倍大小的新哈希表（Node&lt;K,V&gt;[] nt = (Node&lt;K,V&gt;[])new Node&lt;?,?&gt;[n &lt;&lt; 1];） 创建新哈希表完成之后就是链表的搬迁工作了。这个过程中值的注意的是，当一个线程把旧哈希表上桶中的元素搬迁到新的哈希表上之后或者这个桶中没有元素，它用一个ForwardingNode类型的结点挂在这个桶下，以此告诉其他线程这个桶位置已经被处理了，可以说非常高效。 还需要注意的是，在移动桶中元素的过程中，还是需要对链表和红黑树分别处理，前者的判断依据是头结点的hash值大于等于0，后者的判断依据是头结点的hash值小于0并且头结点是TreeBin类的实例。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F18%2FHashMap%E6%98%AF%E5%A6%82%E4%BD%95%E5%B7%A5%E4%BD%9C%E7%9A%84%2F</url>
    <content type="text"><![CDATA[HashMap是如何工作的声明：基于jdk1.8源码。 一、认识HashMapHashMap最早在jdk 1.2就出现了，直到jdk1.7都没有太大的改动： jdk1.7的采用的存储结构是采用了数组+链表，jdk1.8的存储结构数组+链表+红黑树 HashMap允许存储一个键和值都为null的元素（这一点Hashtable不可以），HashMap在多线程环境下没法保证对元素的操作是线程安全的。下面我们就来一步步分析，并针对特定问题给出对应的解决方法。 二、深入分析HashMap1、底层数据结构HashMap的底层数据在jdk1.7是数组+链表的存储结构： jdk1.8采用了数组+链表+红黑树的存储结构： jdk1.8的Node结点，实现基本和jdk1.7的Entry类似，只是名字变了。 2、HashMap的属性和构造方法 重要的属性 123456789101112131415161718//默认的Map大小 16static final int DEFAULT_INITIAL_CAPACITY = 1 &lt;&lt; 4; // aka 16 //Map的最大容量 2^30static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30;//默认加载因子 0.75static final float DEFAULT_LOAD_FACTOR = 0.75f; //链表树化阈值 8static final int TREEIFY_THRESHOLD = 8;//树转链表的阈值 6static final int UNTREEIFY_THRESHOLD = 6;//Hash表的基本数组，table数组transient Node&lt;K,V&gt;[] table; //key-value对的数量transient int size; //table当前的阈值int threshold;//table当前的加载因子final float loadFactor; 构造方法 12345678910111213141516171819202122232425262728293031323334353637/*** 构造一个加载因子是0.75并且初始容量是16的HashMap*/public HashMap() &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; // all other fields defaulted &#125; /*** 构造一个加载因子是0.75并且初始容量是initialCapacity的最近2的幂大小的HashMap*/public HashMap(int initialCapacity) &#123; this(initialCapacity, DEFAULT_LOAD_FACTOR); &#125; /*** 构造一个加载因子是指定加载因子并且初始容量是initialCapacity的最近2的幂大小的HashMap*/public HashMap(int initialCapacity, float loadFactor) &#123; if (initialCapacity &lt; 0) throw new IllegalArgumentException("Illegal initial capacity: " + initialCapacity); if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; if (loadFactor &lt;= 0 || Float.isNaN(loadFactor)) throw new IllegalArgumentException("Illegal load factor: " + loadFactor); this.loadFactor = loadFactor; //tableSizeFor()方法将我们传入的大小值转换为据这个数最小的2的幂，但是有没有觉得这里把初始容量赋给阈值是不是有点奇怪呢？答案在resize()方法中 this.threshold = tableSizeFor(initialCapacity); &#125; /*** 根据已有的Map构造一个新Map*/public HashMap(Map&lt;? extends K, ? extends V&gt; m) &#123; this.loadFactor = DEFAULT_LOAD_FACTOR; putMapEntries(m, false); &#125; 既然都说道这了，我们不妨来看看tablSizeFor()方法的实现吧！ 这个方法的作用就是返回一个离给定数字的差最小的2的幂。下面我们来分析一下这个方法： 首先为什么要对给定的容量cap-1呢？这是为了防止如果给定的容量就是2的幂了，那么进过下面4次右移就会把容量扩大为原来的2倍，且看我慢慢分析。举个例子，比如传了一个容量值为10： 最后判断一下，发现n不小于0并且n不大于最大容量就把n+1 即：（0000 1111）+1 ===&gt; (0001 0000) ，也就是2^4=16。 3、存储元素put()方法原理我们向HashMap存储元素的时候通常使用的就是put()方法，那么在我们调用了put()之后发生了那些事情呢？我们打开源码看看： 可以看到，put()方法只是对putVal()方法进行了一次包装，首先我们看一下在jdk1.8中hash()算法是如何实现的： 123456789101112131415161718192021//jdk1.8中hash算法static final int hash(Object key) &#123; int h; return (key == null) ? 0 : (h = key.hashCode()) ^ (h &gt;&gt;&gt; 16);&#125; //对比jdk1.7中的hash算法final int hash(Object k) &#123; int h = hashSeed; if (0 != h &amp;&amp; k instanceof String) &#123; return sun.misc.Hashing.stringHash32((String) k); &#125; // 先取key的hashCode再和hashSeed进行异或运算 h ^= k.hashCode(); // This function ensures that hashCodes that differ only by // constant multiples at each bit position have a bounded // number of collisions (approximately 8 at default load factor). h ^= (h &gt;&gt;&gt; 20) ^ (h &gt;&gt;&gt; 12); return h ^ (h &gt;&gt;&gt; 7) ^ (h &gt;&gt;&gt; 4);&#125; 在这两个jdk版本中的hash()算法的实现是不同的，但基本逻辑没有变：都是先获取了key的hashCode，然后对这个hashCode进行了移位并且异或运算。但是可以明显看到，jdk1.7中的hash()算法的移位操作多了几步但在jdk1.8中很简单，这样设计是因为在jdk1.8中引入了红黑树后对于hash()算法就不需要有那么高的要求了，就算是不够散列也有红黑树来兜底，但是jdk1.7没有红黑树，为了保证元素的散列性，hash()算法应该尽可能的将key的hashCode的每一位都让他参与到计算中，即只要key的hashCode中任何一位发生变化就会对最终的结果产生影响。 拿到hash值之后，就到了putVal()中真正的处理元素了。下面是putVal()的源码： putVal()方法的逻辑： 第一个if处判断当前的table数组是否为空，如果为空就进入resize()方法初始化一个table数组。在jdk1.8中resize()方法不仅可以扩容，还可以初始化table数组。 第二个if是判断在table[i]位置是否有元素，如果没有就直接new一个Node放进去即可。这里需要注意的是在计算i这个值的时候采用的算法：(n-1)&amp;hash，为什么要这么做呢？通常我们实现的Hash表都是采用hash%数组长度，并且数组长度我们建议最好是质数。在这里为什么不用%操作呢？原因如下： 首先这么做肯定可以达到和取模一样的效果，并且位操作&amp;的效率更高 n表示table当前的容量，但是我们知道table的容量是2的幂，把这个数-1就得到了一个低位连续是1的一个数（二进制表示），此时再做按位与，数组的索引值就完全取决于hash值了。 进入了第三个条件就是说明当前table存在但是table[i]的位置发生了hash碰撞。接下来就是解决hash碰撞的以及当链表长度操作8之后转化为红黑树的逻辑了： 在第三个条件中又存在三个条件： 第一个条件判断插入的新值是否在HashMap中已经存在，如果是的，就会把这个值先取出来，然后在最后的一个if判断中进行修改 第二个条件就说明插入的新值在HashMap中不存在，此时判断当前链表是否已经树化了，如果被树化就调用putTreeVal()把新值修改到红黑树中 第三个条件是插入的新值在HashMap中不存在并且链表还没有树化，可以看到，jdk1.8中采用了尾插法把新的结点插入的（这里一定要注意，jdk1.7采用的是头插法）。 并且在插入的过程中还在不断的监控链表的长度，如果链表的长度一旦&gt;=8了就立即调用treeifyBin()方法将链表转换为红黑树 最后在插入成功之后会进行比较++size&gt;threshlid是否成立，如果成立说明需要扩容了。 总结一下put()方法的流程： （1）通过put()方法传入key-vlaue （2）计算出key的hash值 （3）根据hash值判断vlaue存放的位置，再次之前他会先判断table是否已经初始化了，如果没有就会先初始化；如果初始化过了就会判断vlaue应该存放的位置是否已经有元素了，如果没有那就把value直接存放在数组中即可 （4）如果发生了hash冲突，那就要还要判断此时处理冲突使用的数据结构是什么 （5）如果此时使用的是红黑树，那就调用putTreeValur()把值插入到红黑树中 （6）若此时的数据结构是链表，遍历链表计算出插入之后链表长度是否大于等于8 （7）插入之后大于8了，就要先调整为红黑树，在插入 （8）插入之后不大于8，那么就直接插入到链表尾部即可 最后结合一个流程图再来理解一下put()方法的流程： 4、Hash表的扩容resize()原理在插入新的结点后如果当前数组的元素个数大于阈值了就会进行扩容操作，或者刚开始哈希表的初始化都是在resize()方法中进行的，下面我们一起来分析一下他的源码： 是不是一看到这么长的源码就没有读下去的欲望了？不要拍，接下来我们分解一步步来： （1）确定新容量和新阈值 首先它判断当前hash表是否为空，如果为空就把当前容量设为0，否者拿到当前哈希表的容量oldCap； 拿到当前阈值oldThr,并初始化新的容量newCap和阈值newThr为0 接下来三种情况： 1）如果当前哈表容量oldCap&gt;0，并且当前哈希表的容量大于等于最大允许容量，那就把阈值设为最大的整数；否者将新的容量设置为当前容量的2倍，如果设置后新的容量&lt;最大允许容量并且当前容量&gt;=默认容量（16）就会把新的阈值也设置为当前阈值的2倍 2）第二个成立表示哈希表还没初始化大事阈值初始化了（oldThr&gt;0），此事会将新的容量设置为当前阈值。为什么呢？因为在构造方法中将算出来的容量设置给了阈值。 3）最后一种情况就是哈希表和阈值都没有初始化，那就把新的容量设置为默认容量16，新的阈值设置为默认加载因子0.75*默认容量16=12 最后判断一下新的阈值是否为0，如果为0没那就算出一个阈值字后将阈值更新 （2）申请新的哈希表 至此完成了对新哈希表的创建，这个哈希表的容量是老哈希表的2倍 （3）把当前哈希表中的数据复制到新哈希表中 在真正扩容之前会判断一下当前的哈希表oldTab是否是空的，如果是空的表示这是来初始化哈希表的，这在前两步就完成了，在这里直接返回就可以了。 如果oldTab!=null，那就需要把哈希表中的数据复制到新哈希表中 遍历老的哈希表，没有元素的槽位不管，只处理有元素的槽位； 处理有元素的槽位的逻辑分为三大部分： 1）如果这个槽位没有后继结点了，就直接把元素移动到新的哈希表中，存放的位置是通过hash&amp;(newCap-1)算出来的 2）如果槽位有后继结点并且已近树化了，那就红黑树拆分后，在新的哈希表中重新组装 3）如果槽位有后继结点但是没有树化，那就还是用尾插法把元素移动到新的哈希表总，需要注意的是： A：扩容后，若hash&amp;oldCap=0，那么元素在扩容后的位置=原始位置 B：扩容后，若hash&amp;oldCap!=0，那么元素在扩容后的位置=原始位置+旧数组大小。 5、Hash表获取元素get()原理 首先还是计算出key的hash值，然后调用getNode()方法获取到值 首先判断当前哈希表是否为空，如果为空直接返回null； 如果hash表不空需要再判断key在HashMap中是否存在，如果不存在，还是直接返回null； 如果哈希表不为空并且key在HashMap中存在，那就首先检查一下hash表中的这个元素是不是要找的值，如果是就直接返回vlaue,如果不是还会在判断一下是否存在后继结点，如果不存在直接返回null 如果存在后继结点，那么首先判断一下是红黑树还是链表，如果是红黑树那就到红黑树中取值，如果是链表那就从头开始遍历链表找到值后返回。 三、安全失败机制（fail-safe）和快速失败机制（fail-fast）1、快速失败机制 fail-fast在使用迭代器遍历集合的时候，如果在遍历过程中集合的元素个数发生变化，就会抛出ConcurrentmodificationException 原理：迭代器在遍历时直接访问集合中的内容，并且在遍历过程中使用一个modCount变量，当集合中元素个数发生了变化就会修改modCount的值，当调用hasNext()/next()方法是会判断modCount和exceptedModCount的值是否相等，如果相等就返回继续遍历，否则抛出ConcurrentModificationException，终止遍历。 应用场景：java.util包下的集合类使用了这种机制（Hashtable除外，它使用的是fail-safe）,不能在多线程下发生并发修改（迭代过程中被修改）算是一种安全机制吧。 2、安全失败机制 fail-safe采用安全失败机制的集合容器，在遍历的时候不会直接在原来的内容量上遍历，而是复制一份在复制的副本上遍历。由于遍历是在拷贝的副本上进行的，所以在遍历过程中对原集合所作的修改并不能被迭代器检测到，因此不会引发ConcurrentmodificationException 应用场景：J.U.C包下都是安全失败机制容器，可以在多线程环境下并发的修改和访问。 缺点：基于拷贝内容的优点是避免了Concurrent Modification Exception，但同样地，迭代器并不能访问到修改后的内容，即：迭代器遍历的是开始遍历那一刻拿到的集合拷贝，在遍历期间原集合发生的修改迭代器是不知道的。 四、HashMap几个刁钻面试题总结1、HashMap的数据结构是什么？答：在jdk1.7是采用了数组+链表，jdk1.8采用了数组+链表+红黑树 2、为什么要采用数组+链表作为存储结构？首先要清楚一个基本的理论：数组查询效率高，只要给一个数组索引就可以立马找到对应的元素，但是插入、删除的效率低；链表插入、删除的效率高，但是查询的效率低。因此HashMap的table使用数组就可以通过一个索引值立即定位到确定到元素的槽位（solt）。但是可能有多个key的hashCode计算出来一样 即发生Hash碰撞，此时HashMap采用了拉链法，即以table数组这个槽位为链表头结点，把发生hash碰撞元素串在一根链表上。而且在jdk1.8进行了进一步优化，即如果链表的长度&gt;8时将会转化为红黑树，当红黑树上的结点&lt;6时又会转换为链表。这一点从源码中就可以看到： TREEIFY_THRESHOLD是树化阈值为8，UNTREEIFY_THRESHOLD是非树化阈值为6 3、为什么在jdk1.8要使用红黑树，使用二叉搜索树或者平衡树不可以吗？ （1）二叉搜索树在给定的数据有序时会出现退化为链表的情况 二叉搜索树的思想是：左子树结点比父节点小，右子树结点比父节点大。当给的数据处于无序状态的时候二叉搜索树的性能非常好，只有O(logn)，但是当给的数据有序的时对于二叉搜索树是灾难，基于二叉搜索树规则构建的树会退化为单链表。即如下图所示： （2）平衡树的维护成本太高，不适合HashMap这样有频繁修改的的场景。 平衡树(AVL)就是用来解决二叉搜索树会退化为链表对问题二提出的。它的原理如下： a. 平衡树具有二叉搜索树的全部特性 b. 平衡树要求左子树和右子树的高度差不能超过1 通过平衡树，我们解决了二叉查找树的缺点。对于有 n 个节点的平衡树，最坏的查找时间复杂度也为 O(logn)。但是由于平衡树要求每个节点的左子树和右子树的高度差至多等于1，这个要求实在是太严了，导致每次进行插入/删除节点的时候，几乎都会破坏平衡树的第二个规则，进而我们都需要通过左旋和右旋来进行调整，使之再次成为一颗符合要求的平衡树。 最后就会导致为了维护一个这个平衡树，带来了可能比只是用单链表还高的消耗，这时不可取得。因此为了解决这个问题，工程师们又想到了红黑树。红黑树的性质如下： a. 具有二叉查找树数的所有特点 b.根节点是黑色的 c.每个叶子节点都是黑色的空节点，即叶子节点不存值 d.任意相邻的结点都不能是相同的颜色 e.任意结点到其任意叶子节点的路径上的黑色结点的数目相同 正是由于红黑树的这些特性，红黑树在插入、删除等操作，不会像平衡树那样，频繁着破坏红黑树的规则，所以不需要频繁调整。但是在效率方面，红黑树确实不及平衡树，可以说使用红黑树就是一种折中的方案。 3、为什么不直接上来就使用红黑树，而是达到阈值了才转化为红黑树？ 首先维护一个树的成本比维护一个链表的成本要高。 再者设置链表树化的阈值为8是因为链表的长度达到8的概率很低，看HashMap源码中的一段注释： 画红线的翻译过来就是说：在具有良好分布的用户hashCode的用法中，很少使用到红黑树。 理想情况下，在随机hashCodes下，bin中节点的频率遵循泊松分布，默认调整大小阈值为0.75，平均参数约为0.5，尽管 由于存在较大差异调整粒度。 忽略差异，预期列表大小k的出现是（exp（-0.5）* pow（0.5，k）/阶乘（k））。 也就是说，想让一个链表的长度达到8的概率极低，几乎是不可能事件。 因此综合这两点，为啥一定要维护一个红黑树呢？没必要啊！！！ 4、说一下HashMap的工作原理HashMap的底层是数组+单向链表实现的，数组中的每个元素都是链表的头结点，这个链表的类型是HashMap的内部类Node(它实现了Map.Emtry接口)，HashMap透过put(K,V)和get(K)方法来放入和取值： put()方法存储值时： （1）key-value键值对通过put()方法传入，首先调用hash(key)计算出key的hash值 （2）拿到hash值之后，首先判断哈希表是否初始化了，如果没有初始化就调用resize()方法初始化 （3）如果初始化了，然后结合数组长度计算出key应该存放的下标 （4）如果在这个位置没有元素，那就直接把值放入即可，否则就是发生了hash碰撞 如果key的hash值在HashMap中存在，且它们两者 equals 返回 true，则更新键值对； 如果 key 的 hash 值在 HashMap 中存在，但是它们两者 equals 返回 false，则插入链表的尾部（尾插法）或者红黑树中（树的添加方式）。 获取对象时： （1）get()方法将键值对传入，首先还是计算key的hash值 （2）拿到hash值首先判断一下头结点是不是要找的元素，如果是直接返回value；如果不是就看看头结点是否有后继结点，如果没有就返回null （3）如果头结点有后续结点那就判断如果头结点的类型如果是树就调用红黑树的获取值的方法getTreeNode()，否则还是当做链表处理，从头结点开始遍历，知道hash值相等并且equals返回true是就说明找到目标元素了。 hashCode 是定位的，存储位置；equals是定性的，比较两者是否相等。 5、你知道hash算法的实现吗？为什么要这么实现？JDK1.8中HashMap中的hash算法的实现是通过：key的hashCode()高16位异或低16位实现的（h=(key.hashCode())^(h&gt;&gt;&gt;16)）。 现在的hashCode分布的已经很不错了，而且当发生较大碰撞时也用树形存储降低了冲突。仅仅异或一下，既减少了系统的开销，也不会造成的因为高位没有参与下标的计算(table长度比较小时)，从而引起的碰撞。 6、hash中为什么要使用异或操作？可以保证key的32位hashCode()中是要有一位发生变化，那么真个hash值也会跟着改变。目的是尽可能的减少hash冲突。 7、HashMap 的 table 的容量如何确定？loadFactor 是什么？ 该容量如何变化？这种变化会带来什么问题？（1）HashMap的table数组的容量是通过capaticy参数控制的，默认的数组大小是16，最大额数组大小是2^30。我们可以在HashMap的构造方法中传入指定的容量数值。 （2）loadFatory是装载因子，作用是判断当前哈希表是否可以扩容了。范围是0-1，默认是0.75.和他类似的一个参数是阈值threshold，在一切都是默认值的情况下，阈值是12 （3）扩容时，调用 resize() 方法，将 table 长度变为原来的两倍（注意是 table 长度，而不是 threshold） 8、jdk1.7和jdk1.8中HashMap有哪些不同？（1）在jdk1.8中当链表的长度大于等于8的时候会转换诶红黑树； （2）jdk1.8中采用的是尾插法，而jdk1.7中采用的是头插法； （3）jdk1.8简化了hash算法； （4）jdk1.8修改了resize()的逻辑，使得jdk1.8在resize时不会出现循环链表的问题； （5）jdk1.8中talbe数组的类型改为了Node，jdk1.7中的类型是Entry类型； 9、HashMap，LinkedHashMap，TreeMap 有什么区别？LinkedHashMap是HashMap的子类，他维护了一个双向链表，因此他可以保证元素的插入顺序和元素的遍历顺序是相同的；效率比HashMap低。 TreeMap就是一个红黑树的实现，实现 SortMap 接口，能够把它保存的记录根据键排序 10、HashMap和Hashtable的区别？ HashMap的基类是AbstractMap, Hashtable的基类是Dictionary, 他们共同实现了Map接口 HashMap的初始容量是16，Hashtable的初始容量都是11,负载因子都是0.75。但是扩容机制不同, HashMap是旧数组的2*旧表长度, 而Hashtable是2旧表长度+1 HashMap是非线程安全的，而Hashtable是线程安全的，因为所有的方法都使用了synchronized. HashMap使用迭代器迭代, Hashtable可以使用迭代器和枚举。 HashMap中K和V都可以是null,但是Hashtable中都不能是null. HashMap中取消了contains方法，使用了containsKey和containsValue,但是Hashtable中三个方法都有 对象的定位方法不同: Hashtable:使用K的hashCode直接作为hash值,和数组长度进行求余运算,得到键值对在数组中的位置,然后再使用equals方法形成链表。 HashMap:使用K的hashCode进行高低16位异或运算作为hash值,和数组的长度减一进行&amp;运算， 得到键值对在数组中的位置，然后再使用equals方法形成链表。说一下计算桶的位置为什么是这个样子，就是因为扩容的时候是2的n次方进行扩容, hash值在和2的n次方进行求余运算和&amp;运算的结果一样, 但是&amp;运算要快的多。同时正是因为扩容倍数的特殊性，导致扩容后不需要重新键值对在新数组的位置只需要判断K的hash值多出来的那一位是0还是1. 如果是0, 新表中键值对的位置和旧表-样。 如果是1,新表中键值对的位置等于旧表的位置+旧表的长度。 Hashtable由于是线程安全的，因此采用了一种快速失败的机制。允许多个线程同时修改但不会抛出异常；HashMap采用了一种安全失败机制的机制，他不允许在遍历元素的时候，集合发生改，如果发生改变就会抛出异常。 11、Java 中的另一个线程安全的与 HashMap 极其类似的类是什么？同样是线程安全，它与 Hashtable 在线程同步上有什么不同？ConcurrentHashMap是J.U.C下提供的一个并发容器，他是HashMap的线程安全版本，采用分段锁提高了效率，但是在Hashtable中是将整个hash表使用synchronized锁起来，并发性没有前者好。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F18%2F%E8%B0%88%E8%B0%88%E7%BA%BF%E7%A8%8B%E5%AE%89%E5%85%A8%E7%9A%84%E9%9B%86%E5%90%88%E7%B1%BB%E4%BB%A5%E5%8F%8A%E6%B7%B1%E5%85%A5%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90ConcurrentHashMap%2F</url>
    <content type="text"><![CDATA[谈谈线程安全的集合类以及深入源码剖析ConcurrentHashMap一、早期线程安全的集合JDK从1.0开始就提供了两个线程安全的集合类：Hashtable和Vector 1、HashtableHashtable和HashMap有着同样的功能——提供key value结构，但不同的是Hashtable是线程安全的，它给几乎所有public方法都加上了synchronized关键字，还有一个不同点是HashTable的K，V都不能是null，但HashMap可以，它现在也因为性能原因被弃用了。 2、VectorVector和ArrayList一样是一个可变长度数组、不同的是Vector是线程安全的，它给几乎所有的public方法都加上了synchronized关键字。由于加锁导致性能降低，在不需要并发访问同一对象时，这种强制性的同步机制就显得多余，所以现在Vector已被弃用 二、被Collections.synchronizedXxx修饰的安全集合由于Hashtable和Vector的性能不是很高因此在之后的版本中JDK提供了HashMap、ArrayList等一批集合、但是他们不是线程安全的，因此为了保证线程安全JDK又为我们提提供了一个集合工具类Collections，它里面提供了一系类的以synchronized开头的方法，这些方法可以将这些线程不安全的集合类包装成线程安全的集合类，实现的原理也很简单，就是在调用HashMap原方法之前使用synchronized修饰从而保证了线程安全性，比如我们可以看看synchronizedMap(Map&lt;K,V&gt; m)方法的实现： 他直接new了一个类，并把我们传入的HashMap引用传给他。SynchroinzedMap是Collections的内部类，实现如下： SynchroinzedMap中只是把原方法用synchronized有包装了一遍，性能其实和被淘汰的Hsahtable没有本质提升，但是这里使用了一个设计模式值的我们学习——装饰器模式 三、 J.U.C安全集合java.util.concurrent下的安全集合按照他们的名字大致可以分为三类：Blocking、CopyOnWrite以及Concurrent Blocking大部分实现基于锁，提供线程安全的阻塞队列 CopyOnWrite之类的容器修改比较重 Concurrent：基于CAS提供一系类的优化操作，具有很高的吞吐量，但是他的一致性比较差，比如求大小size并不能保证100%的正确性……]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F18%2F%E7%BA%BF%E7%A8%8B%E6%B1%A0ThreadPoolExecutor%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[线程池ThreadPoolExecutor详解如果并发的线程数量很多，并且每个线程都是执行一个时间很短的任务就结束了，这样频繁创建线程就会大大降低系统的效率，因为频繁创建线程和销毁线程需要时间。 那么有没有一种办法使得线程可以复用，就是执行完一个任务，并不被销毁，而是可以继续执行其他的任务？ 在Java中可以通过线程池来达到这样的效果。今天我们就来详细讲解一下Java的线程池，首先我们从最核心的ThreadPoolExecutor类中的方法讲起，然后再讲述它的实现原理，接着给出了它的使用示例，最后讨论了一下如何合理配置线程池的大小。 首先我们来看一下Java中线程池的继承体系： 最顶层的Executor是一个接口，他讲任务的提交和执行分离开来。 ThreadPoolExecutor是线程池的核心实现类，用来执行被提交的任务。 ScheduledThreadPoolExecutor是一个延时执行任务的实现类，他比Timer更灵活。 Executor下有一个重要子接口ExecutorService，其中定义了线程池的具体行为 1，execute（Runnable command）：履行Ruannable类型的任务, 2，submit（task）：可用来提交Callable或Runnable任务，并返回代表此任务的Future对象 3，shutdown（）：在完成已提交的任务后封闭办事，不再接管新任务, 4，shutdownNow（）：停止所有正在履行的任务并封闭办事。 5，isTerminated（）：测试是否所有任务都履行完毕了。 6，isShutdown（）：测试是否该ExecutorService已被关闭。 接下来我们就以ThreadPoolExecutor来探究一下Java中线程池的原理。 一、ThreadPoolExecutor构造方法123456789public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; //省略.....&#125; ThreadPoolExecutor有很4个构造方法，这里我用参数最全的一个来说明一下各个参数的含义： 1、corePoolSize：线程池中核心线程个数 2、maximunPoolSize：线程池最大允许的线程个数（这里有一个救急线程的概念，就是非核心线程，它的数量是maximunPoolSize-corePoolSize） 3、keepAliveTime：这个参数是给非核心线程设定的，他表示非核心线程可以空闲时间，超过这个时间就会被回收 4、unit：空闲时间的单位 5、workQueue：任务队列，它是一个阻塞队列，用于存放等待执行的任务。Java中提供的阻塞队列有以下几个： （1）ArrayBlockingQueue：基于数组的有界队列，遵循先进先出 （2）LinkedBlockingQueue：基于链表的有界队列，遵循先进先出，吞吐量高于ArrayBlockingQueue （3）SynchronousQueue：一个不存储元素的阻塞队列，每一个插入操作必须要等到另一个线程调用移除操作才可以执行，否则会一直阻塞，吞吐量比LinkedBlockingQueue高 （4）PriorityBlockingQueue：一个具有优先级的阻塞队列 6、threadFactory：线程工厂，用于创建线程以及可以给线程起一个有意义的名字 7、RejectedExecutionHandler：当任务队列和线程池都处于满负荷运行时，新提交的任务应该如何处理的策略，称为饱和策略。Java中提供的策略有以下4种： （1）ThreadPoolExecutor.AbortPolicy：直接抛出异常，这是默认的策略 （2）ThreadPoolExecutor.CallerRunsPolicy：让调用者来执行该任务 （3）ThreadPoolExecutor.DisCardPolicy：不做任何处理，直接把任务丢掉，也不抛出任何异常 （4）ThreadPoolExecutor.DisCardOldestPolicy：丢弃任务队列头部的任务，然后尝试执行当前任务 当然，我们也可以根据我们的业务场景通过实现RejectExeptionPolicy接口实现自定义策略。 二、线程池的重要属性1、线程池状态以及有效线程数量属性—ctl ctl是一个控制线程池状态以及线程池中有效线程数量的int类型字段，在这一个字段中包含了两部分信息： 线程池的运行状态 (runState) 和线程池内有效线程的数量 (workerCount)，这里可以看到，使用了int类型来保存，高3位保存runState，低29位保存workerCount。这么做是为了保证修改线程池状态以及线程池中有效线程数量的操作是一个原子操作的前提前可以借助无锁机制提高效率，如果用两个变量分别保存的话就要通过加锁来保证原子性了。 COUNT_BITS 就是29，CAPACITY就是1左移29位减1（29个1），这个常量表示workerCount的上限值，大约是5亿。 2、ctl有关的方法：1234567// Packing and unpacking ctl //获取线程池的运行状态private static int runStateOf(int c) &#123; return c &amp; ~CAPACITY&#125; //获取活动线程数private static int workerCountOf(int c) &#123; return c &amp; CAPACITY;&#125;//获取运行状态和活动线程数的值private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125; 3、线程池的5个状态 123456// runState is stored in the high-order bits 高3位private static final int RUNNING = -1 &lt;&lt; COUNT_BITS; //111private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS; //000 private static final int STOP = 1 &lt;&lt; COUNT_BITS; //001private static final int TIDYING = 2 &lt;&lt; COUNT_BITS; //010private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; //011 RUNNING：线程池处于运行状态，可以正常处理并接受新任务，线程池的初始状态就是RUNNING； SHUTDOWN：当调用shutdown()方法后会由RUNNING转变为SHUTDOWN状态，此时线程池可以正常处理任务但是无法再接收新任务； STOP：代用shutdownNow()方法后，线程会转变为STOP状态，此时线程不再处理已提交的任务并且无法在接受新任务，并且还会中断处理中的任务； TIDYING：当所有的任务已终止，ctl记录的”任务数量”为0，线程池会变为TIDYING状态。当线程池变为TIDYING状态时，会执行钩子函数terminated()。terminated()在ThreadPoolExecutor类中是空的，若用户想在线程池变为TIDYING时，进行相应的处理；可以通过重载terminated()函数来实现。 TERMINATED：线程池彻底终止，就变成TERMINATED状态。线程池处在TIDYING状态时，执行完terminated()方法之后，就会由 TIDYING -&gt; TERMINATED。 4、线程池构建有关的属性123456789101112private final BlockingQueue&lt;Runnable&gt; workQueue; //任务缓存队列，用来存放等待执行的任务private final ReentrantLock mainLock = new ReentrantLock(); //线程池的主要状态锁，对线程池状态（比如线程池大小、runState等）的改变都要使用这个锁private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;(); //用来存放工作线程private volatile long keepAliveTime; //线程空闲时间 private volatile boolean allowCoreThreadTimeOut; //是否允许为核心线程设置存活时间private volatile int corePoolSize; //核心池的大小（即线程池中的线程数目大于这个参数时，提交的任务会被放进任务缓存队列）private volatile int maximumPoolSize; //线程池最大能容忍的线程数private volatile int poolSize; //线程池中当前的线程数private volatile RejectedExecutionHandler handler; //任务拒绝策略private volatile ThreadFactory threadFactory; //线程工厂，用来创建线程private int largestPoolSize; //用来记录线程池中曾经出现过的最大线程数,跟线程池的容量没有任何关系private long completedTaskCount; //用来记录已经执行完毕的任务个数 三、线程池的基本实现原理ThreadPoolExecutor中有两个方法可以用于向线程池提交任务，分别是execute()和submit()两个方法。execute()方法用于提交不需要返回值的任务，submit()用于提交需要返回值的任务，返回值被封装在Future接口中，可以通过提供的get()方法获取返回值。下++面通过源码我们来探究一下： 1、execute()方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public void execute(Runnable command) &#123; //提交的任务为空将会抛出NPE if (command == null) throw new NullPointerException(); //ctl中记录着当前线程池运行状态和有效线程数量，是一个原子变量 int c = ctl.get(); /**workConutOf(c)将取出当前活跃的线程数量，把它和核心线程数比较， * 如果小于核心线程数就创建一个新的线程执行新提交的任务 */ if (workerCountOf(c) &lt; corePoolSize) &#123; /* * addWorker中的第二个参数表示限制添加线程的数量是根据corePoolSize来判断还是maximumPoolSize来判断； * 如果为true，根据corePoolSize来判断； * 如果为false，则根据maximumPoolSize来判断 */ if (addWorker(command, true)) return; //创建新的线程失败，重新获取ctl c = ctl.get(); &#125; //如果当前线程池是运行状态并且任务添加到队列成功 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); // 再次判断线程池的运行状态，如果不是运行状态，由于之前已经把command添加到workQueue中了， // 这时需要移除该command // 执行过后通过handler使用拒绝策略对该任务进行处理，整个方法返回 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); /* * 获取线程池中的有效线程数，如果数量是0，则执行addWorker方法 * 这里传入的参数表示： * 1. 第一个参数为null，表示在线程池中创建一个线程，但不去启动； * 2. 第二个参数为false，将线程池的有限线程数量的上限设置为maximumPoolSize，添加线程时根据maximumPoolSize来判断； * 如果判断workerCount大于0，则直接返回，在workQueue中新增的command会在将来的某个时刻被执行。 */ else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; /* * 如果执行到这里，有两种情况： * 1. 线程池已经不是RUNNING状态； * 2. 线程池是RUNNING状态，但workerCount &gt;= corePoolSize并且workQueue已满。 * 这时，再次调用addWorker方法，但第二个参数传入为false，将线程池的有限线程数量的上限设置为maximumPoolSize； 如果失败则调用饱和策略处理该任务。 */ else if (!addWorker(command, false)) reject(command); &#125; 总结一下execute()方法运行的主要流程如下图所示： 从图中可以看出，当提交一个新任务当线程池以后，exectue()的处理流程大致如下： 1、首先判断核心线程池中的线程是否都有处于工作状态，如果没有就创建新的线程执行任务，否则进入下一步 2、判断任务队列是否已经满了，如果没有满就班新任务放入阻塞队列中等待被执行；否则进入下一步 3、判断线程池的线程是否都处于工作状态，如果没有就创建新的线程执行任务，否则把任务交给饱和策略处理。 2、addWorker()方法addWorker主要的功能就是创建一个新线程并执行提交的任务。firstTask参数表示该线程创建后执行的第一个任务；core参数如果为true表示限制线程池中的线程数量应该小于corePoolSize,为false表示限制线程池中的线程数量应该小于maximumPoolSize 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); //获取运行状态 int rs = runStateOf(c); /** * 如果rs &gt;= SHUTDOWN，则表示此时不再接收新任务； * 如果这个条件满足后，下面三个条件任意一个满足就会返回false * 1. 当前线程池处于SHUTDOWN状态 * 2. 提交的任务为空 * 3. 任务队列不为空 */ // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp;firstTask == null &amp;&amp;! workQueue.isEmpty())) return false; for (;;) &#123; //获取活动线程个数 int wc = workerCountOf(c); /**这里是实现比较容量大小是否超过限制的关键步骤 *core参数如果为true表示限制线程池中的线程数量应该小于corePoolSize, *为false表示限制线程池中的线程数量应该小于maximumPoolSize */ if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; // 尝试CAS增加workerCount，如果成功，则跳出第一个for循环 if (compareAndIncrementWorkerCount(c)) break retry; // 如果CAS增加workerCount失败，则重新获取ctl的值 c = ctl.get(); // Re-read ctl //如果线程池的运行状态发生改变，返回第一个for循环重试 if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; //根据Runnable对象创建一个Worker w = new Worker(firstTask); //获得Worker对应的线程 final Thread t = w.thread; if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); // rs &lt; SHUTDOWN表示是RUNNING状态 if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; //检查线程是否还活着（活着是否启动） if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); //将任务添加到阻塞队列中，他是一个HashSet workers.add(w); int s = workers.size(); //largestPoolSize记录了线程池曾经出现过的最大的线程数量 if (s &gt; largestPoolSize) largestPoolSize = s; //任务添加成功标记 workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; //最后如果添加任务成功就启动它 if (workerAdded) &#123; t.start(); //任务启动成功标记 workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) //任务启动失败后把任务从HashSet中移除 addWorkerFailed(w); &#125; return workerStarted; &#125; 3、内部类WorkerWorker中的重要属性以及构造方法 1234567891011121314151617181920private final class Worker extends AbstractQueuedSynchronizer implements Runnable&#123; /** Thread this worker is running in. Null if factory fails. */ final Thread thread; /** Initial task to run. Possibly null. */ Runnable firstTask; /** Per-thread task counter */ volatile long completedTasks; /** * Creates with given first task and thread from ThreadFactory. * @param firstTask the first task (null if none) */ Worker(Runnable firstTask) &#123; setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); &#125;&#125; 线程池中的每一个线程被封装成了一个Worker对象，ThreadPoolExecutor维护的其实就是一组Worker对象。 Worker类继承了AQS，并实现了Runnable接口，注意其中的firstTask和thread属性：firstTask用来保存传入的任务；thread是在调用构造方法时保存通过ThreadFactory创建的线程，是用来处理任务的线程。 在调用构造方法时，需要把任务传入，这里通过getThreadFactory().newThread(this);来新建一个线程，newThread方法传入的参数是this，因为Worker本身继承了Runnable接口，也就是一个线程，所以一个Worker对象在启动的时候会调用Worker类中的run方法。Worker继承了AQS，使用AQS来实现独占锁的功能。为什么不使用ReentrantLock来实现呢？可以看到tryAcquire方法，它是不允许重入的，而ReentrantLock是允许重入的： （1）lock方法一旦获取了独占锁，表示当前线程正在执行任务中； （2）如果正在执行任务，则不应该中断线程； （3）如果该线程现在不是独占锁的状态，也就是空闲的状态，说明它没有在处理任务，这时可以对该线程进行中断； （4）线程池在执行shutdown方法或tryTerminate方法时会调用interruptIdleWorkers方法来中断空闲的线程，interruptIdleWorkers方法会使用tryLock方法来判断线程池中的线程是否是空闲状态； （5）之所以设置为不可重入，是因为我们不希望任务在调用像setCorePoolSize这样的线程池控制方法时重新获取锁。如果使用ReentrantLock，它是可重入的，这样如果在任务中调用了如setCorePoolSize这类线程池控制的方法，会中断正在运行的线程。 所以，Worker继承自AQS的作用是判断线程是否空闲以及是否可以被中断。 此外，在构造方法中执行了setState(-1);，把state变量设置为-1，为什么这么做呢？是因为AQS中默认的state是0，如果刚创建了一个Worker对象，还没有执行任务时，这时就不应该被中断，可以看一下Worker中的tryAcquire方法： 12345678910// The value 0 represents the unlocked state// The value 1 represents the locked state. protected boolean tryAcquire(int unused) &#123; //尝试上锁 if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; tryAcquire方法是根据state是否是0来判断的，所以将state设置为-1是为了禁止在执行任务前对线程进行中断。 正因为如此，在runWorker方法中会先调用Worker对象的unlock方法将state设置为0。 4、runWorker()方法在Worker类中的run()方法调用了runWorker()方法来执行任务，runWorker()方法的代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); //尝试获取任务 Runnable task = w.firstTask; w.firstTask = null; //解锁，允许中断了 w.unlock(); // allow interrupts // 是否因为异常退出循环 boolean completedAbruptly = true; try &#123; // 如果task为null，则通过getTask()获取任务去处理 while (task != null || (task = getTask()) != null) &#123; w.lock(); //如果线程池正在停止，那么要保证当前线程是中断状态； //如果不是的话，则要保证当前线程不是中断状态； if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; beforeExecute(wt, task); Throwable thrown = null; try &#123; //执行任务，注意这里是直接调用了run()方法 task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; //将task置为null方便下次使用getTask()获取任务 task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; //对线程做一些善后的工作 processWorkerExit(w, completedAbruptly); &#125; &#125; 总结runWorker()方法的执行过程如下： while循环不断地通过getTask()方法获取任务 getTask()方法从阻塞队列中取任务（下面会分析到） 如果线程池正在停止，那么要保证当前线程是中断状态，否则要保证当前线程不是中断状态； 调用task.run()执行任务； 当通过getTask()获取任务为null时跳出循环，执行processWorkerExit()方法，对线程做一些善后处理； runWorker方法执行完毕，也代表着Worker中的run方法执行完毕，销毁线程。 5、getTask()方法getTask()方法是用来从阻塞队列中获取任务的方法，源码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455private Runnable getTask() &#123; //timeOut变量的值表示上次从阻塞队列中取任务时是否超时 boolean timedOut = false; // Did the last poll() time out? for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); /* * 如果线程池状态rs &gt;= SHUTDOWN，也就是非RUNNING状态，再进行以下判断： * 1. rs &gt;= STOP，线程池是否正在stop； * 2. 阻塞队列是否为空。 * 如果以上条件满足，则将workerCount减1并返回null。 * 因为如果当前线程池状态的值是SHUTDOWN或以上时，不允许再向阻塞队列中添加任务。 */ if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; decrementWorkerCount(); return null; &#125; int wc = workerCountOf(c); // timed变量用于判断是否需要进行超时控制 boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; /* * wc &gt; maximumPoolSize的情况是因为可能在此方法执行阶段同时执行了setMaximumPoolSize方法； * timed &amp;&amp; timedOut 如果为true，表示当前操作需要进行超时控制，并且上次从阻塞队列中获取任务发生了超时 * 接下来判断，如果有效线程数量大于1，或者阻塞队列是空的，那么尝试将workerCount减1； * 如果减1失败，则返回重试。 * 如果wc == 1时，也就说明当前线程是线程池中唯一的一个线程了。 * 当线程池空闲之后非核心线程就是在这里被清除的 */ if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) return null; continue; &#125; try &#123; //poll方法是有时间限制的，超过指定时间就会返回，take方法则会一直阻塞等待任务 Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) //返回任务 return r; // 如果 r == null，说明已经超时，timedOut设置为true timedOut = true; &#125; catch (InterruptedException retry) &#123; // 如果获取任务时当前线程发生了中断，则设置timedOut为false并返回循环重试 timedOut = false; &#125; &#125; &#125; 6、 processWorkerExit()方法在runWorker()方法中当通过getTask()获取任务是返回null时，一个线程的生命就到达终点了，此时他会执行processWorkerExit()方法把自己从线程池维护的HashSet（workers）中移除了。 12345678910111213141516171819202122232425262728293031private void processWorkerExit(Worker w, boolean completedAbruptly) &#123; // 如果completedAbruptly值为true，则说明线程执行时出现了异常，需要将workerCount减1； // 如果线程执行时没有出现异常，说明在getTask()方法中已经已经对workerCount进行了减1操作，这里就不必再减了。 if (completedAbruptly) // If abrupt, then workerCount wasn't adju decrementWorkerCount(); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; //汇总完成的任务数 completedTaskCount += w.completedTasks; //从线程池中移除工作线程w workers.remove(w); &#125; finally &#123; mainLock.unlock(); &#125; // 根据线程池状态进行判断是否结束线程池 tryTerminate(); int c = ctl.get(); if (runStateLessThan(c, STOP)) &#123; if (!completedAbruptly) &#123; int min = allowCoreThreadTimeOut ? 0 : corePoolSize; if (min == 0 &amp;&amp; ! workQueue.isEmpty()) min = 1; if (workerCountOf(c) &gt;= min) return; // replacement not needed &#125; addWorker(null, false); &#125; &#125; 至此，processWorkerExit执行完之后，工作线程被销毁，以上就是整个工作线程的生命周期，从execute()方法开始，Worker使用ThreadFactory创建新的工作线程，runWorker()通过getTask()获取任务，然后执行任务，如果getTask()返回null，进入processWorkerExit()方法，整个线程结束，如图所示： 四 、使用线程池的正确姿势1、向线程池提交任务ThreadPoolExecutor中有两个方法可以用于向线程池提交任务，分别是execute()和submit()两个方法。 execute()：用于提交不需要返回值的任务; submit()：用于提交需要返回值的任务，返回值被封装在Future接口中，可以通过提供的get()方法获取返回值。 我们在使用线程池的时候最好不要直接使用工具类Executors中提供的Executors.newXXXThreadPool()快捷方法创建线程池，因为这种方式会使用无界的任务队列，为避免OOM，我们应该使用ThreadPoolExecutor的构造方法手动指定队列的最大长度： 1234567891011121314151617181920212223242526272829303132333435363738394041public class ThreadPoolTest &#123; public static void main(String[] args) &#123; ThreadPoolExecutor threadPool = null; try &#123; threadPool = new ThreadPoolExecutor(2, 5, 1000, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;&gt;(10), new DefaultTreadFactory(), new ThreadPoolExecutor.CallerRunsPolicy()); for (int i = 0; i &lt; 16; i++) &#123; int j = i; threadPool.execute(new Thread(() -&gt; &#123; try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + "执行了任务" + j); &#125;)); &#125; &#125; finally &#123; if (threadPool != null) threadPool.shutdown(); &#125; &#125;&#125;class DefaultTreadFactory implements ThreadFactory &#123; @Override public Thread newThread(Runnable r) &#123; Thread currentThread = new Thread(r); currentThread.setName("worker" + currentThread.getId()); return currentThread; &#125;&#125; ​ 在使用线程池的时候一定要根据任务的特性合理的配置线程池才能最大限度的发挥线程池带来的好处。对于CPU密集型任务应该配置尽可能少的线程，通常配置线程个数略多与CPU个数即可；对于IO密集型任务，每个线程在IO阻塞的时间远远大于其运行的时间，此时可以配置尽可能多的CPU；当然，这只是一个参考值，具体的设置还需要根据实际情况进行调整，比如可以先将线程池大小设置为参考值，再观察任务运行情况和系统负载、资源利用率来进行适当调整。 2、线程池的初始化默认情况下，创建线程池之后，线程池中是没有线程的，需要提交任务之后才会创建线程。 在实际中如果需要线程池创建之后立即创建线程，可以通过以下两个方法办到： prestartCoreThread()：初始化一个核心线程； prestartAllCoreThreads()：初始化所有核心线程 下面是这2个方法的实现： 12345678910111213//初始化一个核心线程public boolean prestartCoreThread() &#123; return workerCountOf(ctl.get()) &lt; corePoolSize &amp;&amp; addWorker(null, true); &#125; //初始化全部核心线程public int prestartAllCoreThreads() &#123; int n = 0; while (addWorker(null, true)) ++n; return n; &#125; 3、关闭线程池 ThreadPoolExecutor提供了两个方法，用于线程池的关闭，分别是shutdown()和shutdownNow()，其中： shutdown()：不会立即终止线程池，方法执行后会首先打断空闲的线程，之后等所有任务缓存队列中的任务都执行完后才终止，但再也不会接受新的任务,，当执行这个方法后线程池就会从RUNNING==&gt;SHUTDOWN shutdownNow()：立即终止线程池，并尝试打断正在执行的任务，并且清空任务缓存队列，返回尚未执行的任务 4、动态调整线程池容量ThreadPoolExecutor提供了动态调整线程池容量大小的方法：setCorePoolSize()和setMaximumPoolSize()， setCorePoolSize()：设置核心池大小 setMaximumPoolSize()：设置线程池最大能创建的线程数目大小 当上述参数从小变大时，ThreadPoolExecutor进行线程赋值，还可能立即创建新的线程来执行任务。 五、Excutors工具类中的3类基于ThreadPoolExecutor线程池简单分析1、newFixedThreadPool()12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; 特点： 是一个固定大小的线程池，核心线程corePoolSize=maxinumnPoolSize，因此无需超时时间 阻塞队列使用的是LinkedBlockingQueue，是一个无界阻塞队列 FixedThreadPool适用于我了满足资源管理的需求，而需要限制当前线程数量的应用场景，是哟适用于负载比较重的服务器。 2、newCacheedThreadPool()12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 特点： 核心线程数为0，最大线程数是Integer.MAX_VALUE。 阻塞队列采用了SynchronousQueue，使用的SynchronousQueue，也就是说来了任务就创建线程运行，当线程空闲超过60秒，就销毁线程。 适用于执行很多的短期异步任务或负载较轻的服务器 3、newSingleThreadPool()123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125; 特点： 线程池只有一个线程，并且也是使用LinkedBlockingQueue 适用于需要保证顺序地执行各个任务；并且在任意时间点，不会有多个线程是活动的场景。 总结Executors为我们提供了构造线程池的便捷方法，对于服务器程序我们应该杜绝使用这些便捷方法，而是直接使用线程池ThreadPoolExecutor的构造方法，避免无界队列可能导致的OOM以及线程个数限制不当导致的线程数耗尽等问题。ExecutorCompletionService提供了等待所有任务执行结束的有效方式，如果要设置等待的超时时间，则可以通过CountDownLatch完成。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F18%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3ForkJion%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[深入理解Fork/Join框架一、什么是Fork/Join框架ForkJ/Join框架是Java 7提供的一个新的线程池的实现，它体现的是一种分治思想，即：把一个大任务拆分成多个小任务，最终汇总每个小任务的的结果后得到大任务的结果的一种线程池实现。 Fork/Join在分治法的基础上配合多线程技术，可以把每个任务的分解和合并嫁给不同的线程来执行，进一步提高了运算效率。Fork/Join默认会创建和CPU核心数大小相等的线程池，使用与CPU密集型的任务。 二、Fork/Join框架的使用使用Fork/Join框架的大致步骤有以下两步： 分割任务。实现任务分割的逻辑，把一个大任务不断分割才，最终分割成为一个可以直接计算的小任务。 执行任务并合并结果。分割的子任务被放在双端队列中，需要启动线程执行这些任务。 Fork/Join提供了两个类来完成上面的事情： 1、ForkJoinTaskForkJoinTask是能够在ForkJoinPool中执行的任务抽象类，父类是Future，具体实现类有很多，这里主要关注RecursiveAction和RecursiveTask。RecursiveAction是没有返回结果的任务，RecursiveTask是需要返回结果的任务。只需要实现其compute()方法，在compute()中做最小任务控制，任务分解(fork())和结果合并(join())。 RecursiveAction：用于没有返回结果的任务。 RecursiveTask&lt;V&gt;：用于有返回结果的任务,返回结果的参数类型就是泛型参数的类型。 2、ForkJoinPoolForkJoinTask需要ForkJoinPool来执行，任务分割后的子任务会被放到当前工作线程所维护的双端队列中，进入队列的头部。当一个线程的队列里暂时没有任务时，他会随机熊其他工作线程的队列尾部获取一个任务来执行。 ForkJoin框架 的核心就是ForkJoinPool，他和ThreadPoolExecutor都是Executor框架下的具体实现。ForkJoinPool中维护了一个队列数组WorkQueue[],每个WorkQueue维护一个ForkJoinTask数组和当前工作线程。ForkJoinPool实现了工作窃取(work-stealing)算法并执行ForkJoinTask。 ForkJoinPool中执行的默认线程是ForkJoinWorkerThread，由默认工厂(DefaultForkJoinWorkerThreadFactory)产生，可以自己重写要实现的工作线程。同时会将ForkJoinPool引用放在每个工作线程中，供工作窃取时使用。 下面我们通过一个简单的实例来直观的感受一下Fork/Join框架的使用，需求是：计算1+2+…+n,并返回结果。因为需要任务执行的结果，所以我们需要继承RecursiveTask&lt;T&gt;,具体的实现如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public class ForkJoinTest &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; ForkJoinPool forkJoinPool = new ForkJoinPool(); ForkJoinTask&lt;Integer&gt; future = forkJoinPool.submit(new CountTask(1, 1000)); System.out.println(future.get()); &#125;&#125;/*** * 实现一个从1+2+...+n的任务 */class CountTask extends RecursiveTask&lt;Integer&gt; &#123; private int start; private int end; public CountTask(int start, int end) &#123; this.start = start; this.end = end; &#125; @Override protected Integer compute() &#123; int sum = 0; boolean canCompute = (end - start) &lt;= 2; if (canCompute) &#123; for (int i = start; i &lt;= end; i++) &#123; sum += i; &#125; &#125; else &#123; //拆分任务 int mid = (end + start) &gt;&gt;1; CountTask t1 = new CountTask(start, mid); CountTask t2 = new CountTask(mid + 1, end); //执行子任务 t1.fork(); t2.fork(); //等待子任务执行完毕获得其结果 int ret1 = t1.join(); int ret2 = t2.join(); sum = ret1 + ret2; &#125; return sum; &#125;&#125; 三、Fork/Join框架运行的进本原理1、ForkJoinPool类 重要的属性 1234567891011 private static final int TC_SHIFT = 32;//用来配合ctl在控制线程数量时使用 private static final long ADD_WORKER = 0x0001L &lt;&lt; (TC_SHIFT + 15); // sign// 控制ForkJoinPool创建线程数量，(ctl &amp; ADD_WORKER) != 0L 时创建线程，也就是当ctl的第16位不为0时，可以继续创建线程 volatile long ctl; // main pool control //全局锁控制，全局运行状态volatile int runState; // lockable status 记录并行数量和ForkJoinPool的模式(异步或同步final int config; // parallelism, mode //工作队列数组WorkQueue[]volatile WorkQueue[] workQueues; // main registry 2、ForkJoin内部类WorkQueue 重要的属性 12345678910111213141516//队列默认的大小 2^13 即 8192static final int INITIAL_QUEUE_CAPACITY = 1 &lt;&lt; 13;// 64M 2^26static final int MAXIMUM_QUEUE_CAPACITY = 1 &lt;&lt; 26; //并发控制，put任务时的锁控制volatile int qlock; // array数组中取任务的下标volatile int base; // array数组中放置任务的下标int top; //任务数组ForkJoinTask&lt;?&gt;[]ForkJoinTask&lt;?&gt;[] array; // ForkJoinPool，所有线程和WorkQueue共享，用于工作窃取、任务状态和工作状态同步final ForkJoinPool pool; //所属线程，ForkJoin框架中，只有一个WorkQueue是没有owner的，其他的均有具体线程ownerfinal ForkJoinWorkerThread owner; 3、ForkJoinWorkerThread类1234//ForkJoinPool，所有线程和WorkQueue共享，用于工作窃取、任务状态和工作状态同步final ForkJoinPool pool; //当前线程的任务队列，与WorkQueue的owner对应final ForkJoinPool.WorkQueue workQueue; 4、ForkJoinTask类status: 任务的状态，对其他工作线程和pool可见，运行正常则status为负数，异常情况为正数 ​ 上面各个类及变量关系大致如下图所示：ForkJoinPool作为最核心的组件，维护了所有的任务队列WorkQueues，workQueues维护着所有线程池的工作线程，工作窃取算法就是在这里进行的。每一个WorkQueue对象中使用pool保留对ForkJoinPool的引用，用来获取其WorkQueues来窃取其他工作线程的任务来执行。同时WorkQueue对象中的owner是ForkJoinWorkerThread工作线程，绑定ForkJoinWorkerThread和WorkQueue的一对一关系，每个工作线程会优先完成自己队列的任务，当自己队列中的任务为空时，才会通过工作窃取算法从其他任务队列中获取任务。WorkQueue中的ForkJoinTask&lt;?&gt;[] array，是每一个具体的任务，插入array中的第一个任务是最大的任务。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F18%2F%E6%B7%B1%E5%85%A5%E5%88%86%E6%9E%90AQS%E5%AE%9E%E7%8E%B0%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[深入分析AQS实现原理概述AQS是 AbstractQueuedSynchorinizer的简写，中文名是队列同步器。AQS是Java实现阻塞式锁和同步工具的基石。它使用一个int类型的成员变量表示同步状态，通过内置的一个FIFO队列完成资源获取线程的排队工作。AQS是一个抽象类，主要是通过继承的方式来使用，它本身没有实现任何的同步接口，仅仅是定义了同步状态的获取以及释放的方法来提供自定义的同步组件。 一、AQS的实现分析1、基本实现原理AQS使用一个int成员变量state来表示同步状态，通过内置的FIFO队列来完成获取资源线程的排队工作。 状态信息通过protected类型的getState()，setState()，compareAndSetState()进行操作。AQS支持两种类型的同步方式： 独占式：同一时刻只允许一个线程独占式的访问资源； 共享式：同一时刻允许多个共享式的线程访问资源； 共享式访问的资源时，其他共享式的访问均被允许，而独占式访问被阻塞；独占式访问资源时，同一时刻的其他访问均被阻塞。 这两种模式在AQS分别使用两个变量表示： ​ 这样设计方便使用者实现不同类型的同步组件，独占式如ReentrantLock，共享式如Semaphore，CountDownLatch，组合式的如ReentrantReadWriteLock。总之，AQS为使用提供了底层支撑，如何组装实现，使用者可以自由发挥。 同步器的设计是基于模板方法模式的，一般的使用方式是这样： （1）使用者继承AbstractQueuedSynchronizer并实现自定的方法。 （2）将AQS组合在自定义同步组件的实现中，并调用其模板方法，而这些模板方法会调用使用者重写的方法。这其实是模板方法模式的一个很经典的应用。同步器可以重写的方法如下： 12345protected boolean tryAcquire(int arg) //独占式的获取同步状态protected boolean tryRelease(int arg) //独占式释放同步状态protected int tryAcquireShared(int arg) //共享式的获取同步状态,返回值阿玉等于0表示获取成功protected boolean tryReleaseShared(int arg) //共享式的释放同步状态protected boolean isHeldExclusively() //当前同步器是否在独占模式下被线程使用 2、同步队列的基本数据结构​ 上面说到，AQS在其内部维护了一个队列，可是我还要告诉你它内部的等待队列实质是一个双向链表，链表中的每一个节点的构造如下(抛开无用的信息，先了解一下他的底层数据结构)： 12345678910111213141516171819public abstract class AbstractQueuedSynchronizer&#123; private volatile Node head; //等待队列的头结点 private volatile Node tail; //等待队列的尾结点 private volatile int state; //锁状态 //同步器中的结点是用来保证获取同步状态失败的线程引用、 //等待条件以及前驱和后继结点、结点的锁类型以及名称的 static class Node &#123; volatile Node perv; //前驱结点 volatile Node next; //后继结点 /***********和数据结构无关的字段****************/ volatile Thread thread; //获取同步的线程 Node nextWaiter; //请求的是共享锁还是独占锁 volatile int waitStatus; //等待状态 &#125; &#125; ​ 同步器依赖内部的同步队列来完成同步状态的管理，当线程获取同步状态失败的时，同步器会将当前线程以及等待信息等构成一个节点（Node）并将其加入到同步队列，同时会阻塞当前线程，当同步状态释放时，会把首节点的线程唤醒，使其尝试获取同步状态。 其中每一个Node结点在Node这个类中还定义了4种等待状态（waitStatus值）： CANCELLED（1）：表示当前线程已经别取消（等到超时或者被中断了） SIGNAL（-1）：表示后继线程需要被唤醒 CONDITION（-2）：表示结点线程等待在condition上，当被signal后，会从等待队列转移到同步到队列中 PROPAGATE（-3）：表示下一次共享式同步状态会被无条件地传播下去 0：当一个Node被初始化时waitStatus的默认值 3、同步队列加入结点的过程 ​ 结点加入到同步队列中以后进入一个自旋的过程，每个结点都在观察，当条件满足后，如果获取到了同步状态（锁）就可以从自旋状态病虫同步队列中移除，否则依旧留在同步队列自旋。同步队列是遵循FIFO的，首节点表示获取同步状态成功的结点，首节点的线程在释放同步状态时，将会唤醒后继结点，而后继结点将会在获取同步状态成功将会在此时将自己设置为头结点。 ​ 设置首节点是通过获取到同步状态的线程来完成的，有只有一个线程能够获取到同步状态，一次设置头结点的方法不需要使用CAS，他只需要将首节点设置成为原结点的后继结点即可（head-&gt;next=this.next;）。 二、AQS深入源码分析1、独占式同步锁的获取与释放流程分析通过调用同步器的acquire(int arg)方法可以获取同步状态，调用了该方法后的线程不会对中断操作响应。方法的代码如下： 方法的主要完成了同步状态获取、结点构造、加入同步队列以及在同步队列中自旋等操作。主要逻辑是： 首先调用tryAcquire(int arg)方法，该方法的作用是独占式获取同步状态，底层依赖CAS实现，如果获取成功返回true，否则返回false；需要注意的是，这个方法在AQS内部并没有真正的逻辑，他把这部分交给子类实现。 如果获取同步失败，则构造同步结点（独占式的，Node.EXCLUSIVE同一时刻只能有一个线程获取到同步锁）并通过addWaiter(Node node)方法将该节点加入到同步队列的尾部； 最后调用acquireQueued(Node node,int arg)方法使得该线程自旋。 进一步分析结点是如何构造以及加入到同步队列中的，下面是addWaiter()方法的源码： 首先把当前线程以及独占式参数为参数构造一个新节点node； 获取当前尾结点，如果尾结点不为空就把node的前驱结点设置为当前尾结点，之后在使用CAS把当前尾结点的后继结点这是为node，成功之后返回node; 如果当前尾结点为空，表示当前同步队列还没有初始化，此时会调用enq(Node node)方法进行初始化同步队列。 如果pred为null(说明同步队列还没与初始化)，或者pred在极端情况下被背的线程修改了。其实就需要看一下enq(Node node)方法的实现了。enq(Node node)方法的源码如下： 我们可以看到，在enq(Node node)方法中就是一个死循环配合CAS在不断的重试，直到CAS设置成功了才会返回，方法的主要逻辑如下： 获取当前同步队列的尾结点，判断如果是null（说明还没有初始化同步队列），就执行初始化，通过CAS为同步队列设置头结点（第一个结点），此过程循环配合CAS直到执行成功为止；请注意，初始化的头结点并不是当前线程节点，而是调用了无参构造函数的节点。 同步器初始化成功在配合CAS以及循环设置队尾，也是直到成功为止。在不断重试的过程中，只有通过CAS把结点设置成为了尾结点之后，当前线程才能从方法返回，否则就不断的重试。通过不断的重试，以及CAS机制，将并发的添加节点的操作串行化，从而保证了线程安全。 ​ 结点加入到同步队列后，线程就会进入到自旋的过程，每个线程都在观察，当条件满足，获取到了同步状态，就可以从自旋过程退出，否则依旧自旋。下面是acquireQueued(Node node,int arg)方法的源码： 在acquireQueued()方法中，当前线程不断的尝试获取同步状态，从代码中我们也看到了。只有当前驱是head的结点才可以尝试获取锁，这么做的理由有以下两个： （1）这样做可以维护队列的FIFO特性； （2）头结点是成功获取到同步状态的结点，二头结点的线程释放了同步状态后，将会唤醒其后继结点，后继结点的线程被唤醒或需要检查自己的前驱结点是否是头结点。 而acquireQueued()方法的逻辑主要如下： 首先获取当前节点的前驱结点，如果前驱节点是head，那么当前结点可以尝试获取锁； 获取锁成功后就不需要再进行同步操作了,获取锁成功的线程作为新的head节点； 如果获取锁失败，则根据节点的waitStatus决定是否需要挂起线程 如果在执行过程中抛出了异常则取消锁的获取并把当前结点出队 独占锁的获取流程（acquire(int arg)方法）的执行流程可以用下图说明： 当一个线程获得同步状态并执行完相应的逻辑之后，就需要释放同步同步状态，是的后续接待也可以获得同步状态。通过调用同步器的relaese(int arg)方法可以释放同步锁状态，该方法在释放了昂前线程的同步状态之后会唤醒其后继结点。下面是该方法的源码： 方法会首先调用tryRelaese(int args)释放同步状态，这个方法在AQS没有实现，需要子类实现具体的逻辑。tryRelaese(int args)返回true之后调用unparkSuccessor(h)方法,在这个方法内会使用LockSupport.unpark()方法唤醒当前结点的后继结点。关于LockSupport的原理可以参考我的博客LockSupport深入源码剖析 分析到这，适当的做个总结​ 在获取同步锁状态时，同步器维护了一个同步队列，获取同步状态失败的线程都会被包装成一个Node结点加入到同步器的尾部，在添加的时候是以CAS的方式设置尾结点的，并且添加进队列中的结点自旋；移除同步队列的条件是，当前结点的前驱结点是head结点并且成功获取到同步状态。在释放同步锁的时，同步器调用tryRelease(int arg)方法释放同步状态，并且调用LockSupport.unpark(Thread t)方法唤醒头结点的后续结点。 2、共享式同步状态的获取与释放流程分析通过调用同步器的acquireSahared(int arg)方法可以共享式的获取同步状态，源码如下： 在acquireSahared(int arg)方法中，同步器调用tryAcquire(int arg)方法尝试获取同步状态，这个方法同样地AQS没有没有具体实现，需要子类来实现。这个tryAcquire(int arg)方法返回一个int类型的值，当返回值大于等于0时，表示获取到了同步状态；否则就会调用doAcquireShared(int arg)以自旋的方式获取同步状态。doAcquire(int arg)方法源码如下： 在方法doAcquireShared(int arg)自旋的过程中，如果当前结点的前驱结点为head时，还是会调用tryAcquire(int arg)尝试获取同步状态，如果返回值大于等于0，表示获取同步状态成功，于是就可以退出自旋了。同样地，如果在自选的过程中发生了异常就会退出自旋，并且把当前结点从同步器中移除。 当共享式的同步状态的线程需要释放同步状态时同步器可以调用releaseSgared(int arg)方法释放同步状态。 在方法内部调用了tryReleaseShared(int arg)这个方法也是需要子类去实现的，当到方法返回true时表明释放同步状态成功，如果首次调用释放同步状态失败就会调用doReleaseShard(int arg)方法以自旋的方式不断重试 释放同步状态。同时由于这是共享式的，为了保证多个线程同时访问的并发性，方法内部采用了CAS。最终方法会唤醒头头结点的下一个结点，使用方法任然是unparkSuccessor(h)，这个方法在上面分析过，他其实是调用了LockSupport.unpark()方法。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F18%2F%E9%9D%A2%E8%AF%95%E5%B8%B8%E9%97%AE%E7%9A%84%E5%87%A0%E4%B8%AAJava%E5%B9%B6%E5%8F%91%E5%B7%A5%E5%85%B7%E7%B1%BB%E4%BD%A0%E9%83%BDGET%E5%88%B0%E4%BA%86%E5%90%97%EF%BC%9F%2F</url>
    <content type="text"><![CDATA[面试常问的几个Java并发工具类你都GET到了吗？在JDK的并发中提供了几个非常有用的并发工具类。CountDwonLatch、CyclicBarrier、Semaphore以及Exchanger。下面我们就一起了解一下这些类的基本使用以及基本原理吧。 PS：最起码你得知道它们是干什么用得，下面列出得代码也建议你跑跑。其实如果你理解AQS的设计原理的话，这些工具类的原理就不难理解了。 一、闭锁 CountDwonLatchCountDownLatch允许一个或多个线程等待其他线程完成操作之后在进行下面的业务的场景。作用类似于Thread类中的join()方法，但是比join()方法更加强大。下面是一个简单的使用示例： 123456789101112131415161718192021222324252627282930313233343536373839404142public class CountDownLatchTest &#123; public static void main(String[] args) throws InterruptedException &#123; //CountDownLatch的构造参数接收一个int类的参数作为计数器，如果你想等待N个线程，就传入N CountDownLatch latch = new CountDownLatch(2); new Thread(() -&gt; &#123; System.out.println("t1 do with service ......"); //模拟耗时1s try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("t1 do with service done!"); //让锁状态计数器state减1 latch.countDown(); &#125;, "t1").start(); new Thread(() -&gt; &#123; System.out.println("t2 do with service ......"); //模拟耗时1s try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("t2 do with service done!"); //让锁状态计数器state减1 latch.countDown(); &#125;, "t2").start(); System.out.println("wait start...."); latch.await(); //主线程会在这一步阻塞，直到计数器的值减为0了才会退出阻塞状态 /** * 另一个重载方法，可以指定等待的超时时间，超时后计数器的值如果还没减为0也会退出阻塞,用法如下： * if(!latch.await(5, TimeUnit.SECONDS))&#123; * System.out.println("wait time out... withdraw blocking state"); * &#125; */ System.out.println("wait end."); &#125;&#125; 执行结果 为什么join()方法和他的作用类似还需要CountDownLatch？答：因为join()的阻塞原理是不断检查join()所属的线程是否存活，如果线程还存活这就继续阻塞，直到线程死亡了才会退出join()阻塞。但是在实际应用场景下我们一般都是使用线程池来维护线程资源的，怎么可能随意的让一个线程死亡，此时join()就没法使用了，CountdDownLatch就可以解决这个问题，CountDownLatch的阻塞原理是仅仅关注计数器是否为0，若为0才保持阻塞，它并不关注持有计数器的其它线程是否完全执行完毕。 下面是一个CountDownLatch配合线程池使用的示例： 1234567891011121314151617181920212223242526272829303132333435363738394041public class CountDownLatchTest2 &#123; public static void main(String[] args) &#123; ThreadPoolExecutor threadPool = new ThreadPoolExecutor(5, 10, 60, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(10), Executors.defaultThreadFactory(), new ThreadPoolExecutor.CallerRunsPolicy()); CountDownLatch latch = new CountDownLatch(15); try &#123; threadPool.execute(() -&gt; &#123; try &#123; System.out.println("等待其他线程执行完先前操作......."); latch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("最后一步操作开始执行...."); //TODO &#125;); for (int i = 0; i &lt; 15; i++) &#123; int tmp = i; threadPool.execute(() -&gt; &#123; try &#123; //模拟业务处理耗时tmp s Thread.sleep(tmp*1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; latch.countDown(); System.out.println("第" + tmp + "步操作完成"); &#125;); &#125; &#125; finally &#123; //程序执行结束，关闭线程池 threadPool.shutdown(); &#125; &#125;&#125; 执行结果 CountDownLatch原理简单分析CountDownLatch是基于AQS实现的一个同步工具，大部分和同步状态有关的操作在AQS中已经被实现了，CountDownLatch采用在内部聚合AQS的方式，实现了对多个线程的同步控制。在CountDownLatch中有一个内部类Sync继承了AQS，下面是Sync的全部实现： 我们可以看到Sync的构造方法可以接受一个int类型的参数，这个参数就是计数器的值，这个值最终通过setState()方法设置给了AQS中的一个控制同步队列锁状态的字段state。再来看看CountDonwLatch的构造方法就立刻明白了： 在构造方法中直接new了一个Sync,并把我们传入的参数又传给了Sync。 再来看看countDown()方法干了啥： 可以看到，countDown()方法直接调用了同步器的releaseShared()方法，这个方法我的另一篇博客中深入源码分析AQS实现原理中解析过，在这个方法中会首先调用上面Sync子类中的tryReleaseShared()方法，在这个方法中会循环的把AQS中的state字段的值减1，直到减为0了就返回true,表示同步状态释放了。 二、同步屏障 CyclicBarrierCyclicBarrier（[ˈsaɪklɪk ˈbæriə(r)]，同步屏障），作用和CountDownLatch类似，CyclicBarrier的构造方法同样也需要一个int类型的参数，然后计算调用了CyclicBarrier.await()进入阻塞的线程数。当线程数达到了这个数目时，所有进入等待状态的线程被唤醒并继续。 CyclicBarrier就象它名字的意思一样，可看成是个屏障， 所有的线程必须到齐后才能一起通过这个屏障。 CyclicBarrier初始时还可带一个Runnable的参数， 此Runnable任务在CyclicBarrier的数目达到后，所有其它线程被唤醒前被执行。 123456789101112131415161718192021222324252627282930313233343536public class CyclicBarrierTest &#123; public static void main(String[] args) &#123; ThreadPoolExecutor threadPool = new ThreadPoolExecutor(5, 10, 60, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(10), Executors.defaultThreadFactory(), new ThreadPoolExecutor.CallerRunsPolicy()); CyclicBarrier cyclicBarrier = new CyclicBarrier(5); for (int i = 0; i &lt; 5; i++) &#123; threadPool.execute(new Writer(cyclicBarrier)); &#125; threadPool.shutdown(); &#125;&#125;class Writer extends Thread &#123; private CyclicBarrier cbr; public Writer(CyclicBarrier cbr) &#123; this.cbr = cbr; &#125; @Override public void run() &#123; try &#123; System.out.println("线程" + Thread.currentThread().getName() + ",正在写入数据"); Thread.sleep((int)Math.random()*1000); System.out.println("线程" + Thread.currentThread().getName() + ",写入数据成功....."); cbr.await(); System.out.println("所有线程执行完毕.........."); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; 执行结果 CyclicBarrier和CountDownLatch的区别？ 答：CyclicBarrier的计数器可以使用reset()方法重置为初始值，而CountownLatch的计数器是一次性的。不可以恢复。基于这一点，CyclicBarrier能处理更为复杂的业务场景，比如计算发生错误，可以重置计数器，并让线程重新执行一次。 三、信号量 SemaphoreSemaphore（ [ˈseməfɔːr]，信号量），它可以设定一个阈值，基于此，多个线程竞争获取许可信号，做自己的申请后归还，超过阈值后，线程申请许可信号将会被阻塞。 Semaphore可以用来进行流量控制，特别是资源有限的应用场景，比如构建一些对象池，资源池之类的我们也可以创建计数为1的Semaphore，将其作为一种类似互斥锁的机制，这也叫二元信号量，表示两种互斥状态。下面有Semphore实现一个简单的数据库连接池： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113public class SimpleDBPool &#123; //连接池大小 private int poolSize; //数据库连接数组 private Connection[] connections; //流量控制 private Semaphore semaphore; //连接是否在使用中 0表示未使用，1表示在使用 private AtomicIntegerArray busy; public SimpleDBPool(int poolSize) &#123; this.poolSize = poolSize; this.semaphore = new Semaphore(poolSize); connections = new Connection[poolSize]; busy = new AtomicIntegerArray(poolSize); for (int i = 0; i &lt; poolSize; i++) &#123; connections[i] = new DBUtil("jdbc:mysql://xxx.xxx.xxx.xxx:3306/xxx?autoReconnect=true&amp;useSSL=false&amp;characterEncoding=utf-8&amp;zeroDateTimeBehavior=convertToNull&amp;serverTimezone=Asia/Shanghai").getConnection(); &#125; &#125; //使用数据库连接 public Connection borrow() &#123; try &#123; semaphore.acquire(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; for (int i = 0; i &lt; poolSize; i++) &#123; if (busy.get(i) == 0 &amp;&amp; busy.compareAndSet(i, 0, 1)) &#123; System.out.println(Thread.currentThread().getName()+"获得数据库连接==&gt;"+connections[i]+" ,开始执行查询任务...."); return connections[i]; &#125; &#125; //程序永远不会执行带这一行 return null; &#125; //归还数据库连接 public boolean free(Connection connection) &#123; for (int i = 0; i &lt; poolSize; i++) &#123; if (connection == connections[i]) &#123; busy.set(i, 0); semaphore.release(); System.out.println(Thread.currentThread().getName()+"查询结束，归还数据库连接"+connections[i]); return true; &#125; &#125; return false; &#125; static class DBUtil &#123; private String url = null; //数据库的链接地址 public DBUtil(String url) &#123; this.url = url; &#125; //静态代码块，初始化类的时候就加载数据库驱动 static &#123; try &#123; Class.forName("com.mysql.cj.jdbc.Driver"); //加载数据库驱动 &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125; private Connection getConnection() &#123; Connection con = null; try &#123; //暂时先写死 con = DriverManager.getConnection(url, "root", "password"); &#125; catch (SQLException e) &#123; System.out.println("数据库操作异常，请检查用户名、密码"); e.printStackTrace(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; return con; &#125; &#125;&#125;class Test &#123; public static void main(String[] args) &#123; //维护3个连接的数据库连接池 SimpleDBPool dbPool = new SimpleDBPool(3); //线程池 ThreadPoolExecutor threadPool = new ThreadPoolExecutor(5, 10, 60, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(10), Executors.defaultThreadFactory(), new ThreadPoolExecutor.CallerRunsPolicy()); for(int i=0;i&lt;5;i++)&#123; threadPool.execute(()-&gt;&#123; Connection connection = dbPool.borrow(); try &#123; //模拟数据库查询耗时 10s Thread.sleep(10_000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; dbPool.free(connection); &#125;); &#125; threadPool.shutdown(); &#125;&#125; 执行结果 在代码中，虽然有5个线程需要获取数据库连接，但是通过Semaphore限流，每次最大允许3个线程获得数据库连接，从而保证了数据库的安全性。 Semaphore除了上面使用的两个方法： acquire()和release() 之外，还提供了许多有用的方法： 12345public int availablePerimits() //返回此信号量中当前可用的许可证数public int getQueueLength() //返回正在等待获取许可的线程数public boolean hasQueuedThreads() //是否有线程正在等待获取许可protected void reducePermits(int reduction) //减少reduction个许可证protected Collection getQueuedThreads() //返回所有正在等待获取许可的线程的集合]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F18%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3CnocurrentHashMap%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[深入理解CnocurrentHashMap原理HashMap在多线程环境下有线程安全问题，因此在多线程环境下不要直接使用HashMap，而是使用下面几种不同的方式去代替： （1）使用ConcurrentHashMap （2）使用Hashtable （3）使用Collections.synchronizedMap(Map map)方法将HashMap包装成一个线程安全的集合 不过鉴于要保证多线程环境下程序的并发度，后两种方案直接Pass，因为他们保证线程安全的机制是synchronized，在并发很高的环境下效率很低，此时我们就可以使用ConcurrentHashMap。 一、jdk1.7的实现以及源码分析1、 ConcurrentHashMap的数据结构jdk1.7 的ConcurrentHashMap的底层数据结构是数组+链表，如下图所示 ConcurrentHashMap是由Segment数组结构和HashEetry数组组成。Segment继承了ReentrantLock，是一个可重入的锁，它在ConcurretnHashMap中扮演锁的角色；HashEntry则用于存储键值对。它们之间的关系是：一个ConcurrentHashMap包含了一个Segment数组，一个Segment里维护了一个HashEntry数组，HashEntry数组和HashMap结构类似，是一种数组+链表的结构，当一个线程需要对HashEntry中的元素修改的时候，必须先获得Segment锁，下面是ConcutrrentHashMap的类图： 2、Segment内部类Segment是ConcurrentHashMap的内部类，主要组成如下： 123456789101112131415161718192021static final class Segment&lt;K,V&gt; extends ReentrantLock implements Serializable &#123; private static final long serialVersionUID = 2249069246763182397L; // 和 HashMap 中的 HashEntry 作用一样，真正存放key-value的bucket transient volatile HashEntry&lt;K,V&gt;[] table; transient volatile int count; // 记得快速失败（fail—fast）么？ transient int modCount; // 大小 transient int threshold; // 负载因子 final float loadFactor; //构造方法 Segment(float lf, int threshold, HashEntry&lt;K,V&gt;[] tab) &#123; this.loadFactor = lf; this.threshold = threshold; this.table = tab; &#125; &#125; HashEntry是一个和HashMap类似的数据结构，这里值的注意的是他被volatile修饰了。这里复习一下volatile的特性： （1）可以保证共享变量在多线程之间的可见性，即一个线程修改了共享变量的值对于其他线程是这个修改后的是可见的； （2）可以禁止指令重排序； （3）volatile可以保证对单次读写操作的原子性； 3、ConcurrentHashMap的构造方法ConcurrentHashMap的构造方法中通过initialCapacity、loadFactor、concurrencyLevel三个参数完成了对Segment数组、段偏移量segmentShift、段掩码segmentMask和每一个Segment里的HashEntry数组的初始化。我们来看看源码是如何实现的： 12345678910111213141516171819202122232425262728293031public ConcurrentHashMap(int initialCapacity, //初始容量 默认是16 float loadFactor, //加载因子 默认0.75 int concurrencyLevel) &#123; //并发度 由DEFAULT_CONCURRENCY_LEVEL 决定 if (!(loadFactor &gt; 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); if (concurrencyLevel &gt; MAX_SEGMENTS) concurrencyLevel = MAX_SEGMENTS; // Find power-of-two sizes best matching arguments int sshift = 0; //计算ssize左移的次数 int ssize = 1; //计算segment的大小 while (ssize &lt; concurrencyLevel) &#123;//segment的大小为2^n ++sshift; ssize &lt;&lt;= 1; &#125; this.segmentShift = 32 - sshift; this.segmentMask = ssize - 1; if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY; int c = initialCapacity / ssize;//计算每个segment的大小 if (c * ssize &lt; initialCapacity)//若是条件成立，表示c有余数，所以增加一个segment ++c; int cap = MIN_SEGMENT_TABLE_CAPACITY; while (cap &lt; c) cap &lt;&lt;= 1; Segment&lt;K,V&gt; s0 = new Segment&lt;K,V&gt;(loadFactor, (int)(cap * loadFactor), (HashEntry&lt;K,V&gt;[])new HashEntry[cap]); Segment&lt;K,V&gt;[] ss = (Segment&lt;K,V&gt;[])new Segment[ssize]; UNSAFE.putOrderedObject(ss, SBASE, s0); // ordered write of segments[0] this.segments = ss; &#125; 我们来捋捋构造方法： 首先了解几个常量： 1234567static final int DEFAULT_CONCURRENCY_LEVEL = 16; //初始的并发等级，通过并发等级来确定Segment的大小static final int MIN_SEGMENT_TABLE_CAPACITY = 2;// segment的最小值.2 static final int MAX_SEGMENTS = 1 &lt;&lt; 16; //segment数组最大长度，65535private static final int MAXIMUM_CAPACITY = 1 &lt;&lt; 30; //每个HashEnty数组的最大长度 2^30 初始化Segment数组1234567891011121314151617181920if (!(loadFactor &gt; 0) || initialCapacity &lt; 0 || concurrencyLevel &lt;= 0) throw new IllegalArgumentException(); if (concurrencyLevel &gt; MAX_SEGMENTS) concurrencyLevel = MAX_SEGMENTS; //Segment数组的大小必须是2的幂，比兔2，4，8.... int sshift = 0; //计算ssize左移的次数 int ssize = 1; //计算segment的大小 while (ssize &lt; concurrencyLevel) &#123;//segment的大小为2^n ++sshift; //sshift ssize &lt;&lt;= 1; &#125; //segmentShift默认值32-4=28 this.segmentShift = 32 - sshift; //segmentMask默认值是 15 即 0000 0000 0000 1111 this.segmentMask = ssize - 1; . . . Segment&lt;K,V&gt;[] ss = (Segment&lt;K,V&gt;[])new Segment[ssize]; this.segments = ss; 由上面的代码可以知道，Segment数组的长度是ssize,这个参数又是通过concurrencyLevel计算出来的。我了通过按位与的散列算法来定位segment数组索引，必须保证segment数组的长度是2的幂，所以必须计算出一个大于等于concurrencyLevel的最小2个幂大小的数组长度。同时concurrencyLevel最大值是2^16,即65535个，这意味着Segment数组的大小最大也是65535。 初始化segmentShift和segmentMask这两个变量狮是在定位segment是的散列算法中用的，segmentShift用于定位参与散列计算的位数，segmentShift=32-sshift，其中sshift等于ssize从1向左移的次数，在默认情况下concurrencyLevel是16，因此ssize=16,sshift=4。，所以默认情况下是28。 segmentMask是散列运算的掩码，等于ssize-1，默认是15，掩码的二进制的各个位一般都是1.因为ssize的最大长度是65536，所以segmentShift的最大值是16，segmentMask的最大值是65536. 初始化每个Segment1234567891011if (initialCapacity &gt; MAXIMUM_CAPACITY) initialCapacity = MAXIMUM_CAPACITY;int c = initialCapacity / ssize;//计算每个segment的大小if (c * ssize &lt; initialCapacity)//若是条件成立，表示c有余数，所以增加一个segment ++c;int cap = MIN_SEGMENT_TABLE_CAPACITY; //cap=2 while (cap &lt; c) cap &lt;&lt;= 1;//创建一个segment,并且放在 segment[ 0]Segment&lt;K,V&gt; s0 = new Segment&lt;K,V&gt;(loadFactor, (int)(cap * loadFactor), (HashEntry&lt;K,V&gt;[])new HashEntry[cap]); 上面代码中cap的值就是每个HashEntry数组的初始长度，他等于initialCapacity/ssize的倍数，如果有余数在+1。如果c大于1，就会取待遇等于c的2的幂的值，所以c只可能是1或者是2^n。 4、定位SegmentConcurrentHashMap使用了分段锁Segment来维护不同段的数据，那么在插入和获取元素的时候，必须先通过算法定位到Segment上之后才可以在具体的HashEntry用类似HashMap找元素的方法来定位一个元素。首先来看看ConcurretnHashMap使用的hash算法： 12345678private static int hash(int h)&#123; h+=(h&lt;&lt;15)^0xffffcd7d; h^=(h&gt;&gt;&gt;10); h+=(h&lt;&lt;3); h^=(h&gt;&gt;&gt;6); h+=(h&lt;&lt;2)+(h&lt;&lt;14); return h^(h&gt;&gt;&gt;16);&#125; 通过这个hash算法对hashCode在散列，目的是减少hash冲突，是元素可以均匀的分布在egment数组内，提高容器的使用率。基于这个hash(int h)计算出来的hash值，Segment通过下面这个算法定位到具体的Segment: 123final Segment&lt;K,V&gt; segmentFor(int h)&#123; return segments[(hash&gt;&gt;&gt;segmentShift)&amp;segmentMask];&#125; 默认情况下，segmentShift是28，segmentMask是15，因此hash&gt;&gt;&gt;segmentShift的意思就是让hash值的高4位参与到定位Sengmet运算中，上面说到过，segmentMask是散列运算的掩码，它等于ssize-1，ssize又是一个2的幂的数，因此segmentMask二进制的低位是连续的1，那么最终决定Segment位置索引的就是hash&gt;&gt;&gt;segmentShift的值。 5、put()操作put操作需要在定位到Segment之后，对Segment加锁。 如果value==null，空指针异常； 如果value不是null 首先，计算hash(key)，最终的hash值是hashCode(key) ^ hashSeed之后，再经过各种位操作之后的值 然后，通过（hash&gt;&gt;&gt;segmentShift）&amp; segmentMark算法得到Segment[]的下标 构造器中只初始化了Segment[]下标0处的Segment对象，在put时，确定了Segment的位置，先判断该位置上的Segment有没有初始化，没有，先初始化 最后，调用Segment对象的put方法存入键值对。 对每个Segment加锁 确定HashEntry[]的下标。index = (tab.length - 1) &amp; hash; 如果当前HashEntry没有初始化，先初始化，并将键值对插入 已经初始化，遍历HashEntry链，有重复的，新值覆盖旧值，否则，插入 插入之前，判断是否需要扩容，扩容：Segment[]是不能扩容的，只能扩容一个个Segment中的HashEntry[]的大小为原来的两倍 下面结合源码和注释来说明： 1234567891011121314public V put(K key, V value) &#123; //找到对应的segment,把key，value放入对应的segment中 Segment&lt;K,V&gt; s; //value不允许为null if (value == null) throw new NullPointerException(); int hash = hash(key); //定位Segment：(hash&gt;&gt;&gt;sengmentShift)&amp; segmentmask int j = (hash &gt;&gt;&gt; segmentShift) &amp; segmentMask; if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObject(segments, (j &lt;&lt; SSHIFT) + SBASE)) == null) //初始化segments[j] s = ensureSegment(j); return s.put(key, hash, value, false);&#125; Segment内部的put()方法： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263final V put(K key, int hash, V value, boolean onlyIfAbsent) &#123; //每个segment进行put操作的时候都要进行加锁操作 tryLock()方法尝试获取锁 HashEntry&lt;K,V&gt; node = tryLock() ? null : //尝试获取锁失败，计进入 scanAndLockForPut流程，循环尝试获取锁 scanAndLockForPut(key, hash, value); //执行到这里，Segment就已经加上锁了，可以安全执行了 V oldValue; try &#123; //每个Segment中维护了一个HashEntry数组叫table HashEntry&lt;K,V&gt;[] tab = table; //定位HashEntry： hash&amp;(tab.lenght-1) int index = (tab.length - 1) &amp; hash; //找到HashEntry数组中table[index]元素（链表头结点） HashEntry&lt;K,V&gt; first = entryAt(tab, index); //遍历链表 for (HashEntry&lt;K,V&gt; e = first;;) &#123; //e就是每个从链表中取出的结点 if (e != null) &#123; //更新key-value K k; //hash值相等 并且equals方法返回true就说明这是要找的key if ((k = e.key) == key || (e.hash == hash &amp;&amp; key.equals(k))) &#123; oldValue = e.value; if (!onlyIfAbsent) &#123; //替换新值 e.value = value; ++modCount; &#125; //修改成功，退出循环 break; &#125; e = e.next; &#125; else &#123; //新增key-value if (node != null) //1)之前等待锁的时候，如果新的链表接待被创建了，那就把值设置进去，并把此结点的next指向当前链表的头结点 node.setNext(first); else //2)如果显得结点还没创建，那就直接new一个 node = new HashEntry&lt;K,V&gt;(hash, key, value, first); //c就是当前HashEntry的元素多少 size int c = count + 1; //如果错过了阈值并且当前HashEntry的长度小于最大允许长度2^30就会扩容 if (c &gt; threshold &amp;&amp; tab.length &lt; MAXIMUM_CAPACITY) rehash(node); else //如果没有超过阈值，那就把新新节点插入链表头部 setEntryAt(tab, index, node); ++modCount; count = c; oldValue = null; //添加成功，退出循环 break; &#125; &#125; &#125; finally &#123; unlock(); &#125; return oldValue; &#125; 6、rehash()扩容操作Segment数组的长度一旦确定就不能改变，当一个Segment数组在插入新元素之前会先判断是否超过阈值，如果超阈值了，就会扩容，并且只是扩容当前Segment中的HashEntry[]。总的来说，Segment对扩容时机的判断比HashMap更恰当，因为HashMap的扩容是在元素添加会后判断的，如果超过阈值就会扩容，但是很有可能扩容之后就没有新元素插入了，这时HashMap就进行了一次无效的扩容。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061private void rehash(HashEntry&lt;K,V&gt; node) &#123; //因为rehash()操作是被put()调用的，pput()已经获取过锁了，这里就不需要再获取锁了 HashEntry&lt;K,V&gt;[] oldTable = table; //获取旧表的容量 int oldCapacity = oldTable.length; //新表对容量*2 int newCapacity = oldCapacity &lt;&lt; 1; //计算新的阈值 threshold = (int)(newCapacity * loadFactor); //创建新的HashEntry数组，大小是旧数组的2倍 HashEntry&lt;K,V&gt;[] newTable = (HashEntry&lt;K,V&gt;[]) new HashEntry[newCapacity]; int sizeMask = newCapacity - 1; //遍历旧的HashEntry数组 把其中的元素移动到新的HashEntry数组中 for (int i = 0; i &lt; oldCapacity ; i++) &#123; //HashEntry数组索引为i的槽位的值 HashEntry&lt;K,V&gt; e = oldTable[i]; //HashEntry数组索引为i的槽位的值如果不为空就搬移 if (e != null) &#123; //尝试获取链表头结点的下一个结点 HashEntry&lt;K,V&gt; next = e.next; int idx = e.hash &amp; sizeMask; if (next == null) // Single node on list //该槽位只有一个节点，直接搬移过去 newTable[idx] = e; else &#123; // Reuse consecutive sequence at same slot //链表上有多个结点 HashEntry&lt;K,V&gt; lastRun = e; int lastIdx = idx; //由于扩容之后有些key的索引就会改变，需要找到key发生变化的结点和新索引 for (HashEntry&lt;K,V&gt; last = next; last != null; last = last.next) &#123; int k = last.hash &amp; sizeMask; if (k != lastIdx) &#123; //新索引 lastIdx = k; //节点 lastRun = last; &#125; &#125; newTable[lastIdx] = lastRun; // Clone remaining nodes for (HashEntry&lt;K,V&gt; p = e; p != lastRun; p = p.next) &#123; V v = p.value; int h = p.hash; int k = h &amp; sizeMask; HashEntry&lt;K,V&gt; n = newTable[k]; newTable[k] = new HashEntry&lt;K,V&gt;(h, p.key, v, n); &#125; &#125; &#125; &#125; //扩容完成后插入新的结点 int nodeIndex = node.hash &amp; sizeMask; // add the new node //设置新节点为头结点 node.setNext(newTable[nodeIndex]); newTable[nodeIndex] = node; //更新table table = newTable; &#125; 7、get操作Segment的get操作实现非常简单和高效。先经过一次hash()，然后使用散列值运算定位到Segment，在定位到聚义的元素的过程。 get操作的高效是因为整个get操作不需要加锁，为什么他不需要加锁呢？是因为get方法中使用的共享变量都被定义成了volatile类型，比如：统计当前Segment大小的count，和用于存储key-value的HashEntry。定义成volatile的变量能够在多个先后餐呢个之间保证可见性，如果与多个线程读，它读取到的值一定是当前这个变量的最新值。 123456789101112131415161718192021222324public V get(Object key) &#123; Segment&lt;K,V&gt; s; // manually integrate access methods to reduce overhead HashEntry&lt;K,V&gt;[] tab; //计算key的hash值 int h = hash(key); //u为segment对象在数组中的偏移量 long u = (((h &gt;&gt;&gt; segmentShift) &amp; segmentMask) &lt;&lt; SSHIFT) + SBASE; //s就是segment对象 if ((s = (Segment&lt;K,V&gt;)UNSAFE.getObjectVolatile(segments, u)) != null &amp;&amp; (tab = s.table) != null) &#123; //((long)(((tab.length - 1) &amp; h)) &lt;&lt; TSHIFT) + TBASE是目标key的槽位在HashEntry的偏移量 //下面的for循环就是遍历链表的 for (HashEntry&lt;K,V&gt; e = (HashEntry&lt;K,V&gt;) UNSAFE.getObjectVolatile (tab, ((long)(((tab.length - 1) &amp; h)) &lt;&lt; TSHIFT) + TBASE); e != null; e = e.next) &#123; K k; if ((k = e.key) == key || (e.hash == h &amp;&amp; key.equals(k))) //找到目标值返回 return e.value; &#125; &#125; //没找到返回null return null; &#125; 8、size操作size()就是求当前ConcurrentHashMap中元素个数的方法，它是弱一致性的。方法的逻辑大致是：首先他会使用不加锁的模式去尝试多次计算 ConcurrentHashMap 的 size，最多三次，比较前后两次计算的结果，结果一致就认为当前没有元素加入或删除，计算的结果是准确的，然后返回此结果；如果尝试了，他就会给每个 Segment 加上锁，然后计算 ConcurrentHashMap 的 size 返回。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public int size() &#123; final Segment&lt;K,V&gt;[] segments = this.segments; //ConcurrentHashMap大小 int size; boolean overflow; // true if size overflows 32 bits //当前size最新统计的size大小 long sum; // sum of modCounts //前一次的size大小 long last = 0L; // previous sum //重试的次数 int retries = -1; // first iteration isn't retry try &#123; for (;;) &#123; //操作次数，加锁 if (retries++ == RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) //ensureSegment方法确保Segment是被初始化了的 ensureSegment(j).lock(); // force creation &#125; sum = 0L; size = 0; overflow = false; //遍历所有Segment，把所有Segment中的元素个数相加==&gt;这个值在modCount中 for (int j = 0; j &lt; segments.length; ++j) &#123; Segment&lt;K,V&gt; seg = segmentAt(segments, j); if (seg != null) &#123; sum += seg.modCount; int c = seg.count; if (c &lt; 0 || (size += c) &lt; 0) overflow = true; &#125; &#125; if (sum == last) break; last = sum; &#125; &#125; finally &#123; //结束后如果尝试的次数大于RETRIES_BEFORE_LOCK就说明加锁了，在这里需要把每个Segment解锁 if (retries &gt; RETRIES_BEFORE_LOCK) &#123; for (int j = 0; j &lt; segments.length; ++j) segmentAt(segments, j).unlock(); &#125; &#125; //返回结果 return overflow ? Integer.MAX_VALUE : size;&#125; 二、jdk1.8的实现以及源码分析1、ConcurrentHashMap的数据结构JDK1.8的实现已经摒弃了Segment的概念，而是直接使用 数组+链表+红黑树 的数据结构来实现的，并发控制使用的是CAS+synchronized,jdk1.8版本的ConcurrentHashMap看起来就像是优化过之后线程安全的HashMap,虽然在JDK1.8中还能看到Segment，但是已经简化了属性，只是为了兼容旧版本。 ​]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F09%2F%E6%B7%B1%E5%85%A5%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90ReentrantLock%2F</url>
    <content type="text"><![CDATA[深入源码剖析ReentrantLock一、从Lock接口说起锁时用来控制多个线程范文共享资源，保证资源安全性的一种重要手段。在Lock接口出现以前，Java陈旭是靠synchorinzed关键字实现锁功能点的，在jdk1.5之前使用synchroinzed绝对是一个重量级的操作，因为synchroinzed是依赖对象锁实现的，而对象锁（ObjectMonitor）又依赖底层操作系统的mutex lock指令，这个指令需要操作系统在用户态和内核态不断的切换，这是一个很消耗CPU资源的操作。好的一点是Java在jdk 1.5提供了J.U.C并发包，其中新增的Lock接口具有和synchorinzed同样的锁功能，只是在使用的时候需要我们显示的获取和释放锁。 就像下面这样： 1234567Lock lock=new ReentrantLock();lock.lock();try&#123; //TODO&#125;finally&#123; lock.unlock();&#125; Lock接口的APILock是一个接口，它定义了所的获取和释放的基本操作，Lock接口定义方法有如下几个： 123456void lock() //获取锁，调用该方法的线程会获取锁void lockInterruptibly() //可中断地获取锁，该方法可以在获取锁的过程中响应中断boolean tryLock() //尝试分阻塞的获取锁，调用该方法后立即返回，如果获取到锁了返回true,否者返回falseboolean tryLock(long time,TimeUtil util) throws InterrutptionException //超时获取锁void unlock() //释放锁Condition newCondition() //获取等待通知组件，该组件和当前的锁绑定，当前线程只有获得了锁才能调用该组件的wait()方法，调用方法后当前线程释放锁 Lock接口中的这些接口方法在ReentrantLock这个类中有具体的实现，接下来我们来首先了解一下ReentrantLock的基本特性，之后我们在深入源码分析一下这把锁的原理。 二、ReentrantLock基本特点 （1）可重入：和synchronized一样是一个可重入锁 （2）可以响应中断：ReenTrantLock提供了一种能够中断等待锁的线程的机制。 （3）可以通过构造器构造 公平锁 还是 非公平锁 ：ReenTrantLock可以指定是公平锁还是非公平锁; synchronized只能是非公平锁。 （4）可以在获取锁的时候设置超时时间 （5）需要显示的获取和释放锁 三、深入源码分析RentrantLock在阅读ReentrantLock的源码之前，我建议你最好是知道CAS、volatile、以及AQS这些基本的概念的，不然你会越读越糊涂。如果你确实对这些知识优点含糊不清或者压根不知道，那么你可以百度先了解一下，或者你也可以在我的博客Java多线程与高并发分类中找到相应的文章学习。 好了，我么回到主题。首先我们来看一下ReentranLock的类图： 从类图中可以直观的看到，Reentrantlock继承了上面我们说的Lock接口，并且在其内部有三个内部类：Sync、NonfairSync、FairSync。其中Sync继承了AQS，NonfairSync、FairSync继承了Sync，他们分别是非公平锁好公平锁的实现。接下来我们对这三个部分详细分析一下。 1、ReentrantLock的构造方法ReentrantLock有两个构造方法，默认无参的构造方法是一个非公平锁，但是我们可以使用另一个有参构造方法构建一个公平锁。下面是两个构造方法的源码： 可以看到，默认的无参构造方法他是直接new了一个非公平同步器（即非公平锁），而在有参构造方法中，我们传入true表示构造一个公平锁，反之就是非公平锁。 你问我 sync 变量是啥？这是整个ReentrantLock唯一的一个成员变量，ReentrantLock就是通过聚合了一个同步器的子类完成了对多个线程的访问控制。 Sync是一个抽象类，因此在使用的时候一定需要一个具体的实现类，NonfairSync、FairSync就是具体的实现。 现在我们大概已经理清了ReentrantLock中各部分之间的关系了，接下来，我们就从非公平锁入手分析一下lock.lock()这条语句的执行流程。下面使我们在程序中调用的lock()方法的源码： 2、深入源码分析获取非公平锁原理 在public void lock()方法中调用了Sync类的lock()方法，这个方法在NonFairSync中的实现如下： 方法的大致逻辑如下： 1、首先调用AQS中的compareAndSetState(int,int)方法先尝试将控制同步状态的变量由0变为1 ，如果操作成功了就表示同步锁获取成功了（这一步就是非公平性产生的原因），之后就将当前线程设置为独占锁的拥有者； 如果首次获取尝试失败就会调用acquire()方法排队等待获取锁了，这个方法在AQS中，具体的实现原理请参考深入源码分析AQS实现原理。需要注意的是在acquire(int arg)方法中调用了tryAcquire(int arg)方法，此方法在AQS中没有实现，在NonFiarSync中有实现，但是它最终调用了Sync类中的 nonfairTryAcquire(int arg) 方法，下面是该方法的源码： 方法的逻辑大致如下： 1、获取到当前线程以及当前同步队列的锁状态； 2、有两个if分支，如果锁状态变量state==0，表示当前同步锁没有被其他线程占用，那就用CAS原子的将state从0改为1，表示获取同步锁成功了，获取成功之后会把当前线程会把自己设置为同步锁的拥有者。 3、如果当前线程判断同步锁的状态不为0，那就说明同步锁已经在使用中了，于是当前线程再次判断在使用锁的线程是不是自己，如果是自己，那就再次进去，由于此时这个线程就处于重入的状态了，因此绝对没有其他线程和它争抢state了，因此使用普通的 setState(int arg) 方法把state++（此时state就表示当前线程重入的次数）并更新即可。 NonFairSync获取锁的流程图如下所示： 3、深入源码分析获取公平锁原理在前面我说到过，在ReentrantLock的有参构造方法中传入true参数就可以得到一个公平锁，就像下面这样： 1234567ReentrantLock fireLock = new ReentrantLock(true);fireLock.lock(); try&#123; //TODO &#125;finally &#123; fireLock.unlock(); &#125; 在public void lock()方法中调用了Sync类的lock()方法，lock()方法直接将每一个线程排队等待获取锁，这也就是公平的原因，每个线程在同步队列中排队人人都有获取到锁的机会。这个方法在FairSync中的实现如下： 还是同样的配方，还是同样的套路，我们直接看在FairSync中的tryAcquire()方法的实现即可，上图第二个方法就是在FairSync中对tryAcquire()方法的实现，方法的逻辑大致如下： 1、得到当前线程，并且获得同步启动器的同步锁状态 2、如果同步器的锁状态为0，说明还没有线程持有该锁，那么就判断一下当前队列是否还没有初始化，如果没有初始化，那就先初始化，初始化完成后在使用CAS把同步器的state从0设置为1，设置成功了就表示获取锁成功了，之后还是把自己设置为当前同步器锁的持有者。 3、如果当前线程判断同步锁的状态不为0，那就说明同步锁已经在使用中了，于是当前线程再次判断在使用锁的线程是不是自己，如果是自己，那就再次进去，由于此时这个线程就处于重入的状态了，因此绝对没有其他线程和它争抢state了，因此使用普通的 setState(int arg) 方法把state++（此时state就表示当前线程重入的次数）并更新即可。 其实细心观察我们就会发现，这个方法的实现和前面我们将的nonfairTryAcquire(int arg) 方法的实现基本一致。 4、深入源码分析锁的释放由于ReentrantLock在解锁的时候，并不区分公平锁和非公平锁，所以我们直接看解锁的源码： 可以看到，本质释放锁的地方，还是通过AQS实现的。下面是AQS中的release()方法源码： 关于这个方法的解析在我的博客深入源码分析AQS实现原理有说明。这里不再细说，他会首先调用tryRelease()方法尝试释放锁，释放锁成功之后再通过unparkSuccessor()方法（本质是通过LockSupport.unpark()方法）唤醒后继结点。其中tryRelease()在Sync中的实现如下： 方法的逻辑不难理解： 1、没执行一次tryRelease()方法状态变量就会执行一次state–操作 2、接着判断一下当前线程是否是持有锁的线程，如果不是就会抛出异常，否则进入下一步 3、当锁状态state减为0了就说明把锁释放成功了，此时需要把锁的持有线程在AQS中引用设置为null，好让其他线程可以获得锁，最后锁释放成功会返回true。 四、实现自定义同步锁在学习了AQS和Reentrant之后，为了加深对锁的理解以及应用，我们自己来实现一个简单的互斥锁MutexLock。 思路：实现我们可以实现Lock接口，然后在我们的锁类中聚合AQS，使用他来管理多个多个线程的同步访问的排序。并且在测试中我们来做一道经典的多线程题目：启动10个线程，第一个线程从1加到10，第二个线程从11加到20…第十个线程从91加到100，最后再把十个线程结果相加。 自定义互斥锁 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788package top.easyblog.mutex;import java.util.concurrent.TimeUnit;import java.util.concurrent.locks.AbstractQueuedSynchronizer;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;/** * 基于AQS实现自定义独占锁 * * @author ：huangxin * @modified ： * @since ：2020/04/12 22:13 */public class MutexLock implements Lock &#123; private volatile Sync sync; public MutexLock() &#123; this.sync = new Sync(); &#125; static class Sync extends AbstractQueuedSynchronizer &#123; /** * 尝试获取锁 * * @param arg * @return */ @Override protected boolean tryAcquire(int arg) &#123; boolean success = false; if (compareAndSetState(0, 1)) &#123; //加锁成功,设置当前线程为owner线程 setExclusiveOwnerThread(Thread.currentThread()); success = true; &#125; return success; &#125; @Override protected boolean tryRelease(int arg) &#123; setExclusiveOwnerThread(null); setState(0); return true; &#125; @Override protected boolean isHeldExclusively() &#123; return getExclusiveOwnerThread() == Thread.currentThread(); &#125; public Condition newCondition() &#123; return new ConditionObject(); &#125; &#125; @Override public void lock() &#123; sync.acquire(1); &#125; @Override public void lockInterruptibly() throws InterruptedException &#123; sync.acquireInterruptibly(1); &#125; @Override public boolean tryLock() &#123; return sync.tryAcquire(1); &#125; @Override public boolean tryLock(long time, TimeUnit unit) throws InterruptedException &#123; return sync.tryAcquireNanos(1, unit.toNanos(time)); &#125; @Override public void unlock() &#123; sync.release(1); &#125; @Override public Condition newCondition() &#123; return sync.newCondition(); &#125;&#125; 测试类 启动10个线程，第一个线程从1加到10，第二个线程从11加到20…第十个线程从91加到100，最后再把十个线程结果相加 123456789101112131415161718192021222324252627282930313233343536373839404142public class MutexLockTest extends Thread &#123; private int start; static int sum; //自定义的互斥锁 private MutexLock lock; public MutexLockTest(int start) &#123; this.start = start; this.lock = new MutexLock(); &#125; @Override public void run() &#123; int tmp=0; for (int i = 0; i &lt; 10; i++) &#123; tmp += start + i; &#125; lock.lock(); try &#123; sum += tmp; &#125;finally &#123; System.out.println(Thread.currentThread().getName() + "==&gt;" + sum); lock.unlock(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; Thread[] threadList = new Thread[10]; for (int i = 0; i &lt; 10; i++) &#123; threadList[i] = new MutexLockTest(10 * i + 1); threadList[i].start(); &#125; for (int i = 0; i &lt; 10; i++) &#123; threadList[i].join(); &#125; System.out.println("Sum is : " + sum); &#125;&#125; 执行结果]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F09%2F%E6%B7%B1%E5%85%A5%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E5%8E%9F%E5%AD%90%E7%B1%BBAtomicStampedReference%2F</url>
    <content type="text"><![CDATA[深入源码分析原子类AtomicStampedReferenceAtomicStampedReference是Java提出的一个原子类，它可以解决ABA问题。与这个类有同样作用的类是AtomicMarkableReference，他们都可以解决CAS的ABA问题。 一、什么是ABA问题？ABA的危害？ABA问题发生在多线程环境下，说的是当线程A对一个变量使用CAS修改的时候，他两次读到内存地址V中的值一样，然后改线程就简单的认为变量没有发生过修改。然而，同时可能存在另一个线程在这两次读取之间把这个内存地址的值从A修改成了B又修改回了A，这时还简单地认为“没有修改过”显然是错误的。 如上图所示，在线程1两次读取到变量的值都是A，但是在这中间线程2对这个变量做了修改，但是对于线程1来说他却感受不到。 ABA问题在有些场景中不会产生问题，但是在有些场景中是十分要命的，比如下面这个例子： 假设有一个遵循CAS原理的提款机，小明有100元存款，要用这个提款机来取50元。由于提款机硬件出了点小问题，小明的提款操作被同时提交两次，开启了两个线程（线程1,2），两个线程都是获取当前值100元，要更新成50元。正常情况下，应该一个线程更新成功，另一个线程再更新就会失败，小明的存款只被扣一次。 线程1首先执行成功，把余额从100改成50。线程2因为某种原因阻塞了。这时候，小明的妈妈刚好给小明汇款50元（线程3）。 线程2仍然是阻塞状态，线程3执行成功，把余额从50改成100。 线程2恢复运行，由于阻塞之前已经获得了“当前值”100，并且经过compare检测，此时存款实际值也是100，所以“成功”把变量值100更新成了50。这是不合理的。 因此但遇到这样的场景我们需要预防CAS带来的额ABA问题，Java中就提供了AtomicStampedReference和AtommicMarkableReference这两个类来解决ABA问题。他们两个实现的手段大致相同，只是前者是通过使用一个int类型的版本号来控制修改的，只用当预期值和内存地址V中的值相等并且版本号一致时才允许修改，而后者是通过一个boolean类型的变量来说明变量是否被修改过，下面我就以AtomicStampedReference深入源码分析他的机制。 二、AtomicStampedReference源码分析1、内部类 Pair是AtomicStampedReference的内部类，它主要的作用就是把元素和版本号绑定起来。 2、属性1234private volatile Pair&lt;V&gt; pair;private static final sun.misc.Unsafe UNSAFE = sun.misc.Unsafe.getUnsafe();private static final long pairOffset = objectFieldOffset(UNSAFE, "pair", AtomicStampedReference.class); 在AtomicStampedReference中有一个volatile修饰的成员变量Pair类型的pair。pair中保存了reference（元素引用）和版本号（stamp）并且使用Unsafe获取到其偏移量，存储到pairOffset变量中，这个变量在调用Unsafe类中的方法是有用。 3、构造方法 AtomicStampedReference类只有一个构造方法，第一个参数就是元素的引用，第二个是初始版本号。使用方法如下： 12345678910public class AtomicStampedReferenceTest &#123; public static void main(String[] args) &#123; BigDecimal decimal = new BigDecimal(666.666); AtomicStampedReference&lt;BigDecimal&gt; ref = new AtomicStampedReference&lt;&gt;(decimal, 1); System.out.println(ref.compareAndSet(decimal, BigDecimal.valueOf(888.88), 1, ref.getStamp() + 1)); System.out.println(ref.getReference()); &#125;&#125; 4、compareAndSet()方法 expectedReference：表示预期引用 newReference：新的引用 expectedStamp：预期版本号 newStamp：更新后的版本号 整个方法的逻辑是：先获取到当前的pair对象（也就是当前的旧引用值和版本号），之后比较如果当前pair中的引用值和预期引用值相等并且当前版本和预期版本相等的时候，如果新的引用和旧的引用不相等并且者新的版本号和旧的版本号不相等时才会调用casPair()使用CAS的方式修改pair中的值，反之有一处不符合就不会发生替换。下面是casPair()的实现细节： 可以看到，底层最终还是调用了Unsafe类的另一个CAS方法compareAndSwapObject 总结一下compareAndSet()方法的逻辑就是： （1）如果元素值和版本号都没有变化，并且和新的也相同，返回true； （2）如果元素值和版本号都没有变化，并且和新的不完全相同，就构造一个新的Pair对象并执行CAS更新pair。 可以看到，java中的实现手段： 首先，使用版本号控制； 其次，不重复使用节点（Pair）的引用，每次都新建一个新的Pair来作为CAS比较的对象，而不是复用旧的； 最后，外部传入元素值及版本号，而不是节点（Pair）的引用。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F09%2F%E6%B7%B1%E5%85%A5%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E5%8E%9F%E5%AD%90%E7%B1%BBAtomicInteger%2F</url>
    <content type="text"><![CDATA[深入源码分析原子类AtomicIntegerAtomicInteger是java并发包下面提供的原子类，主要操作的是int类型的数值，通过调用底层Unsafe的CAS等方法实现原子操作。 源码分析一、主要属性 （1）unsafe：Unsafe类的实例 （2）value：使用int类型的value存储值，且使用volatile修饰，volatile主要是保证可见性，即一个线程修改对另一个线程立即可见 （2）valueOffset：用于保存字段value的偏移量，用于在后面的的CAS操作 二、构造方法有两个构造方法，如下： AtommicInteger默认的值是0 AtomicInteger我们可以创建带有执行初始值的实例 三、compareAndSet()方法 Unsafe中的compareAndSwapInt()方法： var1：操作的对象 var2：对象中字段的偏移量 var4：旧的期望值 var5：要修改的值 可以看到，这是一个native方法，底层是使用C/C++写的，主要是调用CPU的CAS指令来实现，它能够保证只有当对应偏移量处的字段值是期望值时才更新，即类似下面这样的两步操作： 123if(value== expect ) &#123; value=newValue;&#125; 通过CPU的CAS指令可以保证这两步操作是原子的，也就不会出现多线程环境中可能比较的时候value值是a，而到真正赋值的时候value值可能已经变成b了的问题。 四、getAndIncrement()方法 Unsafe中的getAndAddInt()方法 getAndIncrement()方法底层是调用的Unsafe的getAndAddInt()方法，这个方法有三个参数： var1：操作的对象 var2：对象中字段的偏移量 var4：增量（这里写死为1） 这里方法展现了CAS的运行机制：可以看到它是先获取当前的值，然后再调用compareAndSwapInt()尝试更新对应偏移量处的值，如果成功了就跳出循环，如果不成功就再重新尝试，直到成功为止，这就是（CAS+自旋）的乐观锁机制。 和这个方法类似的有incrementAndGet()、decrementAndGet()、getAndDecrement()、getAndAdd(int)、addAndGet(int)……这些方法的底层都是调用了Unsafe类的compareAndSwapInt()方法，这里参照这理解即可。 五、getAndUpdate(IntUnaryOperator updateFunction) getAndUpdate()方法的参数类型是一个函数式接口，我们可以使用lambda定义各种计算操作，比如像下边实例： 1234567891011121314151617181920212223242526public class AtomicIntegerTest &#123; public static void main(String[] args) &#123; AtomicInteger atomicInteger = new AtomicInteger(100); //x=x+10 atomicInteger.getAndUpdate(x -&gt; x + 10); System.out.println(atomicInteger.get()); //x=x-10 atomicInteger.getAndUpdate(x -&gt; x - 10); System.out.println(atomicInteger.get()); //x=x*10 atomicInteger.getAndUpdate(x -&gt; x * 10); System.out.println(atomicInteger.get()); //x=x/10 atomicInteger.getAndUpdate(x -&gt; x / 10); System.out.println(atomicInteger.get()); //x=x%10 atomicInteger.getAndUpdate(x -&gt; x % 10); System.out.println(atomicInteger.get()); &#125;&#125; 方法显示获得当前value的值，然后通过自定义的lambda操作计算出要修改的值，之后还是通过调用了Unsafe类中的compareAndSwapInt()实现了原子操作。与他有一个类的的方法updateAndGet()实现手段基本一样，只是返回值不同而已。 总结（1）AtomicInteger维护了一个volaitle修饰的int类型的变量value来存储实际的值，这是CAS和voaltile的金典结合，既保证了变量修改的原子性，同时有保证了可见性。 （2）AtomicInteger的核心方法都最终与Unsafe中的compareAndSwapInt()方法有关（CAS），这个方法保证了变量修改的原子性。 （3）AtomicInteger是CAS在Java中的典型实现，看上去很完美，但是它却没有解决CAS带来的一个大问题：ABA问题 至于ABA问题在Java中如何解决，请参考我的另一篇博客深入源码分析原子类AtomicStampedReference]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F09%2F%E6%B7%B1%E5%85%A5%E6%BA%90%E7%A0%81%E5%88%86%E6%9E%90%E9%AB%98%E6%80%A7%E8%83%BD%E5%8E%9F%E5%AD%90%E7%B1%BBLongAdder%2F</url>
    <content type="text"><![CDATA[深入源码分析高性能原子类LongAdder高性能原子类是java8中增加的原子类，它们使用分段的思想（Cell[]），把不同的线程hash到不同的段上去更新，最后再把这些段的值相加得到最终的值，相对Atomic类这些类运行性能更高，这些类主要有： （1）Striped64：下面四个类的父类。 （2）LongAccumulator：long类型的聚合器，需要传入一个long类型的二元操作，可以用来计算各种聚合操作，包括加减乘除模。 （3）LongAdder：long类型的累加器，LongAccumulator的特例，只能用来计算加法，且从0开始计算。 （4）DoubleAccumulator：double类型的聚合器，需要传入一个double类型的二元操作，可以用来计算各种聚合操作，包括加减乘除模。 （5）DoubleAdder：double类型的累加器，DoubleAccumulator的特例，只能用来计算加法，且从0开始计算。 这里我以LongAdder为例来探究一下由大神Doug Lea操刀编写的作品之精妙！！！ 一、LongAdder中几个关键的属性LongAdder继承自Striped64抽象类，Striped64中定义了Cell内部类和各重要属性。 LongAdder的原理是，在最初没有竞争的时候使用CAS更新base值就可以了，当有多线程有过竞争时通过分段的思想，让不同的线程更新不同的段，最后把这些段相加就得到了完整的LongAdder存储的值。 注意！ 最初没有竞争是指一开始没有没有线程之间的竞争，但也有可能是多线程在操作，只是多个线程没有同时更新base的值。 有过竞争是指只要出现过竞争不管后面有没有竞争都使用cells更新值，规则是不同的线程hash到不同的cell上去更新，减少竞争。 二、缓存行伪共享与解决方法1、CPU缓存架构 CPU 是计算机的心脏，所有运算和程序最终都要由它来执行。主内存（RAM）是运行时数据存放的地方，CPU 和主内存之间有好几级缓存（一般是3级缓存L1、L2、L3），因为即使直接访问主内存也是非常慢的，下面是一个CPU访问缓存和访问内存的速度比较： 从CPU到 大约需要的时总周期 寄存器 1 L1（一级缓存） 3~4 L2（二级缓存） 10~20 L3（三级缓存） 40~45 内存 120~240 由于内存和CPU的速度差距还是比较大的，为了提高效率，因此需要在CPU和内存之间加缓存预读取数据来提升效率。 2、缓存行和伪共享问题​ 缓存是由缓存行组成的，通常是 64 字节（常用处理器的缓存行是 64 字节的，比较旧的处理器缓存行是 32 字节），并且它有效地引用主内存中的一块地址。 一个 Java 的 long 类型是 8 字节，因此在一个缓存行中可以存 8 个 long 类型的变量。 当缓存行中的数据被一个CPU修改后，为了保证缓存一致性，其他CPU相同缓存行中的数据就都必须失效。 表面上看这套机制似乎完美，但是请看这么一个场景：主内存中有两个相邻的值a、b都被加载进了不同核心的缓存中，不出意外的话这两个变量在同一个缓存行里，带来的问题就是比如当核心1对a的值做了修改，那么为了保证缓存一致性，其他核心中缓存了a的缓存行都必须失效，问题就在于失效 a 的缓存的同时，也会把 b 失效，反之亦然，虽然保证了缓存的一致性，但是却带来了效率上的降低。 这个问题在LongAdder中是存在的 在LongAdder中Cell是数组的形式，数组我们都知道空间是连续分配的，一个Cell对象的内存占用在64位系统中是24字节（无论有没有开启指针压缩）。因此一个缓存行可以同时最多放下两个Cell对象，这样在同一个缓存行中 的两个Cell对象就会出现一个修改后导致另一个失效的问题。 在jdk1.8中使用@sun.misc.Contended注解解决了这个问题，它的原理是在使用此注解的对象或字段前后加上128字节的padding，使用2倍于大多数硬件缓存行的大小来避免相邻扇区预取导致的伪共享冲突，从而将这个不同的对象预存到不同的缓存行中。 下面是在Striped64中内部类Cell，在他头上就是使用注解@sun.misc.Contended来防止防止缓存行伪共享的。 三、核心方法源码解析LongAdder是一个专门做累加的高性能原子类，他只能做加减运算并且初始值是0，这一点从他的构造方法可以看出。下面是LongAdder做类似i++操作的示例： 12345678public class LongAdderTest &#123; public static void main(String[] args) &#123; LongAdder adder = new LongAdder(); //默认是0 adder.increment(); &#125;&#125; 从increment()方法开始我们分析一下具体的执行原理。increment()是对add(long)方法的再次封装，核心逻辑还得看add(long)方法。 1、add(long)源码解析add(long x)方法是LongAdder的主要方法，使用它可以使LongAdder中存储的值增加x，x可为正可为负。 12345678910111213141516171819202122232425262728293031323334353637383940/** * Adds the given value. * * @param x the value to add */ public void add(long x) &#123; /** * as:父类Striped64中的累加单元数组 * b:当前base值 * v:当前线程hash到Cell中存储的值 * m:cells的长度-1，在hash的时候做掩码使用 * a:当前线程hash到的Cell */ Cell[] as; long b, v; int m; Cell a; /** *条件 1：累加数组cells为空说明之前没有出现过竞争，此时就使用CAS更新base的值，底层调用了Unsafe的compareAndSwapLong()方法 *条件 2：累加数组cells为空，说明之前出现过竞争，此时每个线程更新各自的在cells中的Cell */ if ((as = cells) != null || !casBase(b = base, b + x)) &#123; //true 表示当前竞争还不是很激烈 //false 表示当前竞争很激烈，多个线程hash到同一个Cell，可能要扩容 boolean uncontended = true; /** * 条件 1：累加数组尾空，如果此条件成立，说明正在出现竞争（是从上面条件2CAS更新失败后过来的） * 条件 2：此条件一般不会成立，因为他如果可以成立说明cells数组的长度为0，那as==null也就会成立 * 条件 3：当前线程所在的Cell为空，说明当前线程还没有更新过Cell，应初始化一个Cell * 条件 4：更新当前线程所在的Cell失败，说明现在竞争很激烈，多个线程hash到了同一个Cell，应扩容 */ if (as == null || (m = as.length - 1) &lt; 0 || /** * getProbe()方法返回的是线程中的threadLocalRandomProbe字段 * 它是随机生成的一个值，对于一个确定的线程这个值是固定的 * 除非刻意修改它 */ (a = as[getProbe() &amp; m]) == null || !(uncontended = a.cas(v = a.value, v + x))) longAccumulate(x, null, uncontended); &#125; &#125; add()方法的执行流程图： 2、 longAccumulate()源码解析add()方法中有三种情况会调用longAccumulate()方法，分别是当CAS更新base失败时、当前线程在cells中没有Cell时、当前线程CAS 更新cell失败需要扩容时。因此对于longAccumulate()方法的解读我也分为三个部分，下面是方法的总览： 累加数组cells还未初始化时 123456789101112131415161718192021//没有其他线程对cell加锁（cellsBusy=1表示加锁了，cellsBusy=0表示未加锁）&amp;cells不存在//前两步都成功后就会使用CAS将cellsBusy标志修改为1，表示当前线程对cells加锁了else if (cellsBusy == 0 &amp;&amp; cells == as &amp;&amp; casCellsBusy()) &#123; //初始化一个cells数组 boolean init = false; try &#123; // Initialize table if (cells == as) &#123; //创建的cells数组默认是大小是2 Cell[] rs = new Cell[2]; //紧跟着就创建一个Cell，这里写的很精妙，通过&amp;操作实现了懒加载 rs[h &amp; 1] = new Cell(x); cells = rs; init = true; //初始化成功标志 &#125; &#125; finally &#123; //最后把锁标志释放 cellsBusy = 0; &#125; if (init) //如果初始化cells成功就返回 break;&#125; 执行流程图 累加数组cells存在但是当前线程的累加槽位为空以及累加数组存在并且当前线程的累加槽位存在的情况 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667if ((as = cells) != null &amp;&amp; (n = as.length) &gt; 0) &#123; //1.累加数组cells存在但是当前线程的累加槽位为空 if ((a = as[(n - 1) &amp; h]) == null) &#123; if (cellsBusy == 0) &#123; // Try to attach new Cell //给当前线程创建一个Cell Cell r = new Cell(x); // Optimistically create //检查cells的加锁状况并使用CAS对cells加锁 if (cellsBusy == 0 &amp;&amp; casCellsBusy()) &#123; //是否成功创建标志 boolean created = false; try &#123; // Recheck under lock Cell[] rs; int m, j; //上锁之后再次检查累加数组是否为空&amp;&amp;当前线程在cells中的槽位为空 if ((rs = cells) != null &amp;&amp; (m = rs.length) &gt; 0 &amp;&amp; rs[j = (m - 1) &amp; h] == null) &#123; //把新创建的Cell赋给cells[j] rs[j] = r; created = true; &#125; &#125; finally &#123; //解锁 cellsBusy = 0; &#125; if (created) //创建槽位成功返回 break; //创建槽位失败重试 continue; // Slot is now non-empty &#125; &#125; collide = false; &#125; else if (!wasUncontended) // CAS already known to fail wasUncontended = true; // Continue after rehash //2.累加数组存在并且当前线程的累加槽位存在 //首先，再次尝试CAS更新当前线程所在Cell的值，如果成功了就返回 else if (a.cas(v = a.value, ((fn == null) ? v + x : fn.applyAsLong(v, x)))) break; //当前累加数组cells的大小是否大于CPU数 else if (n &gt;= NCPU || cells != as) collide = false; // At max size or stale else if (!collide) collide = true; else if (cellsBusy == 0 &amp;&amp; casCellsBusy()) &#123; //cells扩容逻辑 try &#123; if (cells == as) &#123; // Expand table unless stale //扩容cells累加数组，扩容后的大小是原cells的2倍 Cell[] rs = new Cell[n &lt;&lt; 1] //把原cells中的值复制到新cells中 for (int i = 0; i &lt; n; ++i) rs[i] = as[i]; cells = rs; &#125; &#125; finally &#123; //解锁 cellsBusy = 0; &#125; collide = false; //数组扩容后重试 continue; // Retry with expanded table &#125; //更新失败或者达到了CPU核心数，重新生成probe，改变线程对应的Cell，并重试 h = advanceProbe(h); &#125; 第一种情况：累加数组cells存在但是当前线程的累加槽位为空的执行流程图 第二种情况：累加数组cells存在并且当前线程的累加槽位存在时对流程图 3、sum()源码解析sum()方法是获取LongAdder中真正存储的值的大小得到方法，通过把base和cells中所有槽位的值相加得到。 1234567891011121314151617181920212223/** * Returns the current sum. The returned value is &lt;em&gt;NOT&lt;/em&gt; an * atomic snapshot; invocation in the absence of concurrent * updates returns an accurate result, but concurrent updates that * occur while the sum is being calculated might not be * incorporated. * * @return the sum */ public long sum() &#123; //拿到累加数组cells Cell[] as = cells; Cell a; //拿到base值 long sum = base; if (as != null) &#123; //如果cells存在那就遍历cells把各个槽位中的值相加得到最终的和 for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) sum += a.value; &#125; &#125; return sum; &#125; 可以看到sum()方法是把base和所有槽位的值相加得到，那么，这里有一个问题，如果前面已经累加到sum上的Cell的value有修改，不是就没法计算到了么？ 答案确实如此，所以LongAdder可以说不是强一致性的，它是最终一致性的。 总结 （1）LongAdder通过long类型的base和Cell数组来存储值 （2）不同的线程会hash到不同的cells累加数组的槽位上更新，减少了竞争 （3）LongAdder的性能非常高，最终会达到一种无竞争的状态； （4）LongAdder消除缓存行伪共享是通过sun.misc.Contended注解实现的，它的原理就是在使用了这个注解对对象或字段前后都会加上128字节的padding（空白，不会对原数据产生影响），使用2倍于大多数硬件缓存行的大小来避免相邻扇区预取导致的伪共享冲突。 （5）cells数组的最大是等于CPU核心数或是小于CPU核心数的最大2的幂，即cells数组的大小不可能大于CPU核心数。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F09%2F%E9%83%BD2020%E5%B9%B4%E4%BA%86%E4%BD%A0%E8%BF%98%E4%B8%8D%E7%90%86%E8%A7%A3volatile%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[都2020年了你还不理解volatile关键字先给出结论： volatile可以保证不同线程对一个变量的可见性，即一个线程修改了被voaltile修饰的变量后，这新值对其他线程来说是立即可见的; volatile可以禁止指令重排序，保证了有序性； volatile不能保证原子性，更加不能保证线程安全，要想保证原子性和线程安全还是乖乖的使用锁吧！ 具体的原理且看我慢慢分析。 一、Java内存模型JMM即Java Memory Model，它将JVM内存抽象为主内存和工作内存。主内存是所有的线程共享的内存区域，包括方法区和堆内存；工作内存是线程私有的，包括程序计数器、JVM桟和本地方法桟。Java规定： 所有的变量都存储在主内存中(虚拟机内存的一部分)，对于所有线程都是共享的。 每个线程都有自己的工作内存，工作内存中保存的是该线程使用到的变量副本（该副本就是主内存中该变量的一份拷贝），线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存中的变量。 线程之间无法直接访问对方的工作内存中的变量，线程间变量的传递均需要通过主内存来完成 屏蔽硬件和操作系统内存读取差异，以达到各个平台下都能达到一致的内存访问效果的产物。并且通过JMM使得程序员不必接触底层的CPU缓存、寄存器、硬件内存、CPU指令优化等。JMM的作用体现在以下几个方面： （1）原子性​ 在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行。并且Java内存模型只保证了基本读取和赋值是原子性操作，如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。 （2）可见性 对于可见性，Java提供了volatile关键字来保证可见性。当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。另外，通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。 （3）有序性​ 在Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行（as-if-serial语义），却会影响到多线程并发执行的正确性。 在Java里面，可以通过volatile关键字来保证一定的“有序性”。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。 二、volatile实现的原理1、volatile保证可见性的原理（1）Lock前缀指令volatile可见性的实现原理是基于lock前缀指令实现的。 1234567891011public class Test &#123; private static volatile int a = 1; public static void test() &#123; a = 2; &#125; public static void main(String [] args) &#123; test(); &#125;&#125; 上面的代码，我们添加hsdis插件到JRE的lib目录后，可以对上述代码进行反汇编打印出来的汇编指令如下： 123450x000000011a5ddf25: callq 0x000000010cb439f0 ; &#123;runtime_call&#125;0x000000011a5ddf2a: vzeroupper0x000000011a5ddf2d: movl $0x5,0x270(%r15)0x000000011a5ddf38: lock addl $0x0,(%rsp)0x000000011a5ddf3d: cmpl $0x0,-0xd4ec2e7(%rip) # 0x000000010d0f1c60 核心就是lock指令。可以说，lock指令就是CPU实现volatile可见性的秘密。通过查IA-32架构软件开发者手册,内容如下： 8.1.4 Effects of a LOCK Operation on Internal Processor Caches For the Intel486 and Pentium processors, the LOCK# signal is always asserted on the bus during a LOCK operation,even if the area of memory being locked is cached in the processor. For the P6 and more recent processor families, if the area of memory being locked during a LOCK operation is cached in the processor that is performing the LOCK operation as write-back memory and is completely contained in a cache line, the processor may not assert the LOCK# signal on the bus. Instead, it will modify the memory location internally and allow it’s cache coherency mechanism to ensure that the operation is carried out atomically. Thisoperation is called “cache locking.” The cache coherency mechanism automatically prevents two or more processors that have cached the same area of memory from simultaneously modifying data in that area. 翻译过来即就是： 对于Intel486和Pentium处理器，即使正在锁定的内存区域已缓存在处理器中，在LOCK操作期间始终会在总线上发出LOCK＃（以lock为前缀的指令）信号。 对于P6和更新的处理器家族，如果在执行LOCK操作的处理器中缓存了在LOCK操作期间锁定的内存区域作为回写内存，并且完全包含在缓存行中，则处理器可能不会声明 总线上的LOCK＃信号。 取而代之的是，它将在内部修改内存位置，并允许其缓存一致性机制来确保该操作是原子执行的。 该操作称为“缓存锁定”。 缓存一致性机制会自动阻止已缓存同一内存区域的两个或更多处理器同时修改该区域中的数据。 in the Pentium and P6 family processors, if through snooping one processor detects that another processor intends to write to a memory location that it currently has cached in shared state, the snooping processor will invalidate its cache line forcing it to perform a cache line fill the next time it accesses the same memory location. 翻译过来就是： 在Pentium和P6 系列处理器中，如果通过嗅探一个处理器来检测其他处理器打算写内存地址，而这个地址当前处于共享状态，那么正在嗅探的处理器将使它的缓存行无效，在下次访问相同内存地址时，强制执行缓存行填充一个处理器的缓存回写到内存会导致其他处理器的缓存无效。 上述引用总结为volatile的两条实现原则: （1）对缓存行加锁内容的修改会导致修改后的内容马上写回主内存； （2）一个处理器的缓存回写到主存会使其他缓存了该共享变量的缓存失效。 （2）缓存一致性协议在多处理器下，为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议，这是CPU底层做的事儿，但是这里我们还是需要了解一下原理的。 为了保证缓存的一致性，每个处理器通过在嗅探在总线上传播的数据来检查自己缓存的数据是否过期了，当处理器发现自己缓存行中的数据过期了，就会键当前处理器缓存行中的数据设置成无效状态，当处理器对这个数据进行修改操作的时候会重新从主内存中加载这个数据到缓存里。 （3）缓存一致性的简单实现方式缓存将具有三个额外的位：V（可用） | D（脏位，表示高速缓存中的数据与内存中的数据不同） | S（共享） 读未命中：CPU_A本地缓存读未命中，会广播到监听总线上，其他所有CPU监听处理器会检查，如果缓存了该地址，并且缓存处于“D（脏位）”，将状态改成有效，同时发送副本到请求节点。 写未命中：CPU_A尝试更新本地缓存，但是更新并不在主存中。其他所有CPU监听处理器可确保将其他高速缓存中的所有副本都设置为“无效”。 以上是主要的场景，具体实现有 MESI 协议等。 2、volatile实现禁止指令重排序的原理（1）什么是指令重排序？为什么要指令重排序？现代CPU在执行一条指令的分为5个阶段：取指令--&gt;指令译码--&gt;执行指令--&gt;内存访问--&gt;数据写回。 为了提高指令执行的吞吐量，现代CPU都支持多级指令流水线（一般就是五级指令流水线），就是可以在一个一个时钟周期内同时对5个指令执行不同阶段的操作，本质上，流水线方式不能缩短一条指令执行的时间，但它提高了CPU的吞吐率。 因此，在流水线模式下，为了提高CPU的指令执行效率以及CPU的吞吐率，就会对指令重新排序，让指令能够尽量不间断的送给CPU处理，当然重排序的前提是重排序前后执行的结果不变。指令重排序分为编译器级别的和处理器级别的，但是他们实现重排序的目的都是为了提高程序的效率。 编译器重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序； 处理器重排序。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序，处理器的重排序又被称为乱序执行（out-of-order execution,OOE）技术； （2）as-if-serial语义as-if-serial语义的意思是：无论如何重排序，单线程内程序的执行结果不能被改变。编译器、runtime和处理器都必须遵循as-if-serial语义。为了遵守这条语义，编译器和处理器不会对存在数据依赖关系的操纵进行重排序，反之，就会被重排序。 （3）指令重排序带来的问题指令重排序的本质是好的，但是在某些时候会导致一些错误。请看下面这段代码，这是美团技术团队博客上给出的一段代码，它描述了由于指令重排序带来的问题。 1234567891011121314151617181920212223242526272829303132public class PossibleReordering &#123; static int x = 0, y = 0; static int a = 0, b = 0; public static void main(String[] args) throws InterruptedException &#123; int i = 0; for (; ; ) &#123; i++; x = 0; y = 0; a = 0; b = 0; Thread one = new Thread(() -&gt; &#123; a = 1; x = b; &#125;); Thread other = new Thread(() -&gt; &#123; b = 1; y = a; &#125;); one.start(); other.start(); one.join(); other.join(); if (x == 0 &amp;&amp; y == 0) &#123; System.err.println("第" + i + "次(" + x + "," + y + ")"); break; &#125; &#125; &#125;&#125; 执行结果： 当执行到第649625次的时候发生了错误，为什么说是错误，正常情况下这段代码的运行结果可能为(1,0)、(0,1)或(1,1)，因为线程one可以在线程two开始之前就执行完了，也有可能反之，甚至有可能二者的指令是同时或交替执行的。也就是说，（0，0）这个结果是如果是按正常顺序执行的话是不可能出现的，但是现在出现了就证明了一件事儿，CPU确实存在对指令的重排序。 （4）volatile禁止指令重排序 为了性能优化，JMM 在不改变正确语义的前提下，会允许编译器和处理器对指令序列进行重排序。JMM 提供了内存屏障阻止这种重排序。 Java 编译器会在生成指令系列时在适当的位置会插入内存屏障指令来禁止特定类型的处理器重排序。 JMM 针对编译器制定 volatile 重排序规则表,如下： 其中“NO”表示禁止指令重排序，为了实现这一语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。 LoadLoad：对于这样的语句Load1:LoadLoad:Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。 StoreStore：对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。 LoadStore：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。 StoreLoad：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。（开销最大，对于大多数处理器是万能屏障，它兼具其他三种屏障的功能） 其实前面的lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能： （1）它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成； （2）它会强制将对缓存的修改操作立即写入主存； （3）如果是写操作，它会导致其他CPU中对应的缓存行无效。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F09%2FJava%E4%B8%AD%E7%9A%84%E7%BA%BF%E7%A8%8B%E6%B1%A0%2F</url>
    <content type="text"><![CDATA[线程池ThreadPoolExecutor详解如果并发的线程数量很多，并且每个线程都是执行一个时间很短的任务就结束了，这样频繁创建线程就会大大降低系统的效率，因为频繁创建线程和销毁线程需要时间。 那么有没有一种办法使得线程可以复用，就是执行完一个任务，并不被销毁，而是可以继续执行其他的任务？ 在Java中可以通过线程池来达到这样的效果。今天我们就来详细讲解一下Java的线程池，首先我们从最核心的ThreadPoolExecutor类中的方法讲起，然后再讲述它的实现原理，接着给出了它的使用示例，最后讨论了一下如何合理配置线程池的大小。 首先我们来看一下Java中线程池的继承体系： 最顶层的Executor是一个接口，他讲任务的提交和执行分离开来。 ThreadPoolExecutor是线程池的核心实现类，用来执行被提交的任务。 ScheduledThreadPoolExecutor是一个延时执行任务的实现类，他比Timer更灵活。 Executor下有一个重要子接口ExecutorService，其中定义了线程池的具体行为 1，execute（Runnable command）：履行Ruannable类型的任务, 2，submit（task）：可用来提交Callable或Runnable任务，并返回代表此任务的Future对象 3，shutdown（）：在完成已提交的任务后封闭办事，不再接管新任务, 4，shutdownNow（）：停止所有正在履行的任务并封闭办事。 5，isTerminated（）：测试是否所有任务都履行完毕了。 6，isShutdown（）：测试是否该ExecutorService已被关闭。 接下来我们就以ThreadPoolExecutor来探究一下Java中线程池的原理。 一、ThreadPoolExecutor构造方法123456789public ThreadPoolExecutor(int corePoolSize, int maximumPoolSize, long keepAliveTime, TimeUnit unit, BlockingQueue&lt;Runnable&gt; workQueue, ThreadFactory threadFactory, RejectedExecutionHandler handler) &#123; //省略.....&#125; ThreadPoolExecutor有很4个构造方法，这里我用参数最全的一个来说明一下各个参数的含义： 1、corePoolSize：线程池中核心线程个数 2、maximunPoolSize：线程池最大允许的线程个数（这里有一个救急线程的概念，就是非核心线程，它的数量是maximunPoolSize-corePoolSize） 3、keepAliveTime：这个参数是给非核心线程设定的，他表示非核心线程可以空闲时间，超过这个时间就会被回收 4、unit：空闲时间的单位 5、workQueue：任务队列，它是一个阻塞队列，用于存放等待执行的任务。Java中提供的阻塞队列有以下几个： （1）ArrayBlockingQueue：基于数组的有界队列，遵循先进先出 （2）LinkedBlockingQueue：基于链表的有界队列，遵循先进先出，吞吐量高于ArrayBlockingQueue （3）SynchronousQueue：一个不存储元素的阻塞队列，每一个插入操作必须要等到另一个线程调用移除操作才可以执行，否则会一直阻塞，吞吐量比LinkedBlockingQueue高 （4）PriorityBlockingQueue：一个具有优先级的阻塞队列 6、threadFactory：线程工厂，用于创建线程以及可以给线程起一个有意义的名字 7、RejectedExecutionHandler：当任务队列和线程池都处于满负荷运行时，新提交的任务应该如何处理的策略，称为饱和策略。Java中提供的策略有以下4种： （1）ThreadPoolExecutor.AbortPolicy：直接抛出异常，这是默认的策略 （2）ThreadPoolExecutor.CallerRunsPolicy：让调用者来执行该任务 （3）ThreadPoolExecutor.DisCardPolicy：不做任何处理，直接把任务丢掉，也不抛出任何异常 （4）ThreadPoolExecutor.DisCardOldestPolicy：丢弃任务队列头部的任务，然后尝试执行当前任务 当然，我们也可以根据我们的业务场景通过实现RejectExeptionPolicy接口实现自定义策略。 二、线程池的重要属性1、线程池状态以及有效线程数量属性—ctl ctl是一个控制线程池状态以及线程池中有效线程数量的int类型字段，在这一个字段中包含了两部分信息： 线程池的运行状态 (runState) 和线程池内有效线程的数量 (workerCount)，这里可以看到，使用了int类型来保存，高3位保存runState，低29位保存workerCount。这么做是为了保证修改线程池状态以及线程池中有效线程数量的操作是一个原子操作的前提前可以借助无锁机制提高效率，如果用两个变量分别保存的话就要通过加锁来保证原子性了。 COUNT_BITS 就是29，CAPACITY就是1左移29位减1（29个1），这个常量表示workerCount的上限值，大约是5亿。 2、ctl有关的方法：1234567// Packing and unpacking ctl //获取线程池的运行状态private static int runStateOf(int c) &#123; return c &amp; ~CAPACITY&#125; //获取活动线程数private static int workerCountOf(int c) &#123; return c &amp; CAPACITY;&#125;//获取运行状态和活动线程数的值private static int ctlOf(int rs, int wc) &#123; return rs | wc; &#125; 3、线程池的5个状态 123456// runState is stored in the high-order bits 高3位private static final int RUNNING = -1 &lt;&lt; COUNT_BITS; //111private static final int SHUTDOWN = 0 &lt;&lt; COUNT_BITS; //000 private static final int STOP = 1 &lt;&lt; COUNT_BITS; //001private static final int TIDYING = 2 &lt;&lt; COUNT_BITS; //010private static final int TERMINATED = 3 &lt;&lt; COUNT_BITS; //011 RUNNING：线程池处于运行状态，可以正常处理并接受新任务，线程池的初始状态就是RUNNING； SHUTDOWN：当调用shutdown()方法后会由RUNNING转变为SHUTDOWN状态，此时线程池可以正常处理任务但是无法再接收新任务； STOP：代用shutdownNow()方法后，线程会转变为STOP状态，此时线程不再处理已提交的任务并且无法在接受新任务，并且还会中断处理中的任务； TIDYING：当所有的任务已终止，ctl记录的”任务数量”为0，线程池会变为TIDYING状态。当线程池变为TIDYING状态时，会执行钩子函数terminated()。terminated()在ThreadPoolExecutor类中是空的，若用户想在线程池变为TIDYING时，进行相应的处理；可以通过重载terminated()函数来实现。 TERMINATED：线程池彻底终止，就变成TERMINATED状态。线程池处在TIDYING状态时，执行完terminated()方法之后，就会由 TIDYING -&gt; TERMINATED。 4、线程池构建有关的属性123456789101112private final BlockingQueue&lt;Runnable&gt; workQueue; //任务缓存队列，用来存放等待执行的任务private final ReentrantLock mainLock = new ReentrantLock(); //线程池的主要状态锁，对线程池状态（比如线程池大小、runState等）的改变都要使用这个锁private final HashSet&lt;Worker&gt; workers = new HashSet&lt;Worker&gt;(); //用来存放工作集private volatile long keepAliveTime; //线程存货时间 private volatile boolean allowCoreThreadTimeOut; //是否允许为核心线程设置存活时间private volatile int corePoolSize; //核心池的大小（即线程池中的线程数目大于这个参数时，提交的任务会被放进任务缓存队列）private volatile int maximumPoolSize; //线程池最大能容忍的线程数private volatile int poolSize; //线程池中当前的线程数private volatile RejectedExecutionHandler handler; //任务拒绝策略private volatile ThreadFactory threadFactory; //线程工厂，用来创建线程private int largestPoolSize; //用来记录线程池中曾经出现过的最大线程数,跟线程池的容量没有任何关系private long completedTaskCount; //用来记录已经执行完毕的任务个数 三、线程池的基本实现原理ThreadPoolExecutor中有两个方法可以用于向线程池提交任务，分别是execute()和submit()两个方法。execute()方法用于提交不需要返回值的任务，submit()用于提交需要返回值的任务，返回值被封装在Future接口中，可以通过提供的get()方法获取返回值。下++面通过源码我们来探究一下： 1、execute()方法12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849public void execute(Runnable command) &#123; //提交的任务为空将会抛出NPE if (command == null) throw new NullPointerException(); //ctl中记录着当前线程池运行状态和有效线程数量，是一个原子变量 int c = ctl.get(); /**workConutOf(c)将取出当前活跃的线程数量，把它和核心线程数比较， * 如果小于核心线程数就创建一个新的线程执行新提交的任务 */ if (workerCountOf(c) &lt; corePoolSize) &#123; /* * addWorker中的第二个参数表示限制添加线程的数量是根据corePoolSize来判断还是maximumPoolSize来判断； * 如果为true，根据corePoolSize来判断； * 如果为false，则根据maximumPoolSize来判断 */ if (addWorker(command, true)) return; //创建新的线程失败，重新获取ctl c = ctl.get(); &#125; //如果当前线程池是运行状态并且任务添加到队列成功 if (isRunning(c) &amp;&amp; workQueue.offer(command)) &#123; int recheck = ctl.get(); // 再次判断线程池的运行状态，如果不是运行状态，由于之前已经把command添加到workQueue中了， // 这时需要移除该command // 执行过后通过handler使用拒绝策略对该任务进行处理，整个方法返回 if (! isRunning(recheck) &amp;&amp; remove(command)) reject(command); /* * 获取线程池中的有效线程数，如果数量是0，则执行addWorker方法 * 这里传入的参数表示： * 1. 第一个参数为null，表示在线程池中创建一个线程，但不去启动； * 2. 第二个参数为false，将线程池的有限线程数量的上限设置为maximumPoolSize，添加线程时根据maximumPoolSize来判断； * 如果判断workerCount大于0，则直接返回，在workQueue中新增的command会在将来的某个时刻被执行。 */ else if (workerCountOf(recheck) == 0) addWorker(null, false); &#125; /* * 如果执行到这里，有两种情况： * 1. 线程池已经不是RUNNING状态； * 2. 线程池是RUNNING状态，但workerCount &gt;= corePoolSize并且workQueue已满。 * 这时，再次调用addWorker方法，但第二个参数传入为false，将线程池的有限线程数量的上限设置为maximumPoolSize； 如果失败则调用饱和策略处理该任务。 */ else if (!addWorker(command, false)) reject(command); &#125; 总结一下execute()方法运行的主要流程如下图所示： 从图中可以看出，当提交一个新任务当线程池以后，exectue()的处理流程大致如下： 1、首先判断核心线程池中的线程是否都有处于工作状态，如果没有就创建新的线程执行任务，否则进入下一步 2、判断任务队列是否已经满了，如果没有满就班新任务放入阻塞队列中等待被执行；否则进入下一步 3、判断线程池的线程是否都处于工作状态，如果没有就创建新的线程执行任务，否则把任务交给饱和策略处理。 2、addWorker()方法addWorker主要的功能就是创建一个新线程并执行提交的任务。firstTask参数表示该线程创建后执行的第一个任务；core参数如果为true表示限制线程池中的线程数量应该小于corePoolSize,为false表示限制线程池中的线程数量应该小于maximumPoolSize 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990private boolean addWorker(Runnable firstTask, boolean core) &#123; retry: for (;;) &#123; int c = ctl.get(); //获取运行状态 int rs = runStateOf(c); /** * 如果rs &gt;= SHUTDOWN，则表示此时不再接收新任务； * 如果这个条件满足后，下面三个条件任意一个满足就会返回false * 1. 当前线程池处于SHUTDOWN状态 * 2. 提交的任务为空 * 3. 任务队列不为空 */ // Check if queue empty only if necessary. if (rs &gt;= SHUTDOWN &amp;&amp; ! (rs == SHUTDOWN &amp;&amp;firstTask == null &amp;&amp;! workQueue.isEmpty())) return false; for (;;) &#123; //获取活动线程个数 int wc = workerCountOf(c); /**这里是实现比较容量大小是否超过限制的关键步骤 *core参数如果为true表示限制线程池中的线程数量应该小于corePoolSize, *为false表示限制线程池中的线程数量应该小于maximumPoolSize */ if (wc &gt;= CAPACITY || wc &gt;= (core ? corePoolSize : maximumPoolSize)) return false; // 尝试CAS增加workerCount，如果成功，则跳出第一个for循环 if (compareAndIncrementWorkerCount(c)) break retry; // 如果CAS增加workerCount失败，则重新获取ctl的值 c = ctl.get(); // Re-read ctl //如果线程池的运行状态发生改变，返回第一个for循环重试 if (runStateOf(c) != rs) continue retry; // else CAS failed due to workerCount change; retry inner loop &#125; &#125; boolean workerStarted = false; boolean workerAdded = false; Worker w = null; try &#123; //根据Runnable对象创建一个Worker w = new Worker(firstTask); //获得Worker对应的线程 final Thread t = w.thread; if (t != null) &#123; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; // Recheck while holding lock. // Back out on ThreadFactory failure or if // shut down before lock acquired. int rs = runStateOf(ctl.get()); // rs &lt; SHUTDOWN表示是RUNNING状态 if (rs &lt; SHUTDOWN || (rs == SHUTDOWN &amp;&amp; firstTask == null)) &#123; //检查线程是否还活着（活着是否启动） if (t.isAlive()) // precheck that t is startable throw new IllegalThreadStateException(); //将任务添加到阻塞队列中，他是一个HashSet workers.add(w); int s = workers.size(); //largestPoolSize记录了线程池曾经出现过的最大的线程数量 if (s &gt; largestPoolSize) largestPoolSize = s; //任务添加成功标记 workerAdded = true; &#125; &#125; finally &#123; mainLock.unlock(); &#125; //最后如果添加任务成功就启动它 if (workerAdded) &#123; t.start(); //任务启动成功标记 workerStarted = true; &#125; &#125; &#125; finally &#123; if (! workerStarted) //任务启动失败后把任务从HashSet中移除 addWorkerFailed(w); &#125; return workerStarted; &#125; 3、内部类WorkerWorker中的重要属性以及构造方法 1234567891011121314151617181920private final class Worker extends AbstractQueuedSynchronizer implements Runnable&#123; /** Thread this worker is running in. Null if factory fails. */ final Thread thread; /** Initial task to run. Possibly null. */ Runnable firstTask; /** Per-thread task counter */ volatile long completedTasks; /** * Creates with given first task and thread from ThreadFactory. * @param firstTask the first task (null if none) */ Worker(Runnable firstTask) &#123; setState(-1); // inhibit interrupts until runWorker this.firstTask = firstTask; this.thread = getThreadFactory().newThread(this); &#125;&#125; 线程池中的每一个线程被封装成了一个Worker对象，ThreadPoolExecutor维护的其实就是一组Worker对象。 Worker类继承了AQS，并实现了Runnable接口，注意其中的firstTask和thread属性：firstTask用来保存传入的任务；thread是在调用构造方法时保存通过ThreadFactory创建的线程，是用来处理任务的线程。 在调用构造方法时，需要把任务传入，这里通过getThreadFactory().newThread(this);来新建一个线程，newThread方法传入的参数是this，因为Worker本身继承了Runnable接口，也就是一个线程，所以一个Worker对象在启动的时候会调用Worker类中的run方法。Worker继承了AQS，使用AQS来实现独占锁的功能。为什么不使用ReentrantLock来实现呢？可以看到tryAcquire方法，它是不允许重入的，而ReentrantLock是允许重入的： （1）lock方法一旦获取了独占锁，表示当前线程正在执行任务中； （2）如果正在执行任务，则不应该中断线程； （3）如果该线程现在不是独占锁的状态，也就是空闲的状态，说明它没有在处理任务，这时可以对该线程进行中断； （4）线程池在执行shutdown方法或tryTerminate方法时会调用interruptIdleWorkers方法来中断空闲的线程，interruptIdleWorkers方法会使用tryLock方法来判断线程池中的线程是否是空闲状态； （5）之所以设置为不可重入，是因为我们不希望任务在调用像setCorePoolSize这样的线程池控制方法时重新获取锁。如果使用ReentrantLock，它是可重入的，这样如果在任务中调用了如setCorePoolSize这类线程池控制的方法，会中断正在运行的线程。 所以，Worker继承自AQS的作用是判断线程是否空闲以及是否可以被中断。 此外，在构造方法中执行了setState(-1);，把state变量设置为-1，为什么这么做呢？是因为AQS中默认的state是0，如果刚创建了一个Worker对象，还没有执行任务时，这时就不应该被中断，可以看一下Worker中的tryAcquire方法： 12345678910// The value 0 represents the unlocked state// The value 1 represents the locked state. protected boolean tryAcquire(int unused) &#123; //尝试上锁 if (compareAndSetState(0, 1)) &#123; setExclusiveOwnerThread(Thread.currentThread()); return true; &#125; return false; &#125; tryAcquire方法是根据state是否是0来判断的，所以将state设置为-1是为了禁止在执行任务前对线程进行中断。 正因为如此，在runWorker方法中会先调用Worker对象的unlock方法将state设置为0。 4、runWorker()方法在Worker类中的run()方法调用了runWorker()方法来执行任务，runWorker()方法的代码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849final void runWorker(Worker w) &#123; Thread wt = Thread.currentThread(); //尝试获取任务 Runnable task = w.firstTask; w.firstTask = null; //解锁，允许中断了 w.unlock(); // allow interrupts // 是否因为异常退出循环 boolean completedAbruptly = true; try &#123; // 如果task为null，则通过getTask()获取任务去处理 while (task != null || (task = getTask()) != null) &#123; w.lock(); //如果线程池正在停止，那么要保证当前线程是中断状态； //如果不是的话，则要保证当前线程不是中断状态； if ((runStateAtLeast(ctl.get(), STOP) || (Thread.interrupted() &amp;&amp; runStateAtLeast(ctl.get(), STOP))) &amp;&amp; !wt.isInterrupted()) wt.interrupt(); try &#123; beforeExecute(wt, task); Throwable thrown = null; try &#123; //执行任务，注意这里是直接调用了run()方法 task.run(); &#125; catch (RuntimeException x) &#123; thrown = x; throw x; &#125; catch (Error x) &#123; thrown = x; throw x; &#125; catch (Throwable x) &#123; thrown = x; throw new Error(x); &#125; finally &#123; afterExecute(task, thrown); &#125; &#125; finally &#123; //将task置为null方便下次使用getTask()获取任务 task = null; w.completedTasks++; w.unlock(); &#125; &#125; completedAbruptly = false; &#125; finally &#123; //对线程做一些善后的工作 processWorkerExit(w, completedAbruptly); &#125; &#125; 总结runWorker()方法的执行过程如下： while循环不断地通过getTask()方法获取任务 getTask()方法从阻塞队列中取任务（下面会分析到） 如果线程池正在停止，那么要保证当前线程是中断状态，否则要保证当前线程不是中断状态； 调用task.run()执行任务； 当通过getTask()获取任务为null时跳出循环，执行processWorkerExit()方法，对线程做一些善后处理； runWorker方法执行完毕，也代表着Worker中的run方法执行完毕，销毁线程。 5、getTask()方法getTask()方法是用来从阻塞队列中获取任务的方法，源码如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455private Runnable getTask() &#123; //timeOut变量的值表示上次从阻塞队列中取任务时是否超时 boolean timedOut = false; // Did the last poll() time out? for (;;) &#123; int c = ctl.get(); int rs = runStateOf(c); /* * 如果线程池状态rs &gt;= SHUTDOWN，也就是非RUNNING状态，再进行以下判断： * 1. rs &gt;= STOP，线程池是否正在stop； * 2. 阻塞队列是否为空。 * 如果以上条件满足，则将workerCount减1并返回null。 * 因为如果当前线程池状态的值是SHUTDOWN或以上时，不允许再向阻塞队列中添加任务。 */ if (rs &gt;= SHUTDOWN &amp;&amp; (rs &gt;= STOP || workQueue.isEmpty())) &#123; decrementWorkerCount(); return null; &#125; int wc = workerCountOf(c); // timed变量用于判断是否需要进行超时控制 boolean timed = allowCoreThreadTimeOut || wc &gt; corePoolSize; /* * wc &gt; maximumPoolSize的情况是因为可能在此方法执行阶段同时执行了setMaximumPoolSize方法； * timed &amp;&amp; timedOut 如果为true，表示当前操作需要进行超时控制，并且上次从阻塞队列中获取任务发生了超时 * 接下来判断，如果有效线程数量大于1，或者阻塞队列是空的，那么尝试将workerCount减1； * 如果减1失败，则返回重试。 * 如果wc == 1时，也就说明当前线程是线程池中唯一的一个线程了。 * 当线程池空闲之后非核心线程就是在这里被清除的 */ if ((wc &gt; maximumPoolSize || (timed &amp;&amp; timedOut)) &amp;&amp; (wc &gt; 1 || workQueue.isEmpty())) &#123; if (compareAndDecrementWorkerCount(c)) return null; continue; &#125; try &#123; //poll方法是有时间限制的，超过指定时间就会返回，take方法则会一直阻塞等待任务 Runnable r = timed ? workQueue.poll(keepAliveTime, TimeUnit.NANOSECONDS) : workQueue.take(); if (r != null) //返回任务 return r; // 如果 r == null，说明已经超时，timedOut设置为true timedOut = true; &#125; catch (InterruptedException retry) &#123; // 如果获取任务时当前线程发生了中断，则设置timedOut为false并返回循环重试 timedOut = false; &#125; &#125; &#125; 6、 processWorkerExit()方法在runWorker()方法中当通过getTask()获取任务是返回null时，一个线程的生命就到达终点了，此时他会执行processWorkerExit()方法把自己从线程池维护的HashSet（workers）中移除了。 12345678910111213141516171819202122232425262728293031private void processWorkerExit(Worker w, boolean completedAbruptly) &#123; // 如果completedAbruptly值为true，则说明线程执行时出现了异常，需要将workerCount减1； // 如果线程执行时没有出现异常，说明在getTask()方法中已经已经对workerCount进行了减1操作，这里就不必再减了。 if (completedAbruptly) // If abrupt, then workerCount wasn't adju decrementWorkerCount(); final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; //汇总完成的任务数 completedTaskCount += w.completedTasks; //从线程池中移除工作线程w workers.remove(w); &#125; finally &#123; mainLock.unlock(); &#125; // 根据线程池状态进行判断是否结束线程池 tryTerminate(); int c = ctl.get(); if (runStateLessThan(c, STOP)) &#123; if (!completedAbruptly) &#123; int min = allowCoreThreadTimeOut ? 0 : corePoolSize; if (min == 0 &amp;&amp; ! workQueue.isEmpty()) min = 1; if (workerCountOf(c) &gt;= min) return; // replacement not needed &#125; addWorker(null, false); &#125; &#125; 至此，processWorkerExit执行完之后，工作线程被销毁，以上就是整个工作线程的生命周期，从execute()方法开始，Worker使用ThreadFactory创建新的工作线程，runWorker()通过getTask()获取任务，然后执行任务，如果getTask()返回null，进入processWorkerExit()方法，整个线程结束，如图所示： 四 、使用线程池的正确姿势1、向线程池提交任务ThreadPoolExecutor中有两个方法可以用于向线程池提交任务，分别是execute()和submit()两个方法。 execute()：用于提交不需要返回值的任务; submit()：用于提交需要返回值的任务，返回值被封装在Future接口中，可以通过提供的get()方法获取返回值。 我们在使用线程池的时候最好不要直接使用工具类Executors中提供的Executors.newXXXThreadPool()快捷方法创建线程池，因为这种方式会使用无界的任务队列，为避免OOM，我们应该使用ThreadPoolExecutor的构造方法手动指定队列的最大长度： 1234567891011121314151617181920212223242526272829303132333435363738394041public class ThreadPoolTest &#123; public static void main(String[] args) &#123; ThreadPoolExecutor threadPool = null; try &#123; threadPool = new ThreadPoolExecutor(2, 5, 1000, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;&gt;(10), new DefaultTreadFactory(), new ThreadPoolExecutor.CallerRunsPolicy()); for (int i = 0; i &lt; 16; i++) &#123; int j = i; threadPool.execute(new Thread(() -&gt; &#123; try &#123; Thread.sleep(5000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + "执行了任务" + j); &#125;)); &#125; &#125; finally &#123; if (threadPool != null) threadPool.shutdown(); &#125; &#125;&#125;class DefaultTreadFactory implements ThreadFactory &#123; @Override public Thread newThread(Runnable r) &#123; Thread currentThread = new Thread(r); currentThread.setName("worker" + currentThread.getId()); return currentThread; &#125;&#125; ​ 在使用线程池的时候一定要根据任务的特性合理的配置线程池才能最大限度的发挥线程池带来的好处。对于CPU密集型任务应该配置尽可能少的线程，通常配置线程个数略多与CPU个数即可；对于IO密集型任务，每个线程在IO阻塞的时间远远大于其运行的时间，此时可以配置尽可能多的CPU；当然，这只是一个参考值，具体的设置还需要根据实际情况进行调整，比如可以先将线程池大小设置为参考值，再观察任务运行情况和系统负载、资源利用率来进行适当调整。 2、线程池的初始化默认情况下，创建线程池之后，线程池中是没有线程的，需要提交任务之后才会创建线程。 在实际中如果需要线程池创建之后立即创建线程，可以通过以下两个方法办到： prestartCoreThread()：初始化一个核心线程； prestartAllCoreThreads()：初始化所有核心线程 下面是这2个方法的实现： 12345678910111213//初始化一个核心线程public boolean prestartCoreThread() &#123; return workerCountOf(ctl.get()) &lt; corePoolSize &amp;&amp; addWorker(null, true); &#125; //初始化全部核心线程public int prestartAllCoreThreads() &#123; int n = 0; while (addWorker(null, true)) ++n; return n; &#125; 3、关闭线程池 ThreadPoolExecutor提供了两个方法，用于线程池的关闭，分别是shutdown()和shutdownNow()，其中： shutdown()：不会立即终止线程池，而是要等所有任务缓存队列中的任务都执行完后才终止，但再也不会接受新的任务,，当执行这个方法后线程池就会从RUNNING==&gt;SHUTDOWN shutdownNow()：立即终止线程池，并尝试打断正在执行的任务，并且清空任务缓存队列，返回尚未执行的任务 4、动态调整线程池容量ThreadPoolExecutor提供了动态调整线程池容量大小的方法：setCorePoolSize()和setMaximumPoolSize()， setCorePoolSize()：设置核心池大小 setMaximumPoolSize()：设置线程池最大能创建的线程数目大小 当上述参数从小变大时，ThreadPoolExecutor进行线程赋值，还可能立即创建新的线程来执行任务。 五、Excutors工具类中的3类基于ThreadPoolExecutor线程池简单分析1、newFixedThreadPool()12345public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;());&#125; 特点： 是一个固定大小的线程池，核心线程corePoolSize=maxinumnPoolSize，因此无需超时时间 阻塞队列使用的是LinkedBlockingQueue，是一个无界阻塞队列 FixedThreadPool适用于我了满足资源管理的需求，而需要限制当前线程数量的应用场景，是哟适用于负载比较重的服务器。 2、newCacheedThreadPool()12345public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE, 60L, TimeUnit.SECONDS, new SynchronousQueue&lt;Runnable&gt;());&#125; 特点： 核心线程数为0，最大线程数是Integer.MAX_VALUE。 阻塞队列采用了SynchronousQueue，使用的SynchronousQueue，也就是说来了任务就创建线程运行，当线程空闲超过60秒，就销毁线程。 适用于执行很多的短期异步任务或负载较轻的服务器 3、newSingleThreadPool()123456public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1, 0L, TimeUnit.MILLISECONDS, new LinkedBlockingQueue&lt;Runnable&gt;()));&#125; 特点： 线程池只有一个线程，并且也是使用LinkedBlockingQueue 适用于需要保证顺序地执行各个任务；并且在任意时间点，不会有多个线程是活动的场景。 总结Executors为我们提供了构造线程池的便捷方法，对于服务器程序我们应该杜绝使用这些便捷方法，而是直接使用线程池ThreadPoolExecutor的构造方法，避免无界队列可能导致的OOM以及线程个数限制不当导致的线程数耗尽等问题。ExecutorCompletionService提供了等待所有任务执行结束的有效方式，如果要设置等待的超时时间，则可以通过CountDownLatch完成。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F07%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3CAS%E6%97%A0%E9%94%81%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[深入理解CAS无锁机制一、什么是CAS?CAS（Compare And Sweap或者Compare And Set，比较替换），CAS和volatile的读写共同支撑起了整合JUC包。工作原理是：一个CAS操作有三个操作数，目标内存地址V，旧的预期值E和将要替换的新值B，在进行替换操作前比较当且仅当目标内存地址V中的值和旧的预期值E值相等的时候才会发生替换，否则什么都不做。 CAS是乐观锁技术，当多个线程尝试使用CAS同时更新同一个变量时，只有其中一个线程能更新变量的值，而其它线程都失败，失败的线程并不会被挂起，而是被告知这次竞争中失败，并可以再次尝试。 二、CAS的原理在Java中通过调用Unsafe类中的JNI代码来支持CAS。它就是借助C来调用CPU底层指令实现的。下面从分析比较常用的CPU（intel x86）来解释CAS的实现原理。下面是sun.misc.Unsafe类中几个支持CAS的方法的源代码： 我们以compareAndSweapInt()为例，这个本地方法在openjdk中依次调用的c++代码为：unsafe.cpp，atomic.cpp和atomicwindowsx86.inline.hpp。这个本地方法的最终实现在openjdk的如下位置：openjdk-7-fcs-src-b147-27jun2011\openjdk\hotspot\src\oscpu\windowsx86\vm\ atomicwindowsx86.inline.hpp（对应于windows操作系统，X86处理器）。下面是对应于intel x86处理器的源代码的片段： 1234567891011121314151617181920// Adding a lock prefix to an instruction on MP machine// VC++ doesn't like the lock prefix to be on a single line// so we can't insert a label after the lock prefix.// By emitting a lock prefix, we can define a label after it.#define LOCK_IF_MP(mp) __asm cmp mp, 0 \ __asm je L0 \ __asm _emit 0xF0 \ __asm L0:inline jint Atomic::cmpxchg (jint exchange_value, volatile jint* dest, jint compare_value) &#123; // alternative for InterlockedCompareExchange int mp = os::is_MP(); __asm &#123; mov edx, dest mov ecx, exchange_value mov eax, compare_value LOCK_IF_MP(mp) cmpxchg dword ptr [edx], ecx &#125;&#125; 如上面源代码所示，程序会根据当前处理器的类型来决定是否为cmpxchg指令添加lock前缀。如果程序是在多处理器上运行，就为cmpxchg指令加上lock前缀（lock cmpxchg）。反之，如果程序是在单处理器上运行，就省略lock前缀（单处理器自身会维护单处理器内的顺序一致性，不需要lock前缀提供的内存屏障效果）。 intel手册对lock前缀指令的说明如下： 确保对内存的读-改-写操作原子执行。在Pentium及Pentium之前的处理器中，带有lock前缀的指令在执行期间会锁住总线，使得其他处理器暂时无法通过总线访问内存。很显然，这会带来昂贵的开销。从Pentium 4，Intel Xeon及P6处理器开始，intel在原有总线锁的基础上做了一个很有意义的优化：如果要访问的内存区域（area of memory）在lock前缀指令执行期间已经在处理器内部的缓存中被锁定（即包含该内存区域的缓存行当前处于独占或以修改状态），并且该内存区域被完全包含在单个缓存行（cache line）中，那么处理器将直接执行该指令。由于在指令执行期间该缓存行会一直被锁定，其它处理器无法读/写该指令要访问的内存区域，因此能保证指令执行的原子性。这个操作过程叫做缓存锁定（cache locking），缓存锁定将大大降低lock前缀指令的执行开销，但是当多处理器之间的竞争程度很高或者指令访问的内存地址未对齐时，仍然会锁住总线。 禁止该指令与之前和之后的读和写指令重排序。 把写缓冲区中的所有数据刷新到内存中。 关于CPU的锁有如下3种： 处理器自动保证基本内存操作的原子性 首先处理器会自动保证基本的内存操作的原子性。处理器保证从系统内存当中读取或者写入一个字节是原子的，意思是当一个处理器读取一个字节时，其他处理器不能访问这个字节的内存地址。奔腾6和最新的处理器能自动保证单处理器对同一个缓存行里进行16/32/64位的操作是原子的，但是复杂的内存操作处理器不能自动保证其原子性，比如跨总线宽度，跨多个缓存行，跨页表的访问。但是处理器提供总线锁定和缓存锁定两个机制来保证复杂内存操作的原子性。 使用总线锁保证原子性 第一个机制是通过总线锁保证原子性。如果多个处理器同时对共享变量进行读改写（i++就是经典的读改写操作）操作，那么共享变量就会被多个处理器同时进行操作，这样读改写操作就不是原子的，操作完之后共享变量的值会和期望的不一致。 ​ 原因是有可能多个处理器同时从各自的缓存中读取变量i，分别进行加一操作，然后分别写入系统内存当中。那么想要保证读改写共享变量的操作是原子的，就必须保证CPU1读改写共享变量的时候，CPU2不能操作缓存了该共享变量内存地址的缓存。 处理器使用总线锁就是来解决这个问题的。所谓总线锁就是使用处理器提供的一个LOCK＃信号，当一个处理器在总线上输出此信号时，其他处理器的请求将被阻塞住,那么该处理器可以独占使用共享内存。 使用缓存锁保证原子性 第二个机制是通过缓存锁定保证原子性。在同一时刻我们只需保证对某个内存地址的操作是原子性即可，但总线锁定把CPU和内存之间通信锁住了，这使得锁定期间，其他处理器不能操作其他内存地址的数据，所以总线锁定的开销比较大，最近的处理器在某些场合下使用缓存锁定代替总线锁定来进行优化。 频繁使用的内存会缓存在处理器的L1，L2和L3高速缓存里，那么原子操作就可以直接在处理器内部缓存中进行，并不需要声明总线锁，在奔腾6和最近的处理器中可以使用“缓存锁定”的方式来实现复杂的原子性。所谓“缓存锁定”就是如果缓存在处理器缓存行中内存区域在LOCK操作期间被锁定，当它执行锁操作回写内存时，处理器不在总线上声言LOCK＃信号，而是修改内部的内存地址，并允许它的缓存一致性机制来保证操作的原子性，因为缓存一致性机制会阻止同时修改被两个以上处理器缓存的内存区域数据，当其他处理器回写已被锁定的缓存行的数据时会起缓存行无效。 但是有两种情况下处理器不会使用缓存锁定。第一种情况是：当操作的数据不能被缓存在处理器内部，或操作的数据跨多个缓存行（cache line），则处理器会调用总线锁定。第二种情况是：有些处理器不支持缓存锁定。对于Inter486和奔腾处理器,就算锁定的内存区域在处理器的缓存行中也会调用总线锁定。 以上两个机制我们可以通过Inter处理器提供了很多LOCK前缀的指令来实现。比如位测试和修改指令BTS，BTR，BTC，交换指令XADD，CMPXCHG和其他一些操作数和逻辑指令，比如ADD（加），OR（或）等，被这些指令操作的内存区域就会加锁，导致其他处理器不能同时访问它。 三、CAS的缺陷CAS可以高效的保证原子性，但是CAS任然存在三大问题：ABA问题、循环时间长开销大和只能保证一个变量的原子性。 1.ABA问题。因为CAS需要在操作值的时候检查下值有没有发生变化，如果没有发生变化则更新，但是如果一个值原来是A，变成了B，又变成了A，那么使用CAS进行检查时会发现它的值没有发生变化，但是实际上却变化了。ABA问题的解决思路就是使用版本号。在变量前面追加上版本号，每次变量更新的时候把版本号加一，那么A－B－A 就会变成1A-2B－3A。 ABA问题Java提供的解决方案jdk1.5 Java提供了AtomicStampedReference类，此类通过引用一个邮戳来控制版本，下面是此类中的核心方法compareAndSwap expectedReference：表示预期值 newReference：新值 expectedStamp：预期邮戳（预期版本号） newStamp：更新后的邮戳（版本号） (1)首先我们可以看看Pair的实现 可以看到，Pair是个静态内部类，他是用来保存预期的邮戳stamp和预期值引用reference的。在AtomicStampedReference内部有一个Pair对象，并且是被volatile修饰的，保证了在多个线程之间的可见性。 之后就是比较当前pair中的值和预期值是否相等，pare中的时间戳是否和预期时间错相等，如果都相等，最终调用了casPair`方法，源码如下，主要就是通过Unsafe类来更新时间戳和新的值。 至于Unsafe类调用的compareAndSwapObject方法那是一个native方法，在Java源码层面是看不到了，所以就不往下追了。 2. 循环时间长开销大。自旋CAS如果长时间不成功，会给CPU带来非常大的执行开销。如果JVM能支持处理器提供的pause指令那么效率会有一定的提升，pause指令有两个作用，第一它可以延迟流水线执行指令（de-pipeline）,使CPU不会消耗过多的执行资源，延迟的时间取决于具体实现的版本，在一些处理器上延迟时间是零。第二它可以避免在退出循环的时候因内存顺序冲突（memory order violation）而引起CPU流水线被清空（CPU pipeline flush），从而提高CPU的执行效率。 3. 只能保证一个共享变量的原子操作。当对一个共享变量执行操作时，我们可以使用循环CAS的方式来保证原子操作，但是对多个共享变量操作时，循环CAS就无法保证操作的原子性，这个时候就可以用锁，或者有一个取巧的办法，就是把多个共享变量合并成一个共享变量来操作。比如有两个共享变量i＝2,j=a，合并一下ij=2a，然后用CAS来操作ij。从Java1.5开始JDK提供了AtomicReference类来保证引用对象之间的原子性，你可以把多个变量放在一个对象里来进行CAS操作。 四、深入源码理解原子类1、原子更新基本类型J.U.C包下主要提供了以下类可以原子的更新基本类型： （1）AtomicInteger：原子的更新int类型 （2）AtomicLong：原子的更新long类型 （3）AtomicBoolean：原子更新布尔类型，内部使用int类型的value存储1和0表示true和false，底层也是对int类型的原子操作。 这些类的基本操作和API都很类似，底层都是对Unsafe类的compareAndSwapXxxx()方法的调用，下面是基本的使用： 1234567891011121314151617181920212223242526272829303132public class CASBase &#123; public static void main(String[] args) &#123; AtomicInteger value = new AtomicInteger(10); //类似++i操作 System.out.println(value.incrementAndGet()); //类似i++操作 System.out.println(value.getAndIncrement()); //类似--i操作 System.out.println(value.decrementAndGet()); //类似i--操作 System.out.println(value.getAndDecrement()); //先获取当前值，在加50 System.out.println(value.getAndAdd(50)); //先加上50之后在获取值 System.out.println(value.addAndGet(50)); //直接设置值为666，返回是否设置成功 value.compareAndSet(value.get(), 666); System.out.println(value.get()); //可以进行任何运算(加减乘除模)并且是原子的,他是调用了compareAndSet()实现的CAS操作 System.out.println(value.updateAndGet(x -&gt; x * 100)); &#125;&#125; 具体的源码分析请参考我的另一篇博客深入源码分析原子类AtomicInteger。 2、原子更新引用类型J.U.C包下提供了以下类可以用于原子的更新引用类型的引用： （4）AtomicReference&lt;V&gt;：原子更新引用类型，通过泛型指定要操作的类，存在ABA问题。 （5）AtomicMarkableReference&lt;V&gt;：原子更新引用类型，内部使用Pair承载引用对象及是否被更新过的标记，避免了ABA问题。 （6）AtomicStampedReference&lt;V&gt;：原子更新引用类型，内部使用Pair承载引用对象及更新的时间戳，避免了ABA问题。 123456789101112131415public class CASReference &#123; public static void main(String[] args) &#123; BigDecimal decimal = new BigDecimal(100); AtomicStampedReference&lt;BigDecimal&gt; stampedReference = new AtomicStampedReference&lt;&gt;(decimal, 1); //CAS设置 预期引用是decimal 新的引用是new BigDecimal(200)，预期版本是1，新的版本是2 stampedReference.compareAndSet(decimal, new BigDecimal(200), 1, stampedReference.getStamp()+1); //获得引用，这里是new BigDecimal(200)的引用，他重写了toString()方法因此会打印200 System.out.println(stampedReference.getReference()); //获得当前版本号 应该是2 System.out.println(stampedReference.getStamp()); &#125;&#125; 具体的源码分析请参考我的另一篇博客深入源码分析原子类AtomicStampedReference。 3、原子更新数组J.U.C包下提供了以下类： （7）AtomicIntegerArray：原子更新int类型数组。 （8）AtomicLongArray：原子更新long类型数组。 （9）AtomicReferenceArray：原子更新引用类型数组。 这几个类的操作基本类似，更新元素时都要指定在数组中的索引位置，基本用法如下： 1234567891011121314151617181920212223242526272829303132333435363738394041public class CASArray &#123; public static void main(String[] args) &#123; //定义一个长度为10的int 类型数组 AtomicIntegerArray array = new AtomicIntegerArray(10); for (int i = 0; i &lt; array.length(); i++) &#123; //给索引为i的元素设置值 array.set(i, i * i); &#125; for (int i = 0; i &lt; array.length(); i++) &#123; //获得索引为i的元素 System.out.println(array.get(i)); &#125; System.out.println("--------------------------------------------------"); //给索引为0的元素做i--操作 操作之后array[0]=-1 System.out.println(array.getAndDecrement(0)); //给索引为0的元素做--i操作 操作之后array[0]=-2 System.out.println(array.decrementAndGet(0)); //给索引为0的元素做i++操作 操作之后array[0]=-1 System.out.println(array.getAndIncrement(0)); //给索引为0的元素做--i操作 操作之后array[0]=0 System.out.println(array.incrementAndGet(0)); //给索引为0的元素加上999 操作之后array[0]=999 ,它返回的是操作之前的值 array.getAndAdd(0, 999); System.out.println(array.get(0)); //比较并替换索引为0的元素为888 预期值999 新值888，他返回的是替换是否成功 if(array.compareAndSet(0,999,888))&#123; System.out.println(array.get(0)); &#125; //可以对索引为0的元素做任何运算操作，第二个参数需要一个lambda表达式 array.updateAndGet(0, (x) -&gt; x * 100); System.out.println(array.get(0)); &#125;&#125; 具体的源码分析请参考我的另一篇博客。 4、原子更新对象中的字段原子更新对象中的字段，可以更新对象中指定字段名称的字段，这些类主要有： （10）AtomicIntegerFieldUpdater：原子更新对象中的int类型字段。 （11）AtomicLongFieldUpdater：原子更新对象中的long类型字段。 （12）AtomicReferenceFieldUpdater：原子更新对象中的引用类型字段。 这几个类的操作基本类似，都需要传入要更新的字段名称，基本用法如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354public class CASObjectField &#123; public static void main(String[] args) &#123; //原子更新int类型字段 AtomicIntegerFieldUpdater&lt;User&gt; age = AtomicIntegerFieldUpdater.newUpdater(User.class, "age"); //原子更新int类型字段 AtomicLongFieldUpdater&lt;User&gt; stamp = AtomicLongFieldUpdater.newUpdater(User.class, "stamp"); //原子更新int类型字段 AtomicReferenceFieldUpdater&lt;User, String&gt; name = AtomicReferenceFieldUpdater.newUpdater(User.class, String.class, "name"); User user = new User("李四", 23, System.currentTimeMillis()); System.out.println(user); age.compareAndSet(user,user.getAge(),34); stamp.compareAndSet(user,user.getStamp(),System.currentTimeMillis()); name.compareAndSet(user,user.getName(),"老王"); System.out.println(user); &#125;&#125;//User类class User &#123; volatile String name; volatile int age; volatile long stamp; public User(String name, int age, long stamp) &#123; this.name = name; this.age = age; this.stamp = stamp; &#125; public String getName() &#123; return name; &#125; public int getAge() &#123; return age; &#125; public long getStamp() &#123; return stamp; &#125; @Override public String toString() &#123; return "User&#123;" + "name='" + name + '\'' + ", age=" + age + ", stamp=" + stamp + '&#125;'; &#125;&#125; 5、高性能原子类高性能原子类是java8中增加的原子类，它们使用分段的思想（Cell[]），把不同的线程hash到不同的段上去更新，最后再把这些段的值相加得到最终的值，相对Atomic类这些类运行性能更高，这些类主要有： （1）Striped64：下面四个类的父类。 （2）LongAccumulator：long类型的聚合器，需要传入一个long类型的二元操作，可以用来计算各种聚合操作，包括加减乘除模。 （3）LongAdder：long类型的累加器，LongAccumulator的特例，只能用来计算加法，且从0开始计算。 （4）DoubleAccumulator：double类型的聚合器，需要传入一个double类型的二元操作，可以用来计算各种聚合操作，包括加减乘除模。 （5）DoubleAdder：double类型的累加器，DoubleAccumulator的特例，只能用来计算加法，且从0开始计算。 这几个类的操作基本类似，其中DoubleAccumulator和DoubleAdder底层其实也是用long来实现的，基本用法如下： 12345678910111213141516public class CASInJDK8 &#123; public static void main(String[] args) &#123; LongAdder longAdder = new LongAdder(); longAdder.add(200); //设置值为200 longAdder.increment(); //i++ System.out.println(longAdder.sum()); //获得longAdder的值 LongAccumulator longAccumulator = new LongAccumulator((left, right) -&gt; left+right*2, 0); longAccumulator.accumulate(34); System.out.println(longAccumulator.get()); //获得longAccumulator的值 &#125;&#125; 具体的源码分析请参考我的另一篇博客深入源码分析高性能原子类LongAdder。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F07%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3Java%E9%AD%94%E6%B3%95%E7%B1%BBUnsafe%2F</url>
    <content type="text"><![CDATA[深入理解Java魔法类Unsafe前言​ Unsafe为我们提供了访问底层的机制，这种机制仅供java核心类库使用，而不应该被普通用户使用。其实例一般情况是获取不到的，源码中的设计是采用单例模式，不是启动类加载器加载初始化就会抛SecurityException异常。 ​ 这个类的提供了一些绕开JVM的更底层功能，基于它的实现可以提高效率。但是，它是一把双刃剑：正如它的名字所预示的那样，它是不安全的，它所分配的内存需要手动free（不被GC回收）。如果对Unsafe类理解的不够透彻，就进行使用的话，就等于给自己挖了无形之坑，最为致命。 ​ 由于sun并没有将其开源，也没给出官方的Document。但是，为了更好地了解java的生态体系，我们应该去学习它，去了解它，不求深入到底层的C/C++代码，但求能了解它的基本功能。 一、获取Unsafe实例Unsafe类是不可以直接new出来，因为它把构造方法是私有化了，同时虽然他也提供了一个getUnsafe()静态方法，但是如果直接调用的这个方法的话就会抛出SecurityException异常。因为我们在外部调用的时候使用的不是启动类加载器，人家这个类就要求必须使用启动类加载器才可以正常使用。 VM类中的isSystemDomainLoader()方法 它在返回实例之前会获取当前调用者的类加载器，如果不是启动类加载器就会抛出SecurityException异常。 普通用户获取Unsafe实例的正确姿势查看源码，我们发现它有一个属性叫theUnsafe，我们直接通过反射拿到它即可。 12345678910public class UnsafeTest &#123; public static void main(String[] args) throws NoSuchFieldException, IllegalAccessException &#123; Class&lt;Unsafe&gt; clazz = Unsafe.class; Field field = clazz.getDeclaredField("theUnsafe"); field.setAccessible(true); Unsafe unsafe = (Unsafe) field.get(null); System.out.println(unsafe); &#125;&#125; 二、底层native方法汇总共计82个public native,下面列出了核心方法： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283//扩充内存 public native long reallocateMemory(long address, long bytes); //分配内存 public native long allocateMemory(long bytes); //释放内存 public native void freeMemory(long address); //在给定的内存块中设置值 public native void setMemory(Object o, long offset, long bytes, byte value); //从一个内存块拷贝到另一个内存块 public native void copyMemory(Object srcBase, long srcOffset, Object destBase, long destOffset, long bytes); //获取值，不管java的访问限制，其他有类似的getInt，getDouble，getLong，getChar等等 public native Object getObject(Object o, long offset); //设置值，不管java的访问限制，其他有类似的putInt,putDouble，putLong，putChar等等 public native void putObject(Object o, long offset); //从一个给定的内存地址获取本地指针，如果不是allocateMemory方法的，结果将不确定 public native long getAddress(long address); //存储一个本地指针到一个给定的内存地址,如果地址不是allocateMemory方法的，结果将不确定 public native void putAddress(long address, long x); //该方法返回给定field的内存地址偏移量，这个值对于给定的filed是唯一的且是固定不变的 public native long staticFieldOffset(Field f); //报告一个给定的字段的位置，不管这个字段是private，public还是保护类型，和staticFieldBase结合使用 public native long objectFieldOffset(Field f); //获取一个给定字段的位置 已经过时 public native Object staticFieldBase(Field f); //确保给定class被初始化，这往往需要结合基类的静态域（field） public native void ensureClassInitialized(Class c); //可以获取数组第一个元素的偏移地址 public native int arrayBaseOffset(Class arrayClass); //可以获取数组的转换因子，也就是数组中元素的增量地址。将arrayBaseOffset与arrayIndexScale配合使用， 可以定位数组中每个元素在内存中的位置 public native int arrayIndexScale(Class arrayClass); //获取本机内存的页数，这个值永远都是2的幂次方 public native int pageSize(); //告诉虚拟机定义了一个没有安全检查的类，默认情况下这个类加载器和保护域来着调用者类 public native Class defineClass(String name, byte[] b, int off, int len, ClassLoader loader, ProtectionDomain protectionDomain); //定义一个类，但是不让它知道类加载器和系统字典 public native Class defineAnonymousClass(Class hostClass, byte[] data, Object[] cpPatches); //锁定对象，必须是没有被锁的 已经过时 public native void monitorEnter(Object o); //解锁对象 已经过时 public native void monitorExit(Object o); //试图锁定对象，返回true或false是否锁定成功，如果锁定，必须用monitorExit解锁 已经过时 public native boolean tryMonitorEnter(Object o); //引发异常，没有通知 public native void throwException(Throwable ee); //CAS，如果对象偏移量上的值=期待值，更新为x,返回true.否则false.类似的有compareAndSwapInt,compareAndSwapLong,compareAndSwapBoolean,compareAndSwapChar等等。 public final native boolean compareAndSwapObject(Object o, long offset, Object expected, Object x); // 该方法获取对象中offset偏移地址对应的整型field的值,支持volatile load语义。类似的方法有getIntVolatile，getBooleanVolatile等等 public native Object getObjectVolatile(Object o, long offset); //线程调用该方法，线程将一直阻塞直到超时，或者是中断条件出现。 public native void park(boolean isAbsolute, long time); //终止挂起的线程，恢复正常.java.util.concurrent包中挂起操作都是在LockSupport类实现的，也正是使用这两个方法 public native void unpark(Object thread); //获取系统在不同时间系统的负载情况 public native int getLoadAverage(double[] loadavg, int nelems); //创建一个类的实例，不需要调用它的构造函数、初使化代码、各种JVM安全检查以及其它的一些底层的东西。即使构造函数是私有，我们也可以通过这个方法创建它的实例,对于单例模式，简直是噩梦，哈哈 public native Object allocateInstance(Class cls) throws InstantiationException; 三、Unsafe的使用示例1、使用Unsafe实例化一个类有一个User类 123456789101112131415161718public class User &#123; String name; int age; public User()&#123; name="小明"; age=10; &#125; @Override public String toString() &#123; return "User&#123;" + "name='" + name + '\'' + ", age=" + age + ", stamp=" + stamp + '&#125;'; &#125;&#125; 通过Unsafe的allocateInstance()方法实例化该对象 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package top.easyblog;import sun.misc.Unsafe;import java.lang.reflect.Field;/** * Unsafe类灵魂追问： * （1）Unsafe是什么？ * &lt;p&gt; * （2）Unsafe只有CAS的功能吗？ * &lt;p&gt; * （3）Unsafe为什么是不安全的？ * &lt;p&gt; * （4）怎么使用Unsafe（怎么获得Unsafe的实例）？ * * @author ：huangxin * @modified ： * @since ：2020/04/07 11:40 */public class UnsafeTest &#123; private static Unsafe unsafe; static &#123; Class&lt;Unsafe&gt; unsafeClass = Unsafe.class; Field field = null; try &#123; field = unsafeClass.getDeclaredField("theUnsafe"); &#125; catch (NoSuchFieldException e) &#123; e.printStackTrace(); &#125; assert field != null; field.setAccessible(true); try &#123; unsafe = (Unsafe) field.get(null); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) throws NoSuchFieldException, IllegalAccessException, InstantiationException &#123; System.out.println(instanceFor(unsafe, User.class)); &#125; /** * 使用Unsafe实例化一个类 * * @param clazz * @param &lt;T&gt; */ public static &lt;T&gt; T instanceFor(Unsafe unsafe, Class&lt;T&gt; clazz) throws InstantiationException &#123; return (T) unsafe.allocateInstance(clazz); &#125;&#125; 执行结果： 从打印的结果来看，字段全是默认初始值，没有执行构造方法初始化。其实allocateInstance()方法只会给对象分配内存，并不会调用构造方法。你问我这个用啥用？这个对于单例模式简直是无解的开挂行为，因为他实例化对象不需要经过构造器。 2、修改私有字段的值使用Unsafe的putXXX()方法，我们可以修改任意私有字段的值。 12345678910111213141516public class UnsafeTest &#123; public static void main(String[] args) throws NoSuchFieldException, IllegalAccessException, InstantiationException &#123; Class&lt;Unsafe&gt; unsafeClass = Unsafe.class; Field field = unsafeClass.getDeclaredField("theUnsafe"); field.setAccessible(true); Unsafe unsafe = (Unsafe) field.get(null); User user =new User(); Field age = user.getClass().getDeclaredField("age"); //使用unsafe.putXxx给属性设值 unsafe.putInt(user,unsafe.objectFieldOffset(age),30); System.out.println(user); &#125;&#125; 这里我们可以配合第1种用法来给一个对象分配内存以及初始化。（当然我们也可以通过反射直接修改。） 3、抛出checked异常我们知道如果代码抛出了checked异常，要不就使用try…catch捕获它，要不就在方法签名上定义这个异常，但是，通过Unsafe我们可以抛出一个checked异常，同时却不用捕获或在方法签名上定义它。 1234// 使用Unsafe抛出异常不需要定义在方法签名上往外抛,直接使用API的方式就可以了public static void throwException() &#123; unsafe.throwException(new Exception());&#125; 4、在堆外分配内存使用java 的new会在堆中为对象分配内存，并且对象的生命周期内，会被JVM GC管理。Unsafe分配的内存，不受Integer.MAX_VALUE的限制，并且分配在非堆内存，使用它时，需要非常谨慎：忘记手动回收时，会产生内存泄露；非法的地址访问时，会导致JVM崩溃。在需要分配大的连续区域、实时编程（不能容忍JVM延迟）时，可以使用它。java.nio使用这一技术。Spark中的Netty也使用了这个技术。 假设我们要在堆外创建一个巨大的byte数组，我们可以使用allocateMemory()方法来实现： OffHeapArray 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778package top.easyblog;import sun.misc.Unsafe;import java.lang.reflect.Field;/** * 堆外数组 * * @author ：huangxin * @modified ： * @since ：2020/04/07 14:59 */public class OffHeapArray &#123; private static final int BYTE = 1; private long size; private long array; private static Unsafe unsafe; static &#123; try &#123; Field thUnsafe = Unsafe.class.getDeclaredField("theUnsafe"); thUnsafe.setAccessible(true); unsafe = (Unsafe) thUnsafe.get(null); &#125; catch (NoSuchFieldException | IllegalAccessException e) &#123; e.printStackTrace(); &#125; &#125; //构造方法中给数组分配内存,理论上可以分配任意大小的数组 public OffHeapArray(long size) &#123; this.size = size; array = unsafe.allocateMemory(size * BYTE); &#125; /** * 获得索引i处的元素 * * @param i * @return */ public int get(long i) &#123; return unsafe.getInt(array + i * BYTE); &#125; /** * 设置值 * * @param i * @param value */ public void set(long i, int value) &#123; unsafe.putInt(array + i * BYTE, value); &#125; /** * 返回数组大小 * * @return */ public long length() &#123; return this.size; &#125; /** * 释放内存 */ public void free() &#123; unsafe.freeMemory(array); &#125; public static void main(String[] args) &#123; System.out.println(unsafe); &#125;&#125; 123456OffHeapArray offHeapArray = new OffHeapArray((long)Integer.MAX_VALUE+100);offHeapArray.set(0, 45);System.out.println(&quot;索引0：&quot;+offHeapArray.get(0));System.out.println(&quot;数组大小：&quot;+offHeapArray.length());//用完之后一定要记得手动释放内存offHeapArray.free(); 执行结果： 你问我这个有啥用？Java的数组最大容量受常量Integer.MAX_VALUE的限制，如果我们用直接申请内存的方式去创建数组，那么数组大小只会收到堆的大小的限制。当时使用这个方式理论上可以创建任意大小的数组。 5、CAS操作J.U.C底层大量使用了CAS，在AQS、ConcurrentHashmap、ForkJoinPool、FutureTask、StampedLock等都有大量的应用。它们的底层是调用的Unsafe的CompareAndSwapXXX()方法。这种方式广泛运用于无锁算法，与java中标准的悲观锁机制相比，它可以利用CAS处理器指令提供极大的加速。 6、park/unpark在LockSupport类中有两个静态方法park()和unpark()，他们的底层调用的就是Unsafe类中对应的park()/unpark()本地方法，当一个线程正在等待某个操作时，JVM调用Unsafe的park()方法来阻塞此线程。当阻塞中的线程需要再次运行时，JVM调用Unsafe的unpark()方法来唤醒此线程。具体的分析请参考我的另一篇博客LockSupport深入源码剖析 。 7、计算对象的内存大小基本的思路如下: （1）通过反射获得一个类的Field （2）通过Unsafe的objectFieldOffset()获得每个Field的offSet（3）对Field按照offset排序，取得最大的offset，然后加上这个field的长度，再加上Padding对齐 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253public class UnsafeTest &#123; private static Unsafe unsafe; static &#123; Class&lt;Unsafe&gt; unsafeClass = Unsafe.class; Field field = null; try &#123; field = unsafeClass.getDeclaredField("theUnsafe"); &#125; catch (NoSuchFieldException e) &#123; e.printStackTrace(); &#125; assert field != null; field.setAccessible(true); try &#123; unsafe = (Unsafe) field.get(null); &#125; catch (IllegalAccessException e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) throws NoSuchFieldException, IllegalAccessException, InstantiationException &#123; System.out.println(sizeOf(new Student())); &#125; /** * 计算一个对象的大小，单位：byte * * @param object * @return */ public static long sizeOf(Object object) &#123; HashSet&lt;Field&gt; fields = new HashSet&lt;&gt;(); Class&lt;?&gt; clazz = object.getClass(); while (clazz != Object.class) &#123; for (Field field : clazz.getDeclaredFields()) &#123; if ((field.getModifiers() &amp; Modifier.STATIC) == 0) &#123; fields.add(field); &#125; &#125; clazz = clazz.getSuperclass(); &#125; long maxSize = 0; for (Field field : fields) &#123; long offset = unsafe.objectFieldOffset(field); if (offset &gt; maxSize) &#123; maxSize = offset; &#125; &#125; return ((maxSize / 8) + 1) * 8; //对齐填充 &#125;&#125; Student类，有一个String类型的引用4字节，int类型4字节，然后MarkWord 8字节，类型指针4字节，这总共8+4+4+4=20字节，然后需要对齐填充到最近的8字节整数倍，应该是24字节。 12345678public class Student &#123; String name; //4B int age; //4B //8+4+8 ==&gt; 24B&#125; 执行结果： 可以看到执行结果符合我们的预期值。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F05%2F%E4%B8%80%E6%96%87%E8%AE%A9%E4%BD%A0%E7%90%86%E8%A7%A3as-if-serila%E5%92%8Chappens-before%E8%AF%AD%E4%B9%89%2F</url>
    <content type="text"><![CDATA[深入理解as-if-serial和happens-before语义概述本文大部分出自《Java并发编程的艺术》，温故而知新，加深对基础的理解程度。 一、指令序列的重排序我们在编写代码的时候，通常自上而下编写，那么希望执行的顺序，理论上也是逐步串行执行，但是为了提高性能，编译器和处理器常常会对指令做重排序。从Java源码到最终实际的指令，需要经过三个阶段的重排序： 1） 编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。2） 指令级并行的重排序。现代处理器采用了指令级并行技术来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。3） 内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。 JMM属于语言级别的内存模型，他确保在不同的编译器和不同的处理器平台上，通过禁止特定类型的编译器重排序和处理器重排序，为程序员提供一致的内存可见性保证。 二、as-if-serial语义as-if-serial语义的含义是：无论如何重排序，单线程程序的执行结果不能被改变。编译器和处理器都必须遵循as-if-serial语义，编译器和处理器为了遵循这一易于，他们就不会对存在数据依赖关系的操作进行重排序。具体来说就是如下表的操作就不会重排序： as-if-serial语义把单线程程序保护了起来，遵守as-if-serial语义的编译器、runtime和处理器共同为编写单线程程序的程序员创建了一个幻觉：单线程程序是按程序的顺序来执行的。 三、happens-before规则happens-before是JMM的核心概念，通过happens-before规则JMM可以实现： 一方面，为程序员提供了足够强的内存可见性保证； 另一方面，对编译器和处理器的限制要尽可能的宽松； 1、happens-before规则JSR-133规范中定义了如下happens-before规则： （1）程序顺序规则：一个线程中的每个操作，happens-brfore于该线程中的任意后序操作。 （2）监视器锁规则：线程对解锁obj之前的对变量的写，对接下来对obj加锁的线程对变量的读可见。 123456789101112131415static int x=0;static final Object obj=new Object();new Thread(()-&gt;&#123; synchronized(obj)&#123; x=1; &#125;&#125;,"t1").start();new Thread(()-&gt;&#123; synchronized(obj)&#123; //t1对x的修改对于t2是可见的，因此将会打印2 System.out.println(x++); &#125;&#125;,"t2").start(); （3）volatile变量规则：一个线程对volatile的写，对接下其他变量对该变量的读可见。 1234567891011121314volatile static int x=0;new Thread(()-&gt;&#123; synchronized(obj)&#123; x=10; &#125;&#125;,"t1").start();new Thread(()-&gt;&#123; synchronized(obj)&#123; //t1对x的修改对于t2是可见的，因此将会打印10 System.out.println(x); &#125;&#125;,"t2").start(); （4）传递性：如果A happens-before B，且 B happens-before C，那么 A happens-before C。 （5）start()规则：线程start()之前对变量的写，对该变量开始后对该变量可见。 12345678910static int x;x=10;new Thread(()-&gt;&#123; synchronized(obj)&#123; //t1启动之前对x的写对它是可见的，因此将会打印10 System.out.println(x); &#125;&#125;,"t1").start(); （6）join()规则：线程结束前对变量的写，对其他线程得知他结束后的读可见。（比如线程调用isAlive()、join()） 12345678910111213static int x;Thread t1=new Thread(()-&gt;&#123; synchronized(obj)&#123; x=10; &#125;&#125;,"t1");t1.start();t1.join();//t1启动之前对x的写对它是可见的，因此将会打印10System.out.println(x); 总的来说：happens-before和as-if-serial语义是一回事 as-if-serial语义保证单线程内程序的执行结果不被重排序改变，hapeens-before关系保证正确同步的多线程程序的执行结果不被重排序改变。 as-if-serial语义给编写单线程程序的程序员创建了一个幻觉：单线程程序是按程序的顺序来执行的。happens-before规则给编写正确同步的多线程程寻的程序员一个幻觉：正确同步的多线程程序是按happens-before指定的顺序来执行的。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F05%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3volatile%E5%85%B3%E9%94%AE%E5%AD%97%2F</url>
    <content type="text"><![CDATA[深入理解volatile关键字先给出结论： volatile可以保证不同线程对一个变量的可见性，即一个线程修改了被voaltile修饰的变量后，这新值对其他线程来说是立即可见的; volatile可以禁止指令重排序，保证了有序性； volatile不能保证原子性，更加不能保证线程安全，要想保证原子性和线程安全还是乖乖的使用锁吧！ 具体的原理且看我慢慢分析。 一、Java内存模型JMM即Java Memory Model，它将JVM内存抽象为主内存和工作内存。主内存是所有的线程共享的内存区域，包括方法区和堆内存；工作内存是线程私有的，包括程序计数器、JVM桟和本地方法桟。Java规定： 所有的变量都存储在主内存中(虚拟机内存的一部分)，对于所有线程都是共享的。 每个线程都有自己的工作内存，工作内存中保存的是该线程使用到的变量副本（该副本就是主内存中该变量的一份拷贝），线程对变量的所有操作都必须在工作内存中进行，而不能直接读写主内存中的变量。 线程之间无法直接访问对方的工作内存中的变量，线程间变量的传递均需要通过主内存来完成 屏蔽硬件和操作系统内存读取差异，以达到各个平台下都能达到一致的内存访问效果的产物。并且通过JMM使得程序员不必接触底层的CPU缓存、寄存器、硬件内存、CPU指令优化等。JMM的作用体现在以下几个方面： （1）原子性​ 在Java中，对基本数据类型的变量的读取和赋值操作是原子性操作，即这些操作是不可被中断的，要么执行，要么不执行。并且Java内存模型只保证了基本读取和赋值是原子性操作，如果要实现更大范围操作的原子性，可以通过synchronized和Lock来实现。由于synchronized和Lock能够保证任一时刻只有一个线程执行该代码块，那么自然就不存在原子性问题了，从而保证了原子性。 （2）可见性 对于可见性，Java提供了volatile关键字来保证可见性。当一个共享变量被volatile修饰时，它会保证修改的值会立即被更新到主存，当有其他线程需要读取时，它会去内存中读取新值。另外，通过synchronized和Lock也能够保证可见性，synchronized和Lock能保证同一时刻只有一个线程获取锁然后执行同步代码，并且在释放锁之前会将对变量的修改刷新到主存当中。因此可以保证可见性。 （3）有序性​ 在Java内存模型中，允许编译器和处理器对指令进行重排序，但是重排序过程不会影响到单线程程序的执行（as-if-serial语义），却会影响到多线程并发执行的正确性。 在Java里面，可以通过volatile关键字来保证一定的“有序性”。另外可以通过synchronized和Lock来保证有序性，很显然，synchronized和Lock保证每个时刻是有一个线程执行同步代码，相当于是让线程顺序执行同步代码，自然就保证了有序性。 二、volatile实现的原理1、volatile保证可见性的原理（1）Lock前缀指令volatile可见性的实现原理是基于lock前缀指令实现的。 1234567891011public class Test &#123; private static volatile int a = 1; public static void test() &#123; a = 2; &#125; public static void main(String [] args) &#123; test(); &#125;&#125; 上面的代码，我们添加hsdis插件到JRE的lib目录后，可以对上述代码进行反汇编打印出来的汇编指令如下： 123450x000000011a5ddf25: callq 0x000000010cb439f0 ; &#123;runtime_call&#125;0x000000011a5ddf2a: vzeroupper0x000000011a5ddf2d: movl $0x5,0x270(%r15)0x000000011a5ddf38: lock addl $0x0,(%rsp)0x000000011a5ddf3d: cmpl $0x0,-0xd4ec2e7(%rip) # 0x000000010d0f1c60 核心就是lock指令。可以说，lock指令就是CPU实现volatile可见性的秘密。通过查IA-32架构软件开发者手册,内容如下： 8.1.4 Effects of a LOCK Operation on Internal Processor Caches For the Intel486 and Pentium processors, the LOCK# signal is always asserted on the bus during a LOCK operation,even if the area of memory being locked is cached in the processor. For the P6 and more recent processor families, if the area of memory being locked during a LOCK operation is cached in the processor that is performing the LOCK operation as write-back memory and is completely contained in a cache line, the processor may not assert the LOCK# signal on the bus. Instead, it will modify the memory location internally and allow it’s cache coherency mechanism to ensure that the operation is carried out atomically. Thisoperation is called “cache locking.” The cache coherency mechanism automatically prevents two or more processors that have cached the same area of memory from simultaneously modifying data in that area. 翻译过来即就是： 对于Intel486和Pentium处理器，即使正在锁定的内存区域已缓存在处理器中，在LOCK操作期间始终会在总线上发出LOCK＃（以lock为前缀的指令）信号。 对于P6和更新的处理器家族，如果在执行LOCK操作的处理器中缓存了在LOCK操作期间锁定的内存区域作为回写内存，并且完全包含在缓存行中，则处理器可能不会声明 总线上的LOCK＃信号。 取而代之的是，它将在内部修改内存位置，并允许其缓存一致性机制来确保该操作是原子执行的。 该操作称为“缓存锁定”。 缓存一致性机制会自动阻止已缓存同一内存区域的两个或更多处理器同时修改该区域中的数据。 in the Pentium and P6 family processors, if through snooping one processor detects that another processor intends to write to a memory location that it currently has cached in shared state, the snooping processor will invalidate its cache line forcing it to perform a cache line fill the next time it accesses the same memory location. 翻译过来就是： 在Pentium和P6 系列处理器中，如果通过嗅探一个处理器来检测其他处理器打算写内存地址，而这个地址当前处于共享状态，那么正在嗅探的处理器将使它的缓存行无效，在下次访问相同内存地址时，强制执行缓存行填充一个处理器的缓存回写到内存会导致其他处理器的缓存无效。 上述引用总结为volatile的两条实现原则: （1）对缓存行加锁内容的修改会导致修改后的内容马上写回主内存； （2）一个处理器的缓存回写到主存会使其他缓存了该共享变量的缓存失效。 （2）缓存一致性协议在多处理器下，为了保证各个处理器的缓存是一致的，就会实现缓存一致性协议，这是CPU底层做的事儿，但是这里我们还是需要了解一下原理的。 为了保证缓存的一致性，每个处理器通过在嗅探在总线上传播的数据来检查自己缓存的数据是否过期了，当处理器发现自己缓存行中的数据过期了，就会键当前处理器缓存行中的数据设置成无效状态，当处理器对这个数据进行修改操作的时候会重新从主内存中加载这个数据到缓存里。 （3）缓存一致性的简单实现方式缓存将具有三个额外的位：V（可用） | D（脏位，表示高速缓存中的数据与内存中的数据不同） | S（共享） 读未命中：CPU_A本地缓存读未命中，会广播到监听总线上，其他所有CPU监听处理器会检查，如果缓存了该地址，并且缓存处于“D（脏位）”，将状态改成有效，同时发送副本到请求节点。 写未命中：CPU_A尝试更新本地缓存，但是更新并不在主存中。其他所有CPU监听处理器可确保将其他高速缓存中的所有副本都设置为“无效”。 以上是主要的场景，具体实现有 MESI 协议等。 2、volatile实现禁止指令重排序的原理（1）什么是指令重排序？为什么要指令重排序？现代CPU在执行一条指令的分为5个阶段：取指令--&gt;指令译码--&gt;执行指令--&gt;内存访问--&gt;数据写回。 为了提高指令执行的吞吐量，现代CPU都支持多级指令流水线（一般就是五级指令流水线），就是可以在一个一个时钟周期内同时对5个指令执行不同阶段的操作，本质上，流水线方式不能缩短一条指令执行的时间，但它提高了CPU的吞吐率。 因此，在流水线模式下，为了提高CPU的指令执行效率以及CPU的吞吐率，就会对指令重新排序，让指令能够尽量不间断的送给CPU处理，当然重排序的前提是重排序前后执行的结果不变。指令重排序分为编译器级别的和处理器级别的，但是他们实现重排序的目的都是为了提高程序的效率。 编译器重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序； 处理器重排序。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序，处理器的重排序又被称为乱序执行（out-of-order execution,OOE）技术； （2）as-if-serial语义as-if-serial语义的意思是：无论如何重排序，单线程内程序的执行结果不能被改变。编译器、runtime和处理器都必须遵循as-if-serial语义。为了遵守这条语义，编译器和处理器不会对存在数据依赖关系的操纵进行重排序，反之，就会被重排序。 （3）指令重排序带来的问题指令重排序的本质是好的，但是在某些时候会导致一些错误。请看下面这段代码，这是美团技术团队博客上给出的一段代码，它描述了由于指令重排序带来的问题。 1234567891011121314151617181920212223242526272829303132public class PossibleReordering &#123; static int x = 0, y = 0; static int a = 0, b = 0; public static void main(String[] args) throws InterruptedException &#123; int i = 0; for (; ; ) &#123; i++; x = 0; y = 0; a = 0; b = 0; Thread one = new Thread(() -&gt; &#123; a = 1; x = b; &#125;); Thread other = new Thread(() -&gt; &#123; b = 1; y = a; &#125;); one.start(); other.start(); one.join(); other.join(); if (x == 0 &amp;&amp; y == 0) &#123; System.err.println("第" + i + "次(" + x + "," + y + ")"); break; &#125; &#125; &#125;&#125; 执行结果： 当执行到第649625次的时候发生了错误，为什么说是错误，正常情况下这段代码的运行结果可能为(1,0)、(0,1)或(1,1)，因为线程one可以在线程two开始之前就执行完了，也有可能反之，甚至有可能二者的指令是同时或交替执行的。也就是说，（0，0）这个结果是如果是按正常顺序执行的话是不可能出现的，但是现在出现了就证明了一件事儿，CPU确实存在对指令的重排序。 （4）volatile禁止指令重排序 为了性能优化，JMM 在不改变正确语义的前提下，会允许编译器和处理器对指令序列进行重排序。JMM 提供了内存屏障阻止这种重排序。 Java 编译器会在生成指令系列时在适当的位置会插入内存屏障指令来禁止特定类型的处理器重排序。 JMM 针对编译器制定 volatile 重排序规则表,如下： 其中“NO”表示禁止指令重排序，为了实现这一语义，编译器在生成字节码时，会在指令序列中插入内存屏障来禁止特定类型的处理器重排序。 LoadLoad：对于这样的语句Load1:LoadLoad:Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。 StoreStore：对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。 LoadStore：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。 StoreLoad：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。（开销最大，对于大多数处理器是万能屏障，它兼具其他三种屏障的功能） 其实前面的lock前缀指令实际上相当于一个内存屏障（也成内存栅栏），内存屏障会提供3个功能： （1）它确保指令重排序时不会把其后面的指令排到内存屏障之前的位置，也不会把前面的指令排到内存屏障的后面；即在执行到内存屏障这句指令时，在它前面的操作已经全部完成； （2）它会强制将对缓存的修改操作立即写入主存； （3）如果是写操作，它会导致其他CPU中对应的缓存行无效。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F03%2F%E4%BD%9C%E4%B8%BAJava%E5%B7%A5%E7%A8%8B%E5%B8%88%E4%BD%A0%E7%9C%9F%E7%9A%84%E7%90%86%E8%A7%A3synchronized%E5%90%97%2F</url>
    <content type="text"><![CDATA[作为Java工程师你真的理解synchronized吗造成线程安全问题的诱因主要有两点： 存在共享数据（临界区资源） 存在多个线程对临界区资源的读写操作 因此，为了保证临界区数据的安全，引入了互斥锁的概念，即一个共享数据只能被一个线程访问，其他线程需要等待（阻塞），直至当前线程处理完毕释放该锁。synchronized就保证了同一时刻只有一个线程对方法或者代码块的共享数据的操作。而且，synchronized保证了一个线程对共享变量操作的变化被其他线程看到（可以替代volatile功能）。synchronized是Java语言内置的锁，可以用于代码块，普通成员方法，静态方法。 一、synchronized的作用范围1、synchronized代码块1234567891011public class SynchronizedTest&#123; private Object lock=new Object(); public void fun()&#123; synchronized(lock)&#123; //do something &#125; &#125; &#125; 一个线程在执行临界区代码之前必须要持有对象锁，否则将会被阻塞。 2、synchronized成员方法1234567891011121314public class SynchronizedTest&#123; public synchronized void fun()&#123; //do something &#125;&#125;等价于public class SynchronizedTest&#123; public void fun()&#123; synchronized(this)&#123; //do something &#125; &#125;&#125; synchronized修饰成员方法，实际上是以当前对象为锁，进入同步代码前要获得当前对象实例的锁。并不存在给方法上锁的说法。 3、synchronized静态方法1234567891011121314public class SynchronizedTest&#123; public synchronized static void fun()&#123; //do something &#125;&#125;等价于public class SynchronizedTest&#123; public static void fun()&#123; synchronized(SynchronizedTest.class)&#123; //do something &#125; &#125;&#125; 由于静态方法是属于类的，因此当我们用synchronized修饰静态方法时，实际上是以这个类的Class对象为锁，又由于Class的相关数据存储在永久带PermGen（jdk1.8 则是 metaspace），永久代是全局共享的，因此静态方法锁相当于类的一个全局锁 。 二、Monitor概念Monitor，意为监视器或管程。monitor 的重要特点是，同一个时刻，只有一个 进程/线程 能进入 monitor 中定义的临界区，这使得 monitor 能够达到互斥的效果。但仅仅有互斥的作用是不够的，无法进入 monitor 临界区的 进程/线程，它们应该被阻塞，并且在必要的时候会被唤醒。显然，monitor 作为一个同步工具，也应该提供这样的管理 进程/线程 状态的机制。 在java虚拟机中，每一个对象头都关联着Monitor（由操作系统提供），每一个监视器和一个对象引用相关联，为了实现监视器的互斥功能，每个对象都关联着一把锁（有时候又叫“互斥量mutex”，信号量）。 一旦方法或者代码块被synchronized修饰，那么这个部分就放入了监视器的监视区域，确保一次只能有一个线程执行该部分的代码，线程在获取锁之前不允许执行该部分的代码。 1、synchronized实现的核心组件 WaitSet：调用 wait 方法被阻塞的线程被放置在这里； Contention List：竞争队列，所有请求锁的线程首先被放在这个竞争队列中； EntryList：Contention List 中那些有资格成为候选资源的线程被移动到 Entry List 中； OnDeck：任意时刻，最多只有一个线程正在竞争锁资源，该线程被成为 OnDeck； Owner：当前已经获取到所资源的线程被称为 Owner !Owner：当前释放锁的线程。 2、synchronized的实现原理 JVM 每次从队列的尾部取出一个数据用于锁竞争候选者（OnDeck），但是并发情况下，ContentionList 会被大量的并发线程进行 CAS 访问，为了降低对尾部元素的竞争，JVM 会将一部分线程移动到 EntryList 中作为候选竞争线程。 Owner 线程会在 unlock 时，将 ContentionList 中的部分线程迁移到 EntryList 中，并指定EntryList 中的某个线程为 OnDeck 线程（一般是最先进去的那个线程）。 Owner 线程并不直接把锁传递给 OnDeck 线程，而是把锁竞争的权利交给 OnDeck，OnDeck需要重新竞争锁。这样虽然牺牲了一些公平性，但是能极大的提升系统的吞吐量，在JVM 中，也把这种选择行为称之为“竞争切换”。 OnDeck 线程获取到锁资源后会变为 Owner 线程，而没有得到锁资源的仍然停留在 EntryList中。如果Owner线程被wait方法阻塞，则转移到WaitSet队列中，直到某个时刻通过notify或者 notifyAll 唤醒，会重新进去 EntryList 中。 处于 ContentionList、EntryList、WaitSet 中的线程都处于阻塞状态，该阻塞是由操作系统来完成的（Linux 内核下采用 pthread_mutex_lock 内核函数实现的）。 Synchronized 是非公平锁。 synchronized 在线程进入 ContentionList 时，等待的线程会先尝试自旋获取锁，如果获取不到就进入 ContentionList，这明显对于已经进入队列的线程是不公平的，还有一个不公平的事情就是自旋获取锁的线程还可能直接抢占 OnDeck 线程的锁资源。 每个对象都有个 monitor 对象，加锁就是在竞争 monitor 对象，代码块加锁是在前后分别加上 monitorenter 和 monitorexit 指令来实现的，方法加锁是通过一个ACC_SYNCHRONIZED标记位来判断的。但是无论是同步代码块，还是同步方法，在汇编指令层面都是通过lock cmpxchg实现，在操作系统底层是通过mutex lock实现的。 synchronized 是一个重量级操作，需要调用操作系统相关接口，性能是低效的，有可能给线程加锁消耗的时间比有用操作消耗的时间更多。 Java1.6，synchronized 进行了很多的优化，有适应自旋、锁消除、锁粗化、轻量级锁及偏向锁等，效率有了本质上的提高。在之后推出的 Java1.7 与 1.8 中，均对该关键字的实现机理做了优化。引入了偏向锁和轻量级锁。都是在对象头中有标记位，不需要经过操作系统加锁。 锁可以从偏向锁升级到轻量级锁，再升级到重量级锁。这种升级过程叫做锁膨胀； JDK 1.6 中默认是开启偏向锁和轻量级锁，可以通过-XX:-UseBiasedLocking 来禁用偏向锁。 三、Java虚拟机对synchronized的优化 Java早期版本中，synchronized属于重量级锁，效率低下，因为监视器锁（monitor）是依赖于底层的操作系统的mutex lock来实现的，而操作系统实现线程之间的切换时需要从用户态转换到内核态，这个状态之间的转换需要相对比较长的时间，时间成本相对较高（这也正是synchronized是重量级的原因），这也是为什么早期的synchronized效率低的原因。庆幸的是在Java 6之后Java官方对从JVM层面对synchronized较大优化，所以现在的synchronized锁效率也优化得很不错了，Java 6之后，为了减少获得锁和释放锁所带来的性能消耗，引入了轻量级锁和偏向锁，接下来我们将简单了解一下Java官方在JVM层面对synchronized锁的优化。 jdk1.6以后Java的锁有4种状态：无锁状态、偏向锁、轻量级锁（自旋锁）和重量级锁。锁可以从偏向锁升级到轻量级锁，再升级到重量级锁，锁可以升级，但是锁不能降级,这种策略是为了提高获得锁和释放锁的效率。 锁升级过程（1）无锁状态 刚new出来的对象就处于无锁状态。此时一个对象的对象头的Mark Word中主要存储的是对象的hashcode（默认全是0，只用程序中调用了hashCode()方法之后才会主动设置这一部分）、对象的分代年龄、最后三位001就可以标志这是一个没有锁的对象。 （2）偏向锁 偏向锁的获取 当一个线程访问同步块并获取锁时，会在锁对象的对象头的Mark Word和栈帧中的锁记录(Lock Record)里存储当前线程ID，以后该线程在进入和退出同步块时不需要进行CAS操作来加锁和解锁，只需简单地测试一下对象头的Mark Word里是否存储着指向当前线程的偏向锁。如果测试成功，表示线程已经获得了锁。如果测试失败，则需要再测试一下Mark Word中偏向锁的标识是否设置成1（表示当前是偏向锁）：如果没有设置，则使用CAS竞争锁；如果设置了，则尝试使用CAS将对象头的偏向锁指向当前线程 偏向锁的撤销 偏向锁使用了一种等到竞争出现才释放锁的机制，所以当其他线程尝试竞争偏向锁时，持有偏向锁的线程才会释放锁。 偏向锁在JDK1.6之后是默认开启的，但是它有一个延迟，会在程序启动后几秒后才会激活，也可以通过JVM参数关闭延迟： ​ -XX:BiasedLockingStartupDelay=0 当程序中的锁竞争是很可能发生的事情的时候可以直接使用JV命名关闭偏向锁： ​ -XX:UseBiasedLocking=false （3）轻量级锁 加锁 线程在执行同步块之前，JVM会先在当前线程的栈桢中创建用于存储锁记录的空间，并将对象头中的Mark Word复制到锁记录中，官方称为Displaced Mark Word。然后线程尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针。如果成功，当前线程获得锁，如果失败，表示其他线程竞争锁，当前线程便尝试使用自旋来获取锁 解锁 轻量级解锁时，会使用原子的CAS操作将Displaced Mark Word替换回到对象头，如果成功，则表示没有竞争发生。如果失败，表示当前锁存在竞争，锁就会膨胀成重量级锁。 （4）重量级锁 当程序中的线程竞争再次加剧的时候，轻量级锁就会最终膨胀为重量级锁，重量级锁就是指当一个线程获得锁之后，其余等待这个锁的线程都将进入到阻塞状态。重量级锁是操作系统层面的锁，此时线程的调度都将由操作系统负责，因此这就会引起频繁的上下文切换，导致线程被频繁的唤醒和挂起，使得程序性能下降。重量级锁的底层实现在JVM层面是通过对象内部的监视器（monitor）实现的。 各种锁的比较： 四、锁降级、锁消除、锁粗化1、锁降级（不重要）锁降级在某些特定情况下回发生，就是在GC的时候会发生，但是此时锁降级也就没有意义了，因此锁降级可以认为是不存在的。 2、锁消除 lock eliminate1234public void add()&#123; StringBuffer sb=new StringBuffer(); sb.append("heello").append("java");&#125; 锁消除是指虚拟机在即时编译器运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行削除。锁削除的主要判定依据来源于逃逸分析的数据支持，如果判断到一段代码中，在堆上的所有数据都不会逃逸出去被其他线程访问到，那就可以把它们当作栈上数据对待，认为它们是线程私有的，同步加锁自然就无须进行。 3、 锁粗化 lock coarsening原则上对于锁的使用都是需要细化到尽量小的范围，大部分情况下，都是正确的，但是一些列的加锁和解锁操作很是麻烦。造成性能损坏。比如下面的情况： 12345678910111213141516171819//锁粗化之前public void fun()&#123; //task1 for(int i=0;i&lt;100li++)&#123; synchrnoized(this)&#123; //task2 &#125; &#125;&#125;//锁粗化优化后public void fun()&#123; //task1 synchronized(this)&#123; for(int i=0;i&lt;100li++)&#123; //task2 &#125; &#125;&#125; 五、synchronized可重入锁实现底层原理1、重入的概念？可重入就是说若一个程序或子程序可以“在任意时刻被中断然后操作系统调度执行另外一段代码，这段代码又调用了该子程序不会出错”，则称其为可重入（reentrant或re-entrant）的。即当该子程序正在运行时，执行线程可以再次进入并执行它，仍然获得符合设计时预期的结果。与多线程并发执行的线程安全不同，可重入强调对单个线程执行时重新进入同一个子程序仍然是安全的。 通俗来说：当线程请求一个由其它线程持有的对象锁时，该线程会阻塞，而当线程请求由自己持有的对象锁时，如果该锁是重入锁，请求就会成功，否则阻塞。 synchronized拥有强制原子性的内部锁机制，是一个可重入锁。因此，在一个线程使用synchronized方法时调用该对象另一个synchronized方法，即一个线程得到一个对象锁后再次请求该对象锁，是永远可以拿到锁的。 2、synchronized实现可重入锁的原理或机制 Java中每一个对象锁中都会和一个monitor关联，monitor中有一个计数器就是专门用来记录线程的重入次数的，当此计数器为0时表示该锁没有被任何线程持有，那么任何线程都可能获得该锁而执行相应的临界区代码；当某一线程请求成功后，JVM会记下锁的持有线程，并且将计数器置为 1；此时其它线程请求该锁，则必须等待；而该持有锁的线程如果再次请求这个锁，就可以再次拿到这个锁，同时计数器会递增+1；当线程退出同步代码块时，计数器会递减-1，如果计数器为 0，则表示当前线程释放了该锁。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F03%2F%E7%AD%89%E5%BE%85%E9%80%9A%E7%9F%A5%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[一、什么是等待/通知机制？多个线程之间也可以实现通信，原因就是多个线程共同刚 访问同一个变量。但是这种通信机制不是 “等待/通知”，两个线程完全是主动地读取一个共享变量。简单的说，等待/通知机制就是一个【线程A】等待，一个【线程B】通知（线程A可以不用再等待了）。比如生产者和消费者模型，消费者等待生产者生产资源，这是等待，生产者生产好资源通知等待的消费者去消费，这是通知。 等待/通知的相关方法是任意Java对象都具备的，因为这些方法被定义在java.lang.Object类中 12345wait() //代用该方法的线程会进入到WAITING状态，并且当前线程会被放置到等待队列中，只有等待另外线程的唤醒或被中断返回，调用wait()方法后线程会释放对象锁，同时该方法必须在同步方法或同步块中使用，否则会抛出IllegalMonitorStateException异常。wait(long) //超时等待一段时间，时间单位是ms,如果没有被唤醒就超时返回wait(long,int) //等待一段时间，并不能精确到纳秒，只会多1ms，如果在这一段时间内没哟被唤醒就超时返回notify() //唤醒一个在等待对象锁的其他线程，如果有多个线程在等待该对象锁，那么会由线程规划器随机唤醒一个线程，此方法也必须在同步方法或同步块中使用，否则会抛出IllegalMonitorStateException异常。notifyAll() //唤醒所有等待此对象锁的线程 注意！（1）notify()或notifyAll()在调用之后，等待线程不会立即从WAITING状态立即变为RUNNING状态，而是需要等到调动notify()或notifyAll()的方法释放对象锁之后才会从WAITING状态返回。（2）wait(long,int) 这个方法其实不能精确到ns，这一点从源码就可以看到,他只是在前面的参数上加了1ms： 二、等待/通知机制的经典范式（模板）（1）等待方（消费者）需遵循如下原则： 获取对象锁 如果条件不满足，那么调用对象的wait()方法，被通知后仍然要检查条件 条件满足则执行对应逻辑 123456synchronized(对象)&#123; while(条件不满足)&#123; 对象.wait(); &#125; 对应的逻辑;&#125; （2）通知方（生产者）需遵循如下原则： 获得对象锁 改变条件 通知所有等待该对象锁的线程 1234synchronized(对象)&#123; 改变条件; 对象.notifyAll();&#125; 三、异步模型——生产者和消费者模型要点： 消费队列可以用来平衡生产和消费的线程资源 生产者专心生产资源，不关心数据如何处理，消费者专心消费资源 消息队列是由容量限制的，当容量满了以后生产者停止生产，当空了后消费者停止消费 JDK中各种阻塞队列使用的就是这种模式 实现生产者消费者 资源：Resourcs.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package top.easyblog.wait;/** * 生产者——消费者模型：资源 * * @author ：huangxin * @modified ： * @since ：2020/04/01 18:21 */public class Resources &#123; //模拟资源的数量 private int num; //资源的最大允许数存放量 private static final int MAX_NUM = 10; /** * 从资源池中取走资源 */ public synchronized void remove() &#123; if (num &gt; 0) &#123; num--; System.out.println("消费者" + Thread.currentThread().getName() + "消耗一件资源，" + "当前资源有" + num + "个"); //通知生产者生产资源 notifyAll(); &#125; else &#123; try &#123; //没有资源，消费者进入等待状态 wait(); System.out.println("消费者" + Thread.currentThread().getName() + "线程进入等待状态"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; /** * 向资源池中添加资源 */ public synchronized void add() &#123; if (num &lt; MAX_NUM) &#123; num++; System.out.println("生产者" + Thread.currentThread().getName() + "+生产一个资源，当前资源有" + num + "个"); //通知消费者消费 notifyAll(); &#125; else &#123; try &#123; //资源生产数量过多，让生产者进入等待状态，并释放锁 wait(); System.out.println(Thread.currentThread().getName() + "线程进入等待"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 生产者：Producer.java 1234567891011121314151617181920212223242526272829303132package top.easyblog.wait;/** * 生产者——消费者模型：生产者 * * @author ：huangxin * @modified ： * @since ：2020/04/01 18:11 */public class Producer implements Runnable &#123; private Resources resources; public Producer(Resources resources) &#123; this.resources = resources; &#125; /** * 生产者每1s生产一个资源 */ public void run() &#123; while (true) &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; resources.add(); &#125; &#125;&#125; 消费者：Customer.java 12345678910111213141516171819202122232425262728293031package top.easyblog.wait;/** * 生产者——消费者模型：消费者 * * @author ：huangxin * @modified ： * @since ：2020/04/01 18:34 */public class Customer implements Runnable &#123; private Resources resources; public Customer(Resources resources) &#123; this.resources = resources; &#125; /** * 消费者每2s消费一个资源 */ public void run() &#123; while (true) &#123; try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; resources.remove(); &#125; &#125;&#125; 四、最后总结一下1、等待/通知机制Java中这一机制的实现是wait()/notify()。 wait()：会将当前线程放入等待队列，让当前线程停止运行直到有其他线程唤醒或者被中断。在调用wait()方法时，当前线程必须已经获得锁，即只能与synchroinzed中使用，执行wait()方法后当前线程会释放锁。 notify()：只能和synchronized配合使用，当此方法执行后会有由线程规划器随机唤醒一个等待中的线程，执行notify()之后，当前线程不会立即释放锁，被唤醒的线程也不会立即获得该对象锁，而是进入到就绪状态（进入到Monitor的EentryList中）准备竞争此对象锁，如果竞争锁失败，此线程也除非再次代用wait(),否者不会再被放到等待队列中了。 2、sleep()和wait()的区别（1）sleep()是Thread类中的方法，wait()是Object()中的方法，因此所有对象都有这个方法（2）wait()必须配合synchronized使用，但是sleep()没有这个要求（3）如果当前线程持有锁，那么调用sleep()方法之后当前线程不会释放锁，此时其他线程四无法获取这个锁的，但是调用wait()方法会释放锁，其他线程可获得该对象锁 3、Java中wait()和notify为什么定义在Object类中而不是在Thread类中？Object中的wait(), notify()等函数，和synchronized一样，会对“对象的同步锁”进行操作。 wait()会使“当前线程”等待，因为线程进入等待状态，所以线程应该释放它锁持有的“同步锁”，否则其它线程获取不到该“同步锁”而无法运行！OK，线程调用wait()之后，会释放它锁持有的“同步锁”；而且，根据前面的介绍，我们知道：等待线程可以被notify()或notifyAll()唤醒。现在，请思考一个问题：notify()是依据什么唤醒等待线程的？或者说，wait()等待线程和notify()之间是通过什么关联起来的？答案是：依据“对象的同步锁”。 负责唤醒等待线程的那个线程(我们称为“唤醒线程”)，它只有在获取“该对象的同步锁”(这里的同步锁必须和等待线程的同步锁是同一个)，并且调用notify()或notifyAll()方法之后，才能唤醒等待线程。虽然，等待线程被唤醒；但是，它不能立刻执行，因为唤醒线程还持有“该对象的同步锁”。必须等到唤醒线程释放了“对象的同步锁”之后，等待线程才能获取到“对象的同步锁”进而继续运行。 总之，notify(), wait()依赖于“同步锁”，而“同步锁”是对象锁持有，并且每个对象有且仅有一个！这就是为什么notify(), wait()等函数定义在Object类，而不是Thread类中的原因。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F01%2FThread%E5%92%8CRunnable%E6%B7%B1%E5%85%A5%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%2F</url>
    <content type="text"><![CDATA[Thread和Runnable深入源码剖析一、Runnable的实现类Thread类本质是Runnable的一个实现类，Runnable从jdk1.0就有了，并且在jdk1.8开始成为了一个函数式接口，这使得我么可以使用lambda简化线程的创建。 二、 Thread类的构造方法 所有构造方法都是调用init()方法来完成对一个线程的初始化，下面是init方法的jdk源码： 从源码中可以看出下面几点： 每个线程都会有一个线程名，默认的名字是&quot;Thread-&quot; + nextThreadNum()； 每个新创建的线程的父线程就是当前线程； 如果一个线程我们没有指定线程组，那么他会和父线程在同一线程组； 如果父线程是守护线程，那么新创建的这个线程也是守护线程，反之同理； 新创建的线程的优先级默认和父线程的优先级相同； currentThread() ==&gt;native方法，获取当前线程 默认线程名是”Thread”+nextThreadNum，线程名可以通过setName()方法修改，并且可以通过方法getName()方法获取到线程名 nextThreadNum()==&gt;同步方法，维护了一个成员变量threadInitNumber，就是一个线程初始化的数字，没创建一个线程就+1 setName() 三、线程的优先级和线程状态123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778/***java中的线程优先级从1-10，默认是NORM_PRIORITY，优先级越高线程获得CPU时间片的概率就越大*/public final static int MIN_PRIORITY = 1;public final static int NORM_PRIORITY = 5;public final static int MAX_PRIORITY = 10;/***Java API提供的设置线程优先级的方法*/public final void setPriority(int newPriority) &#123; ThreadGroup g; checkAccess(); // 优先级范围 1~10 if (newPriority &gt; MAX_PRIORITY || newPriority &lt; MIN_PRIORITY) &#123; throw new IllegalArgumentException(); &#125; if((g = getThreadGroup()) != null) &#123; if (newPriority &gt; g.getMaxPriority()) &#123; newPriority = g.getMaxPriority(); &#125; // 设置优先级 native方法 setPriority0(priority = newPriority); &#125;&#125;/***获得线程的优先级*/public final int getPriority() &#123; return priority;&#125;private native void setPriority0(int newPriority);/**Thread内部类State 专门用来定义了线程的不同妆台，具体每个状态的含义就下面的注释，建议阅读英文注释 * A thread state. A thread can be in one of the following states: * NEW:A thread that has not yet started is in this state. * RUNNABLE:A thread executing in the Java virtual machine is in this state. * BLOCKED:A thread that is blocked waiting for a monitor lock is in this state. * WAITING:A thread that is waiting indefinitely for another thread to * perform a particular action is in this state. * TIMED_WAITING:A thread that is waiting for another thread to perform an action * for up to a specified waiting time is in this state. * TERMINATED:A thread that has exited is in this state. * A thread can be in only one state at a given point in time. * These states are virtual machine states which do not reflect * any operating system thread states. * @since 1.5 */public enum State &#123; // 创建后,但是没有start(),调用了start()后,线程才算准备就绪,可以运行(RUNNABLE) NEW, // 正在运行或正在等待操作系统调度 RUNNABLE, // 线程正在等待监视器锁 // 正在synchronized块/方法上等待获取锁,或者调用了Object.wait(),等待重新获得锁进入同步块 BLOCKED, // 调用Object.wait(),Thread.join()或LockSupport.park()会进入该状态,注意这里的调用均为没有设置超时, // 线程正在等待其他线程进行特定操作,比如,调用了Object.wait()的线程在另一个线程调用Object.notify()/Object.notifyAll() // 调用了Thread.join()的线程在等待指定线程停止,join()的内部实现方式也是Object.wait(),只不过其Object就是线程对象本身 WAITING, // 调用Thread.sleep(),Object.wait(long),Thread.join(long), // LockSupport.parkNanos(long),LockSupport.parkUntil(long)会进入该状态, // 注意,这里的调用均设置了超时 TIMED_WAITING, // 线程执行完成,退出 TERMINATED;&#125;/***jdk1.5开始提供的方法，用于获取线程的状态*/public State getState() &#123; // get current thread state return sun.misc.VM.toThreadState(threadStatus);&#125; 注意！一个线程在被从Object.wait()中被唤醒时,会立即进入BLOCKED状态,这时其并没有获得锁,只是被唤醒了,再次开始对Object的监视器锁进行竞争;只有在其竞争获得锁之后才会进入RUNNABLE状态. 四、run()和start()run()：如果是构造Thread对象的时候,传入了该对象预期执行的任务—-Runnable对象时,执行该任务,否则,什么都不做,当然,可以通过继承Thread类重写run()来修改其行为: 123456789/* What will be run. */private Runnable target;@Overridepublic void run() &#123; if (target != null) &#123; target.run(); &#125;&#125; start()：以前面试最爱问的一个问题：调用start()与调用run()的区别？这还用说嘛？ 12345678910111213141516171819202122232425262728293031323334/* Java thread status for tools,* initialized to indicate thread 'not yet started'*/private volatile int threadStatus = 0;// 启动线程,JVM会调用当前Thread对象的run() // 同步方法public synchronized void start() &#123; // A zero status value corresponds to state "NEW". // 如果调用时不是在线程状态不是NEW,则抛出IllegalThreadStateException if (threadStatus != 0) throw new IllegalThreadStateException(); /* Notify the group that this thread is about to be started * so that it can be added to the group's list of threads * and the group's unstarted count can be decremented. */ group.add(this); boolean started = false; try &#123; // 通过native方法start0()来实现线程启动 start0(); started = true; &#125; finally &#123; try &#123; if (!started) &#123; group.threadStartFailed(this); &#125; &#125; catch (Throwable ignore) &#123; /* do nothing. If start0 threw a Throwable then it will be passed up the call stack */ &#125; &#125;&#125;private native void start0(); 五、线程中断1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/* The object in which this thread is blocked in an interruptible I/O * operation, if any. The blocker's interrupt method should be invoked * after setting this thread's interrupt status. */private volatile Interruptible blocker;private final Object blockerLock = new Object();/* Set the blocker field; invoked via sun.misc.SharedSecrets from java.nio code */void blockedOn(Interruptible b) &#123; synchronized (blockerLock) &#123; blocker = b; &#125;&#125;/** * 中断当前执行线程 * 如果当前线程阻塞在Object.wait(),Thread.join(),Thread.sleep()上, * 那么该线程会收到InterruptedException,且线程的打断标志会被清除; * 如果当前线程阻塞在InterruptibleChannel上,那么该InterruptibleChannel * 会被关闭,线程的打断标志会被置位,且当前线程会收到ClosedByInterruptException; * 如果当前线程阻塞在Selector上,那么该Selector的selection操作将会立即返回一个非0的结果, * 且Selector.wakeup()会被调用,线程的打断标志会被置位, * 如果上述情况均不存在,将当前线程的打断标志置位 * 打断一个isAlive()返回false的线程没有效果,isInterrupted()仍然会返回false; */public void interrupt() &#123; if (this != Thread.currentThread()) checkAccess(); synchronized (blockerLock) &#123; Interruptible b = blocker; // 在Interruptible上阻塞 if (b != null) &#123; interrupt0(); // Just to set the interrupt flag b.interrupt(this); //Interruptible中的一个方法，两个实现类主要在nio包中 return; &#125; &#125; interrupt0();&#125;private native void interrupt0();/***判断是否产生中断，两个方法：interrupted() isInterrupted()*/public static boolean interrupted() &#123; //清除中断标志位 return currentThread().isInterrupted(true);&#125;public boolean isInterrupted() &#123; return isInterrupted(false);&#125;/** * 返回线程是否被打断(打断标志是否被置位) * 传入的参数决定该方法是否会清除中断标志位 */private native boolean isInterrupted(boolean ClearInterrupted); 关于isInterrupted()和interrupted()的区别,上述源码表现得很明显isInterrupted()不会清除中断标示位，interrupted()会清除中断标志位，而且是个静态方法。 六、线程礼让\睡眠\合并—yield() sleep() join()1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798/** * 暗示调度器让出当前线程的执行时间片,调度器可以选择忽略该暗示; * 该方法在用来调试和测试时可能很有用,可以用来重现需要特殊条件才能复现的bug; * 也可以用来进行并发优化等; */public static native void yield();/** * 当前执行线程休眠指定毫秒在休眠期间,不释放任何当前线程持有的锁; */public static native void sleep(long millis) throws InterruptedException;/** * 当前执行线程休眠指定毫秒在休眠期间,不释放任何当前线程持有的锁; * 如果当前被打断(该方法调用前或该方法调用时),抛出InterruptedException,同时将打断标志清掉 */public static void sleep(long millis, int nanos) throws InterruptedException &#123; // 取值范围检查 if (millis &lt; 0) &#123; throw new IllegalArgumentException("timeout value is negative"); &#125; if (nanos &lt; 0 || nanos &gt; 999999) &#123; throw new IllegalArgumentException( "nanosecond timeout value out of range"); &#125; // 纳秒最后还是转换成了毫秒233333 // 可能是考虑都有些 if (nanos &gt;= 500000 || (nanos != 0 &amp;&amp; millis == 0)) &#123; millis++; &#125; sleep(millis);&#125;/** * 当前执行线程等待指定线程(也就是该调用发生的Thread对象)死后再继续执行; * 可以设置超时,如果设置超时为0,则为不设置超时; * 线程结束时(terminate),将会调用自身的notifyAll(),唤醒在该Thread对象上wait()的方法; * 如果该线程被打断,该方法将抛出InterruptedException,并将打断标志位清除 */// 同步方法,同步当前Thread对象,所以才能在其内部调用wait()public final synchronized void join(long millis)throws InterruptedException &#123; long base = System.currentTimeMillis(); long now = 0; if (millis &lt; 0) &#123; throw new IllegalArgumentException("timeout value is negative"); &#125; // 使用isAlive()和wait()的循环实现 if (millis == 0) &#123; while (isAlive()) &#123; wait(0); &#125; &#125; else &#123; while (isAlive()) &#123; long delay = millis - now; if (delay &lt;= 0) &#123; break; &#125; wait(delay); now = System.currentTimeMillis() - base; &#125; &#125;&#125;public final synchronized void join(long millis, int nanos)throws InterruptedException &#123; if (millis &lt; 0) &#123; throw new IllegalArgumentException("timeout value is negative"); &#125; if (nanos &lt; 0 || nanos &gt; 999999) &#123; throw new IllegalArgumentException( "nanosecond timeout value out of range"); &#125; if (nanos &gt;= 500000 || (nanos != 0 &amp;&amp; millis == 0)) &#123; millis++; &#125; join(millis);&#125;public final void join() throws InterruptedException &#123; join(0);&#125;/** * This method is called by the system to give a Thread * a chance to clean up before it actually exits. */private void exit() &#123; if (group != null) &#123; group.threadTerminated(this); group = null; &#125; /* Aggressively null out all reference fields: see bug 4006245 */ target = null; /* Speed the release of some of these resources */ threadLocals = null; inheritableThreadLocals = null; inheritedAccessControlContext = null; blocker = null; uncaughtExceptionHandler = null;&#125; 七、被遗弃的方法——suspend() resume() stop()1234567891011121314151617181920212223242526272829303132333435363738394041/** * 挂起当前线程 * 弃用原因:容易导致死锁 */@Deprecatedpublic final void suspend() &#123; checkAccess(); suspend0();&#125;/** * 从suspend()中恢复线程运行 * 弃用原因:容易导致死锁 */@Deprecatedpublic final void resume() &#123; checkAccess(); resume0();&#125;/** * 强制线程停止执行; * 通过抛出一个ThreadDeath的方式来停止线程; * 废弃原因:stop()会释放所有已持有的锁的监视器,如果存在之前被这些监视器保护的对象处于一个不连续 * 的状态(inconsistent state),这些被损坏的对象将会对其他线程可见,出现不可预期的行为; */@Deprecatedpublic final void stop() &#123; SecurityManager security = System.getSecurityManager(); if (security != null) &#123; checkAccess(); if (this != Thread.currentThread()) &#123; security.checkPermission(SecurityConstants.STOP_THREAD_PERMISSION); &#125; &#125; // A zero status value corresponds to "NEW", it can't change to // not-NEW because we hold the lock. if (threadStatus != 0) &#123; resume(); // Wake up thread if it was suspended; no-op otherwise &#125; // The VM can handle all thread states stop0(new ThreadDeath());&#125; 八、ThreadLocal: 在Thread中有两个关于ThreadLocal的成员变量123456789/***每个线程的ThreadLocalMap*/ThreadLocal.ThreadLocalMap threadLocals = null;/*** InheritableThreadLocal提供了一种父子线程之间的数据共享机制。*/ThreadLocal.ThreadLocalMap inheritableThreadLocals = null; 九、UncaughtExceptionHandler1234567891011121314151617181920212223242526272829303132333435363738394041424344454647// null unless explicitly setprivate volatile UncaughtExceptionHandler uncaughtExceptionHandler;// null unless explicitly setprivate static volatile UncaughtExceptionHandler defaultUncaughtExceptionHandler;/** * 设置UncaughtExceptionHandler,该设置对所有线程有效 * 如果自身没有设置,则交给其线程组的UncaughtExceptionHandler处理,如果再没有, * 则交给默认的的UncaughtExceptionHandler处理,也即这里设置的UncaughtExceptionHandler处理 * 注意这里的设置不应该设置为线程的线程组,这样的设置会造成死循环 */public static void setDefaultUncaughtExceptionHandler(UncaughtExceptionHandler eh) &#123; SecurityManager sm = System.getSecurityManager(); if (sm != null) &#123; sm.checkPermission(new RuntimePermission("setDefaultUncaughtExceptionHandler")); &#125; defaultUncaughtExceptionHandler = eh; &#125;/** * 返回默认的UncaughtExceptionHandler,该UncaughtExceptionHandler对所有线程有效 */public static UncaughtExceptionHandler getDefaultUncaughtExceptionHandler()&#123; return defaultUncaughtExceptionHandler;&#125;/** * 返回该线程的UncaughtExceptionHandler,如果没有,返回该线程的线程组 * ThreadGroup本身实现了UncaughtExceptionHandler接口 */public UncaughtExceptionHandler getUncaughtExceptionHandler() &#123; return uncaughtExceptionHandler != null ? uncaughtExceptionHandler : group;&#125;/** * 设置该线程的UncaughtExceptionHandler */public void setUncaughtExceptionHandler(UncaughtExceptionHandler eh) &#123; checkAccess(); uncaughtExceptionHandler = eh;&#125;/** * uncaught exception 分发给UncaughtExceptionHandler * 该方法被JVM调用 */private void dispatchUncaughtException(Throwable e) &#123; getUncaughtExceptionHandler().uncaughtException(this, e);&#125;]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F01%2FLockSupport%E6%B7%B1%E5%85%A5%E6%BA%90%E7%A0%81%E5%89%96%E6%9E%90%2F</url>
    <content type="text"><![CDATA[LockSupport深入源码剖析与Object的wait()/notify()相比： wait()、notify()、notifyAll()都必须配置Object monitor使用，而LockSupport的park()、unpark()方法不必 park()、unpark()可以精确到一个线程来阻塞和唤醒它，但是notify()只能在Wait Set中随机唤醒一个，并且notifyAll()也只能是唤醒所有的线程，控制精度不及unpark()。 一个线程执行unpark()之前可以调用park()，并且线程执行的效果和先调用park()再调用unpark()一致。 1、LockSupport的基本使用LockSupport中有一组方法可以实现对某一个线程精确的阻塞和唤醒，即：park()及他的重载方法和unpark() （1）正常使用：先阻塞再唤醒 123456789101112131415161718192021222324252627282930313233package top.easyblog;import java.util.concurrent.locks.LockSupport;/** * @author ：huangxin * @modified ： * @since ：2020/04/01 17:06 */public class LockSupportTest &#123; public static void main(String[] args) &#123; Thread t1 = new Thread(() -&gt; &#123; System.out.println("start"); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("park....."); LockSupport.park(); System.out.println("resume....."); &#125;,"t1"); t1.start(); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("unpark..."); LockSupport.unpark(t1); &#125;&#125; 执行结果： （2）先唤醒再阻塞 12345678910111213141516171819202122232425262728293031323334package top.easyblog;import java.util.concurrent.locks.LockSupport;/** * @author ：huangxin * @modified ： * @since ：2020/04/01 17:06 */public class LockSupportTest &#123; public static void main(String[] args) &#123; Thread t1 = new Thread(() -&gt; &#123; System.out.println("start"); try &#123; Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("park....."); LockSupport.park(); System.out.println("resume....."); &#125;,"t1"); t1.start(); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println("unpark..."); LockSupport.unpark(t1); &#125;&#125; 执行结果： 可以看到，这次是先执行了唤醒操作，之后执行了阻塞操作，但是程序并没有像我们预期的那样阻塞，而是正常执行结束了。这是为什么呢？接下来我们就深入到源码中探寻真相！！！ 二、park()、unpark()原理剖析在Java API层面很简单，最终都是调用了UnSafe类的对应的本地方法，为了探究底层原理，我找到了关于这个用C++实现的Parker类，每一个线程都有一个与之关联的Parker对象，Parker对象主要由counter、cond和__mutex组成。下面是Parker类的部分源码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455class Parker : public os::PlatformParker &#123; //Parker继承了PaltformaParkerprivate: volatile int _counter ; //计数 Parker * FreeNext ; //指向下一个Parker JavaThread * AssociatedWith ; // 指向parker所属的线程。 public: Parker() : PlatformParker() &#123; _counter = 0 ; //初始化为0 FreeNext = NULL ; AssociatedWith = NULL ; &#125;protected: ~Parker() &#123; ShouldNotReachHere(); &#125;public: // For simplicity of interface with Java, all forms of park (indefinite, // relative, and absolute) are multiplexed into one call. void park(bool isAbsolute, jlong time); void unpark(); // Lifecycle operators static Parker * Allocate (JavaThread * t) ; static void Release (Parker * e) ;private: static Parker * volatile FreeList ; static volatile int ListLock ; &#125;;//PlatformParker类class PlatformParker : public CHeapObj&lt;mtInternal&gt; &#123; protected: enum &#123; REL_INDEX = 0, ABS_INDEX = 1 &#125;; int _cur_index; // 条件变量数组下标，which cond is in use: -1, 0, 1 pthread_mutex_t _mutex [1] ; //pthread互斥锁 pthread_cond_t _cond [2] ; // pthread条件变量数组,一个用于相对时间，一个用于绝对时间。 public: // TODO-FIXME: make dtor private ~PlatformParker() &#123; guarantee (0, "invariant") ; &#125; public: PlatformParker() &#123; int status; status = pthread_cond_init (&amp;_cond[REL_INDEX], os::Linux::condAttr()); assert_status(status == 0, status, "cond_init rel"); status = pthread_cond_init (&amp;_cond[ABS_INDEX], NULL); assert_status(status == 0, status, "cond_init abs"); status = pthread_mutex_init (_mutex, NULL); assert_status(status == 0, status, "mutex_init"); _cur_index = -1; // mark as unused &#125;&#125;; LockSupport就是通过Parker类中的__counter实现对一个线程的阻塞和唤醒的。 调用park()示意图 Parker::park()： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101void Parker::park(bool isAbsolute, jlong time) &#123; // Ideally we'd do something useful while spinning, such // as calling unpackTime(). // Optional fast-path check: // Return immediately if a permit is available. // We depend on Atomic::xchg() having full barrier semantics // since we are doing a lock-free update to _counter. if (Atomic::xchg(0, &amp;_counter) &gt; 0) return; Thread* thread = Thread::current(); assert(thread-&gt;is_Java_thread(), "Must be JavaThread"); JavaThread *jt = (JavaThread *)thread; // Optional optimization -- avoid state transitions if there's an interrupt pending. // Check interrupt before trying to wait if (Thread::is_interrupted(thread, false)) &#123; return; &#125; // Next, demultiplex/decode time arguments timespec absTime; if (time &lt; 0 || (isAbsolute &amp;&amp; time == 0) ) &#123; // don't wait at all return; &#125; if (time &gt; 0) &#123; unpackTime(&amp;absTime, isAbsolute, time); &#125; // Enter safepoint region // Beware of deadlocks such as 6317397. // The per-thread Parker:: mutex is a classic leaf-lock. // In particular a thread must never block on the Threads_lock while // holding the Parker:: mutex. If safepoints are pending both the // the ThreadBlockInVM() CTOR and DTOR may grab Threads_lock. ThreadBlockInVM tbivm(jt); // Don't wait if cannot get lock since interference arises from // unblocking. Also. check interrupt before trying wait if (Thread::is_interrupted(thread, false) || pthread_mutex_trylock(_mutex) != 0) &#123; return; &#125; int status ; if (_counter &gt; 0) &#123; // no wait needed _counter = 0; status = pthread_mutex_unlock(_mutex); assert (status == 0, "invariant") ; // Paranoia to ensure our locked and lock-free paths interact // correctly with each other and Java-level accesses. OrderAccess::fence(); return; &#125;#ifdef ASSERT // Don't catch signals while blocked; let the running threads have the signals. // (This allows a debugger to break into the running thread.) sigset_t oldsigs; sigset_t* allowdebug_blocked = os::Linux::allowdebug_blocked_signals(); pthread_sigmask(SIG_BLOCK, allowdebug_blocked, &amp;oldsigs);#endif OSThreadWaitState osts(thread-&gt;osthread(), false /* not Object.wait() */); jt-&gt;set_suspend_equivalent(); // cleared by handle_special_suspend_equivalent_condition() or java_suspend_self() assert(_cur_index == -1, "invariant"); if (time == 0) &#123; _cur_index = REL_INDEX; // arbitrary choice when not timed status = pthread_cond_wait (&amp;_cond[_cur_index], _mutex) ; &#125; else &#123; _cur_index = isAbsolute ? ABS_INDEX : REL_INDEX; status = os::Linux::safe_cond_timedwait (&amp;_cond[_cur_index], _mutex, &amp;absTime) ; if (status != 0 &amp;&amp; WorkAroundNPTLTimedWaitHang) &#123; pthread_cond_destroy (&amp;_cond[_cur_index]) ; pthread_cond_init (&amp;_cond[_cur_index], isAbsolute ? NULL : os::Linux::condAttr()); &#125; &#125; _cur_index = -1; assert_status(status == 0 || status == EINTR || status == ETIME || status == ETIMEDOUT, status, "cond_timedwait");#ifdef ASSERT pthread_sigmask(SIG_SETMASK, &amp;oldsigs, NULL);#endif _counter = 0 ; status = pthread_mutex_unlock(_mutex) ; assert_status(status == 0, status, "invariant") ; // Paranoia to ensure our locked and lock-free paths interact // correctly with each other and Java-level accesses. OrderAccess::fence(); // If externally suspended while waiting, re-suspend if (jt-&gt;handle_special_suspend_equivalent_condition()) &#123; jt-&gt;java_suspend_self(); &#125;&#125; park的流程如下： step1.如果有许可可用，则将_counter原子地设置为0，并直接返回。 xchg返回的是旧的_counter；否则将没有许可可用。 step2.获取当前线程，如果当前线程设置了中断标志，则直接返回，因此如果在park前调用了interrupt就会直接返回。 step3.获取定时时间，安全点；如果中断或获取_mutex失败，则直接返回 step4.如果_counter=1，说明之前unpark已经调用过了。所以只需将_counter置为0，解锁返回（表现在程序上就是在执行LockSupport.park()后不会被阻塞）。 step5.对于time = 0，pthread_cond_wait (&amp;_cond[_cur_index], _mutex) 直接挂起； 对于定时的，挂起指定的时间status = os::Linux::safe_cond_timedwait (&amp;_cond[_cur_index], _mutex, &amp;absTime) ; 调用unpark()示意图 Parker::unpark() 1234567891011121314151617181920212223242526272829303132void Parker::unpark() &#123; int s, status ; status = pthread_mutex_lock(_mutex); assert (status == 0, "invariant") ; s = _counter; _counter = 1; if (s &lt; 1) &#123; // thread might be parked if (_cur_index != -1) &#123; // thread is definitely parked if (WorkAroundNPTLTimedWaitHang) &#123; status = pthread_cond_signal (&amp;_cond[_cur_index]); assert (status == 0, "invariant"); status = pthread_mutex_unlock(_mutex); assert (status == 0, "invariant"); &#125; else &#123; // must capture correct index before unlocking int index = _cur_index; status = pthread_mutex_unlock(_mutex); assert (status == 0, "invariant"); status = pthread_cond_signal (&amp;_cond[index]); assert (status == 0, "invariant"); &#125; &#125; else &#123; pthread_mutex_unlock(_mutex); assert (status == 0, "invariant") ; &#125; &#125; else &#123; pthread_mutex_unlock(_mutex); assert (status == 0, "invariant") ; &#125;&#125; unpark的运行流程： step1.对_mutex加锁，并将_counter置为1。 step2.如果之前的counter为0则说明调用了park或者为初始状态（此时为0且没有调用park）。 _step2-1.当前parker对应的线程挂起了。因为_cur_index初始化为-1，且线程唤醒后也会重置为-1。 调用pthread_cond_signal (&amp;_cond[_cur_index])。调用pthread_mutex_unlock(_mutex) step2-2.没有线程在等待条件变量，则直接解锁： pthread_mutex_unlock(_mutex); step3.如果之前的_counter为1，则说明线程调用了一次或多次unpark但是没调用park，则直接解锁。 分析了这么多，总结就是： 在调用park的时候如果__counter是0则会去执行挂起的流程，否则返回，在挂起恢复后再将counter置为0。 在unpark的时候如果 __counter是0则会执行唤醒的流程，否则不执行唤醒流程，并且不管什么情况始终将 _counter重置为1。 在park里，调用pthread_cond_wait时，并没有用while来判断，所以posix condition里的”Spurious wakeup”一样会传递到上层Java的代码里（因为条件需要Java层才能提供）。这也就是为什么Java dos里提到需要注意虚假唤醒的情况。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F01%2FJava%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%92%8C%E9%AB%98%E5%B9%B6%E5%8F%91%E6%80%BB%E7%BB%93%EF%BC%88%E5%9F%BA%E7%A1%80%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Java多线程和高并发总结（基础）一、进程的概念？进程可以理解为一个应用程序执行的实例（比如在windows下打开Word就启动了一个进程），进程是资源分配的最小单位，每个进程都有自己独立的地址空间，每启动一个进程，系统就会为它分配地址空间，建立数据表来维护代码段、堆栈段和数据段。进程主要有数据、程序和程序控制块（PCB）组成，其中PCB是系统感知进程存在的唯一标志。 二、线程的概念？线程是进程中的一个执行单元，一个进程中可以启动多个线程，并且一个进程中的多个线程可以共享此进程中的所用资源。每个线程都有自己独立的运行时桟和程序计数器，线程是CPU调度的最小单位。 三、并发和并行的概念？ 并发（concurrent）：单核CPU 下，操作系统通过任务调度器，将CPU的时间篇分给不同的线程使用，只是由于CPU的切换速度非常快（Windows下一个最小的时间片是15ms），让用户看上去是同步执行的，实际上还是串性执行的。这种线程轮流使用CPU的方法叫并发。 并行（parallel）：多个cpu或者多台机器同时执行一段处理逻辑，是真正意义上的同时执行。 四、创建和启动线程1、继承java.lang.Thread通过继承Thread类来创建并启动多线程的步骤如下: 定义Thread类的子类，并重写Thread的run()方法，该run()方法的方法体就代表了线程要完成的任务，因此把run()方法称为线程执行体。 创建Thread类的实例及创建线程对象。 调用线程对象的satrt()方法来启动该线程。 1234567891011121314151617public class ThreadTest &#123; public static void main(String[] args) &#123; Task task = new Task(); task.setName("test-thread"); task.start(); &#125; static class Task extends Thread&#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()); &#125; &#125;&#125; 2、实现java.lang.Runnable接口实现Runnable接口来创建并启动多线程的步骤如下。 定义Runnable接口的实现类，实现Runnable接口的run()方法，该run()方法的方法体同样是该线程执行体。 创建Runnable接口实现类的实例，并以此实例作为Thread的构造方法的参数来创建Thread对象。 调用线程对象的start()方法来启动该线程。 Java 8 以前的写法： 12345678910111213141516public class RunnableTest&#123; public static void main(String[] args)&#123; Thread t=new Thread(new Task(),"test-thread"); t.start(); &#125; static class Task implements Runnable&#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName()); &#125; &#125; &#125; Java 8以后可以用lambda简化代码 12345678910public class RunnableTest&#123; public static void main(String[] args)&#123; Thread t=new Thread(()-&gt;&#123; System.out.println(Thread.currentThread().getName()); &#125;,"test-thread"); t.start(); &#125;&#125; 3、实现java.util.concurrent.Callable&lt;V&gt;接口​ 从jdk1.5开始提供了Callable接口也可以实现创建一个线程。Callable接口提供了一个call()方法可以作为线程的执行体，类似于Runnable接口的run()方法，但是比run()方法更加强大，call()方法可以有返回值，返回值的类型由泛型的类型决定，并且call()可以抛出异常。并且在jdk1.5中提供了Future接口来表示call()方法的返回值，并且提供了一个FutureTask实现类，该类直接实现了RunnableTask接口，间接实现了Runnable和Future接口。使用Callable创建启动线程的步骤如下： 创建并启动有返回值的线程的步骤如下。 创建Callable接口的实现类，并实现call()方法，该call()方法将作为线程执行体，且该call()方法有返回值。在创建Callable接口实现类的实例。 使用FutureTask类来包装Callable接口对象，该FutureTask对象，封装了该Callable对象的call()方法的返回值。 使用FutureTask类对象作为Thread对象的构造函数参数创建并且启动新线程。 调用FutureTask对象的get()方法，获得子线程执行结束后的返回值。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package top.easyblog;import java.util.concurrent.Callable;import java.util.concurrent.ExecutionException;import java.util.concurrent.FutureTask;/** * @author ：huangxin * @modified ： * @since ：2020/04/01 00:49 */public class CallableTest &#123; public static void main(String[] args) &#123; /** * FutureTask实现了Runnable接口，因此FutureTask也就相当于是一个Runnable实现类 */ FutureTask&lt;Integer&gt; ft = new FutureTask&lt;Integer&gt;(new Task()); Thread thread = new Thread(ft, "callable-test"); thread.start(); try &#123; //FutureTask的get()方法会阻塞 System.out.println(ft.get()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; &#125; static class Task implements Callable&lt;Integer&gt; &#123; /** * 实现call()方法 * * @return * @throws Exception */ public Integer call() throws Exception &#123; int ret = 0; for (int i = 0; i &lt; 100; i++) &#123; ret += i &amp; (i - 1); &#125; return ret; &#125; &#125;&#125; 4、使用线程池五、线程的上下文切换（Thread Context Switch）多线程编程中一般线程的个数都大于 CPU 核心的个数，而一个 CPU 核心在任意时刻只能被一个线程使用，为了让这些线程都能得到有效执行，CPU 采取的策略是为每个线程分配时间片并轮转的形式。当一个线程的时间片用完的时候就会重新处于就绪状态让给其他线程使用，这个过程就属于一次上下文切换。 概括来说就是：当前任务在用完 CPU 时间片切换到另一个任务之前会先保存自己的状态，以便下次再切换会这个任务时，可以再加载这个任务的状态。任务从保存到再加载的过程就是一次上下文切换。 当发生以下情况时，会发生线程上下文切换： 线程的CPU时间片用完 垃圾回收 有更高优先级的线程需要运行 线程自己代用了sleep()、yield()、wait()、join()、park()…. 六、Java中线程的5种状态Java中的线程有5种转态：新建（New）、就绪（Runnable）、运行（Running）、阻塞（Blocked）、死亡（Dead） （1）New：当程序使用 new 关键字创建了一个线程之后，该线程就处于新建状态，此时仅由 JVM 为其分配内存，并初始化其成员变量的值 （2）Runnable：线程被创建后，其他线程调用了线程的start()方法之后该线程处于这个状态。该状态的线程处于可执行线程池中，就绪状态的线程表示有权力去获取CPU时间片了，CPU时间片就是执行权。当线程拿到CPU时间片后就会马上执行run()方法，这时线程就进入了运行状态。 （3）Running：线程获取到CPU时间片后线程执行任务的状态 （4）Blocked：阻塞状态是由于当前执行中的线程因为某种原因放弃CPU使用权，暂时停止运行的状态。处于阻塞状态的线程必须再次切换到Runnable才能再次获取到CPU时间片。阻塞的类型可以分为三种： 等待阻塞：运行中的线程执行了wait()方法，JVM会把该线程放入等待队列（waiting queue） 同步阻塞：运行中的线程尝试获取一个对象的对象锁时，当发现这把锁正在被其他线程使用，那么JVM就会把该线程放入锁池(lock pool ) 其他阻塞：运行中的线程调用了sleep()、join()方法或者发出了I/O请求时，JVM会把该线程置为阻塞状态。当sleep()状态超时、join()等待线程终止或者超时、或者I/O处理完毕时，线程重新转入就绪状态。 （5）Dead：当执行中的线程执行完线程任务、线程被提前强制性的终止、执行过程中发生了Error或Exception线程都会死亡。下图可以更详细的展示Java中一个线程的生命周期： 七、终止线程的4种方式1、线程执行完任务正常结束2、使用退出标志退出线程（推荐）一般 run()方法执行完，线程就会正常结束，然而，常常有些线程是伺服线程。它们需要长时间的运行，只有在外部某些条件满足的情况下，才能关闭这些线程。使用一个变量来控制循环，例如：最直接的方法就是设一个boolean 类型的标志，并通过设置这个标志为 true或 false 来控制 while循环是否退出，代码示例： 1234567891011121314151617181920212223242526272829303132333435363738394041package top.easyblog;public class StopThreadByFlag &#123; public static void main(String[] args) &#123; new Thread(new Task(), "worker1").start(); new Thread(new Task(), "worker2").start(); new Thread(new Task(), "worker3").start(); new Thread(new Task(), "worker4").start(); &#125; static class Task implements Runnable &#123; private volatile static boolean exit = false; private static int sum = 0; private final static Object object = new Object(); /** * 数数任务：4个线程轮流从1数到100 */ public void run() &#123; while (!exit) &#123; synchronized (object) &#123; if (sum &gt; 100) &#123; exit = true; &#125; sum += 1; //让当前线程“休息”一下 try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + "==&gt;" + sum); &#125; &#125; &#125; &#125;&#125; 上面的代码中被volatile修饰的exit变量是实现通过标志控制线程退出的关键。它保证了该变量在不同线程之间的可见性，即：一个线程修改了exit的值之后对于其他线程所示可以感知到的，至于他的底层原理请参考volatile关键字底层原理剖析。 3、使用interrupt()安全的终止程序（推荐）关于使用interruput()方法来终止线程，最佳的说明文档就是javadoc了。在这个方法的javadoc上说明了在使用interruput()的三种情况： （1）如果当前线程处于阻塞状态：比如调用了sleep()、wait()以及重载方法、join()以及重载方法或者其他操作让当前线程进入到阻塞状态，此时调用interrupt()，那么它的“中断状态”会被清除为false并且会收到一个InterruptedException异常 比如一个线程调用了wait()方法后处于阻塞状态，调用interrupt()后会立即将线程的中断标记设为“true”，但是由于线程处于阻塞状态，所以该“中断标记”会立即被清除为“false”，同时，会产生一个InterruptedException的异常。 （2）如果线程被阻塞在一个Selector选择器中，那么通过interrupt()中断它时，线程的中断标记会被设置为true，并且它会立即从选择操作中返回。 （3）线程未处于阻塞状态，那么通过interrupt()中断线程时，它的中断标记会被设置为“true” 代码示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package top.easyblog;/** * @author ：huangxin * @modified ： * @since ：2020/04/01 16:32 */public class StopThreadByInterrupt &#123; public static void main(String[] args) &#123; new Thread(new Task(),"worker").start(); &#125; static class Task implements Runnable &#123; private static int sum = 0; /** * 数数任务：从1数到100 */ public void run() &#123; while (true) &#123; Thread currentThread = Thread.currentThread(); if (currentThread.isInterrupted()) &#123; //在这里面可以处理善后的时情，比如关闭网络连接、关闭数据库连接..... System.out.println("处理善后的事情"); break; &#125; sum += 1; if (sum &gt;= 100) &#123; //数到100停止 currentThread.interrupt(); &#125; //让当前线程“休息”一下 try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); //由于InterruptedException异常会导致当前线程的终端标志被清除，因此这里必须重新发出中断请求,让中断标志恢复 currentThread.interrupt(); &#125; System.out.println(Thread.currentThread().getName() + "==&gt;" + sum); &#125; &#125; &#125;&#125; 4、使用Java API—stop()终止线程（线程不安全：容易造成死锁） 程序中可以直接使用 thread.stop()来强行终止线程，但是 stop()方法是很危险的，就象突然关闭计算机电源，而不是按正常程序关机一样，可能会产生不可预料的结果，不安全主要是：thread.stop()调用之后，创建子线程的线程就会抛出 ThreadDeatherror 的错误，并且会释放子线程所持有的所有锁。一般任何进行加锁的代码块，都是为了保护数据的一致性，如果在调用thread.stop()后导致了该线程所持有的所有锁的突然释放(不可控制)，那么被保护数据就有可能呈现不一致性，其他线程在使用这些被破坏的数据时，有可能导致一些很奇怪的应用程序错误。因此，并不推荐使用 stop 方法来终止线程。 八、等待/通知机制1、什么是等待/通知机制？多个线程之间也可以实现通信，原因就是多个线程共同刚 访问同一个变量。但是这种通信机制不是 “等待/通知”，两个线程完全是主动地读取一个共享变量。简单的说，等待/通知机制就是一个【线程A】等待，一个【线程B】通知（线程A可以不用再等待了）。比如生产者和消费者模型，消费者等待生产者生产资源，这是等待，生产者生产好资源通知等待的消费者去消费，这是通知。 等待/通知的相关方法是任意Java对象都具备的，因为这些方法被定义在java.lang.Object类中 1234567wait() //代用该方法的线程会进入到WAITING状态，并且当前线程会被放置到等待队列中，只有等待另外线程的唤醒或被中断返回，调用wait()方法后线程会释放对象锁，同时该方法必须在同步方法或同步块中使用，否则会抛出IllegalMonitorStateException异常。wait(long) //超时等待一段时间，时间单位是ms,如果没有被唤醒就超时返回wait(long,int) //更精细的超时等待，精确到nsnotify() //唤醒一个在等待对象锁的其他线程，如果有多个线程在等待该对象锁，那么会由线程规划器随机唤醒一个线程，此方法也必须在同步方法或同步块中使用，否则会抛出IllegalMonitorStateException异常。notifyAll() //唤醒所有等待此对象锁的线程 注意！notify()或notifyAll()在调用之后，等待线程不会立即从WAITING状态立即变为RUNNING状态，而是需要等到调动notify()或notifyAll()的方法释放对象锁之后才会从WAITING状态返回。 2、等待/通知机制的经典范式（模板）（1）等待方（消费者）需遵循如下原则： 获取对象锁 如果条件不满足，那么调用对象的wait()方法，被通知后仍然要检查条件 条件满足则执行对应逻辑 123456synchronized(对象)&#123; while(条件不满足)&#123; 对象.wait(); &#125; 对应的逻辑;&#125; （2）通知方（生产者）需遵循如下原则： 获得对象锁 改变条件 通知所有等待该对象锁的线程 1234synchronized(对象)&#123; 改变条件; 对象.notifyAll();&#125; 3、使用等待/通知机制实现生产者和消费者模型资源：Resourcs.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package top.easyblog.wait;/** * 生产者——消费者模型：资源 * * @author ：huangxin * @modified ： * @since ：2020/04/01 18:21 */public class Resources &#123; //模拟资源的数量 private int num; //资源的最大允许数存放量 private static final int MAX_NUM = 10; /** * 从资源池中取走资源 */ public synchronized void remove() &#123; if (num &gt; 0) &#123; num--; System.out.println("消费者" + Thread.currentThread().getName() + "消耗一件资源，" + "当前资源有" + num + "个"); //通知生产者生产资源 notifyAll(); &#125; else &#123; try &#123; //没有资源，消费者进入等待状态 wait(); System.out.println("消费者" + Thread.currentThread().getName() + "线程进入等待状态"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; /** * 向资源池中添加资源 */ public synchronized void add() &#123; if (num &lt; MAX_NUM) &#123; num++; System.out.println("生产者" + Thread.currentThread().getName() + "+生产一个资源，当前资源有" + num + "个"); //通知消费者消费 notifyAll(); &#125; else &#123; try &#123; //资源生产数量过多，让生产者进入等待状态，并释放锁 wait(); System.out.println(Thread.currentThread().getName() + "线程进入等待"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 生产者：Producer.java 1234567891011121314151617181920212223242526272829303132package top.easyblog.wait;/** * 生产者——消费者模型：生产者 * * @author ：huangxin * @modified ： * @since ：2020/04/01 18:11 */public class Producer implements Runnable &#123; private Resources resources; public Producer(Resources resources) &#123; this.resources = resources; &#125; /** * 生产者每1s生产一个资源 */ public void run() &#123; while (true) &#123; try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; resources.add(); &#125; &#125;&#125; 消费者：Customer.java 12345678910111213141516171819202122232425262728293031package top.easyblog.wait;/** * 生产者——消费者模型：消费者 * * @author ：huangxin * @modified ： * @since ：2020/04/01 18:34 */public class Customer implements Runnable &#123; private Resources resources; public Customer(Resources resources) &#123; this.resources = resources; &#125; /** * 消费者每2s消费一个资源 */ public void run() &#123; while (true) &#123; try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; resources.remove(); &#125; &#125;&#125; 九、sleep() 与 与 wait() 区别 wait()方法定义在Object类中，作用于所有对象；sleep()方法定义在Thread类中，作用于当前线程 wait()方法只能在同步块或者同步方法中调用；sleep()可以在任何地方调用 最主要的区别：调用 wait()方法后，线程会放弃对象锁，进入等待此对象的等待锁定池，只有针对此对象调用 notify()方法后本线程才进入对象锁定池准备获取对象锁进入运行状态；而sleep()方法调用后不会释放锁资源，如果sleep()是在同步上下文中调用的，那么其他线程是无法进入到当前同步块或者同步方法中的 十、什么是线程死锁?如何避免死锁?1、什么是线程死锁？多个线程同时被阻塞，他们中的一个或者全部都在等待某个资源被释放。由于线程被无限期地阻塞，因此程序不可能正常终止，最终导致死锁产生。 如下图所示，线程 A 持有锁1，线程 B 持有锁2，他们同时都想申请对方的资源，但是有无法获取到，所以这两个线程就会因互相等待而进入死锁状态。 2、面试官：你给我写一个死锁1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package top.easyblog;/** * 死锁测试 * * @author ：huangxin * @modified ： * @since ：2020/04/01 23:15 */public class DeadLock &#123; private static final Object resources1 = new Object(); //资源1 private static final Object resources2 = new Object(); //资源2 public static void main(String[] args) &#123; Thread t1 = new Thread(() -&gt; &#123; synchronized (resources1) &#123; System.out.println(Thread.currentThread().getName() + "获得了resources1"); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + "等待获取resources2"); synchronized (resources2) &#123; System.out.println(Thread.currentThread().getName() + "获得了resources2"); &#125; &#125; &#125;, "worker1"); Thread t2 = new Thread(() -&gt; &#123; synchronized (resources2) &#123; System.out.println(Thread.currentThread().getName() + "获得了resources2"); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + "等待获取resources1"); synchronized (resources1) &#123; System.out.println(Thread.currentThread().getName() + "获得了resources1"); &#125; &#125; &#125;, "worker2"); t1.start(); t2.start(); &#125;&#125; 执行结果： 3、如果避免死锁？在谈如何避免之前先了解一下产生死锁的4个必要条件： 互斥条件：该资源任意一个时刻只由一个线程占用。 请求与保持条件：一个进程因请求资源而阻塞时，对已获得的资源保持不放。 不剥夺条件：线程已获得的资源在末使用完之前不能被其他线程强行剥夺，只有自己使用完毕后才释放资源。 循环等待条件：若干进程之间形成一种头尾相接的循环等待资源关系 这四个条件是产生线程死锁的必要条件，缺一不可，因此避免死锁就可以破坏掉其中一个条件即可。 （1）破坏互斥条件 这个条件我们没有办法破坏，因为我们用锁本来就是想让他们互斥的（临界资源需要互斥访问）。 （2）破坏请求与保持条件 一次性申请所有的资源。 （3）破坏不剥夺条件 占用部分资源的线程进一步申请其他资源时，如果申请不到，可以主动释放它占有的资源。 （4）破坏循环等待条件 靠按序申请资源来预防。按某一顺序申请资源，释放资源则反序释放。破坏循环等待条件。 十一、临界区 Criticla Section一段代码块内如果对共享资源存在多线程的读写操作，那么成这段代码为临界区。 12345678static int count = 0;public void add()&#123; //临界区 synchronized(this)&#123; count++; &#125;&#125;]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F01%2FJava%E5%A4%9A%E7%BA%BF%E7%A8%8B%E5%92%8C%E9%AB%98%E5%B9%B6%E5%8F%91%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98%E6%B1%87%E6%80%BB%2F</url>
    <content type="text"><![CDATA[Java多线程和高并发常见面试题汇总1、锁的四种状态和升级过程？不同锁状态下的对象头： Java SE1.6以后中锁有四种状态是：无锁状态、偏向锁状态、轻量级锁（自旋锁）状态、重量级锁状态。 锁可以升级但是锁无法降级，这样设计的目的是为了提高获得锁和释放锁的效率。 1.1 锁升级过程 一个对象刚被创建的时处于无锁状态； 当有一个线程访问同步块并获取锁时，将会上偏向锁，即会在对象和此线程的桟帧中的锁记录里存储锁偏向的线程ID，以后该线程在进入和退出此同步块的时候就不需要再进行CAS操作进行加锁和解锁操作了。只需要简单检查一下对象头中的mark word里是否存储着指向当前线程的偏向锁即可，检查通过后当前线程进入同步块该干嘛干嘛！偏向锁只有在当其他线程来竞争这个锁的时候才会主动释放锁。同时偏向锁的撤销时需要等到全局安全点时首先暂停拥有偏向锁的线程，然后检查持有偏向锁的线程是否活着，如果线程不处于活动状态，那则将对象头设置为无锁状态。 关闭偏向锁？ 偏向锁在JDK1.6之后是默认开启的，但是它有一个延迟，会在程序启动后几秒后才会激活，也可以通过JVM参数关闭延迟它： ​ -XX:BiasedLockingStartupDelay=0 当程序中的锁竞争是很可能发生的事情的时候可以直接使用JV命名关闭偏向锁： ​ -XX:UseBiasedLocking=false 当发生多个线程竞争同一个偏向锁的时候锁就会升级为轻量级锁（或者叫自旋锁）。当一个线程执行同步块之前JVM会在当前线程桟帧中创建一个用于名为锁记录（Lock Record）的空间，并将对象头中的Mark Word复制一份到锁记录中。然后尝试使用CAS将对象头中的Mark Word替换为指向锁记录的指针，如果这一步操作成功，当前线程就获得了锁；如果失败了，当前线程不会被立即在操作系统层面挂起，而是会自旋等待锁资源，当自旋一定次数后如果任然没有获得锁，轻量级锁就会升级为重量级锁，当前线程就会被阻塞。另外，当一个线程持有轻量级锁，当前线程在自旋等待获取这个轻量级锁（还没达到自旋次数限制），此时又来了第三个线程请求这个锁，此时轻量级锁也会升级为重量级锁。 轻量级锁获得的两种情况？ （1）使用JVM参数关闭了偏向锁（2）由于多个线程竞争偏向锁导致偏向锁升级为轻量级锁 当程序中的线程竞争再次加剧的时候，轻量级锁就会最终膨胀为重量级锁，重量级锁就是指当一个线程获得锁之后，其余等待这个锁的线程都将进入到阻塞状态。重量级锁是操作系统层面的锁，此时线程的调度都将由操作系统负责，因此这就会引起频繁的上下文切换，导致线程被频繁的唤醒和挂起，使得程序性能下降。重量级锁的底层实现在JVM层面是通过对象内部的监视器（monitor）实现的。 1.2 锁降级（不重要）​ 锁降级在某些特定情况下回发生，就是在GC的时候会发生，但是此时锁降级也就没有意义了，因此锁降级可以认为是不存在的。 1.3 锁消除 lock eliminate1234public void add()&#123; StringBuffer sb=new StringBuffer(); sb.append("heello").append("java");&#125; ​ 锁消除是指虚拟机在即时编译器运行时，对一些代码上要求同步，但是被检测到不可能存在共享数据竞争的锁进行削除。锁削除的主要判定依据来源于逃逸分析的数据支持，如果判断到一段代码中，在堆上的所有数据都不会逃逸出去被其他线程访问到，那就可以把它们当作栈上数据对待，认为它们是线程私有的，同步加锁自然就无须进行。 1.4 锁粗化 lock coarsening​ 原则上对于锁的使用都是需要细化到尽量小的范围，大部分情况下，都是正确的，但是一些列的加锁和解锁操作很是麻烦。造成性能损坏。比如下面的情况： 12345678910111213141516171819//锁粗化之前public void fun()&#123; //task1 for(int i=0;i&lt;100li++)&#123; synchrnoized(this)&#123; //task2 &#125; &#125;&#125;//锁粗化优化后public void fun()&#123; //task1 synchronized(this)&#123; for(int i=0;i&lt;100li++)&#123; //task2 &#125; &#125;&#125; 2、synchrnoized和ReentrantLock的底层实现以及重入的底层原理？2.1 synchrnoized底层实现​ Java中每一个对象锁中都会和一个monitor向关联，同步语句块的实现是通过monitorenter和monitorexit指令，当执行monitorenter指令时，当前线程会尝试获取对象锁对应的monitor的持有权，如果和对象锁关联的监视器中的计数器为0了，那么当前线程就可以顺利的获取到此锁，并且会将计数器设置为1。如果当前线程已经持有该对象锁了，那么这把锁对于此线程是可重入的，并且每重入一次监视器中的计数器的值都会加+1； ​ 如果是同步方法，则是通过ACC_SYNCHRNOIZED标志实现，当方法被调用的时候，调用指令会首先检查方法的ACC_SYNCHRONIZED标志是否被设置了，执行将先去获取monitor，然后在来执行方法，方法之完后释放monitor，在方法执行期间，执行线程持有了monitor，其他任何线程都无法再获得同一个monitor。如果一个同步方法执行期间抛 出了异常，并且在方法内部无法处理此异常，那这个同步方法所持有的monitor将在异常抛到同步方法之外时自动释放。； ​ 无论是上面那种，synchrnoized在汇编指令层面都是通过lock comxchg指令实现。 2.2 ReentrantLock的的底层实现3、什么是CAS？谈谈CAS​ CAS（Compare And Swap,比较并替换），CAS是实现J.U.C包的基石之一（另一个是volatile）。一个CAS需要三个操作，内存地址V，预期旧值E和将要替换的目标值B，执行CAS操作的时候，只有比较当前仅当内存地址V中的值和预期值E相等，才会将内存地址V中的值替换为B，否者不会修改，一般情况下会自旋，直到修改成功。 CAS在Java中的底层实现是通过lock cmpxchg指令（x86架构）实现的，在硬件层面lock指令会在执行的时候锁定北桥芯片的电信号。 3.1 CAS ABA问题以及解决方案？ABA问题?​ 假设有一个遵循CAS机制的ATM取款机，小明账户上有100元，他想取50元，于是他点击了，由于提款机硬件出了点小问题，小明的提款操作被同时提交两次，开启了两个线程thread1和threa2，两个线程都获取到当前预期值为100，需要修改目标值为50。正常情况下，只会有一个线程可以执行成功，但是很巧的线程1执行成功了，但是线程2被阻塞了，恰巧这时候小明妈妈又给小明汇了50，这时小明的余额又恢复成了100，此时线程2又恢复了，按照CAS检查没问题，于是又把小明的余额更新为50，这就是ABA问题带来的问题。 ABA问题的解决方案​ 解决CAS ABA问题很简单，在比较的时候不仅要比较内存V中的值和预期值相等，还应该比较变量的版本号version是否一致。如果版本号都一致，那就表名没有被修改过，否者就证明被修改过，就不予修改。 ABA问题Java提供的解决方案jdk1.5 Java提供了AtomicStampedReference类，此类通过引用一个时间戳来控制版本，下面是此类中的核心方法compareAndSwap expectedReference：表示预期值 newReference：新值 expectedStamp：预期时间戳（预期版本号） newStamp：更新后的时间戳（版本号） (1)首先我们可以看看Pair的实现 可以看到，Pair是个静态内部内，他只是用来保存预期的时间戳stamp和预期值引用reference的。 之后就是比较当前pair中的值和预期值是否相等，pare中的时间戳是否和预期时间错相等，如果都相等，最终调用了casPair`方法，源码如下，主要就是通过Unsafe类来更新时间戳和新的值。 至于Unsafe类调用的compareAndSwapObject方法那是一个native方法，在Java源码层面是看不到了，所以就不往下追了。 4、对volatile的理解？4.1 volatile的两个重要作用（1）保证线程可见性；（2）禁止指令重排序； 4.2 volatile 如何保证线程可见性？volatile的底层实现是通过lock实现的（lock指令会锁住整个总线），而在单核处理器中不存在线程可见性问题，因此lock指令它在多核CPU处理上干了一下两件事： （1）将当前处理器的缓存行的数据写汇到系统的内存中； （2）这个写回的操作会使其他CPU里面缓存了该内存地址的数据失效（缓存一致性）； CPU缓存一致性的大致实现？ 在多处理器下，为了保证其他处理的的缓存是一致的操作是通过实现缓存一致性协议实现的，即每个处理器在总线上嗅探传播来的数据检查自己缓存中的数据是否过期了，当处理器发现自己缓存行中对弈内存地址的数据被修改后就会立即将当前处理器的缓存设置成无效状态，当处理器对这个数据进行操作的时候会将其从操作系统内存中重新读取到缓存中。 注意！volatile无法保证一个操作是原子操作以及无法实现线程安全。 什么是原子操作？ 原子操作就是不会被线程调度机制打断的操作，一旦操作开始就会一直运行到结束，中间不会有任何的线程切换。 4.3 volatitle如何解决指令重排序？（1）为什么要有指令重排序？为了提高程序执行的性能，编译器和执行器(处理器)通常会对指令做一些优化(重排序) 编译器重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序； 处理器重排序。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序，处理器的重排序又被称为乱序执行（out-of-order execution,OOE）技术； （2）解决方案 语言层级：volatile 字节码层级：ACC_VOLATILE 虚拟机层级：在所有volatile操作前后加上内存屏障 在每一个volatile读操作前插入一个StoreStore屏障，在读操作之后插入一个StoreLoad屏障 在每一个volatile写操作后面插入一个LoadLoad和LoadStore屏障 内存屏障 内存屏障也叫内存栅栏，他是一种CPU指令，用于控制特定条件下的重排序和内存可见性问题。Java编译器也会根据内存屏障的规则禁止重排序。内存屏障可以分为以下几种类型： LoadLoad：对于这样的语句Load1:LoadLoad:Load2，在Load2及后续读取操作要读取的数据被访问前，保证Load1要读取的数据被读取完毕。 StoreStore：对于这样的语句Store1; StoreStore; Store2，在Store2及后续写入操作执行前，保证Store1的写入操作对其它处理器可见。 LoadStore：对于这样的语句Load1; LoadStore; Store2，在Store2及后续写入操作被刷出前，保证Load1要读取的数据被读取完毕。 StoreLoad：对于这样的语句Store1; StoreLoad; Load2，在Load2及后续所有读取操作执行前，保证Store1的写入对所有处理器可见。（开销最大，对于大多数处理器是万能屏障，它兼具其他三种屏障的功能） 在hotspot层级：使用操作系统的lock指令直接锁住总线 5、DCL了解吗？DCL单例模式为什么要加volatile?DCL是Double-Checked Locking的简称，他的设计初衷是实现一个线程安全的延迟初始化，即： （1）懒加载resource。 （2）规避synchrnoized方法被频繁访问而带来的性能开销。 下面是DCL的典型用法： 1234567891011121314151617public final class DoubleCheckedLocking&#123; ptivate static DoubleCheckedLocking obj=null; public static DoubleCheckedLocking getInstance()&#123; if(obj!=null)&#123; //第一次检查 synchronized(DoubleCheckedLocking.class)&#123; //加锁 if(obj!=null)&#123; //第二次检查 obj=new DoubleCheckedLocking(); //实例对象，DCL的问题就在这 &#125; &#125; &#125; return obj; &#125; &#125; ​ DCL看似完美，但是他有一个致命的缺陷，由于现代处理器和编译器都有重排序的功能，就是说在单线程环境下不影响代码原本执行结果的前提下，可以对指令执行的顺序执行交换，目的是提高效率。问题就出在了这，重排序在单线程环境下没有问题，但是多线程环境下就会有问题，如下图是多线程环境下的上面代码执行的时序图： ​ DCL的问题是：在多线程环境下回引发线程访问一个未被完全初始化的对象。解决方法两个方案： （1）禁止初始化对象和设置对象引用指向对象内存空间步骤重排序，必须按这个顺序执行 （2）可以重排序，但是不允许其他线程“看到”这个重排序 5.1 方案一：使用volatile禁止指令重排序使用volatile来禁止初始化对象和设置对象引用指向对象内存空间这两步的重排序，以此就可以实现线程安全的延迟初始化。 1234567891011121314151617public final class DoubleCheckedLocking&#123; ptivate volatile static DoubleCheckedLocking obj=null; public static DoubleCheckedLocking getInstance()&#123; if(obj!=null)&#123; //第一次检查 synchronized(DoubleCheckedLocking.class)&#123; //加锁 if(obj!=null)&#123; //第二次检查 obj=new DoubleCheckedLocking(); //现在没有问题了 &#125; &#125; &#125; return obj; &#125; &#125; 5.2 使用类初始化机制解决​ JVM在类加载初始化阶段，会执行类的初始化。在类的初始化期间，JVM会用一个锁来同步多个线程对同一个类的初始化。基于这个特性，可以实现另一套线程安全的延迟初始化。 1234567891011public class Instance&#123; private static class InstanceHolder&#123; public static Instance instance=new Instance(); &#125; public static Instance getInstance()&#123; return InstanceHolder.instance; //这里导致InstanceHolder类被初始化 &#125; &#125; 上面两种方法，如果确实需要对实例字段使用线程安全的延迟初始化，可以使用volatile方案；如果确实需要对静态字段使用线程安全的延迟初始化，可以使用基于类初始化方案。 6、Object obj=new Object()在内存中占用几个字节？注意！以下分析基于64位JVM 6.1 Java内存布局回顾首先说一下对象的内存布局，有以下3个部分： 对象头（Object header）：对象头分为两部分，MarkWord和类型指针。 实例数据(instance data)：实例数据，对象中真正存实例数据的地方 对齐填充(padding)：为了保证对象的大小是8字节的整数倍，如果对象的大小不是8字节整数倍就需要填充，否则就不需要填充，这么做的意义是CPU在读数据的时候是按总线宽度读取的，CPU总线宽度通常就是8字节整数倍，这样做可以提高效率。 对象在内存中的布局示意图： 可以通过OpenJDK提供的一个工具来分析Java对象内存布局—JOL（Java Object Layout） 12345 &lt;dependency&gt; &lt;groupId&gt;org.openjdk.jol&lt;/groupId&gt; &lt;artifactId&gt;jol-core&lt;/artifactId&gt; &lt;version&gt;0.9&lt;/version&gt;&lt;/dependency&gt; 解析出的对象布局如下： ​ OFFSET偏移量0~4的8个字节是Mark Word，紧接着4个字节的Klass Pointer，这两部分构成对象头12字节，由于是空对象没有实例数据，这部分为0，最后填充为8字节整数倍，12字节的下一个8字节的这数倍是16字节，因此一个空对象啥都不干需要占用16字节的堆空间。另外引用需要占用4字节，因此这条语句需要占用16+4=20字节的空间。 6.2 扩展：包含实例数据的对象内存大小计算这里有一个Student类 我们同样适用JOL工具分析，结果如下： 结果显而易见，对象头12字节，String类型的引用占4字节，int类型4字节这些一共20字节，最后根据虚拟机规范需要填充成为8字节的整数倍，因此最终的大小是24字节。 7、ThreadLocal的理解？ThreadLocal如何解决内存泄漏问题？7.1 ThreadLocal是什么？ThreadLocal是一个本地线程副本变量工具类。ThreadLocal中填充的变量只属于当前线程，与其他线程无关。ThreadLocal为变量在每个线程中都创建了一个副本，每个线程可以访问自己内部的副本变量。 7.2 ThreadLocal源码解析ThreadLocal常用的三个核心方法 1234public T get() //用于获取当前线程的副本变量值public void set(T value) //用于保存当前线程的副本变量值public void remove() //移除当前线程的副本变量值public void initialValue() //为当前线程初始副本变量值 （1）set()方法 流程： 1、获取当前线程 2、尝试获取当前线程的ThreadLocalMap（就是一个类似于HashMap的东西），如果Map是空的，那么就会实例化一个ThreadLocalMap，同时把值加入到Map中（和3相同） 3、会把当前ThreadLocal对象作为key，传入的value作为value,添加到当前线程的ThreadLocalMap中 在上面的过程中为什么总是强调当前线程的ThreadLocalMap呢？我们点击getMap()方法一看就知道了。 拿到ThreadLocalMap程序会首先判断一下当前线程中的这个ThreadLocalMap是否为空，如果为空（一般是在第一次执行的时候）那么会实例化一个ThreadLocalMap给当前线程，下面是jdk源码（是不是非常简单）： 当ThreadLocalMap不为空的时候，程序在添加新值就会执行ThreadLocal内部的一个私有set()方法，在下面的程序中操作Entry数组是这个方法流程的核心： 1、首先程序拿到当前线程的当前线程的ThreadLocalMap的Eentry 2、计算出这个Entry数组的长度以及hashCode 3、中间若干过程忽略，最终他以当前ThreadLocal为key，传入的值为value，以Entry的形式添加到了当前线程的ThreadLocalMap中 抱着对真相的探究，我们继续往下追，去看看这个Entry是何方神圣！！！ 原来这个Entry是ThreadLocalMap的内部类并且他继承的父类很有意思—WeakReference&lt;ThreadLoccal&gt;，这是一个弱引用，通过前面的分析我们得知，每一对ThreadLocal实例和线程变量副本value都是以一个Entry的形式添加到当前线程的ThreadLoacalMap中的，那它为什么要继承WeakReference&lt;ThreadLoccal&gt;呢？ 其实这个ThreadLocal解决内存泄漏有很大的关系，熟悉WeakReference的同学应该都知道，如果一个实例对象只有弱引用的话，那么一旦发生GC无论当前堆空间是否紧张，这个实例是一定会被GC清除的。为了更加清除的说明请看下图，tl是我们在桟空间的一个引用，他和ThreaLocal是强引用，正常使用没啥问题，但是当tl不用的时候，如果Entry中的key如果和ThreadLocal是强引用的话，那么这个ThreadLocal就产生了内存泄漏，但是如果采用了弱引用就不存在这个问题了，弱引用户自动被GC清除，此时ThreadLocal中的key的泄漏问题解决了。 但是Entry对象中的value在GC的时候是不会被回收的，如果创建ThreadLocal的线程一直持续运行，那么这个Entry对象中的value就有可能一直得不到回收，发生内存泄露。为了解决这个问题，ThreadLocal中提供了一个remove()方法，并且我们也应该在ThreadLocal使用完之后主动的调用这个方法，帮助GC可以清除掉整个Entry。下面我们直接看remove方法的核心实现，逻辑很简单，找到目标key之后直接调用clear方法将此Entry和ThreadLocalMap引用设为null，并且重新计算Entry的布局。至此ThreadLocal的内存泄漏问题才算是解决了。 8、对as-if-serial和happend-before语义的理解？9、synchronized关键字的特性？]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F01%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[计算机网络部分1、OSl七层模型和TCP/IP四层模型 从上到下： 应用层：通过应用进程之间的交互完成特定的网络应用。该层常见的协议有HTTP（80）、HTTPS（443）、DNS、SMTP（电子邮件）….. 运输层：为应用进程之间提供端到端的逻辑通信。各种应用进程之间需要的“可靠或尽力而为”的两类服务，必须靠运输层以复用或分用的方式加载到网络层。 运输层重要的两个协议：TCP和UDP协议 TCP（传输控制协议）——提供面向连接的，可靠的数据传输服务。 UDP（用户数据包协议）——提供无连接的，尽最大努力的数据传输服务（不保证数据的可靠性） 网络层：在 计算机网络中进行通信的两个计算机之间可能会经过很多个数据链路，也可能还要经过很多通信子网。网络层的任务就是选择合适的网间路由和交换结点， 确保数据及时传送。 在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组和包进行传送。在 TCP/IP 体系结构中，由于网络层使用 IP 协议，因此分组也叫 IP 数据报 ，简称 数据报。 数据链路层： 数据链路层将网络层交下来的 IP 数据报组装成帧，在两个相邻节点间的链路上传送帧 物理层：实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异 2、TCP三次握手与四次挥手2.1 TCP三次握手 刚开始客户端处于 closed 的状态，服务端处于 listen 状态 第一次握手：客户端将SYN标识置为1，并且随机产生一个初始化序列号 ISN(c)=J然后将数据包发送给服务器，此时客户端进入到SYN_SENT状态，等待服务器回复； 第二次握手：服务器正常收到客户端发来的SYN标志位为1,标识客户端想建立通信连接，于是服务器将SYN和ACK都置为1，并且设置ack=J+1,seq为另外一个随机值k，并将数据包发送给客户端以确认连接请求，之后服务器进入到SYN_RCVD状态； 第三次握手：客户端收到服务器的回复后，先检查ACK是否为1，并且ack是否为J+1，如果正确则将ACK置1，ack置为k+1，并将该数据包发送给服务器，服务器检查ACK是否为1，ack是否为k+1，如果正确则连接建立成功，Client和Server进入ESTABLISHED状态，完成三次握手，随后Client与Server之间可以开始传输数据了 SYN 是 TCP/IP 建立连接时使用的握手信号。在客户机和服务器之间建立正常的 TCP 网络连接时，客户机首先发出一个 SYN 消息，服务器使用 SYN-ACK 应答表示接收到了这个消息，最后客户机再以 ACK(Acknowledgement[汉译：确认字符 ,在数据通信传输中，接收站发给发送站的一种传输控制字符。它表示确认发来的数据已经接受无误。 ]）消息响应。这样在客户机和服务器之间才能建立起可靠的TCP连接，数据才可以在客户机和服务器之间传递。 2.2 为什么需要三次握手？（为什么不是两次或者四次以及更多次？）TCP三次握手的目的就是建立可靠的通信通道，简单点说就是通信双方需要确认自己与对方的发送和接收都是正常的。 第一次握手：客户端什么都确定不了；服务器端可以确定：自己的接收能力正常，以及客户端的发送能力正常 第二次握手：客户端可以确认：自己收发正常，服务器收发正常；服务器可以确认：客户端发送正常，自己接收正常 第三次握手：客户端确认：自己收发正常，对方收发正常；服务器：自己收发正常，对方收发正常。 所以三次握手就可以确定双方收发正常，并且三次缺一不可。 2.3 TCP四次挥手 刚开始双方都处于 establised 状态，假如是客户端先发起关闭请求，则： 第一次挥手：Client发送一个FIN标志，报文中会指定一个序列号，用来关闭客户端到服务器的数据传送。此时客户端处于FIN_WAIT1状态； 第二次挥手：Server收到Client的FIN后，返会确认序号ack为之前接收到的序列号+1，表明已经收到客户端的报文了，此时服务端处于 CLOSE_WAIT2状态。； 第三次挥手：当Server也要断开连接的时候，Server发送FIN标志到Client，且指定一个序列号，用来关闭服务器到客户端的数据传送。此时服务器处于LAST_ACK状态； 第四次挥手：Client收到Server的FIN后，返回确认号ack为接收到的序列号+1，之后客户端进入到TIME_WAIT状态；此时需要过一阵子以确保服务端收到自己的 ACK 报文之后才会进入 *CLOSED *状态 最后服务器收到客户端的ACK标志后，就会关闭此链接，进入到CLOSED状态 为什么Client最后需要等待服务器接收到自己发送的ACK消息后才进入到CLOSED状态？ 答：客户端要确保服务器接收到了自己返回的ACK报文，如果没有收到的话，服务器会重新发 FIN 报文给客户端，客户端再次收到 FIN 报文之后，就知道之前的 ACK 报文丢失了，然后再次发送 ACK 报文。 状态的含义： LISTEN - 侦听来自远方TCP端口的连接请求； SYN-SENT -在发送连接请求后等待匹配的连接请求； SYN-RECEIVED - 在收到和发送一个连接请求后等待对连接请求的确认； ESTABLISHED- 代表一个打开的连接，数据可以传送给用户； FIN-WAIT-1 - 等待远程TCP的连接中断请求，或先前的连接中断请求的确认； FIN-WAIT-2 - 从远程TCP等待连接中断请求； CLOSE-WAIT - 等待从本地用户发来的连接中断请求； CLOSING -等待远程TCP对连接中断的确认； LAST-ACK - 等待原来发向远程TCP的连接中断请求的确认； TIME-WAIT -等待足够的时间以确保远程TCP接收到连接中断请求的确认； CLOSED - 没有任何连接状态； 2.4 为什么需要四次挥手？​ 根本原因是，一方发送FIN只表示自己发完了所有要发的数据，但还允许对方继续把没发完的数据发过来。 2.5 为什么建立连接是三次握手，但是关闭连接需要四次挥手？（同2.4原理一样）​ 建立连接的时候，服务器处于LISTEN状态，当收到客户端的SYN数据请求建立连接的时候，服务器会把SYN和ACK放在一个报文中恢复给客户端； ​ 关闭连接时，服务器收到客户端的FIN报文后，仅仅表示客户端不在发送数据了，但是还可以接受数据，而自己也未必全部数据都发送给对方了，所以己方可以立即关闭，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN都是分开发送的，从而导致多了一次。 3、TCP和UDP的区别 TCP提供一个面向连接的，可靠的数据传输服务。TCP在传输数据之前，一定会建立一个可靠的连接，数据传输完成后释放连接。TCP 不提供广播或多播服务；TCP是面向字节流的；TCP有拥塞控制机制；TCP首部开销(20个字节)比UDP的首部开销(8个字节)要大； UDP传输数据之前不需要建立连接，UDP是一种不可靠的，“尽力而为”的数据传输服务，远程主机收到消息后不需要给出任何确认，在要求高速通信但是对数据可靠性没有太大要求的时候UDP是很好的选择。 4、TCP如何保证可靠传输？主要有使用校验和、序列号、确认应答进制、超时重传机制、拥塞控制、流量控制和连接管理等方法来保证数据传输的可靠和高效性。 校验和：发送数据之前计算校验和，并填充校验值；接收方按同样的计算方法计算接收到的数据的校验和，并与接收到的校验和比对，TCP 将丢弃这个报文段和不确认收到此报文段； 序列号：TCP在传输的会后将每个字节都进行了编号，这个编号就是序列号； 确认应答机制（ACK报文）：TCP要求在接收到数据后应该对传输方进行确认应答，也就是发送ACK保温，ACK报文中带有确认序列号，告诉发送方格，接收到了那些数据，下一次从哪里开始发送。 超时重传机制：发送方在发送完数据后等待一个时间，时间到达没有接收到ACK报文，那么对刚才发送的数据进行重新发送 拥塞控制：当网络拥塞的时候，减少数据的发送。 拥塞窗口 为了进行拥塞控制，TCP需要维护一个拥塞窗口的状态变量。塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个。 TCP采用四种算法进行拥塞控制：慢开始、拥塞避免、快重传和快恢复。 慢开始：开始发送数据时，先发送少量的数据探路。探清当前的网络状况，然后在决定以多大的速率传输。 拥塞避免：拥塞避免算法的思路是让拥塞窗口cwnd缓慢增大，即每经过一个往返时间RTT就把发送放的cwnd加1. 快重传和快恢复： 在 TCP/IP 中，快速重传和恢复（fast retransmit and recovery，FRR）是一种拥塞控制算法，它能快速恢复丢失的数据包 流量控制：TCP发送端根据接收端的处理能力，决定发送的速率。 滑动窗口 TCP 利用滑动窗口实现流量控制。流量控制是为了控制发送方发送速率，保证接收方来得及接收。 接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。 连接控制：TCP建立连接需要三次握手，关闭连接需要四次挥手。 5、浏览器中输入URL地址到服务器响应发生了哪些事情? 总体来说就是： DNS解析，查找殒域名的IP地址 建立TCP连接 发送HTTP请求 服务器处理请求并返回响应信息 浏览器解析渲染页面 6、HTTP协议详解6.1 HTTP协议的特点 2.http协议默认端口:80 3.简单快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。每种方法规定了客户与服务器联系的类型不同。由于HTTP协议简单，使得HTTP服务器的程序规模小，因而通信速度很快。 4.HTTP允许传输任意类型的数据对象。正在传输的类型由Content-Type加以标记。 5.无连接：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。 6.无状态：HTTP协议是无状态协议。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。 6.2 HTTP协议的版本HTTP/1.0,发送请求，创建一次连接，获得一个web资源，连接断开 HTTP/1.1，发送请求，创建一次连接，获得多个web资源，连接断开 6.3 HTTP协议的组成HTTP协议由HTTP请求和HTTP响应组成。 HTTP请求：请求行、请求头和请求体。 HTTP响应：响应行、响应头和响应体。 6.4 HTTP状态码 常见状态码含义： 200 ：服务器成功处理了请求。 204：服务器成功处理了请求，但没有返回任何内容 301：请求的网页已永久移动到新位置。服务器返回此响应（对 GET 或 HEAD 请求的响应）时，会自动将请求者转到新位置 302：服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来响应以后的请求 304：自从上次请求后，请求的网页未修改过 400：服务器无法理解请求参数 401：请求要求身份验证。对于登录后请求的网页，服务器可能返回此响应。 403：服务器拒绝请求 404：服务器找不到请求页面 405：服务器不支持请求的使用的方法 500：服务器内部错误，无法完成请求 502：错误网关 503：服务器目前无法使用（由于超载或停机维护）。通常，这只是暂时状态。 6.5 HTTP长连接和短连接在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个HTML或其他类型的Web页中包含有其他的Web资源（如JavaScript文件、图像文件、CSS文件等），每遇到这样一个Web资源，浏览器就会重新建立一个HTTP会话。 从HTTP/1.1起，默认使用长连接，用以保持连接特性。在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接。 HTTP协议的长连接和短连接，实质上是TCP协议的长连接和短连接。 6.6 HTTP是不保存状态的协议,如何保存用户状态?Http是一种无状态的基于请求响应模型的协议，它无法保存用户的状态。常用的解决方法有： 在服务器端使用Session 在客户端本地使用Cookie Cookie 和 Session都是用来跟踪浏览器用户身份的会话方式，但是两者的应用场景不太一样。 Cookie 一般用来保存用户信息** 比如①我们在 Cookie 中保存已经登录过得用户信息，下次访问网站的时候页面可以自动帮你登录的一些基本信息给填了；②一般的网站都会有保持登录也就是说下次你再访问网站的时候就不需要重新登录了 Session 的主要作用就是通过服务端记录用户的状态。 典型的场景是购物车 总的来说，Session存储在服务器端，Cookie存储在客户端本地。Session相对Cookie更安全，因此尽量避免向Cookie中保存敏感的数据，即使普通的数据，也应该加密存储； 6.7 URL和URI的区别？ URI是统一资源标识符，可以唯一标识一个资源。 URL是统一资源定位符，可以提供该资源的路径。它是一种具体的 URI，即 URL 可以用来标识一个资源，而且还指明了如何 locate 这个资源。 URI的作用就像身份证号码一样，而URL的作用就像家庭地址一样，他是URI的具体形式，提供了可以找到资源的路径。 7、HTTPS协议详解7.1 HTTPS中的SSL和TSLHTTPS协议是HTTP协议的安全版本，主要就是因为HTTPS协议工作在SSL和TLS协议之上。 SSL是安全套接层：SSL 协议位于 TCP/IP 协议与各种应用层协议之间，为数据通讯提供安全支持。 TLS是传输安全性协议 7.2 浏览器使用HTTPS协议传输数据的流程 大致流程如下： 客户端通过URL链接和服务器建立SSL连接 服务器收到请求后，会将网站支持的证书信息（证书中包含公钥）传送一份给客户端 客户端和服务器协商SSL连接的安全等级 客户端浏览器根据双方同意的安全等级，建立会话密钥，然后利用网站的公钥将会话密钥加密，并传送给网站。 服务器利用自己的私钥解密出会话秘钥 服务器利用会话密钥加密与客户端之间的通信 7.3 HTTPS协议的缺点 HTTPS协议多次握手，导致页面的加载时间延长近50%； HTTPS连接缓存不如HTTP高效，会增加数据开销和功耗； 申请SSL证书需要钱，功能越强大的证书费用越高。 SSL涉及到的安全算法会消耗 CPU 资源，对服务器资源消耗较大。 7.4 Http和Https的区别？ Http协议直接运行在TCP协议之上，明文传输，客户端和服务端都无法验证对方的身份（无状态协议）； Https是身披SSL外壳的Http协议，运行在SSL协议之上，SSL协议运行在TCP协议之上，是添加了加密和认证机制的HTTP。二者之间存在如下不同： 端口不同：Http和Https使用的协议不同，同时使用的端口也不同，Http是80端口，Https是443端口 资源消耗：相对于Http协议，Https协议由于需要加解密处理，因此需要消耗更多的CPU和 内存资源 Https需要第三方机构的数字证书，而要获得证书需要向认证机构购买 Https加密机制是一种共享密钥加密和公开密钥加密并用的混合加密机制 7.4.1 对称加密和非对称加密？ 对称加密是指加密和解密使用同一个秘钥，这种方式最大的问题是秘钥的发送问题，即秘钥如何安全的发送给接收方； 非对称加密是指使用一对非对称秘钥，公钥和私钥，公钥可以随意发布，但是私钥只有自己知道。发送密文的一方使用对方的公钥解密，而接收方接收到消息后使用自己的私钥解密。非对称加密可以保证数据的安全性，但是效率过低，因此不适合对大量数据加密。]]></content>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F04%2F01%2F%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E9%83%A8%E5%88%86%2F</url>
    <content type="text"><![CDATA[操作系统部分1、什么是操作系统？​ 操作系统是管理计算机软件和软件资源的程序，是计算机系统的内核和基石。它的本质是运行在计算机上的软件，为用户提供了一个和系统交互的操作页面。 2、Linux操纵系统分类 内核版本：Linux其实不是一个操作系统，严格来讲，Linux只是一个操作系统的内核。内核提供了计算机软件和硬件的交互平台，内核提供系统服务，比如文件管理、IO管理、设备管理…… 发行版本：一些组织或个人基于Linux内核二次开发的重新发布的版本。Linux发行版有很多产品，比如：CentOS、ubuntu、RedHat…… 3、Linux文件系统3.1 Linux支持的文件系统？123456789Minix：最古老、最可靠Xia：minix的修正版Ext：ext2的老版本Ext2：当前最通用的Linux文件系统Ext3：ext2+log是linux通用的文件系统Smb：是一种支持Windows for Workgroups、Windows NT和LanManager的基于SMB协议的网络文件系统。NFS：网络文件系统Msdos：与MSDOS、OS/2等FAT文件系统兼容 3.2 Linux系统目录结构 系统根目录： / Linux系统的根目录 系统启动必须： /boot：存放的启动Linux 时使用的内核文件，包括连接文件以及镜像文件。 /etc：存放所有的系统需要的配置文件和子目录列表，更改目录下的文件可能会导致系统不能启动。 /lib：存放基本代码库（比如c++库），其作用类似于Windows里的DLL文件。几乎所有的应用程序都需要用到这些共享库。 /sys： 这是linux2.6内核的一个很大的变化。该目录下安装了2.6内核中新出现的一个文件系统 sysfs 。sysfs文件系统集成了下面3种文件系统的信息：针对进程信息的proc文件系统、针对设备的devfs文件系统以及针对伪终端的devpts文件系统。该文件系统是内核设备树的一个直观反映。当一个内核对象被创建的时候，对应的文件和目录也在内核对象子系统中 指令集合： /bin：存放着最常用的程序和指令 /sbin：只有系统管理员能使用的程序和指令。 外部文件管理： /dev ：Device(设备)的缩写, 存放的是Linux的外部设备。注意：在Linux中访问设备和访问文件的方式是相同的。 /media：类windows的其他设备，例如U盘、光驱等等，识别后linux会把设备放到这个目录下。 /mnt：临时挂载别的文件系统的，我们可以将光驱挂载在/mnt/上，然后进入该目录就可以查看光驱里的内容了。 临时文件： /run：是一个临时文件系统，存储系统启动以来的信息。当系统重启时，这个目录下的文件应该被删掉或清除。如果你的系统上有 /var/run 目录，应该让它指向 run。 /lost+found：一般情况下为空的，系统非法关机后，这里就存放一些文件。 /tmp：这个目录是用来存放一些临时文件的。 账户： /root：系统管理员的用户主目录。 /home：用户的主目录，以用户的账号命名的。 /usr：用户的很多应用程序和文件都放在这个目录下，类似于windows下的program files目录。 /usr/bin：系统用户使用的应用程序与指令。 /usr/sbin：超级用户使用的比较高级的管理程序和系统守护程序。 /usr/src：内核源代码默认的放置目录。 运行过程中要用： /var：存放经常修改的数据，比如程序运行的日志文件（/var/log 目录下）。 /proc：管理内存空间！虚拟的目录，是系统内存的映射，我们可以直接访问这个目录来，获取系统信息。这个目录的内容不在硬盘上而是在内存里，我们也可以直接修改里面的某些文件来做修改。 扩展用的： /opt：默认是空的，我们安装额外软件可以放在这个里面。 /srv：存放服务启动后需要提取的数据（不用服务器就是空） 4、Linux文件基本属性Linux系统是一种典型的多用户系统，不同的用户处于不同的地位，拥有不同的权限。为了保护系统的安全性，Linux系统对不同的用户访问同一文件（包括目录文件）的权限做了不同的规定。 在Linux中我们可以使用ll或者ls –l命令来显示一个文件的属性以及文件所属的用户和组，如： （1）Linux的打印出来的信息中第一个字母表示的就是该文件是目录、文件或链接文件等等 d —目录 -—文件 l—链接文件 b—装置文件里面的可供储存的接口设备(可随机存取装置) c—装置文件里面的串行端口设备，例如键盘、鼠标(一次性读取装置) （2）接下来的字符3个为一组，且均为rwx的组合。其中r表示可读，w表示可写，x表示可执行。这三个标识的位置不会改变，如何文件没有此项权限就用-表示。 第0位表示文件的类型，详情参考（1）处 第1-3位表示文件的属主权限（即文件的拥有者的权限） 第4-6位确定属组（所有者的同组用户）拥有该文件的权限 第7-9位确定其他同住用户对该文件的权限 4.1 更改文件属性 *chgrp * (change group)更改文件属组 1chgrp [-R] 属组名 文件名 -R：递归更改文件属组，就是在更改某个目录文件的属组时，如果加上-R的参数，那么该目录下的所有文件的属组都会更改。 *chown *（change own）更改文件的属主 12chown [-R] 属主名 文件名chown [-R] 属主名:属组名 文件名 将nginx-1.17.8文件的属主修改为root chmod （change modfiy）更改文件的属性（权限） 1chmod [-R] xzy 文件目录 xyz : 就是刚刚提到的数字类型的权限属性，为 rwx 属性数值的相加。 -R : 进行递归(recursive)的持续变更，亦即连同次目录下的所有文件都会变更 Linux文件属性有两种设置方法，一种是数字，一种是符号。Linux文件的基本权限有九个，分别是owner/group/others，三种身份各有自己的read/write/execute权限。 （1）数字改变权限 文件的权限字符为：『-rwxrwxrwx』， 这九个权限是三个三个一组的！其中，我们可以使用数字来代表各个权限，各权限的分数对照表如下： 1234r:4w:2x:1-:0 每种身份(owner/group/others)各自的三个权限(r/w/x)分数是需要累加的，例如上面的nginx-1.17.8这个文件的权限字符是：『drwxr-xr-x』 d：表示这是一个文件夹 owner=4+2+1=7 group=4+0+1=5 others=4+0+1=5 给文件设置权限也是使用这样的原理，比如将nginx-1.17.8这个文件的权限修改为owner可读可写可执行，group可读不可写可执行，others没有任何权限，那么权限字符串是：rwxr-x—，即750，那么命令可以这么写 1chmod -R 750 nginx-1.17.8 （2）符号改变权限 我们就可以使用 u, g, o 来代表三种身份的权限！ 此外， a 则代表 all，即全部的身份。读写的权限可以写成 r, w, x，也就是可以使用下表的方式来看： 比如我们将nginx-1.17.8文件的权限修改为：rwxrwxr– 1chmod -R u=rwx,g=rwx,o=r nginx-17.8 5、Linux基本命令大全 ls: 列出目录 cd：切换目录 pwd：显示目前的目录，`pwd -P显示当前目录的的真实路径 mkdir：创建一个新的目录 touch filename：创建文件 vi/vim filename：修改文件（如果文件不存在会先创建） rmdir：删除一个空的目录 cp: 复制文件或目录 rm -rf filename: 移除文件或目录 mv: 移动文件与目录，或修改文件与目录的名称 whoami ：打印当前有效用户名 ，作用类似于id -un命令 users ： 用于显示当前登录系统的所有用户 login：用于给出登录界面，可用于重新登录或者切换用户身份，也可通过它的功能随时更换登入身份。 clear：清除当前终端屏幕上的任何信息 find 目录 文件：寻找目录（查） tar -zcvf 打包压缩后的文件名 要打包的文件 ：压缩文件 tar [-xvf] 压缩文件 ：解压文件 参数含义： z：调用gzip压缩命令 c：打包文件 x：代表解压 v：显示运行过程 f：指定文件名 Linux用户管理命令 useradd 选项 用户名:添加用户账号 userdel 选项 用户名:删除用户帐号 usermod 选项 用户名:修改帐号 passwd 用户名:更改或创建用户的密码 passwd -S 用户名 :显示用户账号密码信息 passwd -d 用户名: 清除用户密码 useradd命令用于Linux中创建的新的系统用户。useradd可用来建立用户帐号。帐号建好之后，再用passwd设定帐号的密码．而可用userdel删除帐号。使用useradd指令所建立的帐号，实际上是保存在/etc/passwd文本文件中。 passwd命令用于设置用户的认证信息，包括用户密码、密码过期时间等。系统管理者则能用它管理系统用户的密码。只有管理者可以指定用户名称，一般用户只能变更自己的密码。 Linux用户组管理命令 groupadd 选项 用户组 :增加一个新的用户组 groupdel 用户组:要删除一个已有的用户组 groupmod 选项 用户组 : 修改用户组的属性 grep 要搜索的字符串 要搜索的文件 --color： 搜索命令，–color代表高亮显示 ps -ef /ps -aux：这两个命令都是查看当前系统正在运行进程，两者的区别是展示格式不同。如果想要查看特定进程可以使用ps -ef |grep 进程名或pa -aux |grep 进程名 kill -9 进程pid：杀死进程（-9 表示强制终止。） 网络常用命令： ifconfig：查看系统的网卡信息 ping：查看与某台机器的连接情况,经常用来测试本机的网络连通性 nestat -an：查看当前系统的端口使用 yum：提供了查找、安装、删除某一个、一组甚至全部软件包的Shell前端软件包管理器 1yum [option] [command] [packagename...] options：可选，选项包括-h（帮助），-y（当安装过程提示选择全部为”yes”），-q（不显示安装的过程）等等。 command：要进行的操作。 package操作的对象。 常用的命令 yum update 更新所有软件命令 yum check-update 列出所有可更新的软件清单 yum update packagename 更新指定的软件 yum install [-y] packagename 安装软件，写上-y参数后当安装过程提示选择全部为”yes” yum remove packagename 删除软件 yum search packagename 搜索软件 yum list 列出所有可安裝的软件清单 除了这些常用命令外，我们还可以使用 man [命令] 来查看各个命令的使用文档，如 ：man cp。或者在http://man.linuxde.net/这个网站上哭诉查询命令的用法 6、shell编程总结​ Shell 是一个用 C 语言编写的程序，它是用户使用 Linux 的桥梁。Shell 既是一种命令语言，又是一种程序设计语言。Shell 是指一种应用程序，这个应用程序提供了一个界面，用户通过这个界面访问操作系统内核的服务。 ​ Shell 脚本（shell script），是一种为 shell 编写的脚本程序，shell 和 shell script 是两个不同的概念。Shell 编程跟 JavaScript、php 编程一样，只要有一个能编写代码的文本编辑器和一个能解释执行的脚本解释器就可以了。 Linux 的 Shell 种类众多，常见的有： Bourne Shell（/usr/bin/sh或/bin/sh） Bourne Again Shell（/bin/bash） C Shell（/usr/bin/csh） K Shell（/usr/bin/ksh） Shell for Root（/sbin/sh） Bourne Again Shell，由于易用和免费，Bash 在日常工作中被广泛使用。同时，Bash 也是大多数Linux 系统默认的 Shell。 ####]]></content>
  </entry>
  <entry>
    <title><![CDATA[Docker常见异常处理（持续更新）]]></title>
    <url>%2F2020%2F03%2F18%2FDocker%E5%B8%B8%E8%A7%81%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%EF%BC%88%E6%8C%81%E7%BB%AD%E6%9B%B4%E6%96%B0%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1. 启动docker时映射到宿主机时出现/usr/bin/docker-current: Error response from daemon: driver failed…的解决方案启动docker映射到宿主机时出现如下错误时： 1/usr/bin/docker-current: Error response from daemon: driver failed programming external connectivity on endpoint jovial_saha (5f31b67b738bca942f993bbb75bd363dff460b2243dff5bd940991d2ffd1346c): Bind for 0.0.0.0:8080 failed: port is already allocated. 这是由于来自守护进程的错误响应，而致使外部连接失败。解决的办法就是将其docker进程 kill掉，然后再 清空掉iptables下nat表下的所有链（规则） 。最后，将 docker的网桥删除，并重启docker服务. 123456[root@7con ] pkill docker #终止进程[root@7con ] iptables -t nat -F #清空nat表的所有链[root@7con ] ifconfig docker0 down #停止docker默认网桥[root@7con ] yum install bridge-utils -y # 部分机器是无法使用brctl，所以需要提前安装[root@7con ] brctl delbr docker0 #删除网桥 [root@7con ] systemctl restart docker #重启docker 重启后不出以意外的话就恢复正常了。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[基于Linux平台的Nginx配置阿里云SSL证书实现HTTPS访问]]></title>
    <url>%2F2020%2F03%2F18%2F%E5%9F%BA%E4%BA%8ELinux%E5%B9%B3%E5%8F%B0%E7%9A%84Nginx%E9%85%8D%E7%BD%AE%E9%98%BF%E9%87%8C%E4%BA%91SSL%E8%AF%81%E4%B9%A6%E5%AE%9E%E7%8E%B0HTTPS%E8%AE%BF%E9%97%AE%2F</url>
    <content type="text"><![CDATA[1、前提工作1.1 准备一台具有公网IP的Linux服务器1.2 申请一个域名，并将此域名和服务器的公网IP绑定1.3 在阿里开发者平台上申请并获取SSL证书（1）在开启SSL后，来到下图所示页面，选择一个证书类型后，不用管他上面的报价，点击申请。 （2）在接下来的这个页面中，选择你想要的证书服务类型 （3）购买成功之后，跟随系统的引导完成证书的签发之后点击下载SSL证书。这里我下载了Nginx。证书有两个，一个是证书文件`*.pem`，另一个是证书密钥文件`*.key`。 1.4 在服务器上安装Nginx服务器2、配置SSL证书登录Nginx服务器，在Nginx安装目录（默认Nginx安装目录为/usr/local/nginx/conf）下创建cert目录，并将下载的证书文件和密钥文件拷贝到cert目录中。 上传好证书和秘钥文件后，我们打开改Nginx安装目录/conf/nginx.conf文件。找到以下配置信息： 按照下文中注释内容修改nginx.conf文件： 123456789101112131415161718192021222324252627282930313233343536373839404142434445http&#123;#其他配置省略 upstream tomcatServer&#123; server 121.36.xx.xx:8080; server 121.36.xx.xx:8081; &#125;server &#123; listen 80; server_name easyblog.top; rewrite ^(.*)$ https://$server_name$1 permanent; #http请求转换到https &#125;# 以下属性中以ssl开头的属性代表与证书配置有关，其他属性请根据自己的需要进行配置。server&#123; listen 443 ssl; #SSL协议访问端口号为443。此处如未添加ssl，可能会造成Nginx无法启动 server_name www.easyblog.top; #配置你的域名 root html; index index.html index.htm; ssl_certificate /usr/local/nginx/conf/cert/3622141_www.easyblog.top.pem; #SSL证书 ssl_certificate_key /usr/local/nginx/conf/cert/3622141_www.easyblog.top.key; #SSL证书秘钥 ssl_session_timeout 5m; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE:ECDH:AES:HIGH:!NULL:!aNULL:!MD5:!ADH:!RC4; #使用此加密套件 ssl_protocols TLSv1 TLSv1.1 TLSv1.2; #使用该协议进行配置。 ssl_prefer_server_ciphers on; #禁止在header中出现服务器版本，防止黑客利用版本漏洞攻击 server_tokens off; #如果是全站 HTTPS 并且不考虑 HTTP 的话，可以加入 HSTS 告诉你的浏览器本网站全站加密，并且强制用 HTTPS 访问 #fastcgi_param HTTPS on; #fastcgi_param HTTP_SCHEME https; #access_log /usr/local/nginx/logs/httpsaccess.log; #把以前在80端口的配置迁移过来 location / &#123; proxy_pass http://tomcatServer; index index.html index.htm; proxy_set_header Host $host; proxy_set_header X-Real-IP $remote_addr; proxy_set_header X-Real-Port $remote_port; proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; &#125; &#125;&#125; 修改后保存之后别急着重启，先检查一下配置是否正确： 123[root@ecs-sn3-medium-2-linux-20191128162047 conf]# ../sbin/nginx -tnginx: the configuration file /usr/local/nginx/conf/nginx.conf syntax is oknginx: configuration file /usr/local/nginx/conf/nginx.conf test is successful 没问题后再重启Nginx，就可以使用https了。 1[root@ecs-sn3-medium-2-linux-20191128162047 conf]# ../sbin/nginx -s reload 注意！如果检查时提示nginx: [emerg] the &quot;ssl&quot; parameter requires ngx_http_ssl_module in /usr/local/nginx/conf/nginx.conf:xxx,那就说明我们在安装Nginx的时候没有安装http_ssl_module模块，这一点我们可以使用nginx -V命令来查看。解决办法：重新配置Nginx安装http_ssl_module模块即可。（1）进入到nginx的源码包 12[root@ecs-sn3-medium-2-linux-20191128162047 nginx-1.17.8]# pwd/root/nginx-1.17.8 （2）在源码包下执行如下命令: 1[root@ecs-sn3-medium-2-linux-20191128162047 nginx-1.17.8]# ./configure --prefix=/usr/local/nginx --with-http_stub_status_module --with-http_ssl_module （3）使用make命令编译（不要执行make install，执行后就会覆盖安装已经存在Nginx） 1[root@ecs-sn3-medium-2-linux-20191128162047 nginx-1.17.8]# make 最终效果：]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM—垃圾回收器（Grabage Collector）基础篇]]></title>
    <url>%2F2020%2F02%2F23%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E2%80%94%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8%EF%BC%88Grabage%20Collector%EF%BC%89%E5%9F%BA%E7%A1%80%E7%AF%87%2F</url>
    <content type="text"><![CDATA[1、如何判断对象可以被回收1.1 引用计数法&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;给对象添加一个引用计数器，每当有一个地方引用该对象的时候此计数器+1；当一个引用失效后计数器-1，当计数器的值减为0了的对象就不在可能被使用了。 优点： 实现简单，判定效率高。 缺点：当对象之间的相互循环引用时，会导致GC失效，从而造成内存泄漏。 1234567891011121314public class ReferenceCountGCTest&#123; private Object instance=null; public static void main(String[] args)&#123; ReferenceCountGCTest obj1=new ReferenceCountGCTest(); ReferenceCountGCTest obj2=new ReferenceCountGCTest(); obj1.instance=obj2; obj2.instance=onj1; obj1=obj2=null; //发生GC后，obj1和obj2都没法在引用计数法实现的GC中被清除 System.gc(); &#125;&#125; 1.2 可达性分析算法&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;以一系列“GC Roots”为起点，从这些对象开始向下搜索，当一个对象到GC Roots没有任何引用链相连接（GC Roots沿着引用链到达不了目标对象）时，就可以断定此对象是不可用的。目前主流的商用程序语言（Java、C#等）在主流的实现中，都是通过可达性分析来判定对象是否存活的。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如图 1.1 所示，GC Roots到Object1、Object2、Object3、Object4都是可达的（可达意为GC Roots沿着某条路径（引用链）一定可以找到该对象），但是GC Roots到Object5、Object6、Object7没有可达的引用链，因此它们将会被判断为可回收的对象。 ![可达性分析算法判定对象是否可以回收](http://image.easyblog.top/1582340634188cbd9a85a-2a5a-48ef-acf6-bca177d9caad.jpg) 图 1.1 可达性分析算法判定对象是否可以回收 优点：更加精确和严谨，可以分析出循环数据结构相互引用的情况； 缺点：实现比较复杂、需要分析大量数据，消耗大量时间、分析过程需要GC停顿（引用关系不能发生变化），即停顿所有Java执行线程（称为”Stop The World”，是垃圾回收重点关注的问题）。 在Java语言中可以作为GC Roots的对象有以下几种： 虚拟机桟桟帧中的局部变量表所引用的对象。 方法区中类的静态的属性所引用的对象。 方法区中常量引用的对象。 本地方法桟中本地方法所引用的对象。 2、 Java中的几种引用#####（1）强引用 类似Object obj=new Objectt()这样的引用方式就是强引用，只有所有的GC Roots对象都不通过强引用引用该对象的时候，该对象才能被垃圾回收。（2）软引用 仅有软引用引用一个对象时，在垃圾回收后系统内存任然不足，将会再次发生GC把这些软引用对象清除，如果回收后内存还是不足，才会抛出内省溢出异常。 一个软引用可以使用SoftReference类来实现。软引用可以配合引用队列来释放软引用自生。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;软引用可以用于存放一些重要性不是很强又不能随便让清除的对象，比如图片切换到后台不需要马上显示了，对于内存敏感的高速缓存等。如下实例就可以说明： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package top.easyblog;import java.lang.ref.SoftReference;import java.util.ArrayList;import java.util.Arrays;import java.util.List;/** * 软引用的应用： * VM Options：-Xmx20m -XX:+PrintGCDetails -verbose:gc * * @author ：huangxin * @modified ： * @since ：2020/02/22 14:23 */public class JavaReferencesTest &#123; private static final int _4MB = 1024 * 1024 * 4; public static void main(String[] args) &#123; /**设置-Xmx20m后运行报堆内存溢出异常 List&lt;byte[]&gt; lists=new ArrayList&lt;&gt;(); for(int i=0;i&lt;=5;i++)&#123; lists.add(new byte[_4MB]); &#125;*/ softReferenceTest(); &#125; /** *软引用测试：假如现在有多幅图片需要显示，如果是使用直接引用，这段代码在设置-Xmx20m后一定会报内存溢出 * 但是根据实际应用场景，图片加载被看过后就可以不需要了，因此我们可以把这些引用设置为软引用或弱引用 */ public static void softReferenceTest() &#123; //List强引用SoftReference，SoftReference软引用byte[] List&lt;SoftReference&lt;byte[]&gt;&gt; lists = new ArrayList&lt;&gt;(); for (int i = 1; i &lt;=5; i++) &#123; SoftReference&lt;byte[]&gt; reference = new SoftReference&lt;&gt;(new byte[_4MB]); System.out.println(reference.get()); lists.add(reference); System.out.println(lists.size()); &#125; System.out.println("===============循环结束============"); for (SoftReference&lt;byte[]&gt; ref : lists) &#123; System.out.println(ref.get()); &#125; &#125;&#125; 运行结果及分析： ![运行结果](http://image.easyblog.top/15823565202886de68a8c-fdc5-4086-bca1-ec9fb4601f9b.png) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在图中①处系统内存发现内存紧张了，因此发生了一次GC，此时系统内存挪一挪还可以放下一个4MB大小的byte[]对象，但是当第5次申请内存的时候发现系统内存又不用了，我们也看到了，此时对于20M的堆内存已经用了4*4MB了，再加上其他的对象占用一点内存，堆上是真的没有足够的空间分配给第5个4MB大小的byte[]对象了，此时我们软引用的作用就发挥出来了，从图中可以看到最后一次Full GC直接把新生代中对象清空了，并且老年代的内存占用也大幅减少，而清除掉的这些正是前面分配的被软引用的对象（从最终打印的几个null值可以看出），如果没有这种机制，那么前面几个对象是被List所引用的，GC是没有办法清除它们的。 使用引用队列释放软引用/弱引用对象自身在上面的例子中验证了软引用第一条特点：被软引用引用的对象会在系统内存紧张的时候被回收，但是SoftReference这个对象并没有回收，这也会对系统内存造成浪费，因此下面我们就使用引用队列来把这个对象也清除了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package top.easyblog;import java.lang.ref.Reference;import java.lang.ref.ReferenceQueue;import java.lang.ref.SoftReference;import java.util.ArrayList;import java.util.Arrays;import java.util.List;/** * 软引用的应用： * VM Options：-Xmx20m -XX:+PrintGCDetails -verbose:gc * * @author ：huangxin * @modified ： * @since ：2020/02/22 14:23 */public class JavaReferencesTest &#123; private static final int _4MB = 1024 * 1024 * 4; public static void main(String[] args) &#123; softReferenceTest(); &#125; //使用引用队列删除SoftReference public static void softReferenceTest() &#123; List&lt;SoftReference&lt;byte[]&gt;&gt; lists = new ArrayList&lt;&gt;(); //引用队列: ReferenceQueue&lt;byte[]&gt; queue = new ReferenceQueue&lt;&gt;(); for (int i = 1; i &lt;= 5; i++) &#123; //在构造器中传参数引用队列，使一个SoftReference对象和引用队列关联，当软引用所关联的byte[]被回收后，软引用对象自己会把自己加入到引用队列中 SoftReference&lt;byte[]&gt; reference = new SoftReference&lt;&gt;(new byte[_4MB], queue); System.out.println(reference.get()); lists.add(reference); System.out.println(lists.size()); &#125; //加入引用队列中的都是无用的SoftReference对象，在这里直接遍历删除 Reference&lt;? extends byte[]&gt; poll = queue.poll(); while (poll != null) &#123; lists.remove(poll); poll = queue.poll(); &#125; System.out.println("===============循环结束============"); for (SoftReference&lt;byte[]&gt; ref : lists) &#123; System.out.println(ref.get()); &#125; &#125;&#125; 运行结果： ![运行结果](http://image.easyblog.top/15823589086212406ec0b-7af8-4c05-8ae8-a3d4d5cdc925.png) （3）弱引用 仅有弱引用引用一个对象时，在垃圾回收的时候一定会回收该对象。 一个弱引用可以使用WeakReference类来实现。弱引用可以配合引用队列来释放弱引用自生 （4） 虚引用 它是最弱的是一种引用关系，必须配合引用队列来使用，主要配合ByteBuffer使用，被引用的对象回收的时候，会将虚引用入队，有Reference Handler线程调用虚引用相关方法释放直接内存。 最后通过一幅图来说明一下JVM回收机制究竟如何区别对待各种引用类型： ![JVM回收机制究竟如何区别对待各种引用类型](http://image.easyblog.top/1582353391248907b90f4-5375-4f65-a295-dd7e1aa1bb6a.jpg)图 2.1 JVM回收机制对待各种引用类型 3、垃圾回收算法3.1 标记-清除算法（Merk-Sweep）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;标记 -清除算法分为两个阶段：标记和清除。首先使用上面介绍的可达性分析算法标记出所有需要回收的对象。在标记完成后统一回收所有标记的对象，实质是将回收的对象的起始和结束地址记下来，下次在给新的对象分配内存的时候如果大小合适就覆盖这片内存。标记清除算法比较简单粗暴，实现也比较简单。但是它留下了两个比较麻烦的问题： 效率问题，标记和清除两个过程效率都不高 空间问题，标记清除过后会产生大量的内存碎片，太多的内存碎片会在需要给大对象分配内存的时候，无法找到足够的连续空间而不得不触发另一次GC。![标记清除算法](http://image.easyblog.top/1582375596759873ad1cb-70d1-4690-b273-d4ac36a3d10f.png)图3.1 标记-清除算法示意图 3.2 复制算法（Copying）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;复制算法把一块可用的空间分为大小均等的两块区域，每次只使用其中的一块，当这块内存快用完时同样是需要先做标记，然后将有用对独向复制到另一个区域，之后把已使用过的内存一次清理掉。复制算法解决了标记清理算法带来的内存碎片问题，并且实现简单，运行高效；但是这种的算法的代价是“浪费”了一半的内存可用空间。 图3.2 复制算法示意图 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在现代的商用JVM堆内存的新生代采用了复制算法，在Sun HotSpot虚拟机中新生代分为Eden空间和两块较小的Survivor空间，每次使用Eden空间和一个Survivor空间，每次GC的时候都会将Eden和Survivor的From区中的有效对象进行标记，一同复制到Survivor的To区。然后彻底清除原来的Eden区和From区的内存对象。与此同时To区就是下一次回收的From区。这一过程中新生代的内存只有90%再被使用，总会有10%的空间”浪费“。 内存担保（Handle Promotion）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;然而我们并不能保证上一次新生代收集下来的存活对象都可以在另一个Survivor空间中可以装得下，当另外一块Survivor空间的内存不够的时候，我们就要依赖其他内存进行分配担保（Handle Promotion）。分配担保中如果另外一块Survivor空间没有足够的空间存放上一次新生代收集下来的存活对象时，这些对象将直接通过分配担保机制进入到老年代。 3.3 标记-整理算法（ Mark-Compact）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;复制算法需要一块额外的内存空间，用于存放幸存的内存对象。这无疑造成了内存的浪费。因此在原有的标记清除算法的基础上，提出了优化方案。也就是标记到的可用对象整体向一侧移动，然后直接清除掉可用对象边界以外的内存。这样既解决了内存碎片的问题。又不需要原有的空间换时间的硬件浪费。由于老年代中的幸存对象较多，而且对象内存占用较大。这就使得一旦出现内存回收，需要被回收的对象并不多，碎片也就相对的比较少。所以不需要太多的复制和移动步骤。因此这种方法常常被应用到老年代中。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;标记整理算法的缺点： 标记整理算法由于需要不断的移动对象到另外一侧，而这种不断的移动其实是非常不适合杂而多的小内存对象的。每次的移动和计算都是非常复杂的过程。因此在使用场景上，就注定限制了标记整理算法的使用不太适合频繁创建和回收对象的内存中。 图3.3 标记整理算法示意图 3.4 分代垃圾回收机制（Generational Collection）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这种算法就是将内存以代的形式划分，然后针对情况分别使用性价比最高的算法进行处理。在Java中，一般将堆分为老年代和新生代。新创建的对象往往被放置在新生代中。而经过不断的回收，逐渐存活下来的对象被安置到了老年代中。越新的对象越可能被回收，越老的对象反而会存活的越久。因此针对这两种场景，新生代和老年代也会分别采用前文所述的两种算法进行清理。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM—垃圾回收器（Grabage Collector）进阶篇]]></title>
    <url>%2F2020%2F02%2F23%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E2%80%94%E5%9E%83%E5%9C%BE%E5%9B%9E%E6%94%B6%E5%99%A8%EF%BC%88Grabage%20Collector%EF%BC%89%E8%BF%9B%E9%98%B6%E7%AF%87%2F</url>
    <content type="text"><![CDATA[1、如何判断对象可以被回收1.1 引用计数法&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;给对象添加一个引用计数器，每当有一个地方引用该对象的时候此计数器+1；当一个引用失效后计数器-1，当计数器的值减为0了的对象就不在可能被使用了。 优点： 实现简单，判定效率高。 缺点：当对象之间的相互循环引用时，会导致GC失效，从而造成内存泄漏。 1234567891011121314public class ReferenceCountGCTest&#123; private Object instance=null; public static void main(String[] args)&#123; ReferenceCountGCTest obj1=new ReferenceCountGCTest(); ReferenceCountGCTest obj2=new ReferenceCountGCTest(); obj1.instance=obj2; obj2.instance=onj1; obj1=obj2=null; //发生GC后，obj1和obj2都没法在引用计数法实现的GC中被清除 System.gc(); &#125;&#125; 1.2 可达性分析算法&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;以一系列“GC Roots”为起点，从这些对象开始向下搜索，当一个对象到GC Roots没有任何引用链相连接（GC Roots沿着引用链到达不了目标对象）时，就可以断定此对象是不可用的。目前主流的商用程序语言（Java、C#等）在主流的实现中，都是通过可达性分析来判定对象是否存活的。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;如图 1.1 所示，GC Roots到Object1、Object2、Object3、Object4都是可达的（可达意为GC Roots沿着某条路径（引用链）一定可以找到该对象），但是GC Roots到Object5、Object6、Object7没有可达的引用链，因此它们将会被判断为可回收的对象。 图 1.1 可达性分析算法判定对象是否可以回收 优点：更加精确和严谨，可以分析出循环数据结构相互引用的情况； 缺点：实现比较复杂、需要分析大量数据，消耗大量时间、分析过程需要GC停顿（引用关系不能发生变化），即停顿所有Java执行线程（称为”Stop The World”，是垃圾回收重点关注的问题）。 在Java语言中可以作为GC Roots的对象有以下几种： 虚拟机桟桟帧中的局部变量表所引用的对象。 方法区中类的静态的属性所引用的对象。 方法区中常量引用的对象。 本地方法桟中本地方法所引用的对象。 2、 Java中的几种引用#####（1）强引用 类似Object obj=new Objectt()这样的引用方式就是强引用，只有所有的GC Roots对象都不通过强引用引用该对象的时候，该对象才能被垃圾回收。（2）软引用 仅有软引用引用一个对象时，在垃圾回收后系统内存任然不足，将会再次发生GC把这些软引用对象清除，如果回收后内存还是不足，才会抛出内省溢出异常。 一个软引用可以使用SoftReference类来实现。软引用可以配合引用队列来释放软引用自生。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;软引用可以用于存放一些重要性不是很强又不能随便让清除的对象，比如图片切换到后台不需要马上显示了，对于内存敏感的高速缓存等。如下实例就可以说明： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package top.easyblog;import java.lang.ref.SoftReference;import java.util.ArrayList;import java.util.Arrays;import java.util.List;/** * 软引用的应用： * VM Options：-Xmx20m -XX:+PrintGCDetails -verbose:gc * * @author ：huangxin * @modified ： * @since ：2020/02/22 14:23 */public class JavaReferencesTest &#123; private static final int _4MB = 1024 * 1024 * 4; public static void main(String[] args) &#123; /**设置-Xmx20m后运行报堆内存溢出异常 List&lt;byte[]&gt; lists=new ArrayList&lt;&gt;(); for(int i=0;i&lt;=5;i++)&#123; lists.add(new byte[_4MB]); &#125;*/ softReferenceTest(); &#125; /** *软引用测试：假如现在有多幅图片需要显示，如果是使用直接引用，这段代码在设置-Xmx20m后一定会报内存溢出 * 但是根据实际应用场景，图片加载被看过后就可以不需要了，因此我们可以把这些引用设置为软引用或弱引用 */ public static void softReferenceTest() &#123; //List强引用SoftReference，SoftReference软引用byte[] List&lt;SoftReference&lt;byte[]&gt;&gt; lists = new ArrayList&lt;&gt;(); for (int i = 1; i &lt;=5; i++) &#123; SoftReference&lt;byte[]&gt; reference = new SoftReference&lt;&gt;(new byte[_4MB]); System.out.println(reference.get()); lists.add(reference); System.out.println(lists.size()); &#125; System.out.println("===============循环结束============"); for (SoftReference&lt;byte[]&gt; ref : lists) &#123; System.out.println(ref.get()); &#125; &#125;&#125; 运行结果及分析： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在图中①处垃圾回收器发现系统内存紧张了，因此发生了一次GC，此时系统内存挪一挪还可以放下一个4MB大小的byte[]对象，但是当第5次申请内存的时候发现系统内存又不用了，我们也看到了，此时对于20M的堆内存已经用了4*4MB了，再加上其他的对象占用一点内存，堆上是真的没有足够的空间分配给第5个4MB大小的byte[]对象了，此时我们软引用的作用就发挥出来了，从图中可以看到最后一次Full GC直接把新生代中对象清空了，并且老年代的内存占用也大幅减少，而清除掉的这些正是前面分配的被软引用的对象（从最终打印的几个null值可以看出），如果没有这种机制，那么前面几个对象是被List所引用的，GC是没有办法清除它们的。 使用引用队列释放软引用/弱引用对象自身在上面的例子中验证了软引用第一条特点：被软引用引用的对象会在系统内存紧张的时候被回收，但是SoftReference这个对象并没有回收，这也会对系统内存造成浪费，因此下面我们就使用引用队列来把这个对象也清除了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354package top.easyblog;import java.lang.ref.Reference;import java.lang.ref.ReferenceQueue;import java.lang.ref.SoftReference;import java.util.ArrayList;import java.util.Arrays;import java.util.List;/** * 软引用的应用： * VM Options：-Xmx20m -XX:+PrintGCDetails -verbose:gc * * @author ：huangxin * @modified ： * @since ：2020/02/22 14:23 */public class JavaReferencesTest &#123; private static final int _4MB = 1024 * 1024 * 4; public static void main(String[] args) &#123; softReferenceTest(); &#125; //使用引用队列删除SoftReference public static void softReferenceTest() &#123; List&lt;SoftReference&lt;byte[]&gt;&gt; lists = new ArrayList&lt;&gt;(); //引用队列: ReferenceQueue&lt;byte[]&gt; queue = new ReferenceQueue&lt;&gt;(); for (int i = 1; i &lt;= 5; i++) &#123; //在构造器中传参数引用队列，使一个SoftReference对象和引用队列关联，当软引用所关联的byte[]被回收后，软引用对象自己会把自己加入到引用队列中 SoftReference&lt;byte[]&gt; reference = new SoftReference&lt;&gt;(new byte[_4MB], queue); System.out.println(reference.get()); lists.add(reference); System.out.println(lists.size()); &#125; //加入引用队列中的都是无用的SoftReference对象，在这里直接遍历删除 Reference&lt;? extends byte[]&gt; poll = queue.poll(); while (poll != null) &#123; lists.remove(poll); poll = queue.poll(); &#125; System.out.println("===============循环结束============"); for (SoftReference&lt;byte[]&gt; ref : lists) &#123; System.out.println(ref.get()); &#125; &#125;&#125; 运行结果： （3）弱引用 仅有弱引用引用一个对象时，在垃圾回收的时候一定会回收该对象。 一个弱引用可以使用WeakReference类来实现。弱引用可以配合引用队列来释放弱引用自生 （4） 虚引用 它是最弱的是一种引用关系，必须配合引用队列来使用，主要配合ByteBuffer使用，被引用的对象回收的时候，会将虚引用入队，有Reference Handler线程调用虚引用相关方法释放直接内存。 最后通过一幅图来说明一下JVM回收机制究竟如何区别对待各种引用类型： 图 2.1 JVM回收机制对待各种引用类型 3、垃圾回收算法3.1 标记-清除算法（Merk-Sweep）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;标记 -清除算法分为两个阶段：标记和清除。首先使用上面介绍的可达性分析算法标记出所有需要回收的对象。在标记完成后统一回收所有标记的对象，实质是将回收的对象的起始和结束地址记下来，下次在给新的对象分配内存的时候如果大小合适就覆盖这片内存。标记清除算法比较简单粗暴，实现也比较简单。但是它留下了两个比较麻烦的问题： 效率问题，标记和清除两个过程效率都不高 空间问题，标记清除过后会产生大量的内存碎片，太多的内存碎片会在需要给大对象分配内存的时候，无法找到足够的连续空间而不得不触发另一次GC。图3.1 标记-清除算法示意图 3.2 复制算法（Copying）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;复制算法把一块可用的空间分为大小均等的两块区域，每次只使用其中的一块，当这块内存快用完时同样是需要先做标记，然后将有用对独向复制到另一个区域，之后把已使用过的内存一次清理掉。复制算法解决了标记清理算法带来的内存碎片问题，并且实现简单，运行高效；但是这种的算法的代价是“浪费”了一半的内存可用空间。 图3.2 复制算法示意图 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在现代的商用JVM堆内存的新生代采用了复制算法，在Sun HotSpot虚拟机中新生代分为Eden空间和两块较小的Survivor空间，每次使用Eden空间和一个Survivor空间，每次GC的时候都会将Eden和Survivor的From区中的有效对象进行标记，一同复制到Survivor的To区。然后彻底清除原来的Eden区和From区的内存对象。与此同时To区就是下一次回收的From区。这一过程中新生代的内存只有90%再被使用，总会有10%的空间”浪费“。 内存担保（Handle Promotion）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;然而我们并不能保证上一次新生代收集下来的存活对象都可以在另一个Survivor空间中可以装得下，当另外一块Survivor空间的内存不够的时候，我们就要依赖其他内存进行分配担保（Handle Promotion）。分配担保中如果另外一块Survivor空间没有足够的空间存放上一次新生代收集下来的存活对象时，这些对象将直接通过分配担保机制进入到老年代。 3.3 标记-整理算法（ Mark-Compact）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;复制算法需要一块额外的内存空间，用于存放幸存的内存对象。这无疑造成了内存的浪费。因此在原有的标记清除算法的基础上，提出了优化方案。也就是标记到的可用对象整体向一侧移动，然后直接清除掉可用对象边界以外的内存。这样既解决了内存碎片的问题。又不需要原有的空间换时间的硬件浪费。由于老年代中的幸存对象较多，而且对象内存占用较大。这就使得一旦出现内存回收，需要被回收的对象并不多，碎片也就相对的比较少。所以不需要太多的复制和移动步骤。因此这种方法常常被应用到老年代中。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;标记整理算法的缺点： 标记整理算法由于需要不断的移动对象到另外一侧，而这种不断的移动其实是非常不适合杂而多的小内存对象的。每次的移动和计算都是非常复杂的过程。因此在使用场景上，就注定限制了标记整理算法的使用不太适合频繁创建和回收对象的内存中。 图3.3 标记整理算法示意图 3.4 分代垃圾回收机制（Generational Collection）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这种算法就是将内存以代的形式划分，然后针对情况分别使用性价比最高的算法进行处理。在Java中，一般将堆分为老年代和新生代。新创建的对象往往被放置在新生代中。而经过不断的回收，逐渐存活下来的对象被安置到了老年代中。越新的对象越可能被回收，越老的对象反而会存活的越久。因此针对这两种场景，新生代和老年代也会分别采用前文所述的两种算法进行清理。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title></title>
    <url>%2F2020%2F02%2F20%2F%E5%89%8D%E7%AB%AFUI%E8%87%AA%E5%8A%A8%E8%81%94%E6%83%B3%E5%8A%9F%E8%83%BD%2F</url>
    <content type="text"><![CDATA[前端UI自动联想功能12345678910111213141516171819202122232425262728&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;label&gt;Select your preferred code editor:&lt;/label&gt; &lt;input type="text" id="txt_ide" list="ide" /&gt; &lt;datalist id="ide"&gt; &lt;option value="Brackets" /&gt; &lt;option value="Coda" /&gt; &lt;option value="Dreamweaver" /&gt; &lt;option value="Espresso" /&gt; &lt;option value="jEdit" /&gt; &lt;option value="Komodo Edit" /&gt; &lt;option value="Notepad++" /&gt; &lt;option value="Sublime Text 2" label="the develpoer's choice" /&gt; &lt;option value="Taco HTML Edit" /&gt; &lt;option value="Textmate" /&gt; &lt;option value="Text Pad" /&gt; &lt;option value="TextWrangler" /&gt; &lt;option value="Visual Studio" /&gt; &lt;option value="VIM" /&gt; &lt;option value="XCode" /&gt; &lt;/datalist&gt;&lt;/body&gt;&lt;/html&gt;]]></content>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM—堆（Heap）]]></title>
    <url>%2F2020%2F02%2F11%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E2%80%94%E5%A0%86%EF%BC%88Heap%EF%BC%89%2F</url>
    <content type="text"><![CDATA[1、堆（Heap）概述&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Java堆（Java Heap）是JVM所管理的最大的一块内存空间。Java堆是被所有线程共享的一块内存区域，在JVM启动的时候创建。堆的唯一目的就是存放对象实例的，Java中几乎所有的对象实例和数组都在对上分配内存。Java堆的容量可以是固定大小的，也可以随着程序执行的需求动态扩展，并在不需要过多空间时自动收缩。Java堆所使用的内存亦不需要保证是连续的。 Heap 用来存储数组与new 关键字创建的对象实例，例如： 1Student stu = new Student(); &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先JVM 会在Heap 中分配出Student 对象存储的内存区域，并将地址返回，然后再在JVM Stack 中的局部表量表中创建Student 对象的引用用来存放Heap 分配的Student 地址。之后就可以在程序中使用栈中的引用对象来访问堆中的数组或对象。当使用完对象后，我们不必显式的管理堆内存释放工作，堆内存的释放会由GC(垃圾收集器)自动完成。 图1 对象的分配和访问 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Java堆是垃圾回收器工作的主要区域，因此堆也被称为“GC堆”（Garbage Collected Heap）。从垃圾回收的角度来看，由于现在的收集器基本采用**分代收集算法**，所以Java堆可以细分为：**新生代（Young/New Generation）和老年代（Old/Tenured Generation 老年代）**。新生对象放置在新生代中，新生代由**Eden空间** 、**Survivor From空间** 、**Survivor To空间** 组成；老年代用于存放程序中经过指定次数垃圾回收后还存活的对象。 图2 堆内存 ##### （1）**Young/New Generation 新生代** &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;程序中新建的对象都将分配到新生代中，新生代又由Eden(伊甸园)与两块Survivor(幸存者) Space 构成。**Eden 与Survivor Space 的空间大小比例默认为8:1**，即当Young/New Generation 区域的空间大小总数为10M 时，Eden 的空间大小为8M，两块Survivor Space 则各分配1M，这个比例可以通过-XX:SurvivorRatio 参数来修改。Young/New Generation的大小则可以通过-Xmn参数来指定。 ● Eden：刚刚新建的对象将会被放置到Eden 中，这个名称寓意着对象们可以在其中快乐自由的生活。 ● Survivor 空间：幸存者区域是新生代与老年代的缓冲区域，两块幸存者区域在逻辑上分别为s0 与s1。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当触发Minor GC 后将Eden区中仍然存活的对象移动到S0中去(From Eden To s0)。这样Eden 就会被清空可以分配给新的对象。当再一次触发Minor GC后，S0和Eden 中存活的对象被移动到S1中(From s0 To s1)，S0即被清空。在同一时刻, 只有Eden和一个Survivor Space同时被操作。所以s0与s1两块Survivor 区同时会至少有一个为空闲的，这点从下面的图中可以看出。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当每次对象从Eden 复制到Survivor Space 或者从Survivor Space 之间复制，计数器会自动增加其值。 默认情况下如果复制发生超过16次，JVM 就会停止复制并把他们移到老年代中去。如果一个对象不能在Eden中被创建，它会直接被创建在老年代中。 ● 新生代GC(Minor GC)：指发生在新生代的垃圾收集动作，因为 Java 对象大多都具备朝生夕灭的特性，通常很多的对象都活不过一次GC，所以Minor GC 非常频繁，一般回收速度也比较快。 ● Minor GC 清理过程(图中红色区域为垃圾)： 图3 Minor GC发生之前 图4 Minor GC发生之后 **注意**： 1. 图中的"From" 与"To" 只是逻辑关系而不是Survivor 空间的名称，也就是说谁装着对象谁就是"From"。 2. 一个对象在幸存者区被移动/复制的次数决定了它是否会被移动到堆中。 （2）old/Tenured Generation 老年代&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;老年代用于存放程序中经过几次垃圾回收后还存活的对象，例如缓存的对象等，老年代所占用的内存大小即为-Xmx 与-Xmn 两个参数之差。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;堆是JVM 中所有线程共享的，因此在其上进行对象内存的分配均需要进行加锁，这也导致了new 对象的开销是比较大的，鉴于这样的原因，Hotspot JVM 为了提升对象内存分配的效率，对于所创建的线程都会分配一块独立的空间，这块空间又称为TLAB（Thread Local Allocation Buffer），其大小由JVM 根据运行的情况计算而得，在TLAB 上分配对象时不需要加锁，因此JVM 在给线程的对象分配内存时会尽量的在TLAB 上分配，在这种情况下JVM 中分配对象内存的性能和C 基本是一样高效的， 但如果对象过大的话则仍然是直接使用堆空间分配，TLAB 仅作用于新生代的Eden，因此在编写Java 程序时，通常多个小的对象比大的对象分配起来更加高效，但这种方法同时也带来了两个问题，一是空间的浪费，二是对象内存的回收上仍然没法做到像Stack 那么高效，同时也会增加回收时的资源的消耗，可通过在启动参数上增加 -XX:+PrintTLAB来查看TLAB 这块的使用情况。 ● 老年代GC(Major GC/Full GC)：指发生在老年代的GC，出现了Major GC，通常会伴随至少一次Minor GC（但也并非绝对，在ParallelScavenge 收集器的收集策略里则可选择直接进行Major GC）。Major GC 的速度一般会比Minor GC 慢10倍以上。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;虚拟机给每个对象定义了一个对象年龄(age)计数器。如果对象在 Eden 出生并经过第一次 Minor GC 后仍然存活，并且能被 Survivor 容纳的话，将被移动到 Survivor 空间中，并将对象年龄设为 1。对象在 Survivor 区中每熬过一次 Minor GC，年龄就增加 1 岁，当它的年龄增加到一定程度（默认为 15 岁）时，就会被晋升到老年代中。对象晋升老年代的年龄阈值，可以通过参数 -XX:MaxTenuringThreshold 来设置。 （3）JVM中给对象分配内存的过程当一个对象被创建后，内存申请过程如下： JVM 会试图为相关Java 对象在Eden区 中初始化一块内存区域。 当Eden 空间足够时，内存申请结束。否则进入第三步。 JVM 试图释放在Eden 中所有不活跃的对象（执行1或更高级的垃圾回收）, 释放后若Eden 空间仍然不足以放入新对象，则试图将部分Eden 中活跃对象放入Survivor 区。 Survivor 区被用来作为新生代与老年代的缓冲区域，当老年代空间足够时，Survivor 区的对象会被移到老年代，否则会被保留在Survivor 区。 当老年代空间不够时，JVM 会在老年代进行0级的完全垃圾收集(Major GC/Full GC)。 Major GC/Full GC后，若Survivor 及老年代仍然无法存放从Eden 复制过来的部分对象，导致JVM 无法在Eden 区为新对象创建内存区域，JVM 此时就会抛出内存不足的异常。 （4）Java堆的调优参数总结JVM的调优参数，我这里首推官方文档，常用的Java堆有关的调优参数如下： -Xms size：设置初始堆大小，默认为物理内存的1/64(&lt;1GB)；默认(MinHeapFreeRatio参数可以调整)空余堆内存小于40%时，JVM就会增大堆直到-Xmx的最大限制 -Xmx size：设置最大堆大小，默认(MaxHeapFreeRatio参数可以调整)空余堆内存大于70%时，JVM会减少堆直到 -Xms的最小限制 。等价的参数：-XX:MaxHeapSize=size -Xmn size：设置新生代的内存空间大小，即Eden+ 2个survivor space。 在保证堆大小不变的情况下，增大新生代后,将会减小老生代大小。此值对系统性能影响较大,Sun官方推荐配置为整个堆的3/8。 等价的参数：-XX:NewSize=size -XX:SurvivorRatio：设置新生代中Eden区域与Survivor区域的容量比值，默认值为8。两个Survivor区与一个Eden区的比值为2:8,一个Survivor区占整个年轻代的1/10。 -XX:NewRatio=ratio：设置年轻代（包括Eden和两个Survivor区）与年老代的比值（除去持久代）。设置为4，则年轻代与年老代所占比值为1：4，年轻代占整个堆栈的1/5 -XX:MaxTenuringThreshold=threshold：设置垃圾最大年龄。如果设置为0的话，则年轻代对象不经过Survivor区，直接进入年老代。对于年老代比较多的应用，可以提高效率。如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象在年轻代的存活时间，增加在年轻代即被回收的概论。 -Xss size：设置每个线程的堆栈大小。JDK5.0以后每个线程堆栈大小默认为1M，以前每个线程堆栈大小默认为256K。更具应用的线程所需内存大小进行调整。在相同物理内存下，减小这个值能生成更多的线程。但是操作系统对一个进程内的线程数还是有限制的，不能无限生成，经验值在3000~5000左右。 -XX:TLABSize=size：设置TLAB的初始大小，将它设置为0表示让JVM自动选择初始大小。 *-XX:+PrintGCDetails *：打印 GC 信息 -XX:+HeapDumpOnOutOfMemoryError： 让虚拟机在发生内存溢出时 Dump 出当前的内存堆转储快照，以便分析用 2、Java堆的调优参数总结JVM的调优参数，我这里首推官方文档，常用的Java堆有关的调优参数如下： -Xms size：设置初始堆大小，默认为物理内存的1/64(&lt;1GB)；默认(MinHeapFreeRatio参数可以调整)空余堆内存小于40%时，JVM就会增大堆直到-Xmx的最大限制 -Xmx size：设置最大堆大小，默认(MaxHeapFreeRatio参数可以调整)空余堆内存大于70%时，JVM会减少堆直到 -Xms的最小限制 。等价的参数：-XX:MaxHeapSize=size -Xmn size：设置新生代的内存空间大小，即Eden+ 2个survivor space。 在保证堆大小不变的情况下，增大新生代后,将会减小老生代大小。此值对系统性能影响较大,Sun官方推荐配置为整个堆的3/8。 等价的参数：-XX:NewSize=size -XX:SurvivorRatio：设置新生代中Eden区域与Survivor区域的容量比值，默认值为8。两个Survivor区与一个Eden区的比值为2:8,一个Survivor区占整个年轻代的1/10。 -XX:NewRatio=ratio：设置年轻代（包括Eden和两个Survivor区）与年老代的比值（除去持久代）。设置为4，则年轻代与年老代所占比值为1：4，年轻代占整个堆栈的1/5 -XX:MaxTenuringThreshold=threshold：设置垃圾最大年龄。如果设置为0的话，则年轻代对象不经过Survivor区，直接进入年老代。对于年老代比较多的应用，可以提高效率。如果将此值设置为一个较大值，则年轻代对象会在Survivor区进行多次复制，这样可以增加对象在年轻代的存活时间，增加在年轻代即被回收的概论。 -Xss size：设置每个线程的堆栈大小。JDK5.0以后每个线程堆栈大小默认为1M，以前每个线程堆栈大小默认为256K。更具应用的线程所需内存大小进行调整。在相同物理内存下，减小这个值能生成更多的线程。但是操作系统对一个进程内的线程数还是有限制的，不能无限生成，经验值在3000~5000左右。 -XX:TLABSize=size：设置TLAB的初始大小，将它设置为0表示让JVM自动选择初始大小。 *-XX:+PrintGCDetails *：打印 GC 信息 -XX:+HeapDumpOnOutOfMemoryError： 让虚拟机在发生内存溢出时 Dump 出当前的内存堆转储快照，以便分析用 3、HotSpot VM对象探秘3.1 对象的创建过程 判断类是否加载，检查常量池中是否可以定位到指定类的符号引用，并且检查这个符号引用所代表的类时候已经被加载、链接和初始化过。 可以定位到符号引用，并且已经被加载过：进入下一步 没法定位到符号引用或没有被加载过：执行相应的类加载过程。 分配内存（指针碰撞：Serial、ParNew/空闲列表：CMS）。 初始化零值，为对象中的实例字段赋零值（不是给静态属性赋零值，静态属性在类加载的时候就初始化完成了，详情参考深入理解JVM—虚拟机类加载机制）。 设置对象头（Object Header），如设置此对象是哪个类的实例、如何才能知道类的元数据信息、对象的hashcode、对象的GC分代年龄……。 执行类的构造方法（站在JVM的角度是执行&lt;init&gt;方法），初始化类的实例字段。 这5步执行后一个真正可用的对象才算完全产生出来。 3.2 对象的内存布局&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在HotSpot虚拟机中对象在内存中的存储布局可以分为：对象头、实例数据和对齐填充3部分。 图3.1 对象的内存布局 ##### （1）对象头（Object Header） &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对象头在HotSpot虚拟机中被分为了两部分，**一部分官方称为Mark Word;另一部分是类型指针**。如果对象是一个Java数组，那在对象头中还有一块用于记录数组长度的数据。 图3.2 对象头 * 第一部分**Mark Word用于存储对象自身的运行时数据**，如哈希码（HashCode）、GC 分代年龄、锁状态标志、线程持有的锁、偏向线程 ID、对象分代年龄等信息。Mark Word被设计成一个非固定的数据结构以便在极小的空间内存储尽量多的信息，它会根据自己的状态复用自己的存储空间 * 第二部分是**类型指针，即对象指向它的类元数据的指针，虚拟机通过这个指针来确定这个对象是哪个类的实例**。 在 32 位的 HotSpot 虚拟机中，如果对象处于未被锁定的状态下，那么 Mark Word 的 32bit 空间中的 25bit 用于存储对象哈希码，4bit 用于存储对象分代年龄，2bit 用于存储锁标志位，1bit 固定为 0，如下表所示： 在 32 位系统下，存放 Class 指针的空间大小是 4 字节，Mark Word 空间大小也是4字节，因此头部就是 8 字节，如果是数组就需要再加 4 字节表示数组的长度，如下表所示： ![32位系统中对象头](http://image.easyblog.top/1582278388550516977d8-269e-4bba-9fc5-3a25bf297a51.png) 在 64 位系统及 64 位 JVM 下，开启指针压缩，那么头部存放 Class 指针的空间大小还是4字节，而 Mark Word 区域会变大，变成 8 字节，也就是头部最少为 12 字节，如下表所示： （2）实例数据（Instance Data）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;实例数据部分是对象真正存储的有效信息，也是在程序代码中所定义的各种类型的字段内容。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这部分的存储顺序会受到虚拟机分配策略参数（FieldsAllocationStyle）和字段在 Java 源码中定义顺序的影响。 （3）对齐填充（Padding）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于HotSpot VM的自动内存管理系统要求对象的起始地址必须是8字节的整数倍，即：Java对象的大小必须是8字节的整数倍，而对象头的大小正好是8字节的整数倍，所以当对象的实例数据没有对齐的时候，就需要对齐填充来补全。因此对齐填充并不是必须存在的，也没有特殊的含义，它仅仅起到了占位符的作用。 3.3 对象的访问定位&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;目前主流的对象访问方式有使用句柄 和 直接指针两种方式。 （1）句柄访问&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在Java堆内存中划分一块内存专门用来作为句柄池，JVM桟的局部变量表的reference存储对象的句柄地址，而句柄中保存了对象实例数据与类型数据的具体地址，如下图所示：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;使用句柄方式最大的好处就是reference中存储的是稳定的句柄地址，在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而reference本身不需要被修改。 （2）直接指针访问&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;此时reference直接存储对象在堆中的地址，不再需要句柄池，这样做最大的好处是提高了性能，因为它节省了一次指针定位的时间开销。然而这也是HotSpot VM所选择的对象访问方式。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM—方法区]]></title>
    <url>%2F2020%2F02%2F11%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E2%80%94%E6%96%B9%E6%B3%95%E5%8C%BA%2F</url>
    <content type="text"><![CDATA[1、方法区概述&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;方法区（Method Area）和Java堆内存一样是线程共享的一块内存区域，它被主要用来存储已经被虚拟机加载的类信息（字段、方法、构造器的字节码）、常量、静态变量、JIT编译后的代码等等（说的再简单直白点就是用来存储每个已经记载的类的结构信息）。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;然而方法区只是JVM规范中定义的一个概念，在具体的虚拟机产品中对于方法区有不同的实现，以Java目前商用最广泛的HotSpot虚拟机来说，在JDK1.7及以前方法区的实现叫做永久代（Permenent Generation），在JDK1.8以后又变成了元空间（Metaspace）。他们其实是一个东西，只不过是不同版本下的不同实现而已。 图1 方法区 2、方法区中存储内容概述2.1 类信息存储 JVM 中类的类型信息，对每一个加载的类型， JVM 必须在方法区中存储以下的类型信息 ● 这个类型的全限定名；● 这个类型直接父类的全限定名（除非这个类型是 interface 或者是java.lang.Object，这两种情况下都没有父类）；● 这个类型的修饰符（public，abstract，final的某个子集）；类型名称在java类文件和jvm中都以完整有效名出现。在java源代码中，完整有效名由类的所属包名称加一个”.”，再加上类名 组成。例如，类Object的所属包为java.lang，那它的完整名称为java.lang.Object，但在类文件里，所有的”.”都被 斜杠“/”代替，就成为java/lang/Object。完整有效名在方法区中的表示根据不同的实现而不同。 2.2 域（属性）信息（程序中的一个范围）JVM必须在方法区中保存类的所有属性的相关信息以及属性的声明顺序 ,具体需要保持的相关信息包括： ● 属性名；● 属性类型；● 属性修饰符(public, private, protected,static,final volatile,transient的某个子集) 2.3 方法信息JVM必须保存所有方法的如下信息，同样和属性信息一样也要保存方法声明顺序，方法的相关信息 ● 方法名；● 方法的返回类型(或 void)；● 方法参数的数量和类型(有序的)；● 方法的修饰符(public, private, protected, static, final, synchronized, native, abstract的一个子集)除了abstract和native方法外，其他方法还有保存方法的字节码(bytecodes)操作数栈和方法栈帧的局部变量区的大小。 2.4 类变量● 类变量被类的所有实例共享并且在内存中只有一份，即使没有类实例时你也可以访问它。这些变量只与类相关，所以在方法区中，它们成为类数据在逻辑上的一部分。在JVM使用一个类之前，它必须在方法区中为每个non-final类变量分配空间（在类加载的准阶段）。●常量(被final修饰的类变量)的处理方法则不同，每个常量都会在常量池中有一个拷贝。non-final类变量被存储在声明它的类信息内。 注意 ！ ● java类中的成员变量有静态和非静态，静态成员变量是共享数据，在共享区，也叫方法区中；● 非静态成员变量在堆内存中，作用于每个实例（在堆上创建对象时即给其分配区域）● 局部变量在栈内存内，Java虚拟机栈为每一个被调用方法都分配一个栈帧，用于存放方法中的局部变量，对象的引用类型都会在此分配内存，引用指向的对象是在堆上。 2.5 运行时常量池 （Runtime Constant Pool）&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;运行时常量池（Runtime Constant Pool）是方法区的一部分。.class字节码文件中除了有类的版本、字段、方法、接口等描述类的信息外，还有一项信息是*常量池（Constant Pool Table），用于存放编译器生成的各种字面量（文本字符串、声明为final的常量值等）和 符号引用**（类和接口的全限定名、字段的名称和描述符、方法的名称和描述符），这部分内容将在类加载后进入方法区的运行时常量池中存放。 图2 使用javap命令查看字节码中的常量池 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;运行时常量池相对于常量池的一个重要特征是具有动态性。这是什么意思呢，就是当你的java源文件文件一旦编译形成class文件后，你的常量池就确定了，而**运行时常量池在运行期间也可能有新的常量放入池中**（如String类的intern（）方法）。 3、方法区的OOM3.1 永久代的OOM和元空间的OOM&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;由于方法区只是JVM规范中的一个概念，具体的实现在不同的虚拟机上有很多不同，即使是同一个虚拟机的不同版本对于方法区的实现也会有许多差异，接下来我们就以HotSpot为例来演示一下方法区的OOM（OutOfMemoryError）。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;JDK 7及以前在HotSpot虚拟机中方法区的具体实现是永久代，此时的永久代真实划分的内存还是在运行时数据内的，当空间不够时将抛出错误java.lang.OutOfMemoryError:PermGen space;JDK8及以后方法区的具体实现变成了元空间，元空间的真实内存划分是在物理内存（Native Memory）上的，解决了JDK 7以前方法区容易发生OOM的问题，但是这并不代表元空间就不会发生OOM了，极端情况下当物理内存满了还是会导致抛出错误java.lang.OutOfMemoryError:Metaspace。 3.2 对方法区内存大小的调节JVM参数依然是先看管方文档，设置永久代或元空间大小的JVM参数如下： 图3.1 永久代内存大小调节参数 ● **-XX:MaxPermSize=size**是用来设置永久代最大内存的，当超出这个内存限制将会抛出`java.lang.OutOfMemoryError:PermGen space`。 ● **-XX:PermSize=size**是用来设置永久代触发垃圾回收的最小内存的。 **注意**！这些参数只有在JDK8以前的Java版本中有用。 图3.2 元空间内存大小调节参数 ● **-XX:MaxMetaspaceSize=size**是用来设置元空间最大内存大小的，从官网的说明可以看到，这片区域默认是没有大小限制的，当设置了大小并且使用超过了限制或者没有设置大小使用导致物理内存被占满都将会抛出`java.lang.OutOfMemoryError:Metaspace`。 ● **-XX:MetaspaceSize=size**是用来设置元空间触发垃圾回收的最小内存的。 **注意**！这些参数只有在JDK8及以后的Java版本中有用。 3.3 方法区OOM再现分别在JDK6和JDK8环境下运行下面使用CGLib实现的一个代理操作： 12345678910111213141516171819202122232425262728293031323334package top.easyblog;import net.sf.cglib.proxy.Enhancer;import net.sf.cglib.proxy.MethodInterceptor;import net.sf.cglib.proxy.MethodProxy;import java.lang.reflect.Method;/** * @author ：huangxin * @modified By： * @Description：TODO * @since ：2020/02/16 00:20 */public class MethodAreaOOMTest &#123; public static void main(String[] args) &#123; while(true)&#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(OOMObject.class); enhancer.setUseCache(false); enhancer.setCallback(new MethodInterceptor() &#123; @Override public Object intercept(Object obj, Method method, Object[] args, MethodProxy proxy) throws Throwable &#123; return proxy.invokeSuper(obj, args); &#125; &#125;); enhancer.create(); &#125; &#125; static class OOMObject &#123; &#125;&#125; 导入代码后还需要导入CGLib的依赖： 12345&lt;dependency&gt; &lt;groupId&gt;cglib&lt;/groupId&gt; &lt;artifactId&gt;cglib&lt;/artifactId&gt; &lt;version&gt;3.1&lt;/version&gt;&lt;/dependency&gt; 在JDK8环境下运行上面的代码，发生如下图所示报错： 在JDK6环境下运行上面代码，发生如下图所示报错： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于这个例子值得特别注意的是，我们在这个例子中模拟的场景并非纯粹是一个实验，这样的应用经常会出现在实际应用中：当前的很多主流框架，如 Spring 和 Hibernate 对类进行增强时，都会使用到 CGLib 这类字节码技术，增强的类越多，就需要越大的方法区来保证动态生成的 Class 可以加载入内存，此时就需要我们根据实际情况通过JVM参数调节方法区空间的大小从而解决问题了。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM—字符串常量池StringTable]]></title>
    <url>%2F2020%2F02%2F11%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E2%80%94%E5%AD%97%E7%AC%A6%E4%B8%B2%E5%B8%B8%E9%87%8F%E6%B1%A0StringTable%2F</url>
    <content type="text"><![CDATA[深入理解JVM—字符串常量池StringTable&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先我们来看一道关于字符串的面试题，请大家先不要直接上机运行，自己先在脑子里运行一下这段程序，如果你可以很清晰的得到所有输出，那么恭喜你！这篇文章你就不要在浪费时间再看了；如果你在某一步还有不清楚的，那么这篇文章将会一网打尽所有你对String常量池的疑虑。 123456789101112131415161718192021222324252627282930313233343536package top.easyblog;/** * 字符串常量池测试 * * @author ：huangxin * @modified By： * @since ：2020/02/16 15:57 */public class StringTableTest &#123; public static void main(String[] args) &#123; String s1="a"; String s2="b"; String s3="a"+"b"; String s4=s1+s2; String s5=new String("ab"); String s6="ab"; String s7=s4.intern(); //问： System.out.println(s3==s4); System.out.println(s3==s5); System.out.println(s3==s6); System.out.println(s3==s7); String str1=new String("c")+new String("d"); String str2="cd"; str1.intern(); String str3=str1.intern(); //问： System.out.println(str2==str1); System.out.println(str2==str3); &#125;&#125; 运行结果： 1、StringTable概述&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;StringTable又可以称为StringPool，字符串常量池，在JDK1.7以前字符串常量池是方法区中的运行时常量池的一部分，JDK1.7及以后JVM为了提高性能和减少对方法区内存的开销把字符串常量池被移到了堆内存中。字符串常量池的作用大致是：每当我们创建字符串的时候，JVM首先会检查字符串常量池，如果该字符串已经存在于字符串常量池中，那么就直接返回它在常量池中的直接引用；否则，就会实例化该字符串并且将其放到常量池中，由于String字符串的不可变性我们可以十分肯定常量池中一定不存在两个相同的字符串。 2、StringTable的特性概述 字面量字符串会在编译阶段直接添加到常量池中 常量池中的字符创建仅仅是符号，只有在第一次用到的时候才会创建对象（字符串的延迟加载性） 利用串池的机制，可以避免字符串的重复创建 字符串变量的拼接原理是通过StringBuilder实现的（JDK1.8） 字符串常量的拼接原理是编译阶段的优化 可以使用String类的intern()方法，主动将串池中还没有的字符串对象放入串池 JDK1.7及以后会将这个字符串对象尝试放入串池，如果串池中有这个字符串则不会放入，如果没有就放入，最后会返回串池中对象的直接引用。 JDK1.7以前会将这个字符串对象尝试放入串池，如果串池中有这个字符串则不会放入，如果没有则把此对象复制一份再放入串池，最后会返回串池中对象的直接引用 3、String在JVM中的解析(JDK1.7+)3.1 字符串的两种创建方式在Java中我们创建字符串的方式一般有两种形式：直接字面量 和 new String()创建对象,例如： 12String str1="abc"; //字面量创建String str2=new String("abc"); //new 对象形式创建 这两行代码在内存解析的过程如下图： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从图中可以看出，str1使用字面量创建字符串，在编译期的时候就对常量池进行判断是否存在该字符串，如果存在则不创建直接返回对象的引用；如果不存在，则先在常量池中创建该字符串实例再返回实例的引用给str1。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;再来看看str2，str2使用关键词new创建字符串，JVM会首先检查字符串常量池，如果该字符串已经存在常量池中，那么就不再在字符串常量池创建该字符串对象，而直接堆中复制该对象的副本，然后将堆中对象的地址赋值给引用str2；如果字符串不存在常量池中，就会实例化该字符串并且将其放到常量池中，然后在堆中复制该对象的副本，然后将堆中对象的地址赋值给引用str2。 3.2 字符串拼接&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;字符拼接也有两种形式：一种全是字面量（常量）拼接，这种拼接方式形成的字符串会在编译期就被优化直接形成目标字符串并存到字符串常量池中；另一种含有变量的字符串拼接，这种拼接方式的底层原理是利用StringBuilder拼接好目标字符串后在转换为新的字符串对象（并不会主动放进字符串常量池中）。 （1）常量拼接：编译阶段就可以确定 例如：String str1=&quot;Hello,&quot;+&quot;java&quot;; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;前面说到过，String字符串的不可变性我们可以十分肯定常量池中一定不存在两个相同的字符串，根据这个特点，在编译阶段javac编译器就会把各个待拼接的常量直接组合为目标字符串并放入字符串常量池中，这一过程同样需要判断是否已经存在该字符串。 （2）变量拼接：编译阶段无法确定，只有在运行后才可以知道结果例如： 123String str1=&quot;hello,&quot;;String str2=&quot;java&quot;; //str1、str2对应的字符串在编译阶段就被放进了字符串常量池找中String str3=str1+str2; // 实质：new StringBuilder().append(&quot;hello,&quot;).append(&quot;java&quot;).toString(); ==&gt; new String(&quot;hello,java&quot;); 上面三行代码在JVM中的解析过程如下图所示： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当使用“+”连接字符串变量时在运行期才能确定的，连接的本质是通过StringBuilder拼接之后再toString()新建一个新的String对象存储在堆中。下面是这三行代码编译后使用javap工具反编译出来的字节码： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;字节码中0~5行的作用就是从常量池中加载字符串常量并将其引用存储在局部变量表中。第6行字节码创建了一个StringBuilder实例，第10行调用了StringBuilder调用了StringBuilder的无参构造器初始化Stringuilder实例，接着13~17行就是从局部变量表中取出刚才存储的两个字符串引用的值调并用StringBuider类的append()方法拼接字符串；最后拼接完成后调用了StringBuilder的toString()方法产生了一个新的String对象存储到堆中，之后在局部变量表中str3指向了堆中这个String对象的地址（24行的astore_3这条指令）。 （3）更一般的字符串拼接—常量和变量混合拼接将（2）中的例子改为如下 123String str1="hello,";String str2="java"; String str3="1"+"23"+str1+"4"+"5"+str2; 直接看编译后的字节码： 通过字节码和（2）的规律我们不难得到内存模型如下： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;其本质和（1）（2）还是一样的，只要是常量，在编译期间就会确定下来并被加入常量池中，而且这里还遵循贪心原则，就是编译器会尽可能多的把可以确定下来的常量构成一个新串加入到字符串常量池中，之后对于变量就只能在运行的时候处理了，拼接的时候还是需要借助StringBuilder的append()方法；并且最后依然只会返回在堆中字符串对象的地址。 3.3 String.intern()方法解析intern()方法在JDK1.7以前和JDK1.7及以后的实现略微有所差别：● JDK1.7以前会将这个字符串对象尝试放入串池，如果串池中有这个字符串则不会放入，如果没有则把此对象复制一份再放入串池，最后会返回串池中对象的直接引用。● JDK1.7及以后会将这个字符串对象尝试放入串池，如果串池中有这个字符串则不会放入，如果没有就存储堆中这个字符串的引用，也就是字符串常量池中存储的是指向堆里的对象，最后还是会返回字符串常量池中该字符串的直接引用。 验证下面我们看一个案例： 123456public class StringTest &#123; public static void main(String[] args) &#123; String s3 = new String("ab") + new String("c"); System.out.println(s3 == s3.intern());&#125; JDK6的执行结果为：falseJDK7和JDK8的执行结果为：true JDK6-的内存模型如下： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们都知道JDK6中的常量池是放在永久代（方法区）的，永久代和Java堆是两个完全分开的区域。当调用str1.intern()后，JVM首先会检查字符串常量池中是否存在该字符串，如果没有就把该字符串复制一份然后添加到字符串常量池中，最后返回指向该常量的引用。如果之后str2在调用intern()方法，那么就会直接返回常量池中“abc”的引用。因此上面代码s3和s3.intern不相等的原因就是因为它们两个任然不是同一个对象。 JDK7/8+的内存模型如下： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;JDK7/8+中，字符串常量池已经被转移至Java堆中，开发人员也对intern 方法做了一些修改。因为字符串常量池和new的对象都存于Java堆中，为了优化性能和减少内存开销，当调用 intern 方法时，如果常量池中已经存在该字符串，则返回池中字符串；否则直接存储堆中的引用，也就是字符串常量池中存储的是指向堆里的对象。所以结果为true。 4、StringTable 垃圾回收&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;字符串常量池是有垃圾回收的，无论是在JDK1.6以前还是在JDK1.7以后对于字符串常量池都是由垃圾回收机制的。接下来我们就在JDK1.8环境下通过一段代码验证一下StringTable的垃圾回收。 12345678910111213141516171819202122232425package top.easyblog;/** * StringTable GC测试 * VM Options:-Xmx10m -XX:+PrintStringTableStatistics -XX:+PrintGCDetails -verbose:gc（打印垃圾回收详细信息） * * @author ：huangxin * @modified ： * @since ：2020/02/17 15:05 */public class StringTableGCTest &#123; public static void main(String[] args) &#123; int i=0; try&#123; &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; System.out.println(i); &#125; &#125;&#125; 运行后我们来看看控制台打印信息 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;我们看到没有发生GC，并且当前键值的数量是1773个。之后我们往常量池中不断添加字符串，主要就观察有没有发生`GC`以及`StringTable statistics`就好了 123456789101112131415161718192021222324252627package top.easyblog;/** * StringTable GC测试 * VM Options:-Xmx10m -XX:+PrintStringTableStatistics -XX:+PrintGCDetails -verbose:gc（打印垃圾回收详细信息） * * @author ：huangxin * @modified ： * @since ：2020/02/17 15:05 */public class StringTableGCTest &#123; public static void main(String[] args) &#123; int i=0; try&#123; for(int j=0;j&lt;100000;j++)&#123; String.valueOf(j).intern(); i++; &#125; &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; System.out.println(i); &#125; &#125;&#125; 运行后我们再来看看控制台打印信息 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;这一次我们看到总共进行了3次GC，并且打印的当前字符串常量池的键值对数量远远小于添加的字符串数量10,0000个，说明对字符串常量池进行了垃圾回收。 5、StringTable性能调优5.1 调节-XX:StringTableSize=size&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;StringTable的底层数据结构是hash表，hash表的基本组成就是数组和链表，hash表中的每个数组单元我们叫做桶（bucket），桶的数量越多，hash冲突的几率就越低，但同时耗费的空间就越多。因此对于StringTable的性能调优额基本原理就是在减少hash碰撞（调整StringTable桶的个数）以及和内存消耗之间找到系统运行的平衡点。下面以一个例子来说明： 1234567891011121314151617181920212223242526272829303132package top.easyblog;import java.io.*;/** * StringTable调优 * VM Options:-XX:StringTableSize=size（设置StringTable桶的个数） -XX:+PrintStringTableStatistics * @author ：huangxin * @modified ： * @since ：2020/02/17 16:33 */public class StringTableOptimize &#123; public static void main(String[] args) &#123; try(BufferedReader reader=new BufferedReader(new InputStreamReader(new FileInputStream(new File("d://dictionary.txt")))) ) &#123; String line=null; long start=System.nanoTime(); while (true)&#123; line=reader.readLine(); if(line==null)&#123; break; &#125; line.intern(); &#125; System.out.println("cost:"+(System.nanoTime()-start)/1000000+"ms"); &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125;&#125; 在使用默认值的情况下上面的代码的运行结果如下： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通过上图可以看到使用JVM默认对StringTable设置的桶的个数（60013）时，执行向字符串常量池中添加40万条字符串花费了442ms，接下来我尝试把StringTable的桶的个数调大了些（200000），运行结果如下： &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;运行结果和我的预期相符合，执行同样的代码花费的时间减少了约0.1s，并且多次运行的数值都是在这个值附近，说明增加StringTable桶的个数对那种系统中有大量字符串时的性能提高是有帮助的。为了进一步验证，我又把StringTable桶的个数调节的很小（2000）,运行结果（如下图）再次验证了通过调节StringTable桶的个数是有助于当系统中有大量字符串时的性能提升的。 5.2 使用intern()方法当系统中需要处理大量字符串并且这些字符串可能会存在重复的问题，那么这时可以使用intern()方法将这些字符串添加到常量池中，以减少对堆内存的消耗。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM—运行时数据区之程序计数器]]></title>
    <url>%2F2020%2F02%2F11%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E2%80%94%E8%BF%90%E8%A1%8C%E6%97%B6%E6%95%B0%E6%8D%AE%E5%8C%BA%E4%B9%8B%E7%A8%8B%E5%BA%8F%E8%AE%A1%E6%95%B0%E5%99%A8%2F</url>
    <content type="text"><![CDATA[1、JVM内存模型概述Java虚拟机（JVM）在Java程序运行的过程中，会将它所管理的内存划分为若干个不同的数据区域，这些区域有的随着JVM的启动而创建，有的随着用户线程的启动和结束而建立和销毁。一个基本的JVM运行时内存模型如下所示： 图 1 JVM运行时数据区 上图是展示JDK8及以后的虚拟机规范对JVM运行时内存的划分。在JVM的运行时数据区中Java虚拟机桟、本地方法桟和程序计数器是每个线程私有的，同时堆区和方法区（即图中展示的元数据区和代码缓存）是线程共享的内存。也就是说堆和方法区在一个JVM中各自只有一份，它们是随着JVM的启动而创建的，但是Java虚拟机桟、本地方法桟和程序计数器是线程私有的，每个线程一份，多个线程就可以随线程的启动创建多份，它们的关系可以用下面的图来表示： 图 2 JVM运行时数据区 2、程序计数器（PC）2.1 什么是程序计数器 程序计数器（Program Counter Register）是一块较小的内存空间，它可以看做是当前线程所执行的字节码的行号指示器。在虚拟机的概念模型里（仅是概念模型，各种虚拟机可能会通过一些更高效的方式去实现），字节码解释器工作时就是通过改变这个计数器的值来选取下一条需要执行的字节码指令，分支、循环、跳转、异常处理、线程恢复等基础功能都需要依赖这个计数器来完成。&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;—— 摘自《深入理解JAVA虚拟机》 2.2 程序计数器的特点 1）线程私有，随着线程的启动而创建，并且随着线程的销毁而销毁（即生命周期和线程的生命周期一样）。2）执行Java方法时，程序计数器是有值的，且记录的是正在执行的字节码指令的地址;当执行Native方法的时候。计数器的值为空（Undefined）。3）程序计数器内存区域是Java虚拟机规范中唯一没有规定OOM（OutOfMemoryError）的区域。 2.3 关于程序计数器的几个常见问题（1）使用PC存储字节码指令地址有什么用呢/为什么要使用PC来记录当前线程的执行地址呢？因为Java 虚拟机的多线程是通过切换线程并分配处理器执行时间的方式来实现的，在任何一个确定的时间，一个处理器（对于多核处理器来说是一个内核）都只会执行一条线程中的指令，因此当CPU不停的切换各个线程，下次切换回来后就需要知道接着从哪个地方开始继续执行。使用PC就可以记录下切换前的下一条字节码指令的地址，下次切换回来后直接跳转到PC所记录的地址接着执行即可。 （2）PC为什么要设定成为线程私有的？在Java的多线程环境下，多个线程如果像共享堆内存一样共享一个PC寄存器，那么前一个线程刚保存的下一条字节码指令地址数据就会被下一个线程覆盖，最终还是和没有使用PC是一样的效果。因此为了能够精确的记录各个线程正在执行的当前字节码指令地址，最好的办法自然是为每一个线程分配一个PC寄存器，毕竟PC的体积也很小。 （3）为什么执行Native方法的时候PC的值是Undefined？因为native方法是Java通过JNI直接调用本地C/C++库（可以近似的认为native方法相当于C/C++暴露给Java的一个接口，Java通过调用这个接口从而调用到C/C++方法），由于该方法是通过C/C++而不是Java进行实现。那么自然无法产生相应的字节码，并且C/C++执行时的内存分配是由C/C++语言决定的，而不是由JVM决定的。 （4）为什么PC不会产生OOM?程序计数器保存的是当前执行的字节码的偏移地址（也就是之前说的行号，其实那不是行号，是指令的偏移地址，只是为了好理解，才说是行号的），当执行到下一条指令的时候，改变的只是程序计数器中保存的地址，并不需要申请新的内存来保存新的指令地址；因此，永远都不可能内存溢出的。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM—Java虚拟机桟]]></title>
    <url>%2F2020%2F02%2F11%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E2%80%94Java%E8%99%9A%E6%8B%9F%E6%9C%BA%E6%A1%9F%2F</url>
    <content type="text"><![CDATA[1、虚拟机桟概述由于跨平台性的设计，JVM的指令架构是基于桟的结构来设计的，这么做的优点：一是具有了跨平台性，其次使得指令集更小，编译器更容易实现，但缺点也很明显：实现同样的功能需要更多的指令和性能下降。栈是运行时的单位，堆是存储的单位 栈解决的程序运行问题，即程序如何执行，或者说如何处理数据；堆解决的是数据存储问题，即就是数据如何放、放哪儿 在java中一个线程就会相应有一个线程栈与之对应，因为不同的线程执行逻辑有所不同，因此需要一个独立的线程栈。堆是所有线程共享的。栈因为是运行单位。因此里面存储的是和当前线程相关的数据。包括局部变量、程序运行状态、方法返回值等；而堆只负责存储对象信息。 堆中存什么，栈中存什么？ 堆中存的是对象，栈中存的是基本数据类型和堆中对象的引用，一个对象的大小不可以估计，或者说是可以动态变化的，但是在栈中，一个对象只对应了一个4byte引用 对象，从某种意义上说，是由基本类型组成的。可以把一个对象看作为一棵树，对象的属性如果还是对象，则还是一颗树（即非叶子节点），基本类型则为树的叶子节点。程序参数传递时，被传递的值本身都是不能进行修改的，但是，如果这个值是一个非叶子节点（即一个对象引用），则可以修改这个节点下面的所有内容。堆和栈中，栈是程序运行最根本的东西。程序运行可以没有堆，但是不能没有栈。而堆是为栈进行数据存储服务，说白了堆就是一块共享的内存。不过，正是因为堆和栈的分离的思想，才使得Java的垃圾回收成为可能。 1.1 Java虚拟机桟（Java Virtual Machine Stacks）的特点（1） 桟内存线程私有的，它的生命周期与线程相同（即随着线程的创建而创建，随着线程的销毁而销毁）（2）虚拟机桟描述的是Java方法执行的内存模型：每个方法在执行的同时都会创建一个 桟帧 用于存储 局部变量（Local Variables）、操作数桟（Operand Stack）、动态链接（Dynamic Linking）、方法返回地址（Return Address） 等信息。新创建的桟帧会被保存到Java虚拟机栈的栈顶，方法执行完毕后自动将此桟帧出栈。一般我们把虚拟机桟栈顶的桟帧称作当前方法。 图1.1 Java虚拟机桟栈帧（3）虚拟机桟没有GC，但是Java虚拟机规范中，对此区域定义了 两种异常情况 ： 如果线程请求的桟深度大于虚拟机允许的深度，将抛出StackOverflowError异常如果虚拟机的实现中允许虚拟机桟动态扩展，当需要扩展但是内存不够的时候将会抛出OutOfMemoryError异常 1.2 Java虚拟机桟相关参数调优首先学习JVM调优我们还是应该主要参考官方文档 。打开官方文档后选择Main Tools to Create and Build Applications=&gt;java，之后在页面使用快捷键Ctrl+F搜索-Xss就可以看到关于参数-Xss的说明和用法。 图1.2.1 Java虚拟机桟调优参数-Xss 根据官网的说明，**-Xss就是用来设置线程桟（虚拟机桟）的大小的**。在参数后面加上k/K表示KB，m/M表示MB，g/G表示GB。并且还说明了不同平台上的虚拟机桟默认的大小 ，Linux、macOS、Oracle Solaris是1024KB，Windows上默认值受虚拟内存的影响。 示例：写一个简单的测试代码验证一下这个-Xss参数对Java虚拟机桟的调节效果，测试代码如下： 123456789101112131415package top.easyblog;/** * @author HuangXin * @since 2020/2/12 19:24 */public class JVMStackErrorTest &#123; private static int count=0; public static void main(String[] args) &#123; System.out.println(count++); main(args); &#125;&#125; 在没有设置桟大小使用默认值时，在我电脑上发生StackOverflowError异常时打印的count值为9544 图1.2.2 调参之前报错信息 **在IDEA中设置虚拟机桟的大小** 具体操作看图中的演示： 图1.2.3 选择Run-->Edit Configurations... 图1.2.4 设置VM options参数为-Xss256m 设置好后再次运行刚刚的程序，发现过了好久才报StackOverflowError异常，而且最后打印的count值为3893229，截图如下： 图1.2.5 调参之后报错信息 2、Java虚拟机桟的存储单位2.1 Java虚拟机桟桟中存储的什么？ 每个线程都有自己的桟，Java虚拟机桟都是以桟帧（Stack Frame）为基本单位存在。 一个线程上每个被调用的方法都有一个桟帧。 桟帧是一个内存区块，是一个数据集，维护着方法执行过程中的各种数据信息。 2.2 Java虚拟机桟的运行原理 不同线程中所包含的桟帧是不允许存在相互引用的，即不可能在一个线程的某个桟帧中引用另外一个线程中某个桟帧。（线程可以共享同一个进程中的共享数据，但是线程内的数据无法共享） 如果当方法调用了其他方法，方法返回之际，当前桟帧会传回此方法的执行结果给前一个桟帧，接着JVM会丢弃当前桟帧，使得前一个桟帧重新成为当前桟帧。 Java的方法有两种返回方式：一种是方法正常执行结束返回，使用return命令;另一种是抛出异常，没有捕获导致虚拟机挂掉。两种返回方式都会导致桟帧被弹出。 2.3 桟帧的内部结构详解每个桟帧的结构包括：局部变量表（Loval Variables）、操作数桟（Operand Stack）、 动态链接（Dynamic Linking）、 方法返回地址（Return Address） 和一些其他的 一些附加信息 图2.3.1 JVM桟帧结构 ###### 2.3.1 局部变量表（Loval Variables） 1、局部变量表也被称为局部变量数组或本地变量表。 2、局部变量表本质是一个数组，主要用于存储方法参数和定义在方法体内的局部变量的值，可以存放的数据类型有boolean、byte、char、short、int、float、long、double、对象引用（reference）和returnAddress类型。（基本数据类型存储的是数值，引用类型存储的是引用） 图2.3.2 局部变量表存储结构 3、局部变量表中32位以内的类型只占用一个Slot（包括returnAddress），64位的类型（long和double）占用两个Slot。byte、short、char在存储的时候会被转换为int，boolean也会被转换为int，0 表示 false，非0 表示true 4、由于局部变量表是建立在线程的桟帧上的，是线程私有的，因此不存在线程安全问题。 5、局部变量表所需要的容量大小是在编译期间就可以确定下来的，并保存在方法的Code属性的locals数据项中，并且在方法运行期间是不会改变局部变量表的大小的。 图2.3.3 局部变量表大小 6、在固定的虚拟机桟内存大小下，可以调用的方法的个数取决于桟帧的大小。对于一个方法而言，它的参数和局部变量越多，使得局部变量表膨胀，它的桟帧也会变大，以满足方法调用所需传递的信息增大的需求。 7、局部变量表中的变量只有在当前方法调用中才有效，当方法调用结束后随着方法桟帧的销毁而销毁。 8、JVM会为局部变量表中的每个Slot都分配一个访问索引，通过这个索引即可成功访问到局部变量表中指定的局部变量表的值。 图2.3.4 局部变量表分析 9、如果需要访问局部变量表中的一个64bit局部变量值时，使用的时候只需要使用其起始Slot索引即可。 10、如果当前桟帧是由构造方法或者实例方法创建的，那么方法所属对象引用this将会作为局部变量放在局部变量表的index=0的Slot处，其余变量从Slot的index=1开始按定义的顺序存储。 图2.3.5 实例方法的第一个Slot存放的一定是this引用 11、为了节约桟帧的空间，局部变量表的Slot是可以重复利用的。 图2.3.6 局部变量表的Slot可以复用 2.3.2 操作数桟（Operand Stack） 操作数桟就是JVM执行引擎的一个工作区，本质是一个由数组构成的桟，当一个方法开始执行的时候，一个新的操作数桟就会被创建。操作数桟初始是空的，主要用于保存计算过程的中间结果，同时作为计算过程变量的临时存储空间。 每一个操作数桟所需要的最大桟深度会在编译器就确定下来了，这个值保存在方法Code属性的max_stack选项中。 桟中的任何一个元素可以是任意Java类型。32位的类型占用一个桟单位深度，64位的类型占用两个桟单位深度 操作数桟并非采用访问索引的方式来进行数据访问，而是只能通过入栈和出栈操作完成一次数据访问。 基本执行逻辑主要是对变量值的入栈、出栈、运算、入栈… 例如将两个int类型的局部变量相加再将结果保存至第三个局部变量： 12345 public void test1()&#123; int i=10; int j=20; int k=i+j;&#125; 使用JDK自带的javap反汇编器，可以查看java编译器为我们生成的字节码。通过它，我们可以对照源代码和字节码，从而了解很多编译器内部的工作。反汇编得到上面方法的字节码如下： 12345678910111213141516171819202122232425262728public void test1(); descriptor: ()V flags: ACC_PUBLIC Code: //stack表示操作数桟最大深度，locals表示局部变量表的大小 stack=2, locals=4, args_size=1 0: bipush 10 //将常量10将加载到操作数桟 2: istore_1 //将操作数桟中的10存储到局部变量表的索引为1的位置（因为这个方法是实例方法，所以局部变量表的索引为0的Slot存储的是当前对象的引用this） 3: bipush 20 //将常量10将加载到操作数桟 5: istore_2 //将操作数桟中的20存储到局部变量表的索引为2的位置 6: iload_1 //取出局部变量表中索引位置为1的数值放到操作数桟的栈顶 7: iload_2 //取出局部变量表中索引位置为2的数值放到操作数桟的栈顶 8: iadd //最顶部的两个数出栈有执行引擎翻译iadd指令为机器指令后交给CPU进行求和运算 9: istore_3 //将计算的结果放到局部变量表索引为3的Slot中 10: return //方法执行结束，返回。 LineNumberTable: //源代码行号和字节码地址的对应关系（源代码行号：字节码地址） line 12: 0 line 13: 3 line 14: 6 line 15: 10 LocalVariableTable: //局部变量表 字节码起始地址 索引 变量 变量的数据类型 Start Length Slot Name Signature 0 11 0 this Ltop/easyblog/OperandStackTest; 3 8 1 i I 6 5 2 j I 10 1 3 k I&#125; 操作数栈中元素的类型必须与字节码指令的序列严格匹配，例如上面的iadd操作时，不能出现iadd操作需要的值第一个为long 第二个为 float 的情况。 2.3.3 动态链接（Dynamic Linking）在Java源文件被编译到直接码文件时，所有的变量和方法引用都作为符号引用保存在class文件的常量池。而我们都知道每一个桟帧内部包含一个结构—动态链接，它就是指向运行时常量池中该桟帧所属方法的引用。每个桟帧持有一个引用就是为了将符号引用转换为调用方法的直接引用。 可以用下面的图形象的解释： 图2.3.7 动态链接图解 ###### 2.3.4 方法返回地址（Return Address） &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;当一个方法开始执行后，只有两种方式可以退出这个方法：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;第一种方式是执行引擎遇到方法返回的字节码指令，这时候可能会有返回值传递给上层的方法调用者（调用当前方法的方法称为调用者），是否有返回值和返回值的类型将根据遇到何种方法返回指令来决定，这种退出方法的方式称为正常完成出口（Normal Method InvocationCompletion）。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;另外一种退出方式是，在方法执行过程中遇到了异常，并且这个异常没有在方法体内得到处理，无论是Java虚拟机内部产生的异常，还是代码中使用athrow字节码指令产生的异常，只要在本方法的异常表中没有搜索到匹配的异常处理器，就会导致方法退出，这种退出方法的方式称为异常完成出口（Abrupt Method Invocation Completion）。一个方法使用异常完成出口的方式退出，是不会给它的上层调用者产生任何返回值的。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;无论采用何种退出方式，在方法退出之后，都需要返回到方法被调用的位置，程序才能继续执行，方法返回时可能需要在栈帧中保存一些信息，用来帮助恢复它的上层方法的执行状态。一般来说，方法正常退出时，调用者的PC计数器的值可以作为方法返回地址，栈帧中很可能会保存这个计数器值。而方法异常退出时，返回地址是要通过异常表来确定的，栈帧中一般不会保存这部分信息。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;方法退出的过程实际上就等同于把当前栈帧出栈，因此退出时可能执行的操作有：恢复上层方法的局部变量表和操作数栈，把返回值（如果有的话）压入调用者栈帧的操作数栈中，调整PC计数器的值以指向方法调用指令后面的一条指令等。 3、方法调用3.1 虚方法和非虚方法&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;首先应该明确的是方法的调用不等于方法的执行，方法的调用阶段唯一的任务就是确定被调用的方法的版本，暂时还没有涉及到方法内部的具体运行过程。通过JVM类加载有关内容的学习，我们知道了在类加载的解析阶段会将class文件中的一部分符号引用转化为直接引用，可以这样做的前提是方法在编译的时候就能确定下来。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在Java中符合“编译期可知，运行期不可变”的方法我们称作非虚方法，主要包括静态方法、私有方法、构造方法、父类方法以及被final修饰的方法。除此而外的方法都叫虚方法。与之对应的，在JVM规范中提供了5个有关方法调用的字节码指令，具体如下： invokestatic：调用静态方法，解析阶段可以确定唯一版本 invokespecial：调用实例构造器&lt;init&gt;方法，私有方法和父类方法，也是解析阶段可以确定唯一版本 invokevirtual ：调用虚方法和final修饰的方法（但是final修饰的方法不是虚方法） invokeinterface：调用接口方法 invokedynamic：动态解析出需要调用的方法，然后执行 invokestatic、invokespecial、invokevirtual、invokeinterface这4条方法调用字节码指令是伴随着Sun的第一款Java虚拟机问世以来就有的，直到JDK7才新增了invokedynamic指令，这条新增的指令是Java实现“动态类型语言”支持的改进之一，也就是为JDK8的Lamba表达式技术而准备的。它与前面4个指令的最大的区别是由前面4个指令调用的方法分派逻辑是固化到JVM内部的，而invokedynamic指令调用的方法分派逻辑完全是由程序员来控制的。 3.2 静态分派解析调用的过程一定是静态过程，在编译期间就可以完全确定，在类加载的解析阶段就会把涉及的符号引用全部转换为可以确定的直接引用。而分派调用则可分为静态分派和动态分派，具体的有静态单分派、静态多分派、动态单分派、动态多分派这4种组合。下面我们一起来看一下JVM中的方法分派是如何进行的。 首先我们来看一段代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344package top.easyblog.methodinvoke;/** * @author ：huangxin * @modified By： * @Description： 方法静态分派演示 * @since ：2020/02/14 11:33 */public class StaticDispatch &#123; static class Human&#123; &#125; static class Man extends Human&#123; &#125; static class Woman extends Human&#123; &#125; public void sayHello(Human human)&#123; System.out.println("hello,human"); &#125; public void sayHello(Man human)&#123; System.out.println("hello,man"); &#125; public void sayHello(Woman human)&#123; System.out.println("hello,woman"); &#125; public static void main(String[] args) &#123; Human man=new Man(); Human woman=new Woman(); StaticDispatch staticDispatch = new StaticDispatch(); staticDispatch.sayHello(man); staticDispatch.sayHello(woman); &#125;&#125; 运行结果： 结论这段代码对于学过Java的同学应该不难看出运行结果，主要考察的是对重载概念的理解。但你有想过为什么两次都执行了参数类型为Human的重载吗？在说原因之前我们需要知道两个概念：以Human man=new Man();这条语句来说，我们把Human称为静态类型或外观类型，Man我们称为实际类型。静态类型和实际类型在编译的时候都可发生变化，但是静态类型在编译期最终是可知的；而实际类型要在运行后才能确定。因为在编译阶段，javac编译器会根据参数的静态类型决定使用哪个重载版本，所以选择了sayHello(Human)作为调用目标，并把这个方法的符号引用写到main方法的两条invokevirtual指令参数中。所有依赖静态类型来定位方法执行版本的分派动作称为静态分派，静态分派的典型应用就是方法重载。静态分派发生在编译阶段，因此确定静态分派的动作实际上不是由虚拟机执行的。 重载方法的匹配优先级规律首先还是看一段代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package top.easyblog.methodinvoke;import java.io.Serializable;/** * @author ：huangxin * @modified By： * @Description：方法重载优先级匹配测试 * @since ：2020/02/14 15:32 */public class StaticDispatchPriority &#123; public void sayHello(char obj) &#123; System.out.println("char obj"); &#125; public void sayHello(int obj) &#123; System.out.println("int obj"); &#125; public void sayHello(long obj) &#123; System.out.println("long obj"); &#125; public void sayHello(float obj) &#123; System.out.println("float obj"); &#125; public void sayHello(double obj) &#123; System.out.println("double obj"); &#125; public void sayHello(Character obj) &#123; System.out.println("Character obj"); &#125; public void sayHello(Serializable obj) &#123; System.out.println("Serializable obj"); &#125; public void sayHello(Comparable obj) &#123; System.out.println("Comparable obj"); &#125; public void sayHello(char... obj) &#123; System.out.println("char... obj"); &#125; public static void main(String[] args) &#123; new StaticDispatchPriority().sayHello('a'); &#125;&#125; 运行上面这段代码，会打印出char obj，这很好理解，a是一个char类型的数据，自然会寻找参数为char的重载方法，如果注释掉这个方法，那么运行结果又会变成int obj，这是由于a的Unicode值为97，进一步的会依次转型为long-&gt;float-&gt;double。最终把double形参的方法也注释掉后，会打印出Character obj ，发生了自动装箱，a被包装成了封装类型java.lang.Character，继续注释掉Character形参方法后，我们看到编辑器报错了此时匹配上了两个方法：sayHello(Serializable obj)和sayHello(Comparable obj) 为什么会匹配上Serializable 和Comparable 呢？这个不难解释，我们打开Character类一看就知道了，Character实现了Serializable 和Comparable这两个接口 至于会同时匹配上两个实现接口类型的重载方法，那是因为它两的优先级是一样的，这时就需要我们程序员通过强制类型转换显式的指定要调用那个方法了。 最后会匹配变长参数的方法sayHello(char… obj)。因此，从这个案例中我们可以总结出Java中方法重载的优先级匹配规则：优先匹配基本数据类型（char-&gt;int-&gt;long-&gt;float-&gt;double），其次匹配它的包装类型，如果没有包装类型但是有包装类型的父类，那么将在继承关系中从下往上开始搜索，越接近上层的优先级约定，优先级最低的是变长参数重载。 3.3 动态分派3.3.1 Java语言方法重写的本质首先我们还是看一段代码： 123456789101112131415161718192021222324252627282930313233343536373839package top.easyblog.methodinvoke;/** * @author ：huangxin * @modified By： * @Description： 演示动态分配 * @since ：2020/02/14 18:08 */public class DynamicDispatch &#123; static abstract class Human&#123; protected abstract void sayHello(); &#125; static class Man extends Human&#123; @Override protected void sayHello() &#123; System.out.println("man say hello"); &#125; &#125; static class Woman extends Human&#123; @Override protected void sayHello() &#123; System.out.println("woman say hello"); &#125; &#125; public static void main(String[] args) &#123; Human man=new Man(); Human woman=new Woman(); man.sayHello(); woman.sayHello(); man=new Woman(); man.sayHello(); &#125;&#125; 运行结果 ： 运行结果不会出乎人的意料，对于习惯了面向对象思维的Java程序员会觉得这个结果理所当然。但是还是那个问题，为啥会这样？虚拟机是如何知道要调用哪个方法的？我们使用javap命令输出字节码来看看： 图 3.2.1 main方法字节码 0~15行的作用是创建对象、分配空间，并把对象的引用保存在局部变量表中。之后16~21行是事情本质的关键，我们看到字节码中调用方法使用了`invokevirtual`指令，原因就需要从`incokevirtual`指令的多态查找说起： > 1. 找到操作数栈顶的第一个元素所指向的对象的实例类型C > 2. 如果在C类型中找到与常量池中描述符合简单名称都相符的方法，则进行访问权限检查，如果通过就返回这个方法的直接引用，查找结束；如果没有通过，则返回java.lang.IllegalAccessError > 3. 否者，继续按照继承树从下往上对C的各个父类进行第二步的搜索和检查和验证。 > 4. 如果始终没有找到合适方法，就抛出java.lang.AbstractMethodError异常。 所以，由于incokevirtual指令执行的第一步工作就是确定实际类型，所以两次调用中incokevirtual指令都把常量池中的类方法符号引用解析到了不同的直接引用上，而这也就是我们常说的“编译时看左边，运行时看右边”这句话或者Java中方法重写的本质。 3.3.2 虚方法表通过上面的学习我们知道了方法重写的原理，那么由于动态分派是非常频繁的操作，如果在每次动态分派的过程中都要重新在类的方法元数据中搜索合适的目标的话就可能影响到执行效率。因此，为了提高性能，JVM采用了在类的方法区建立一个虚方法表（Virtual Method Table，vtable）与之对应的是在invokeinteface执行的时候也会用到接口方法表（Interface Method Table,itable）,使用虚方法表的索引来代替元数据查找以提高性能。方法表一般会在类加载的链接阶段完成初始化，准备了类的实例变量之后，虚拟机也会把该类的得到表初始化完毕。]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络部分]]></title>
    <url>%2F2020%2F02%2F09%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E9%83%A8%E5%88%86%2F</url>
    <content type="text"><![CDATA[1、OSl七层模型和TCP/IP四层模型 从上到下： 应用层：通过应用进程之间的交互完成特定的网络应用。该层常见的协议有HTTP（80）、HTTPS（443）、DNS、SMTP（电子邮件）….. 运输层：为应用进程之间提供端到端的逻辑通信。各种应用进程之间需要的“可靠或尽力而为”的两类服务，必须靠运输层以复用或分用的方式加载到网络层。 运输层重要的两个协议：TCP和UDP协议 TCP（传输控制协议）——提供面向连接的，可靠的数据传输服务。 UDP（用户数据包协议）——提供无连接的，尽最大努力的数据传输服务（不保证数据的可靠性） 网络层：在 计算机网络中进行通信的两个计算机之间可能会经过很多个数据链路，也可能还要经过很多通信子网。网络层的任务就是选择合适的网间路由和交换结点， 确保数据及时传送。 在发送数据时，网络层把运输层产生的报文段或用户数据报封装成分组和包进行传送。在 TCP/IP 体系结构中，由于网络层使用 IP 协议，因此分组也叫 IP 数据报 ，简称 数据报。 数据链路层： 数据链路层将网络层交下来的 IP 数据报组装成帧，在两个相邻节点间的链路上传送帧 物理层：实现相邻计算机节点之间比特流的透明传送，尽可能屏蔽掉具体传输介质和物理设备的差异 2、TCP三次握手与四次挥手2.1 TCP三次握手 刚开始客户端处于 closed 的状态，服务端处于 listen 状态 第一次握手：客户端将SYN标识置为1，并且随机产生一个初始化序列号 ISN(c)=J然后将数据包发送给服务器，此时客户端进入到SYN_SENT状态，等待服务器回复； 第二次握手：服务器正常收到客户端发来的SYN标志位为1,标识客户端想建立通信连接，于是服务器将SYN和ACK都置为1，并且设置ack=J+1,seq为另外一个随机值k，并将数据包发送给客户端以确认连接请求，之后服务器进入到SYN_RCVD状态； 第三次握手：客户端收到服务器的回复后，先检查ACK是否为1，并且ack是否为J+1，如果正确则将ACK置1，ack置为k+1，并将该数据包发送给服务器，服务器检查ACK是否为1，ack是否为k+1，如果正确则连接建立成功，Client和Server进入ESTABLISHED状态，完成三次握手，随后Client与Server之间可以开始传输数据了 SYN 是 TCP/IP 建立连接时使用的握手信号。在客户机和服务器之间建立正常的 TCP 网络连接时，客户机首先发出一个 SYN 消息，服务器使用 SYN-ACK 应答表示接收到了这个消息，最后客户机再以 ACK(Acknowledgement[汉译：确认字符 ,在数据通信传输中，接收站发给发送站的一种传输控制字符。它表示确认发来的数据已经接受无误。 ]）消息响应。这样在客户机和服务器之间才能建立起可靠的TCP连接，数据才可以在客户机和服务器之间传递。 2.2 为什么需要三次握手？（为什么不是两次或者四次以及更多次？）TCP三次握手的目的就是建立可靠的通信通道，简单点说就是通信双方需要确认自己与对方的发送和接收都是正常的。 第一次握手：客户端什么都确定不了；服务器端可以确定：自己的接收能力正常，以及客户端的发送能力正常 第二次握手：客户端可以确认：自己收发正常，服务器收发正常；服务器可以确认：客户端发送正常，自己接收正常 第三次握手：客户端确认：自己收发正常，对方收发正常；服务器：自己收发正常，对方收发正常。 所以三次握手就可以确定双方收发正常，并且三次缺一不可。 2.3 TCP四次挥手 刚开始双方都处于 establised 状态，假如是客户端先发起关闭请求，则： 第一次挥手：Client发送一个FIN标志，报文中会指定一个序列号，用来关闭客户端到服务器的数据传送。此时客户端处于FIN_WAIT1状态； 第二次挥手：Server收到Client的FIN后，返会确认序号ack为之前接收到的序列号+1，表明已经收到客户端的报文了，此时服务端处于 CLOSE_WAIT2状态。； 第三次挥手：当Server也要断开连接的时候，Server发送FIN标志到Client，且指定一个序列号，用来关闭服务器到客户端的数据传送。此时服务器处于LAST_ACK状态； 第四次挥手：Client收到Server的FIN后，返回确认号ack为接收到的序列号+1，之后客户端进入到TIME_WAIT状态；此时需要过一阵子以确保服务端收到自己的 ACK 报文之后才会进入 *CLOSED *状态 最后服务器收到客户端的ACK标志后，就会关闭此链接，进入到CLOSED状态 为什么Client最后需要等待服务器接收到自己发送的ACK消息后才进入到CLOSED状态？ 答：客户端要确保服务器接收到了自己返回的ACK报文，如果没有收到的话，服务器会重新发 FIN 报文给客户端，客户端再次收到 FIN 报文之后，就知道之前的 ACK 报文丢失了，然后再次发送 ACK 报文。 状态的含义： LISTEN - 侦听来自远方TCP端口的连接请求； SYN-SENT -在发送连接请求后等待匹配的连接请求； SYN-RECEIVED - 在收到和发送一个连接请求后等待对连接请求的确认； ESTABLISHED- 代表一个打开的连接，数据可以传送给用户； FIN-WAIT-1 - 等待远程TCP的连接中断请求，或先前的连接中断请求的确认； FIN-WAIT-2 - 从远程TCP等待连接中断请求； CLOSE-WAIT - 等待从本地用户发来的连接中断请求； CLOSING -等待远程TCP对连接中断的确认； LAST-ACK - 等待原来发向远程TCP的连接中断请求的确认； TIME-WAIT -等待足够的时间以确保远程TCP接收到连接中断请求的确认； CLOSED - 没有任何连接状态； 2.4 为什么需要四次挥手？​ 根本原因是，一方发送FIN只表示自己发完了所有要发的数据，但还允许对方继续把没发完的数据发过来。 2.5 为什么建立连接是三次握手，但是关闭连接需要四次挥手？（同2.4原理一样）​ 建立连接的时候，服务器处于LISTEN状态，当收到客户端的SYN数据请求建立连接的时候，服务器会把SYN和ACK放在一个报文中恢复给客户端； ​ 关闭连接时，服务器收到客户端的FIN报文后，仅仅表示客户端不在发送数据了，但是还可以接受数据，而自己也未必全部数据都发送给对方了，所以己方可以立即关闭，也可以发送一些数据给对方后，再发送FIN报文给对方来表示同意现在关闭连接，因此，己方ACK和FIN都是分开发送的，从而导致多了一次。 3、TCP和UDP的区别 TCP提供一个面向连接的，可靠的数据传输服务。TCP在传输数据之前，一定会建立一个可靠的连接，数据传输完成后释放连接。TCP 不提供广播或多播服务；TCP是面向字节流的；TCP有拥塞控制机制；TCP首部开销(20个字节)比UDP的首部开销(8个字节)要大； UDP传输数据之前不需要建立连接，UDP是一种不可靠的，“尽力而为”的数据传输服务，远程主机收到消息后不需要给出任何确认，在要求高速通信但是对数据可靠性没有太大要求的时候UDP是很好的选择。 4、TCP如何保证可靠传输？主要有使用校验和、序列号、确认应答进制、超时重传机制、拥塞控制、流量控制和连接管理等方法来保证数据传输的可靠和高效性。 校验和：发送数据之前计算校验和，并填充校验值；接收方按同样的计算方法计算接收到的数据的校验和，并与接收到的校验和比对，TCP 将丢弃这个报文段和不确认收到此报文段； 序列号：TCP在传输的会后将每个字节都进行了编号，这个编号就是序列号； 确认应答机制（ACK报文）：TCP要求在接收到数据后应该对传输方进行确认应答，也就是发送ACK保温，ACK报文中带有确认序列号，告诉发送方格，接收到了那些数据，下一次从哪里开始发送。 超时重传机制：发送方在发送完数据后等待一个时间，时间到达没有接收到ACK报文，那么对刚才发送的数据进行重新发送 拥塞控制：当网络拥塞的时候，减少数据的发送。 拥塞窗口 为了进行拥塞控制，TCP需要维护一个拥塞窗口的状态变量。塞控制窗口的大小取决于网络的拥塞程度，并且动态变化。发送方让自己的发送窗口取为拥塞窗口和接收方的接受窗口中较小的一个。 TCP采用四种算法进行拥塞控制：慢开始、拥塞避免、快重传和快恢复。 慢开始：开始发送数据时，先发送少量的数据探路。探清当前的网络状况，然后在决定以多大的速率传输。 拥塞避免：拥塞避免算法的思路是让拥塞窗口cwnd缓慢增大，即每经过一个往返时间RTT就把发送放的cwnd加1. 快重传和快恢复： 在 TCP/IP 中，快速重传和恢复（fast retransmit and recovery，FRR）是一种拥塞控制算法，它能快速恢复丢失的数据包 流量控制：TCP发送端根据接收端的处理能力，决定发送的速率。 滑动窗口 TCP 利用滑动窗口实现流量控制。流量控制是为了控制发送方发送速率，保证接收方来得及接收。 接收方发送的确认报文中的窗口字段可以用来控制发送方窗口大小，从而影响发送方的发送速率。将窗口字段设置为 0，则发送方不能发送数据。 连接控制：TCP建立连接需要三次握手，关闭连接需要四次挥手。 5、浏览器中输入URL地址到服务器响应发生了哪些事情? 总体来说就是： DNS解析，查找殒域名的IP地址 建立TCP连接 发送HTTP请求 服务器处理请求并返回响应信息 浏览器解析渲染页面 6、HTTP协议详解6.1 HTTP协议的特点 2.http协议默认端口:80 3.简单快速：客户向服务器请求服务时，只需传送请求方法和路径。请求方法常用的有GET、HEAD、POST。每种方法规定了客户与服务器联系的类型不同。由于HTTP协议简单，使得HTTP服务器的程序规模小，因而通信速度很快。 4.HTTP允许传输任意类型的数据对象。正在传输的类型由Content-Type加以标记。 5.无连接：无连接的含义是限制每次连接只处理一个请求。服务器处理完客户的请求，并收到客户的应答后，即断开连接。采用这种方式可以节省传输时间。 6.无状态：HTTP协议是无状态协议。无状态是指协议对于事务处理没有记忆能力。缺少状态意味着如果后续处理需要前面的信息，则它必须重传，这样可能导致每次连接传送的数据量增大。另一方面，在服务器不需要先前信息时它的应答就较快。 6.2 HTTP协议的版本HTTP/1.0,发送请求，创建一次连接，获得一个web资源，连接断开 HTTP/1.1，发送请求，创建一次连接，获得多个web资源，连接断开 6.3 HTTP协议的组成HTTP协议由HTTP请求和HTTP响应组成。 HTTP请求：请求行、请求头和请求体。 HTTP响应：响应行、响应头和响应体。 6.4 HTTP状态码 常见状态码含义： 200 ：服务器成功处理了请求。 204：服务器成功处理了请求，但没有返回任何内容 301：请求的网页已永久移动到新位置。服务器返回此响应（对 GET 或 HEAD 请求的响应）时，会自动将请求者转到新位置 302：服务器目前从不同位置的网页响应请求，但请求者应继续使用原有位置来响应以后的请求 304：自从上次请求后，请求的网页未修改过 400：服务器无法理解请求参数 401：请求要求身份验证。对于登录后请求的网页，服务器可能返回此响应。 403：服务器拒绝请求 404：服务器找不到请求页面 405：服务器不支持请求的使用的方法 500：服务器内部错误，无法完成请求 502：错误网关 503：服务器目前无法使用（由于超载或停机维护）。通常，这只是暂时状态。 6.5 HTTP长连接和短连接在HTTP/1.0中默认使用短连接。也就是说，客户端和服务器每进行一次HTTP操作，就建立一次连接，任务结束就中断连接。当客户端浏览器访问的某个HTML或其他类型的Web页中包含有其他的Web资源（如JavaScript文件、图像文件、CSS文件等），每遇到这样一个Web资源，浏览器就会重新建立一个HTTP会话。 从HTTP/1.1起，默认使用长连接，用以保持连接特性。在使用长连接的情况下，当一个网页打开完成后，客户端和服务器之间用于传输HTTP数据的TCP连接不会关闭，客户端再次访问这个服务器时，会继续使用这一条已经建立的连接。Keep-Alive不会永久保持连接，它有一个保持时间，可以在不同的服务器软件（如Apache）中设定这个时间。实现长连接需要客户端和服务端都支持长连接。 HTTP协议的长连接和短连接，实质上是TCP协议的长连接和短连接。 6.6 HTTP是不保存状态的协议,如何保存用户状态?Http是一种无状态的基于请求响应模型的协议，它无法保存用户的状态。常用的解决方法有： 在服务器端使用Session 在客户端本地使用Cookie Cookie 和 Session都是用来跟踪浏览器用户身份的会话方式，但是两者的应用场景不太一样。 Cookie 一般用来保存用户信息** 比如①我们在 Cookie 中保存已经登录过得用户信息，下次访问网站的时候页面可以自动帮你登录的一些基本信息给填了；②一般的网站都会有保持登录也就是说下次你再访问网站的时候就不需要重新登录了 Session 的主要作用就是通过服务端记录用户的状态。 典型的场景是购物车 总的来说，Session存储在服务器端，Cookie存储在客户端本地。Session相对Cookie更安全，因此尽量避免向Cookie中保存敏感的数据，即使普通的数据，也应该加密存储； 6.7 URL和URI的区别？ URI是统一资源标识符，可以唯一标识一个资源。 URL是统一资源定位符，可以提供该资源的路径。它是一种具体的 URI，即 URL 可以用来标识一个资源，而且还指明了如何 locate 这个资源。 URI的作用就像身份证号码一样，而URL的作用就像家庭地址一样，他是URI的具体形式，提供了可以找到资源的路径。 7、HTTPS协议详解7.1 HTTPS中的SSL和TSLHTTPS协议是HTTP协议的安全版本，主要就是因为HTTPS协议工作在SSL和TLS协议之上。 SSL是安全套接层：SSL 协议位于 TCP/IP 协议与各种应用层协议之间，为数据通讯提供安全支持。 TLS是传输安全性协议 7.2 浏览器使用HTTPS协议传输数据的流程 大致流程如下： 客户端通过URL链接和服务器建立SSL连接 服务器收到请求后，会将网站支持的证书信息（证书中包含公钥）传送一份给客户端 客户端和服务器协商SSL连接的安全等级 客户端浏览器根据双方同意的安全等级，建立会话密钥，然后利用网站的公钥将会话密钥加密，并传送给网站。 服务器利用自己的私钥解密出会话秘钥 服务器利用会话密钥加密与客户端之间的通信 7.3 HTTPS协议的缺点 HTTPS协议多次握手，导致页面的加载时间延长近50%； HTTPS连接缓存不如HTTP高效，会增加数据开销和功耗； 申请SSL证书需要钱，功能越强大的证书费用越高。 SSL涉及到的安全算法会消耗 CPU 资源，对服务器资源消耗较大。 7.4 Http和Https的区别？ Http协议直接运行在TCP协议之上，明文传输，客户端和服务端都无法验证对方的身份（无状态协议）； Https是身披SSL外壳的Http协议，运行在SSL协议之上，SSL协议运行在TCP协议之上，是添加了加密和认证机制的HTTP。二者之间存在如下不同： 端口不同：Http和Https使用的协议不同，同时使用的端口也不同，Http是80端口，Https是443端口 资源消耗：相对于Http协议，Https协议由于需要加解密处理，因此需要消耗更多的CPU和 内存资源 Https需要第三方机构的数字证书，而要获得证书需要向认证机构购买 Https加密机制是一种共享密钥加密和公开密钥加密并用的混合加密机制 7.4.1 对称加密和非对称加密？ 对称加密是指加密和解密使用同一个秘钥，这种方式最大的问题是秘钥的发送问题，即秘钥如何安全的发送给接收方； 非对称加密是指使用一对非对称秘钥，公钥和私钥，公钥可以随意发布，但是私钥只有自己知道。发送密文的一方使用对方的公钥解密，而接收方接收到消息后使用自己的私钥解密。非对称加密可以保证数据的安全性，但是效率过低，因此不适合对大量数据加密。]]></content>
      <categories>
        <category>计算机网络部分</category>
      </categories>
      <tags>
        <tag>计算机网络部分</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM—走进Java虚拟机]]></title>
    <url>%2F2020%2F02%2F09%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E2%80%94%E8%B5%B0%E8%BF%9BJava%E8%99%9A%E6%8B%9F%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[1、JDK，JRE，JVM之间的关系仅从传统意义上来看，Sun定义的Java技术体系包括：Java程序设计语言、各种平台上的JVM、Class文件格式、Java API类库、来自商业机构和开源社区的第三方Java类库。 JDK全程为Java SE Development Kit（Java开发工具），是用于支持Java程序开发的最小环境，提供了编译和运行Java程序所需的各种资源和工具，包括：Java程序设计语言，Java API类库，JVM。 JRE全称为Java runtime environment（Java运行环境），是支持Java程序运行的最小环境，包括：Java API类库中的SE API子集，JVM。 JVM是运行Java程序的核心虚拟机。 他们的关系可以用下图表示： 图 1 Java体系结构 2、Java的发展史Java之父：詹姆斯·高斯林 1991年，由James Gosling博士领导的绿色计划中产生了Java语言的前生Oak(橡树)，用于嵌入式系统，没有成功；1995年互联网发展，改名为Java，开始火爆，提出Write once ，Run anywhere的原则；1996年1月 发布JDK1.0，jvm为Sun Classic VM；1996年5月 首届JavaOne大会；1997年2月 JDK1.1（内部类、反射、jdbc、javabean、rmi）；1998年 JDK1.2 发布。同时Sun发布了JSP/Servlet、EJB规范，以及将Java分成了J2SE、 J2EE 和J2ME。2000年5月 JDK1.3 发布，Java Hotspot VM正式发布，成为Java默认的虚拟机；2002年2月 JDK1.4 Struts 、Hibernate、 Spring、 正则表达式 、NIO、 日志 、Xml解析器；2004年9月 JDK1.5(tiger) 自动装箱拆箱 泛型 注解 枚举 增强for 可变参数 Spring2.X；2006年 JDK6 JavaSe JavaEE JavaME 提供脚本语言支持 支持http服务器api；2009年 Oralcel以74亿美元收购Sun,获得了Java商标和最具价值的HotSpot虚拟机。此时，Oracle拥有市场占有率最高的两款虚拟机HotSpot和JRockit，并计划在未来对他们进行整合：HotRockit2011年 JDK7发布。在JDK 1.7u4中正式启用了新的垃圾回收器G1。2014年 Java8发布, Lambda表达式、 函数式接口 、方法引用 、默认方法 、Stream；2017年 Java9发布，加入模块化并将G1设置为默认GC，替代CMS。2018年 Java11发布，LTS版本的JDK，发布了革命性的ZGC。2019年 JDK12发布，加入RedHat领导开发的Shenandoah GC. 3、Java虚拟机发展史Sun Classic VM1996年随着JDK1.0的发布，Java使用了世界上第一款商用虚拟机，只能使用纯解释器（没有JITJust in time编译器）的方法来执行Java代码，在JDK1.4被废弃。 Exact VMExact Memory Management 准确式内存管理；编译器和解释器混合工作以及两级即时编译器。 HotSpot VMHotSpot最初是由一家“Longview Technologies”的小公司设计的，1997年此公司被Sun收购，JDK1.3时，，HotSpot VM成为Java默认的虚拟机。HotSpot VM的特性正如他的名字一样，它使用了热点代码探测技术： 通过计数器找到最具有编译价值的代码，触发即使编译和桟上替换（OSR） 通过编译器和解释器协同工作，在最优化程序响应时间和最佳的性能汇总取得平衡 JRockitBEA公司（现在已经被Oracle收购）开发，是当前世界上最快的Java虚拟机，专注于服务端应用，全部靠编译器执行（JRockit内部不包含解析器的实现）。 J9IBM开发 原名：IBM Techn0ology for Java Virtual Machine IT4j。是除HotSpot、JRockit之外目前最有影响的三大商用虚拟机之一。 KVMkilobyte 简单、轻量、高度可移植，在手机平台运行，运行速度慢。 Azul VM/Liquid VM高性能的Java虚拟机，在HotSpot基础上改进，专用的虚拟机。 Dalvik VM 谷歌开发的，应用于Android系统，并且在Android2.2中提供了JIT Dalvik VM只能称作虚拟机，而不能称作“Java虚拟机”，因为他没有遵循Java虚拟机规范，因此不能直接执行Java的class文件 采用了寄存器指令集架构而不是栈结构，执行dex（dalvik Executable）文件。 Microsoft JVMMicrosoft 为了在IE3浏览器中支持Java Applets,开发了Microsoft JVM，它只能运行在windows下面。1997年，Sun以商标侵权，不正当竞争罪名指控微软成功后，微软在Windows XP SP3中去掉了Microsoft JVM虚拟机，现在Windows上安装的JDK中都是HotSpot VM。 Taobao VM 基于openJDK开发自己的定制版本AlibabJDK，简称AJDK。是整个阿里Java体系的基石。 基于OpenJDK 、HotSpot VM深度定制并且开源的高性能服务器版JVM。 4、Java虚拟机的概念4.1 虚拟机的分类虚拟机（Virtual Machinel），就是一台虚拟的计算机。它是一款软件，用来执行一系列虚拟计算机指令。大体上，虚拟机可以分为系统虚拟机和程序虚拟机。 系统虚拟机：大名鼎鼎的Visual Box、VMware就属于系统虚拟机，它们完全是对真实计算机的仿真，提供了一个可运行完整操作系统的软件平台。 程序虚拟机：典型代表就是Java虚拟机（JVM）,它专门为执行单个计算机程序而设计，在Java虚拟机中执行的指令我们称作Java字节码指令。 4.2 Java虚拟机 Java虚拟机是一台执行Java字节码的程序虚拟计算机，他拥有独立的运行机制，虽然他叫Java虚拟机，但其运行的字节码指令未必全是有Java语言编译而成，JVM是一个跨语言的平台。 JVM平台的各种语言可以共享Java虚拟机带来的跨平台性、优秀的垃圾回收，以及可靠的即时编译器。 Java技术的核心就是Java虚拟机（JVM），因为所有的Java程序最终运行在JVM内部。 JVM的作用：JVM就是二进制字节码的运行环境，负责装载字节码到其内部，解释/编译为对应平台上的机器指令。 JVM的特点：一次编译，到处运行；自动内存管理；自动垃圾回收功能…… 4.3 JVM的整体结构上面介绍到JVM是一种用于专门执行单个计算机程序而设计的程序虚拟机，他主要包括类加载子系统、运行时数据区（内存结构）和执行引擎（包括垃圾回收器）三部分组成，关于JVM的组成如下图所示： 图4.3 JVM整体结构示意简图 各部分功能简介1）类加载子系统负责从文件系统或者网络中加载Class信息，加载的类信息存放于一块称为方法区的内存空间。除了类的信息外，方法区中可能还会存放运行时常量池信息，包括字符串字面量和数字常量（这部分常量信息是Class文件中常量池部分的内存映射）。 2）Java堆在虚拟机启动的时候建立，它是Java程序最主要的内存工作区域。几乎所有的Java对象实例都存放在Java堆中。堆空间是所有线程共享的，这是一块与Java应用密切相关的内存空间。 3）Java的NIO库允许Java程序使用直接内存。直接内存是在Java堆外的、直接向系统申请的内存空间。通常访问直接内存的速度会优于Java堆。因此出于性能的考虑，读写频繁的场合可能会考虑使用直接内存。由于直接内存在Java堆外，因此它的大小不会直接受限于Xmx指定的最大堆大小，但是系统内存是有限的，Java堆和直接内存的总和依然受限于操作系统能给出的最大内存。 4）垃圾回收系统是Java虚拟机的重要组成部分，垃圾回收器可以对方法区、Java堆和直接内存进行回收。其中，Java堆是垃圾收集器的工作重要场所。和C/C++不同，Java中所有的对象空间释放都是隐式的，也就是说，Java中没有类似free()或者delete()这样的函数释放指定的内存区域。对于不再使用的垃圾对象，垃圾回收系统会在后台默默工作，默默查找、标识并释放垃圾对象，完成包括Java堆、方法区和直接内存中的全自动化管理。 5）每一个Java虚拟机线程都有一个私有的Java栈，一个线程的Java栈在线程创建的时候被创建，Java栈中保存着帧信息、局部变量、方法参数，同时和Java方法的调用、返回密切相关。 6）本地方法栈和Java栈非常类似，最大的不同在于Java栈用于Java方法的调用，而本地方法栈则用于Native方法的调用，作为对Java虚拟机的重要扩展，Java虚拟机允许Java直接调用本地方法（通常使用C编写） 7）PC（Program Counter Register）也是每一个线程私有的空间，Java虚拟机会为每一个Java线程创建PC。在任意时刻，一个Java线程总是在执行一个方法，这个正在被执行的方法称为当前方法。如果当前方法不是本地方法，PC寄存器就会指向当前正在被执行的指令。如果当前方法是本地方法，那么PC寄存器的值就是undefined 8)执行引擎是Java虚拟机的最核心组件之一，它负责执行虚拟机的字节码，现代虚拟机为了提高执行效率，会使用即时编译技术(JIT)将Java方法编译成机器码后再执行。 4.4 JVM的指令集架构模型 Java编译器输入的指令流基本上是一种基于桟的指令集架构，另外一种指令集架构则是基于寄存器的指令集架构。 具体来说，这两种指令集架构之间的区别如下： 基于桟的指令集架构的特点 设计和实现更简单，适用于资源受限的系统 避开了寄存器分配难题，使用零地址指令方式分配； 指令流中的指令大部分是零地址指令，其执行过程依赖于操作桟，指令集更小，编译器更容易实现 不要需要依赖具体的硬件，可移植性好。 基于寄存器的指令集架构放入特点 典型的应用是x86的二进制指令集，比如传统的PC以及Android的Davlik虚拟机 指令集完全依赖硬件，可移植性差 性能更优秀，指令执行效率高 花费更少指令去完成一项操作 在大部分情况下，基于寄存器的架构的指令往往都以一地址指令、二地址指令和三地址指令为主。 4.5 JVM的生命周期4.5.1 JVM的启动Java虚拟机的启动是通过引导类加载器（bootstarp class loader）创建一个初始类来完成的，这个类是由虚拟机的具体实现指定的。4.5.2 JVM的执行 一个运行中的JVM有着一个清晰的任务：执行Java程序 程序开始执行JVM才启动，程序执行结束JVM就停止 执行一个所谓的Java程序的时候，真正在执行的其实是一个Java虚拟机进程。 4.5.3 JVM的退出以下几种情况JVM会退出： 程序正常执行结束 程序在执行过程中遇到了异常或错误而异常终止 由于操作系统出现错误而导致Java虚拟机进程异常退出 某个线程调用Runtime类或者System类的exit（）方法，或调用了Runtime类的halt()方法，并且Java安全管理器也允许这次exit或halt操作 除此之外，JNI（Java Native Interface）规范描述了用JNI来加载或卸载JVM时，JVM退出的情况]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解JVM—虚拟机类加载机制]]></title>
    <url>%2F2020%2F02%2F09%2F%E6%B7%B1%E5%85%A5%E7%90%86%E8%A7%A3JVM%E2%80%94%E8%99%9A%E6%8B%9F%E6%9C%BA%E7%B1%BB%E5%8A%A0%E8%BD%BD%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[1、JVM内存结构概述JVM是Java技术的核心，因为任何Java程序最终都需要运行在JVM上。构成JVM的主要三分部分有：类加载子系统、运行时数据区和执行引擎。他们各自发挥着各自的本领，构建起强大的JVM。JVM的具体组成如下图所示： 图1 JVM整体结构示意（详）图 看完这个图，我想大家对于JVM应该会有一个基本的认识，最起码知道了JVM最重要的三大组成部分的位置以及他们内部的大致结构，并且这幅图还间接展示了一个被Java前端编译器编译后生成的class字节码文件被执行的过程，那么我们学习JVM也就可以按照字节码文件执行的流程来学习，这样下来结合原理/结构图我们一定会对JVM有更深刻的认识。因此本片博客我们就来了解一下类加载子系统。 2、类加载的时机2.1 类的生命周期类从被加载到虚拟机内存中开始，到卸载出内存为止，他的整个生命周期包括：加载（Loading）、验证（Verify）、准备（Prepare）、解析（Resolve）、初始化（Initialization）、使用（Using）和卸载（Unloading）7个阶段。其中验证、准备和解析可以合起来统称为链接（Linking）。各个阶段的发生顺序： 图2.1 类的生命周期 其中，加载、验证、准备、初始化和卸载这5个阶段的顺序必须按照图示的顺序按部就班的开始，而解析阶段不一定：它在某些情况下可以在初始化阶段之后在开始，这是为了支持Java的动态绑定特性。 2.2 类的加载时机Java虚拟机中并没有明确规定类的加载时机，这个不同的虚拟机产品会有不同的实现。但是Java虚拟机规范中对于类的初始化阶段有明确的规定，当出现以下5种情况时必须立即对类进行初始化（间接说明了类的5种加载的时机）： 当使用new关键字实例化对象、读取或设置一个类的静态字段、调用一个类的静态方法的时候 使用java.lang.reflect包的方法对类进行反射调用的时候，如果类还没有初始化过，则需要初始化 当初始化一个类的时候如果发现他的父类还没有初始化，那么需要先初始化父类 当虚拟机启动的时候，用户指定的执行主类（含有main方法的那个类）会优先初始化这个类 当使用动态语言支持时如果一个java.lang.invoke.MethodHandle实例最后的解析结果为RET_getStatic、RET_putStatic、RET_invokeStatic的方法句柄，并且这个方法句柄所在的类没有进行初始化，则需要先初始化。 这5种场景中的行为称为对一个类的主动引用，除此之外，其他的所有引用类的方法都不会触发初始化，被称为被动引用。 3、类的加载过程图3.1 类的加载流程 接下来我们来详细学习一下JVM中类加载的全过程，也就是：加载、验证、准备、解析和初始化各个阶段中JVM类加载子系统都干了什么。 3.1 加载（Loading）在加载阶段，JVM完成下面3件事： 通过一个类的全限定名来获取定义此类的二进制字节流 将字节流所代表的静态存储结构转化为方法区的运行时数据结构 在内存中生成一个代表这个类的java.lang.Class对象，作为方法区这个类的各种数据的访问接口 总结一下，加载阶段JVM的工作就是：将类.class字节码文件中的二进制数据读入到内存中，将其放在运行时数据区的方法区内，然后在堆区创建一个java.lang.Class对象，用来封装类在方法区中的数据结构 其中.class字节码文件的获取途径有以下（但不限这几种）方法： 从本地系统中直接加载 通过网络获取。典型的应用场景：Applet 从zip、jar、war、ear等格式的压缩包中获取 运行时计算生成，使用最多的是：动态代理技术 有其他文件生成，典型场景：JSP 从专用的数据库中提取.class文件 从加密文件中获取，是典型的防class文件被反编译的保护措施 3.2 链接（Linking）链接具体有三个过程：验证、准备和解析。验证阶段： 验证是链接的第一步，这一步的作用是为了确保Class文件中字节流包含的信息符合虚拟机的要求，并且不会危害虚拟机的自生安全。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;验证大致上会完成下面4个阶段的检查动作：文件格式验证、元数据验证、字节码验证和符号引用验证。如果输入的字节流不符合class文件格式的约定，JVM就会抛出一个java.lang.VerifyError异常或其子类异常。验证阶段的具体4个动作的作用： 文件格式验证：验证的第一步，作用是验证字节流是否符合Class文件格式的规范，并且能被当前版本的虚拟机处理，具体的验证点包括：是否以魔数oxCAFEBABE开头，主次版本号是否在当前JVM处理的范围…… 元数据验证：第二阶段的验证，目的是对字节码描述的信息进行语义分析，以保证器描述的信息符合Java语言规范。 字节码验证：第三个阶段的验证，主要目的是通过数据流和控制流分析，确定程序语义是否合法、是否符合逻辑 符号引用验证：最后一个阶段的验证，发生在虚拟机将符号引用转化为直接引用的时候，这个转化加载链接的第三个阶段—解析的时候发生，这次验证主要目的就是确保解析动作可以正常的执行 最后需要说明一点：虚拟机的类加载机制中，验证阶段绝对是非常重要的一个阶段，但是它并不是必要的阶段。如果我们的程序（无论是我们自己写的还是第三方的）都已经被反复使用和验证的情况下，那么在真正运行的时候就可以考虑使用-Xverify none来关闭大部分的类验证措施，以缩短类加载的时间，毕竟时间就是金钱！！！ 准备阶段： 准备阶段是JVM正式为类变量分配内存并为类变量设置初始值的阶段，这些变量所使用的内存将在方法区中进行分配。 不过要清楚几点是： 这个阶段给类变量设置的初始值并不是变量后面有程序员指定的值，而是统一设置为零值。正真指定的值这时是存放在类构造器&lt;clinit&gt;()方法中，例如下面的例子：12&gt; public static int a=100; //在准备阶段变量a会在方法区中分得内存并被赋初值为0，之后又会在初始化阶段初始化为100&gt; 即被static修饰同时又被final修饰的常量由于在编译的时候就被分配值了，准备阶段只会显示的初始化，也即准备阶段不会管这些常量的。 这里只会为一个类中的类变量分配内存并初始化零值，实例变量将会在对象实例化的时候随对象一起分配在Java堆中。 解析阶段： 解析阶段是JVM将常量池的符号引用转换为直接引用的过程。解析操作主要针对的类或接口、字段、类方法、接口方法、方法类型、方法句柄和调用点限定7类符号限定引用进行。 3.3 初始化（Initialization）初始化阶段是类加载过程的最后一个阶段，到了这一步才正真开始执行类中定义的Java程序代码。初始化阶段就是系统给类变量赋指定值并且执行静态代码块的阶段，或者说初始化阶段是执行类构造器&lt;clinit&gt;()方法的过程。 关于&lt;clinit&gt;()方法我们需要明确下面几点： &lt;clinit&gt;()方法是由javac编译器自动收集类中所有类变量的赋值动作和静态代码块中的语句合并而来，不需要人为定义。 &lt;clinit&gt;()方法虽然叫类构造器，但它与类的构造函数（类的构造函数在虚拟机视角下是&lt;init&gt;()方法）不同，他不需要显示的调用父类构造器，虚拟机会保证在子类的&lt;clinit&gt;()方法执行前，父类的&lt;clinit&gt;()方法已经执行完毕。 &lt;clinit&gt;()方法不是必须的，如果一个类中没有静态语句块，也没有类变量，那么编译器就可以不为这个类生成&lt;clinit&gt;()方法。 虚拟机会保证一个类的&lt;clinit&gt;()方法在多线程环境中被正确地加锁、同步。如果有多个线程同时去初始化一个类，那么只会有一个线程去执行这个类的&lt;clinit&gt;()方法，其他的线程都会阻塞。 4、类加载器从JVM的角度来讲，只存在两种不同的类加载器：引导类加载器（Bootstrap ClassLoader）和用户自定义类加载器。之所以这样划分是因为引导类加载器是使用C++实现的，它是虚拟机的一部分，而其他的加载器（比如扩展类加载器、应用类加载器……）都是使用Java语言实现的，独立于虚拟机外部，并且都直接或间接的继承自java.lang.ClassLoader这个抽象类。 但是从Java开发人员的角度来看，JVM的类加载器可以细分为以下几种： 4.1 启动类加载器（Bootstrap ClassLoader） 1）启动类加载器使用C++语言实现，它就是JVM的组成部分2）它用来加载Java的核心类库（$JAVA_HOME/jre/lib/rt.jar、resoures.jar，sun.boot.class.path路径下的内容），用于提供JVM自身需要的类（大致就是以java、javax、sun开头的类库）3）由于是使用C++实现的，因此它不继承自java.lang.Classloader，也没有父加载器，并且启动类加载器无法被Java程序直接引用，如果尝试获取启动类加载器，那么一定返回的是null 4.2 扩展类加载器（Extension ClassLoader） 由Java语言实现，具体的实现在sun.misc.Launcher$ExtClassLoader这个内部类中，他派生与ClassLoader，主要负责加载$JAVA_HOME/jre/lib/ext目录中的类库，或者被java.ext.dirs系统变量所指定的路径中的所有类库。 4.3 应用类加载器（Application ClassLoder） 由sun.misc.Launcher$AppClassLoader实现。由于这个类加载器是ClassLoader中getSystemClassLaoder()方法的返回值，因此也称其为系统类加载器。它一般负责加载用户路径（ClassPath）上的类库，我们自己写的类一般情况下就是通过这个类加载器加载的。 4.4 关于自定义类加载器通过上面的学习，我们了解到如果用Java来实现我们自己的类加载器，我们首先可以继承java.lang.ClassLoader，它的 loadClass() 实现了双亲委派模型的逻辑，因此自定义类加载器一般不去重写它，但是需要重写 findClass() 方法。最后我们再来看一下ClassLoader、ExtClassLoader、AppClassloader之间在语言层面的继承关系 图4.1 双亲委派模型示意图 5、双亲委派机制图5.1 双亲委派模型示意图 双亲委派机制工作原理： 1）如果一个类加载器收到了类加载的请求，他不会自己立即去加载，而是把这个加载请求委托给父级加载器执行加载请求；2）如果一个父级加载器还存在父级加载器，则进一步向上委托，依次递归，请求最终会传达到最顶层的启动类加载器；3）如果父级加载器可以完成加载任务，就成功返回，倘若父级加载器无法完成加载任务，则它的子级类加载器才会尝试自己加载，如果还是不行在给子级加载器的子级加载器去加载，这就是双亲委派机制。 需要指出的是： 双亲委派模型示意图所展示的不是几种类加载器的继承关系，而是他们在加载一个的时候的委托关系，而这些类本质上也并不存在继承关系，示意图中所展示的只是一种层级（阶级）关系 一个类如果所有的类加载器都加载失败，那么系统就会抛出ClassNotFoundException异常]]></content>
      <categories>
        <category>JVM</category>
      </categories>
      <tags>
        <tag>JVM</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx常用命令]]></title>
    <url>%2F2020%2F02%2F02%2Fnginx%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[nginx常用命令在Linux系统中nginx的常用命令如下（执行下面的命令需要进入nginx安装目录（正常情况下Linux上的路径是/usr/local/nginx）下的sbin目录）： 1234567891011121314151617nginx -s quit 优雅停止nginx，有连接时会等连接请求完成再杀死worker进程 nginx -s stop 强制停止nginxnginx -s reload 优雅重启，并重新载入配置文件nginx.confnginx -s reopen 重新打开日志文件，一般用于切割日志nginx -c filename 指定配置文件nginx -t 检查nginx的配置文件nginx -h 查看帮助信息nginx -v 查看版本 nginx -V 详细版本信息，包括编译参数]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx配置实例—nginx+keepalived实现主备服务器的高可用集群]]></title>
    <url>%2F2020%2F02%2F01%2FNginx%E9%85%8D%E7%BD%AE%E5%AE%9E%E4%BE%8B%E2%80%94nginx%2Bkeepalived%E5%AE%9E%E7%8E%B0%E4%B8%BB%E5%A4%87%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%9A%84%E9%AB%98%E5%8F%AF%E7%94%A8%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[1、什么是负载均衡高可用？nginx作为负载均衡服务器，所有请求都到了nginx,可见nginx处于非常重要的位置，如果nginx服务器宕机将会导致后端web服务将无法提供，后果严重。 为了屏蔽负载均衡服务器的宕机，需要建立一个备份机。主服务器和备份机上都运行高可用（High Availablitity）监控程序，通过传送诸如“I am alive”这样的信息来监控对方的运行状况，当备份机不能再一定时间内收到这样的信息，它就接管主服务器的服务ip并继续提供负载均衡服务；当备份管理器又从主管服务器收到“I am alive”这样的信息时，它就释放服务ip地址，这样的主服务器就开始再次提供负载均衡服务。 2、Nginx+Keepalived实现主备2.1 什么是keepalived？（1）keepalived是进群工作管理中保证集群高可用的一个服务软件，用来防止单点故障。（2）keepalived的作用是检测web服务器的状态，如果有一台web服务器死机，或工作出现故障，keepalived将检测到，并将有故障的web服务器从系统中剔除，当web服务器工作正常后keepalived自动将web服务器加入到服务器群中，这些工作全部自动完成，不需要人工干涉，需要人工做的只是修复故障的web服务器。 2.2 keepalived的工作原理keepalived是以vrrp协议为实现基础的，vrrp全称Virtual Router Redundancy Protocol,即虚拟路由冗余协议。虚拟路由冗余协议，可以认为是实现路由器高可用的协议，即将N台提供相同功能的路由器组成一个路由器组，这个组里面有一个master和多个backup,master上面有一个对外提供服务的vip(VIP=virtual IP Address,即虚拟ip地址，该路由器所在局域网内其他机器的默认路由为该vip),master会发组播，当backup收不到VRRP包时就认为master宕掉了，这时就需要根据VRRP的优先级来选举一个backup当master。这样的话就可以保证路由器的高可用了。keepalived主要有三个模块，分别是core、check、VRRP。core模块为keepalived的核心，负载进程的启动、维护以及全局配置文件的加载和解析。check负责健康检查，包括常见的各种检查方式。VRRP模块是来实现VRRP协议的。 3、配置Nginx高可用集群图 nginx高可用架构示意图 我的实验环境： 1).两台nginx，一主一备分别在独立的Linux系统上运行，ip分别是：192.168.92.128和192.168.92.1342).分别在192.168.92.128 和192.168.92.134两台服务器上安装nginx和keepalived 3.1 安装nginxnginx的安装请参考Nginx快速入门—基本概念以及在Linux上安装Nginx 这里为了体现效果，我把nginx的默认index.html页面修改一下 图 3.1.1 master nginx的修改 图 3.1.2 backup nginx的修改 3.2 安装和配置keepalived直接输入下面的命令安装keepalived： 1234#yum安装keepalivedyum -y intsall keepalived#设置开机自动启动keepalived（可选）chkconfig keepalived on 安装完成后会在/etc下生成一个配置文件，它的绝对路径是/etc/keepalived/keepalived.conf，它就是用来配置nginx主备关系的配置文件。 主nginx的keepalived配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; acassen@firewall.loc failover@firewall.loc sysadmin@firewall.loc &#125; notification_email_from Alexandre.Cassen@firewall.loc smtp_server 192.168.200.1 smtp_connect_timeout 30 router_id 193.168.92.128 vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0&#125;vrrp_script chk_nginx &#123; script "/etc/keepalived/nginx_check.sh" #检测脚本的绝对路径 interval 2 #每2秒检测一次nginx的运行状态 weight -20 #失败一次，将自己的优先级-20 &#125;vrrp_instance VI_1 &#123; state BACKUP # 状态，主节点为MASTER，备份节点为BACKUP interface ens33 # 绑定网卡，通过ifconfig查看自己的网卡 virtual_router_id 51 # 虚拟路由的ID号,两个节点设置必须一样,可选IP最后一段使用,相同的VRID为一个组,他将决定多播的MAC地址 priority 50 # 节点优先级，值范围0～254，MASTER要比BACKUP高 advert_int 1 # 组播信息发送时间间隔，两个节点必须设置一样，默认为1秒 mcast_src_ip 192.168.92.128 #本机的ip，需要修改 # 设置验证信息，两个节点必须一致 authentication &#123; auth_type PASS auth_pass 1111 &#125; # 虚拟IP，两个节点设置必须一样。可以设置多个，一行写一个 virtual_ipaddress &#123; 192.168.92.150 &#125; track_script &#123; chk_nginx # nginx存活状态检测脚本 &#125;&#125;...... 备份nginx的keepalived配置 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152! Configuration File for keepalivedglobal_defs &#123; notification_email &#123; acassen@firewall.loc failover@firewall.loc sysadmin@firewall.loc &#125; notification_email_from Alexandre.Cassen@firewall.loc smtp_server 192.168.200.1 smtp_connect_timeout 30 router_id 193.168.92.134 vrrp_skip_check_adv_addr vrrp_strict vrrp_garp_interval 0 vrrp_gna_interval 0&#125;vrrp_script chk_nginx &#123; script "/etc/keepalived/nginx_check.sh" #检测脚本的绝对路径 interval 2 #每2秒检测一次nginx的运行状态 weight -20 #失败一次，将自己的优先级-20 &#125;vrrp_instance VI_1 &#123; state BACKUP # 状态，主节点为MASTER，备份节点为BACKUP interface ens33 # 绑定网卡，通过ifconfig查看自己的网卡 virtual_router_id 51 # 虚拟路由的ID号,两个节点设置必须一样,可选IP最后一段使用,相同的VRID为一个组,他将决定多播的MAC地址 priority 50 # 节点优先级，值范围0～254，MASTER要比BACKUP高 advert_int 1 # 组播信息发送时间间隔，两个节点必须设置一样，默认为1秒 mcast_src_ip 192.168.92.134 #本机的ip，需要修改 # 设置验证信息，两个节点必须一致 authentication &#123; auth_type PASS #密码相同的为一个集群 auth_pass 1111 &#125; # 虚拟IP，两个节点设置必须一样。可以设置多个，一行写一个 virtual_ipaddress &#123; 192.168.92.150 &#125; track_script &#123; chk_nginx # nginx存活状态检测脚本 &#125;&#125;...... 之后在/etc/keepalived目录下新建检测脚本，内容如下： 1234567891011121314151617181920212223242526#!/bin/bashCOUNT=$(ps -C nginx --no-header |wc -l)echo $COUNT#判断Nginx 是否都挂掉了if [ $COUNT -eq 0 ]then #如果挂掉了，就启动nginx /usr/local/nginx/sbin/nginx echo "restart nginx" #等5秒钟后，再次查看是否 启动成功 sleep 5 #如果nginx没有启动起来，就直接干掉keepalived COUNT=$(ps -C nginx --no-header |wc -l) if [ $COUNT -eq 0 ] then echo "shudonw keepalived" #如果killall命令不能使用，就需要安装psmisc工具了 #yum install -y psmisc killall keepalived fifi 之后给脚本权限： 1chmod +x /etc/keepalived/nginx_check.sh keepalived的相关命令 keepalived的启动、重启、和停止命令： systemctl start keepalived.service &nbsp;&nbsp; #启动keepalived systemctl restart keepalived.service &nbsp;&nbsp; #重启keepalived systemctl stop keepalived.service &nbsp;&nbsp;#停止keepalived 启动后可以使用:systemctl status keepalived.service查看keepalived的状态，如果发现异常及时修改直到正常启动，正常运行截图： 图 3.2.1 正常启动keepalived 或者可以使用命令：`ps -ef|grep keepalived` 两边的nginx和keepliaved都启动后，在浏览器中输入我们刚才配置的虚拟ip，不出意外应该走的是主 nginx，如下图： 图3.2.2 配置成功 4、测试故障转移4.1 主服务器正常提供服务初始时候，nginx主服务器正常，将vip绑定到自身，对外提供服务，从服务器始终与主服务器保持通信，监测主服务器的健康状态。 图 4.1 主服务器正常服务 4.2 主服务器宕机，备份服务器接替主服务器的工作当nginx主服务器宕机或发生异常，总之以任何理由造成服务器上的健康监测程序发生异常，无法和从服务器上的健康监测程序通信，此时从服务器上的健康监测机制就会认为主服务器挂了，从而将vip绑定到自身，成功上位，充当主服务器的角色。 图 4.2.1 主服务器宕机后 验证：关闭主服务器（192.168.92.128）上的nginx：/usr/local/nginx/sbin/nginx -s quit,之后在浏览器地址栏中输入vip：192.168.92.150 图 4.2.1 切换到备用服务器（192.168.92.134） 4.3 “一山不容二虎”：主服务器恢复后，备份服务器主动让位在keepalive机制中，主服务器终究是主服务器，一旦主服务器恢复，边从新绑定vip，继续充当主服务器，而从服务器又成为了热备。 图 4.3 主服务器恢复 验证：重启主服务器（192.168.92.128）和主服务器的keepalived，再次输入192.168.92.150，主服务器恢复服务： 图3.2.2 配置成功]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[力扣：力扣：两两交换链表中的节点]]></title>
    <url>%2F2020%2F01%2F31%2F%E5%8A%9B%E6%89%A3%EF%BC%9A%E4%B8%A4%E4%B8%A4%E4%BA%A4%E6%8D%A2%E9%93%BE%E8%A1%A8%E4%B8%AD%E7%9A%84%E8%8A%82%E7%82%B9%2F</url>
    <content type="text"><![CDATA[给定一个链表，两两交换其中相邻的节点，并返回交换后的链表。你不能只是单纯的改变节点内部的值，而是需要实际的进行节点交换。 示例: 给定 1-&gt;2-&gt;3-&gt;4, 你应该返回 2-&gt;1-&gt;4-&gt;3.给定 1-&gt;2-&gt;3-&gt;4-&gt;5 ，你应该返回 2-&gt;1-&gt;4-&gt;3-&gt;5. 题解只需要维护3个指针：prev、start和end，prev用于连接前一次交换后的start结点（第一次交换是preHead结点）和后一次交换后的end结点；而start结点和end结点分别表示每次交换前的前一个结点和后一个结点，交换前应该先把前一次交换后的start结点和本次的end结点先连上，不然链表就断了，之后再进行start结点和end结点的交换，他两的交换也是有要求的：先改变start结点的指向，之后再改变end结点的指向，最后交换完成后改变prev指向本次交换后的start结点（变成后一个结点了），以此循环，直到prev所指的结点后面凑不够两个节点了，返回头结点结束。 图 算法思路示意图 12345678910111213141516171819202122232425262728/** * Definition for singly-linked list. * public class ListNode &#123; * int val; * ListNode next; * ListNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123; public ListNode swapPairs(ListNode head) &#123; ListNode preHead=new ListNode(0); preHead.next=head; //用于记录head结点的位置 ListNode prev=preHead; while(prev.next!=null&amp;&amp;prev.next.next!=null)&#123; //分别记录下两个节点的位置 ListNode start=prev.next; ListNode end=prev.next.next; //连接前一次交换的start结点（第一次交换是preHead结点）和后一次交换的end结点 prev.next=end; //交换两个节点:为了防止链断掉应该先交换start指针的指向，之后改变end结点的指向 start.next=end.next; end.next=start; //维护prev准备进行下一次交换:start交换后跑到后面去了 prev=start; &#125; return preHead.next; &#125;&#125; 复杂度分析 时间复杂度：O(N)，其中 N 指的是链表的节点数量。 空间复杂度：O(1)。]]></content>
      <categories>
        <category>LetCode</category>
      </categories>
      <tags>
        <tag>LetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx配置实例—动静分离]]></title>
    <url>%2F2020%2F01%2F30%2FNginx%E9%85%8D%E7%BD%AE%E5%AE%9E%E4%BE%8B%E2%80%94%E5%8A%A8%E9%9D%99%E5%88%86%E7%A6%BB%2F</url>
    <content type="text"><![CDATA[1、动静分离概念重温Nginx动静分离可以简单的理解为把动态跟静态分离开来，不能理解成只是单纯的把动态页面和静态页面物理上的分离。严格意义上来说应该是把动态请求和静态请求分离，即nginx处理静态请求，tomcat等应用服务器处理动态请求。动静分离从目前的实现角度来讲大致分为两类：一种是纯粹把静态文件放在一个独立的服务器上，有一个独立的域名，也是目前主流推崇的方案；另一种是动态文件和静态文件混在一起发布，通过nginx分离开来，通过location配置不同的后缀名实现不同的请求转发。 2、Nginx动静分离实战配置2.1 准备静态资源首先在Liunx系统根目录下新建一个文件夹/resources/static用于存放静态文件 123[root@localhost /]# cd static[root@localhost static]# mkdir images[root@localhost static]# wget -o images http://nginx.org/nginx.png 2.2 准备动态资源在tomcat的webapps/ROOT目录下新建test.jsp,内容如下： 12345678910111213&lt;%@ page language="java" import="java.util.*" pageEncoding="utf-8"%&gt;&lt;HTML&gt; &lt;HEAD&gt; &lt;TITLE&gt;JSP Test Page&lt;/TITLE&gt; &lt;/HEAD&gt; &lt;BODY&gt; &lt;% Random rand = new Random(); out.println("&lt;h1&gt;Random number:&lt;/h1&gt;"); out.println(rand.nextInt(99)+100); %&gt; &lt;/BODY&gt;&lt;/HTML&gt; 2.3 在nginx中配置对静态请求和动态请求的处理逻辑完成资源文件的准备后，启动两个tomcat，分别监听8080和8081，之后在nginx的配置文件做如下简单配置： 123456789101112131415161718192021222324http &#123; #配置两个tomcat，让nginx均衡负载 upstream tomcatserver&#123; server 192.168.92.128:8080; server 192.168.92.128:8081; &#125; server &#123; listen 80; server_name 192.168.92.128; charset utf-8； #对静态资源的配置，使用Nginx进行处理响应 location ~ .*\.(js|css|ico|png|jpg|eot|svg|ttf|woff)$ &#123; #root目录指向的就是静态资源所在的路径 root /static/images/; &#125; #对动态请求，由nginx转发到tomcat等应用服务器进行处理 location ~ .*\.jsp$ &#123; proxy_pass http://tomcatserver; &#125; &#125;&#125; 配置好后重启nginx，然后在浏览器地址栏中输入www.123.com/nginx.png ,能看到nginx的Logo图，说明对静态资源的配置没有问题；之后再输入www.123.com/test.jsp，能看到`Random number:xxx`，说明对动态请求的配置也能正常工作，运行截图如下： 图 1 nginx处理静态请求 图 2 nginx处理动态请求 整合动态资源和静态资源上面通过一个简单的小测试体验了一下nginx的动静分离的效果，测试结果达到了预期效果。接下来我们来把他们整合在一起，即在一个页面中即有动态的也有静态的资源，通过nginx中配置帮我们完成对资源的请求，而我们所需做的就是输入www.123.com 这个地址即可。（1）在/rsources目录下新建目录template，并在template中新建文件：index.html，文件内容如下： 1234567891011121314151617181920212223242526&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8" /&gt; &lt;title&gt;测试ajax和跨域访问&lt;/title&gt; &lt;script src="http://libs.baidu.com/jquery/2.1.4/jquery.min.js"&gt;&lt;/script&gt;&lt;/head&gt;&lt;script type="text/javascript"&gt;$(document).ready(function()&#123; $.ajax(&#123; type: "GET", url: "http://www.123.com/test.jsp", success: function(data) &#123; $("#get_data").html(data) &#125;, error: function() &#123; alert("fail!!,请刷新再试!"); &#125; &#125;);&#125;);&lt;/script&gt; &lt;body&gt; &lt;h1&gt;测试动静分离&lt;/h1&gt; &lt;img src="http://www.123.com/nginx.png"&gt; &lt;div id="get_data"&gt;&lt;/div&gt; &lt;/body&gt;&lt;/html&gt; 保存文件之后修改nginx配置文件如下： 1234567891011121314151617181920212223242526272829http &#123; #配置两个tomcat，让nginx均衡负载 upstream tomcatserver&#123; server 192.168.92.128:8080; server 192.168.92.128:8081; &#125; server &#123; listen 80; server_name 192.168.92.128; charset utf-8; location / &#123; root /resources/template/; index index.html; &#125; #对静态资源的配置，使用Nginx进行处理响应 location ~ .*\.(js|css|ico|png|jpg|eot|svg|ttf|woff)$ &#123; #root目录指向的就是静态资源所在的路径 root /resources/static/images/; &#125; #对动态请求，由nginx转发到tomcat等应用服务器进行处理 location ~ .*\.jsp$ &#123; proxy_pass http://tomcatserver; &#125; &#125;&#125; 配置好后重启nginx，然后在浏览器地址栏中输入www.123.com ，如果在网页上能看到如下图所示内容表示配置成功，运行截图如下： 图 3 动静资源正常加载]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[力扣：合并k个有序链表]]></title>
    <url>%2F2020%2F01%2F30%2F%E5%8A%9B%E6%89%A3%EF%BC%9A%E5%90%88%E5%B9%B6%20k%20%E4%B8%AA%E6%8E%92%E5%BA%8F%E9%93%BE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[合并 k 个排序链表，返回合并后的排序链表。请分析和描述算法的复杂度。 示例: 输入:[ 1-&gt;4-&gt;5, 1-&gt;3-&gt;4, 2-&gt;6]输出: 1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4-&gt;5-&gt;6 题解解法1：两两链表逐一比较这是我首先想到的方法，由于前几天刚做过一个类似的题目：合并两个有序链表。力扣的地址是：https://leetcode-cn.com/problems/merge-two-sorted-lists/ 。所以，此个题启发，把k个链表的合并转换为k-1此两个链表的合并问题，第一次先合并lists[0]和lists[1]，此后用lists[i]和新生成的主链表两两合并，最终成功解决问题，代码如下： 123456789101112131415161718192021222324252627282930313233343536373839404142/** * Definition for singly-linked list. * public class ListNode &#123; * int val; * ListNode next; * ListNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123; public ListNode mergeKLists(ListNode[] lists) &#123; if(lists==null||lists.length==0)&#123; return null; &#125; if(lists.length==1)&#123; return lists[0]; &#125; ListNode l1=lists[0]; //l1是主链 for(int i=1;i&lt;lists.length;i++)&#123; l1=meregTwoLists(l1,lists[i]); &#125; return l1; &#125; private ListNode meregTwoLists(ListNode l1,ListNode l2)&#123; if(l1==null) return l2; if(l2==null) return l1; ListNode preHead=new ListNode(0); ListNode preNode=preHead; while(l1!=null&amp;&amp;l2!=null)&#123; if(l1.val&lt;=l2.val)&#123; preNode.next=l1; l1=l1.next; &#125;else&#123; preNode.next=l2; l2=l2.next; &#125; preNode=preNode.next; &#125; preNode.next=l1==null?l2:l1; return preHead.next; &#125;&#125; 复杂度分析 时间复杂度：O(kN)，其中k 是链表的数目两个链表的合并的时间复杂度是O(m+n)，即O(N)，N=m+n，表示两个合并链表的总长度，k个链表合并的时间复杂度O(kN)。 空间复杂度：O(1)只需要常量级的空间就可以完成合并。 解法2：分治归并解法1的思路简单清晰虽然是可行的，但是它有一个致命的缺陷，有大量的结点被遍历（比较）了多次，实际上我们并不需要对他们遍历多次，我们可以参照归并排序的思想： 将 k 个链表配对并将同一对中的链表合并。 第一轮合并以后，k 个链表被合并成了 k/2个链表，平均长度为2N/k，然后是 k/4个链表，k/8个链表等等。 重复这一过程，直到我们得到了最终的有序链表。因此，我们在每一次配对合并的过程中都会遍历几乎全部 N个节点，并重复这一过程 log2(k) 次 图 分治合并思路图解 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748/** * Definition for singly-linked list. * public class ListNode &#123; * int val; * ListNode next; * ListNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123; /** *合并k个链表 **/ public ListNode mergeKLists(ListNode[] lists) &#123; int len=lists.length; if(len&lt;1)&#123; return null; &#125; while(len&gt;1)&#123; for(int i=0;i&lt;len/2;i++)&#123; lists[i]=meregTwoLists(lists[i],lists[len-i-1]); &#125; len=(len+1)/2; &#125; return lists[0]; &#125; /** *合并两个链表 **/ private ListNode meregTwoLists(ListNode l1,ListNode l2)&#123; if(l1==null) return l2; if(l2==null) return l1; ListNode preHead=new ListNode(0); ListNode preNode=preHead; while(l1!=null&amp;&amp;l2!=null)&#123; if(l1.val&lt;=l2.val)&#123; preNode.next=l1; l1=l1.next; &#125;else&#123; preNode.next=l2; l2=l2.next; &#125; preNode=preNode.next; &#125; preNode.next=l1==null?l2:l1; return preHead.next; &#125;&#125; 复杂度分析： 时间复杂度： O(Nlogk) ，其中k 是链表的数目。我们可以在 O(n)O(n) 的时间内合并两个有序链表，其中 nn 是两个链表中的总节点数。将所有的合并进程加起来，我们可以得到时间复杂度是O(Nlogk)。 空间复杂度：O(1)只需要常量级的空间就可以完成合并。]]></content>
      <categories>
        <category>LetCode</category>
      </categories>
      <tags>
        <tag>LetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx配置实例—负载均衡]]></title>
    <url>%2F2020%2F01%2F30%2FNginx%E9%85%8D%E7%BD%AE%E5%AE%9E%E4%BE%8B%E2%80%94%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F</url>
    <content type="text"><![CDATA[1、Nginx负载均衡配置预期实现效果： 在浏览器地址栏中输入：http://www.123.com ，nginx收到请求后把请求平均分匹配到Linux服务器上监听8080和8081端口的两个tomcat服务器上。 1.1 准备工作（1）首先在host文件中配置域名映射：192.168.92.128 www.123.com（2）准备两个tomcat服务器，分别监听8080和8081端口，并在各自目录下新建一个edu目录，并创建index.html测试页面，配置完成后启动，让两个tomcat跑起来。 1.2 nginx负载均衡配置在nginx的http模块下配置upstream模块，upstream的语法是： 1234upstream 自定义域名&#123; [负载均衡策略;] server xxx.xxx.xxx.xxx:port [weight=xx] [down|backup|max_fails=xx|fail_timeout=xx]l];&#125; 注：[]中的内容是可选的。简单配置如下： 12345678910111213141516171819202122http &#123; #配置负载均衡：默认使用轮询策略 upstream myserver&#123; server 192.168.92.128:8080; server 192.168.92.128:8081; &#125; server &#123; listen 80; server_name 192.168.92.128; charset utf-8; location /&#123; root html; proxy_pass http://myserver; index index.html index.htm; proxy_connect_timeout 600; proxy_read_timeout 600; &#125; error_page 404 /404.html; &#125;&#125; 测试结果在浏览器地址栏中输入www.123.com/edu ,结果和预期一样，nginx让两个tomcat轮询处理请求： 负载均衡配置运行结果 2、upstream模块详解upstream是Nginx中配置负载均衡的关键模块，基本语法： 123upstream 自定义域名&#123; ......&#125; upstream有关的参数如下： server：用于配置反向服务地址和端口，语法：server address [parameters]; weight：权重，语法：weight=number，默认是1 max_conns：语法：max_conns=number，用于限制到代理服务器的同时活动连接的最大数量，默认是0 max_fail：语法：max_fails=number，允许请求失败的次数。经常和fail_timeout参数配合使用。 fail_timeout：语法：fail_timeout=time， 经过max_fails失败后，服务暂停的时间(默认10s) backup： 预留的备份服务器(当其他的节点挂掉，备份服务器启动) down：当前的server暂时不参与负载均衡(不对外提供服务) slow_start：语法：slow_start=time，设置服务器不正常运行时，或者在一段时间后服务器变为不可用时，服务器将其权重从零恢复到指定值的时间。 默认值为零，即禁用慢速启动。 service：语法：service=name，启用DNS SRV记录的解析并设置服务名称。 为了使此参数起作用，必须为服务器指定resolve参数，并指定不带端口号的主机名。 resolve：监视与服务器域名相对应的IP地址的更改，并自动修改upstream配置，而无需重新启动nginx。 配置示例： 1234567upstream myserver&#123; server 192.168.92.128:8080 max_fail=3 fail_timeout=100; server 192.168.92.128:8081 max_fail=3 fail_timeout=100; server 192.168.92.128:8082 backup; #备用服务器 server 192.168.92.128:8083 down; #不参与请求的服务器 server 192.168.92.128:8084 backup max_conns=1000; #备用服务器，当启用后最大连接数是1000&#125; max_fail=3 fail_timeout=100的含义是：当一台服务器在100s内如果出现了3次请求失败，就会报机器的状态设置为down，并且会在100s后尝试重新启用这个服务器。 3、nginx负载均衡调度算法详解Nginx目前支持的调度策略有以下5种： （1）轮询（默认）每个请求按时间顺序逐一分配到不同的后端服务器，如果后端服务器down掉，能自动剔除。 1234upstream myserver&#123; server 192.168.92.128:8080; server 192.168.92.128:8081;&#125; #####（2）加权轮询指定轮询权重，权重(weight)和访问比率成正比，用于后端服务器性能不均的情况。 123456upstream myserver&#123; #在server语句中加入weight参数指定一个权重就进入到加权轮询模式 #8080获得的请求是8081的2倍 server 192.168.92.128:8080 weight=10; server 192.168.92.128:8081 weight=5; &#125; #####（3）ip_hash每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，可以解决session共享的问题。应用场景：保持session 一至性 123456upstream myserver&#123; #指定ip_hash，就进入到ip_hash模式 ip_hash; server 192.168.92.128:8080; server 192.168.92.128:8081; &#125; #####（4）url_hash（第三方）按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，后端服务器为缓存时比较有效。 应用场景：静态资源缓存,节约存储，加快速度 1234hash $request_uri;hash_method crc32; server 192.168.92.128:8080;server 192.168.92.128:8081; 其中，hash_method为使用的hash算法，需要注意的是：此时，server语句中不能加weight等参数。 #####（5）fair（第三方）按后端服务器的响应时间来分配请求，响应时间短的优先分配。 fair; #指定fair就会进入到fair模式 server 192.168.92.128:8080; server 192.168.92.128:8081;]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[力扣：合并两个有序链表]]></title>
    <url>%2F2020%2F01%2F30%2F%E5%8A%9B%E6%89%A3%EF%BC%9A%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E6%9C%89%E5%BA%8F%E9%93%BE%E8%A1%A8%2F</url>
    <content type="text"><![CDATA[将两个有序链表合并为一个新的有序链表并返回。新链表是通过拼接给定的两个链表的所有节点组成的。 示例： 输入：1-&gt;2-&gt;4, 1-&gt;3-&gt;4输出：1-&gt;1-&gt;2-&gt;3-&gt;4-&gt;4 题解设定一个哨兵节点 prehead ，这可以在最后让我们比较容易地返回合并后的链表。并且维护一个 preNode指针，我们需要做的是调整它的 next 指针。然后，重复以下过程，直到 l1 或者 l2 指向了 null ：如果 l1 当前位置的值小于等于 l2 ，我们就把 l1 的值接在 prev 节点的后面同时将 l1 指针往后移一个。否则，我们对 l2 做同样的操作。不管我们将哪一个元素接在了后面，我们都把 prev 向后移一个元素。 在循环终止的时候， l1 和 l2 至多有一个是非空的。由于输入的两个链表都是有序的，所以不管哪个链表是非空的，它包含的所有元素都比前面已经合并链表中的所有元素都要大。这意味着我们只需要简单地将非空链表接在合并链表的后面，并返回合并链表。 123456789101112131415161718192021222324252627/** * Definition for singly-linked list. * public class ListNode &#123; * int val; * ListNode next; * ListNode(int x) &#123; val = x; &#125; * &#125; */class Solution &#123; public ListNode mergeTwoLists(ListNode l1, ListNode l2) &#123; ListNode preHead=new ListNode(0); ListNode preNode=preHead; while(l1!=null&amp;&amp;l2!=null)&#123; if(l1.val&lt;=l2.val)&#123; preNode.next=l1; l1=l1.next; &#125;else&#123; preNode.next=l2; l2=l2.next; &#125; preNode=preNode.next; &#125; preNode.next=l1==null?l2:l1; return preHead.next; &#125;&#125; 复杂度分析时间复杂度：O(n + m)。每次循环迭代中，l1 和 l2 只有一个元素会被放进合并链表中， while 循环的次数等于两个链表的总长度。所有其他工作都是常数级别的，所以总的时间复杂度是线性的。 空间复杂度：O(1) 。迭代的过程只会产生几个指针，所以它所需要的空间是常数级别的。]]></content>
      <categories>
        <category>LetCode</category>
      </categories>
      <tags>
        <tag>LetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx配置文件详解（配置文件结构）]]></title>
    <url>%2F2020%2F01%2F30%2FNginx%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3%EF%BC%88%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E7%BB%93%E6%9E%84%EF%BC%89%2F</url>
    <content type="text"><![CDATA[Nginx配置文件结构在nginx的安装目录下的conf目录下有一个nginx.conf,这个就是nginx默认的配置文件，默认的内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113#user nobody;worker_processes 1;error_log logs/error.log;#error_log logs/error.log notice;#error_log logs/error.log info;#pid logs/nginx.pid;events &#123; worker_connections 1024;&#125;http &#123; include mime.types; default_type application/octet-stream; #log_format main '$remote_addr - $remote_user [$time_local] "$request" ' # '$status $body_bytes_sent "$http_referer" ' # '"$http_user_agent" "$http_x_forwarded_for"'; #access_log logs/access.log main; sendfile on; #tcp_nopush on; #keepalive_timeout 0; keepalive_timeout 65; #gzip on; server &#123; listen 80; server_name localhost; #charset koi8-r; #access_log logs/host.access.log main; location / &#123; root html; index index.html index.htm; &#125; #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html &#123; root html; &#125; # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \.php$ &#123; # proxy_pass http://127.0.0.1; #&#125; # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \.php$ &#123; # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #&#125; # deny access to .htaccess files, if Apache's document root # concurs with nginx's one # #location ~ /\.ht &#123; # deny all; #&#125; &#125; # another virtual host using mix of IP-, name-, and port-based configuration # #server &#123; # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125; # HTTPS server # #server &#123; # listen 443 ssl; # server_name localhost; # ssl_certificate cert.pem; # ssl_certificate_key cert.key; # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / &#123; # root html; # index index.html index.htm; # &#125; #&#125;&#125; Nginx配置文件结构： 123456789101112131415161718192021222324.... #全局块events&#123; #events块 &#125;http&#123; #http块 ..... #http全局块 server&#123; #server块 ..... #server全局块 location [PATTERN]&#123; #location块 &#125; location [PATTERN]&#123; &#125; &#125; server&#123; .... &#125;&#125; 1、main：配置影响nginx全局的指令。一般有运行nginx服务器的用户组，nginx进程pid存放路径，日志存放路径，配置文件引入，允许生成worker process数等。可配置的参数如下： （1）user：来指定Nginx Worker进程运行用户以及用户组，默认由nobody账号运行（2）worker_processes：指定了Nginx要开启的子进程数。每个Nginx进程平均耗费10M~12M内存。根据经验，一般指定1个进程就足够了。如果是多核CPU，建议指定和CPU的数量一样的进程数即可。（3）error_log：用来定义全局错误日志文件。日志输出级别有debug、info、notice、warn、error、crit可供选择，其中，debug输出日志最为最详细，而crit输出日志最少。（4）pid：用来指定进程id的存储文件位置。（5）worker_rlimit_nofile：用于指定一个nginx进程可以打开的最多文件描述符数目，这里是65535，需要使用命令“ulimit -n 65535”来设置。配置示例： 1234567&gt; user nobody;worker_processes 1;error_log logs/error.log;error_log logs/error.log notice;error_log logs/error.log info;pid logs/nginx.pid;&gt; 2、events块：配置影响nginx服务器或与用户的网络连接。有每个进程的最大连接数，选取哪种事件驱动模型处理连接请求，是否允许同时接受多个网路连接，开启多个网络连接序列化等。 （1）use：用来指定Nginx的工作模式。Nginx支持的工作模式有select、poll、kqueue、epoll、rtsig和/dev/poll。其中select和poll都是标准的工作模式，kqueue和epoll是高效的工作模式，不同的是epoll用在Linux平台上，而kqueue用在BSD系统中,对于Linux系统，epoll工作模式是首选。（2）worker_connections：用于定义Nginx每个进程的最大连接数，即接收前端的最大请求数，默认是1024。最大客户端连接数由worker_processes和worker_connections决定，即Max_clients=worker_processesworker_connections，在作为反向代理时，Max_clients变为：Max_clients = worker_processes * worker_connections/4。进程的最大连接数受Linux系统进程的最大打开文件数限制，在执行操作系统命令“ulimit -n 65536”后worker_connections的设置才能生效。*配置示例**： 12345&gt; events&#123;&gt; use poll;&gt; worker_connections 1024; &gt;&#125;&gt; 3、http块：可以嵌套多个server，http模块负责HTTP服务器相关属性的配置，有server和upstream两个子模块的配置。如文件引入，mime-type定义，日志自定义，是否使用sendfile传输文件，连接超时时间，单连接请求数等。 （1）include ：设定文件的mime类型,类型在配置文件目录下的mime.type文件定义，来告诉nginx来识别文件类型。（2）default_type：设定了默认的类型为二进制流，也就是当文件类型未定义时使用这种方式，例如在没有配置asp的locate环境时，Nginx是不予解析的，此时，用浏览器访问asp文件就会出现下载了。（3）log_format：用于设置日志的格式，和记录哪些参数，这里设置为main，刚好用于access_log来纪录这种类型。配置示例： 123456789101112&gt; include mime.types;&gt; default_type application/octet-stream;&gt; log_format main '$remote_addr - $remote_user [$time_local] "$request" ' '$status $body_bytes_sent "$http_referer" ' '"$http_user_agent" "$http_x_forwarded_for"'; &gt; access_log logs/access.log main; &gt; sendfile on;&gt; tcp_nopush on; keepalive_timeout 0; keepalive_timeout 65;gzip on;&gt; 4、server块：配置虚拟主机的相关参数，一个http中可以有多个server。 （1）listen：用于指定虚拟主机监听的服务端口。（2）server_name：用来指定IP地址或者域名，多个域名之间用空格分开。（3）root ：表示在这整个server虚拟主机内，全部的root web根目录。注意要和locate {}下面定义的区分开来。（4）index ：全局定义访问的默认首页地址。注意要和locate {}下面定义的区分开来。（5）charset：用于设置网页的默认编码格式。（6）access_log：用来指定此虚拟主机的访问日志存放路径，最后的main用于指定访问日志的输出格式。配置示例： 12345678910&gt; server &#123; listen 80; server_name localhost; root /Users/hk/www; index index.php index.html index.htm; charset utf-8; access_log logs/host.access.log main; aerror_log logs/host.error.log main;&gt;&#125;&gt; 5、location块：location模块 负载均衡,反向代理,虚拟域名等配置。是来定位的，定位URL，解析URL，它也提供了强大的正则匹配功能，也支持条件判断匹配，可以通过location指令实现Nginx对动,静态网页进行过滤处理。 （1）location / 表示匹配访问根目录。（2）root：用于指定访问根目录时，虚拟主机的web目录，这个目录可以是相对路径（相对路径是相对于nginx的安装目录）。也可以是绝对路径。（3）proxy_pass：代理转发，如果在proxy_pass后面的url加/，表示绝对根路径；如果没有/，表示相对路径，把匹配的路径部分也给代理走。（4）proxy_set_header：允许重新定义或者添加发往后端服务器的请求头。（5）include：加载配置文件，后面介绍nginx多个配置文件时候会提到。（6）index：定义页面显示html，一般和alias配合使用。（7）root：定位localtion匹配的url资源路径。配置示例： 12345&gt; location / &#123; root html; index index.html index.htm;&#125;&gt; 6、upstream：模块负债负载均衡模块，通过一个简单的调度算法来实现客户端IP到后端服务器的负载均衡。 Nginx的负载均衡模块目前支持4种调度算法:（1）weight 轮询（默认）。每个请求按时间顺序逐一分配到不同的后端服务器，如果后端某台服务器宕机，故障系统被自动剔除，使用户访问不受影响。weight指定轮询权值，weight值越大，分配到的访问机率越高，主要用于后端每个服务器性能不均的情况下。（2）ip_hash。每个请求按访问IP的hash结果分配，这样来自同一个IP的访客固定访问一个后端服务器，有效解决了动态网页存在的session共享问题。（3） fair。比上面两个更加智能的负载均衡算法。此种算法可以依据页面大小和加载时间长短智能地进行负载均衡，也就是根据后端服务器的响应时间来分配请求，响应时间短的优先分配。Nginx本身是不支持fair的，如果需要使用这种调度算法，必须下载Nginx的upstream_fair模块。（4）url_hash。按访问url的hash结果来分配请求，使每个url定向到同一个后端服务器，可以进一步提高后端缓存服务器的效率。Nginx本身是不支持url_hash的，如果需要使用这种调度算法，必须安装Nginx 的hash软件包。 在HTTP Upstream模块中，可以通过server指令指定后端服务器的IP地址和端口，同时还可以设定每个后端服务器在负载均衡调度中的状态。常用的状态有：down，表示当前的server暂时不参与负载均衡。backup，预留的备份机器。当其他所有的非backup机器出现故障或者忙的时候，才会请求backup机器，因此这台机器的压力最轻。max_fails，允许请求失败的次数，默认为1。当超过最大次数时，返回proxy_next_upstream 模块定义的错误。fail_timeout，在经历了max_fails次失败后，暂停服务的时间。max_fails可以和fail_timeout一起使用。]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx快速入门—基本概念以及在Linux下安装]]></title>
    <url>%2F2020%2F01%2F27%2FNginx%E5%85%A5%E9%97%A8-%E5%AE%89%E8%A3%85Nginx%2F</url>
    <content type="text"><![CDATA[1、什么是Nginx？百度百科： Nginx (engine x) 是一个高性能的HTTP和反向代理web服务器，同时也提供了IMAP/POP3/SMTP服务。Nginx是由伊戈尔·赛索耶夫为俄罗斯访问量第二的Rambler.ru站点（俄文：Рамблер）开发的，第一个公开版本0.1.0发布于2004年10月4日。 我的理解： Nginx(engine x)是一个高性能的HTTP反向代理服务器，特点是占用内存少，并发能力强，事实上nginx的并发能力确实是同类型网页服务器中中表现最好的。Nginx专门为性能优化而开发，性能是其最重要的考量，能经受住高并发的考验，有报告表明能支持高达50000个并发连接数。 2、Nginx中重要的概念 反向代理 负载均衡 动静分离 2.1 反向代理（1）正向代理 正向代理,也就是传说中的代理,他的工作原理就像一个跳板,简单的说,我是一个用户,我访问不了某网站,但是我能访问一个代理服务器，这个代理服务器呢,他能访问那个我不能访问的网站，于是我先连上代理服务器,告诉他我需要那个无法访问网站的内容，代理服务器去取回来,然后返回给我。从网站的角度,只在代理服务器来取内容的时候有一次记录，有时候并不知道是用户的请求,也隐藏了用户的资料,这取决于代理告不告诉网站。 简单说正向代理就是一个位于客户端和原始服务器(origin server)之间的服务器，为了从原始服务器取得内容，客户端向代理发送一个请求并指定目标(原始服务器)，然后代理向原始服务器转交请求并将获得的内容返回给客户端。客户端必须要进行一些特别的设置才能使用正向代理。 图2.1.1 正向代理示意图 （2）反向代理反向代理正好相反，对于客户端而言反向代理服务器就像是原始服务器（实质并不是），并且客户端不需要进行任何特别的设置。客户端向反向代理服务器（例如：Nginx）的命名空间(name-space)中的内容发送普通请求，接着反向代理服务器将判断向何处(原始服务器)转交请求，并将获得的内容返回给客户端，就像这些内容原本就是它自己的一样。 图 2.1.2 反向代理示意图 （3）正向代理和反向代理的区别从用途上来讲：正向代理的典型用途是为在防火墙内的局域网客户端提供访问Internet的途径。正向代理还可以使用缓冲特性减少网络使用率。反向代理的典型用途是将防火墙后面的服务器提供给Internet用户访问。反向代理还可以为后端的多台服务器提供负载平衡，或为后端较慢的服务器提供缓冲服务。另外，反向代理还可以启用高级URL策略和管理技术，从而使处于不同web服务器系统的web页面同时存在于同一个URL空间下。 从安全性来讲：正向代理允许客户端通过它访问任意网站并且隐藏客户端自身，因此你必须采取安全措施以确保仅为经过授权的客户端提供服务。反向代理服务器对外都是透明的，访问者并不知道自己访问的是一个代理服务器。 2.2 负载均衡单个服务器解决不了问题时，我们通过增加服务器的数量，然后将任务分发到各个的服务器上，将原先请求集中到一个服务器上改变为分发到多个服务器，这一过程就是负载均衡。 图2.2.1 负载均衡示意图 2.3 动静分离为了加快网站的解析速度，可以把静态资源和动态资源分开部署到不同的服务器上进行解析，以加快解析速度，降低了原先单个服务器解析的压力。 图2.3.1 动静分离示意图 3、Linux上安装Nginx3.1 安装Nginx所需依赖Nginx安装需要的依赖：pcre、openssl、zlib、和gcc，因此我们需要在安装nginx之前先安装所需的依赖，下面是一条一键安装上面四个依赖的命令： 1yum -y install gcc zlib zlib-devel pcre-devel openssl openssl-devel 3.2 安装Nginx依赖安装完毕后，我们可以到Nginx官网：http://nginx.org/download/ 找到合适的Nginx版本下载下来进行安装。 1234567#在本地新建nginx文件夹mkdir /usr/local/nginxcd /usr/local/nginx#下载nginxwget http://nginx.org/download/nginx-1.17.8.tar.gz#解压nginxtar -zvxf nginx-1.17.8.tar.gz 图3.2.1 解压成功 进入到解压出来的文件夹中执行以下命令; 1234#检查配置./configure#编译安装Nginxmake &amp;&amp; make install 安装成功后就会在/usr/local/nginx下生成Nginx的相关文件conf、html、logs、sbin，如图： 图3.2.1 Nginx目录结构 目录结构说明： conf ：Nginx的配置文件夹，它里面有一个nginx.conf，这是配置Nginx的重要文件 sbin：Nginx命令的目录，如Nginx的启动命令nginx logs：Nginx默认的日志路径，包括错误日志及访问日志 html：这是编译安装时Nginx的默认站点目录，类似 Apache的默认站点htdocs目录 3.3 启动Nginx进入到sbin目录，目录下只有一个执行脚本nginx,执行命令./nginx，然后找到Linux虚拟机的ip直接访问，如果看到下面的画面，证明Nginx就安装成功了： 图3.2.2 安装成功 注意：由于Nginx的配置文件中默认的端口是80，因此当没法访问的时候请先检查你的配置以及对应的端口是否在防火墙中是否是开放的。 检查防火墙端口是否开放：firewall-cmd --list-all 增加ka端口：sudo firewall-cmd --add-port=80 重启防火墙：firewall-cmd --reload]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker实战—手动部署SpringBoot项目到已存在的外部Tomcat]]></title>
    <url>%2F2020%2F01%2F17%2FDocker%E5%AE%9E%E6%88%98%E2%80%94%E6%89%8B%E5%8A%A8%E9%83%A8%E7%BD%B2SpringBoot%E9%A1%B9%E7%9B%AE%2F</url>
    <content type="text"><![CDATA[废话不多说，直接进入正题。在Linux云服务器上先安装docker ,（以centos为例）执行命令yum -y install docker即可。因为Docker 软件包和依赖包已经包含在默认的 CentOS-Extras 软件源里了。然后systemctl docker start即可开启docker服务。（具体的可以参照我的另一篇博客CentOS 7下安装Docker）。因为我的这个项目使用到了MySQL和Redis，因此需要先他们在docker中启动起来，具体操作看下面： 1、启动MySQL容器使用docker pull mysql 拉取最新的官方MySQL镜像，然后执行命令docker run -d --name mysql -e MYSQL_ROOT_PASSWORD=&quot;xxxx&quot; -e MYSQL_DATABASE=&quot;easyblog&quot; -p 3306:3306 docker.io/mysql。 图1 启动mysql容器成功 稍微解释一下命令的含义： > -d &nbsp; &nbsp; &nbsp;后台执行 > -&nbsp;-name&nbsp; &nbsp; &nbsp; 指定容器实例的名称 > -e MYSQL_ROOT_PASSWORD &nbsp; &nbsp; &nbsp; 初始化root用户的密码 > -e MYSQL_DATABASE &nbsp; &nbsp; &nbsp; 在启动的mysql容器中创建一个数据库 > -p &nbsp; &nbsp; &nbsp;映射主机端口和容器端口 2、启动Redis容器同样和启动mysql类似，先docker pull redis 拉取redis，然后执行命令：docker run --name redis -p 6379:6379 -d redis redis-server --appendonly yes --requirepass &quot;xxxx&quot; 图2 启动redis容器成功 命令中 ： > redis-server - -appendonly yes ：在容器执行redis-server启动命令，并打开redis持久化配置 > - -requirepass "xxx" ： 设置redis的密码，不是必须的 3、准备SpringBoot项目并将其打包为****.war由于我们的Tomcat服务器是另外早已经部署好了的，有专门的维护方式。此时我们需要剥离掉SpringBoot应用内置的Tomcat服务器，进而将应用发布并部署到外置的Tomcat容器之中： 3.1、修改打包的方式修改的方法有两种：一种是在使用【Spring Initializr】新建项目的时候选择Packing为war；或者在pom.xml文件中修改 3.1.1 使用【Spring Initializr】新建项目的时候选择Packing为war 图 3.1 选择打包方式 3.1.2 pom.xml文件中修改 1234&lt;artifactId&gt;springboot_servlet_contanier&lt;/artifactId&gt;&lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;!--修改为war的打包方式--&gt;&lt;packaging&gt;war&lt;/packaging&gt; #####3. 2、 排除SpringBoot内置的tomcat 1234567891011&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;!-- 移除嵌入式tomcat插件 --&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; 3.3、 添加原生tomcat依赖123456789101112131415161718192021222324252627&lt;!--添加原生tomcat依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;!--使用jsp还要添加下面对依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;taglibs&lt;/groupId&gt; &lt;artifactId&gt;standard&lt;/artifactId&gt; &lt;version&gt;1.1.2&lt;/version&gt; &lt;type&gt;jar&lt;/type&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/javax.servlet/jstl --&gt;&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;type&gt;jar&lt;/type&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;javax.servlet.jsp&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet.jsp-api&lt;/artifactId&gt; &lt;version&gt;2.2.1&lt;/version&gt;&lt;/dependency&gt; 3.4、 修改启动类，并重写初始化方法12345678910111213141516171819202122232425package top.easyblog;import org.mybatis.spring.annotation.MapperScan;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.boot.builder.SpringApplicationBuilder;import org.springframework.boot.web.servlet.support.SpringBootServletInitializer;import org.springframework.cache.annotation.EnableCaching;@EnableCaching@MapperScan(value = "top.easyblog.mapper")@SpringBootApplication// 修改启动类：继承 SpringBootServletInitializer 并重写 configure 方法public class Application extends SpringBootServletInitializer &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder builder) &#123; // 注意这里一定要指向原先用main方法执行的Application启动类 return builder.sources(Application.class); &#125;&#125; 一些准备就绪后，执行以下Maven命令将我们的程序打成war包： 1mvn clean package -Dmaven.test.skip=true #清除以前target目录下的东西然后打包 -Dmaven.test.skip=true参数的含义是跳过mvn test 打包成功后可以在工程目录的target目录找到项目的war包，把这个war包上传到服务器。这里我使用rz命令把它上传到我服务器的/usr/local/docker/webapps目录下。 3.5、 启动tomcat容器流程还是一样的，先用docker pull tomcat命令拉取tomcat最新版本，然后运行tomcat。运行tomcat时有以下几点注意： 在运行的时候挂载主机的/usr/local/docker/weapps/ROOT.war到tomcat容器内部的webapps目录下。 由于mysql、redis都是在docker容器中运行着，容器之间是隔离的，没有办法通过127.0.0.1/localhost直接通信，但是docker提供了link机制（--link 运行中容器的名字:该容器你给起的别名），可以用于docker内部容器的通信。 最重要的一点 在配置文件中host地址一定要写你配置的–link的名字。切记！ 图 3.2 配置文件host地址的写法示例 一切检查无误后，执行下面的命令启动web服务器—tomcat： 1docker run --name tomcat-8080 -d -p 80:8080 -v /usr/local/docker/webapps/ROOT.war:/usr/local/tomcat/webapps/ROOT.war --link mysql:mysql --link redis:redis docker.io/tomcat 运行结果： 图 3.3 运行成功]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty入门—实现简单的HTTP服务器]]></title>
    <url>%2F2020%2F01%2F04%2FNetty%E5%85%A5%E9%97%A8-%E5%AE%9E%E7%8E%B0%E7%AE%80%E5%8D%95%E7%9A%84HTTP%E6%9C%8D%E5%8A%A1%E5%99%A8%2F</url>
    <content type="text"><![CDATA[Netty是一个基于事件驱动的异步非阻塞网络应用程序框架，可以用于快速开发可维护的高性能协议服务器和客户端，今天我们就用Netty来简单实现一个Http服务器。注意：如果要实现一个完整的Http服务器，那将是十分复杂的。所以，这里只是实现最基本的，请求-响应。 要求：1、Netty 服务器监听8080端口，当浏览器发出http://localhost:8080 请求后，服务器给浏览器返回一句话“服务器收到请求！Hello Client”;2、服务器要对某些特定的请求进行过滤/拦截 废话不多说，直接上代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141package top.easyblog.netty.http;import io.netty.bootstrap.ServerBootstrap;import io.netty.buffer.ByteBuf;import io.netty.buffer.Unpooled;import io.netty.channel.*;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioServerSocketChannel;import io.netty.handler.codec.http.*;import io.netty.util.CharsetUtil;import java.net.URI;/** * @author HuangXin * @since 2020/1/4 21:28 * 使用Netty写一个Http服务器并监听8080端口， * 当浏览器发出http://localhost:8080请求后可以返回给浏览器信息“服务器收到请求！” */public class HttpServer &#123; //监听的端口 private static final int DEFAULT_PORT = 8080; private int port = -1; //bossGroup 只负责处理accept事件 private EventLoopGroup bossGroup; //workerGroup 负责具体的数据业务处理 private EventLoopGroup workerGroup; public HttpServer() &#123; this.bossGroup=new NioEventLoopGroup(); this.workerGroup=new NioEventLoopGroup(); &#125; public HttpServer(int port) &#123; this(); this.port = port; &#125; private ServerBootstrap initServer() &#123; ServerBootstrap serverBootstrap = new ServerBootstrap(); serverBootstrap.group(bossGroup, workerGroup) //设置两个线程组 .channel(NioServerSocketChannel.class) //设置服务器通道的类型 .option(ChannelOption.SO_BACKLOG, 128) //设置线程队连接个数 .childOption(ChannelOption.SO_KEEPALIVE, true) //设置连接保持活动 .childOption(ChannelOption.TCP_NODELAY, true) //设置服务器非延迟发送 .childHandler(new HttpServerChannelInitializer()); ///给workerGroup的pipleline设置hanlder return serverBootstrap; &#125; public void start() &#123; try &#123; ServerBootstrap serverBootstrap = initServer(); ChannelFuture channelFuture; if (port &gt; 0) &#123; channelFuture = serverBootstrap.bind(port).sync(); //监听异步过程bind() channelFuture.addListener((ChannelFutureListener) channelFuture1 -&gt; &#123; if (channelFuture1.isSuccess()) &#123; System.out.println("服务器启动成功，正在监听"+port+"端口"); &#125; else &#123; System.out.println("服务器监听" + port + "端口失败,原因：" + channelFuture1.cause()); &#125; &#125;); &#125; else &#123; channelFuture = serverBootstrap.bind(DEFAULT_PORT).sync(); //监听异步过程bind() channelFuture.addListener((ChannelFutureListener) channelFuture1 -&gt; &#123; if (channelFuture1.isSuccess()) &#123; System.out.println("服务器启动成功，正在监听"+DEFAULT_PORT+"端口"); &#125; else &#123; System.out.println("服务器监听" + DEFAULT_PORT + "端口失败,原因：" + channelFuture1.cause()); &#125; &#125;); &#125; //监听服务器的关闭 channelFuture.channel().closeFuture().sync(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; if (bossGroup != null) &#123; bossGroup.shutdownGracefully(); &#125; if (workerGroup != null) &#123; workerGroup.shutdownGracefully(); &#125; &#125; &#125; /** *定义我们自己的初始化器HttpServerChannelInitializer */ static class HttpServerChannelInitializer extends ChannelInitializer&lt;SocketChannel&gt; &#123; @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; ChannelPipeline pipeline = socketChannel.pipeline(); //HttpSererCodec是netty提供一个基于Http编/解码器 pipeline.addLast(new HttpServerCodec()); //添加自定义的handler pipeline.addLast(new HttpServerHandler()); &#125; &#125; /** * SimpleChannelInboundHandler是ChannelInboundHandler的子类 ，继承SimpleChannelInboundHandler也可以实现一个handler * HttpObject 是客户端和服务器通讯的数据封装 */ static class HttpServerHandler extends SimpleChannelInboundHandler&lt;HttpObject&gt; &#123; //用于读取客户端的数据 @Override protected void channelRead0(ChannelHandlerContext ctx, HttpObject httpObject) throws Exception &#123; if (httpObject instanceof HttpRequest) &#123; System.out.println("客户端地址：" + ctx.channel().remoteAddress()); HttpRequest request= (HttpRequest) httpObject; URI uri=new URI(request.uri()); //过滤部分请求，不响应 if("/static".equals(uri.getPath())||"/image".equals(uri.getPath()))&#123; return; &#125; System.out.println("请求路径：" + ((HttpRequest) httpObject).uri()); ByteBuf content = Unpooled.copiedBuffer("服务器收到请求！Hello Client",CharsetUtil.UTF_8); //构造一个http请求 DefaultFullHttpResponse response = new DefaultFullHttpResponse(HttpVersion.HTTP_1_1, HttpResponseStatus.OK, content); response.headers().set(HttpHeaderNames.CONTENT_TYPE, "text/plain"); response.headers().set(HttpHeaderNames.CONTENT_LENGTH, content.readableBytes()); ctx.channel().writeAndFlush(response).addListener(ChannelFutureListener.CLOSE); &#125; &#125; &#125;&#125; 上面代码看似很长，但是会一点Netty的同学不难看懂，上面的代码无非干了下面几件事： 初始化连个线程池boosGroup和workerGroup，他们的实现类型都是NioEventLoopGroup，其中boosGroup只负责处理accept事件连接请求，workerGroup负责具体的数据业务处理 使用ServerBootStrap进行初始化配置，其中初始化配置有：配置两个事件循环组(boosGroup和workerGroup)，配置服务器通道的类型为NioServerSocketChannel,配置初始化器以及一些其他的配置，具体的代码中有详细对注释。 自定义初始化器，并在初始化其中指定自定义的Handler 自定义Handler，对请求进行处理 并响应请求 启动服务器演示效果123456789101112131415package top.easyblog;import static org.junit.Assert.assertTrue;import org.junit.Test;import top.easyblog.netty.http.HttpServer;/** * Unit test for simple App. */public class AppTest &#123; public static void main(String[] args) &#123; new HttpServer().start(); &#125;&#125; 启动服务器并在postman中输入http://localhost:8080 ,运行结果截图如下：]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Netty入门—"HelloWorld"级别的服务器和客户端TCP通信]]></title>
    <url>%2F2020%2F01%2F03%2FNetty%E5%85%A5%E9%97%A8%E2%80%94HelloWorld%E7%BA%A7%E5%88%AB%E7%9A%84%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%92%8C%E5%AE%A2%E6%88%B7%E7%AB%AFTCP%E9%80%9A%E4%BF%A1%2F</url>
    <content type="text"><![CDATA[首先引入Netty的依赖包，这里以pom的方式导入Netty的依赖 123456&lt;!-- Netty依赖 --&gt;&lt;dependency&gt; &lt;groupId&gt;io.netty&lt;/groupId&gt; &lt;artifactId&gt;netty-all&lt;/artifactId&gt; &lt;version&gt;4.1.44.Final&lt;/version&gt;&lt;/dependency&gt; 编写服务端的程序NettyServer.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131package top.easyblog.netty.simple;import io.netty.bootstrap.ServerBootstrap;import io.netty.buffer.ByteBuf;import io.netty.buffer.Unpooled;import io.netty.channel.*;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.ServerSocketChannel;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioServerSocketChannel;import io.netty.util.CharsetUtil;import io.netty.util.ReferenceCountUtil;/** * @author HuangXin * @since 2020/1/1 21:59 */public class NettyServer &#123; public static void main(String[] args) &#123; //创建两个线程组，BossGroup(只负责连接请求) 和 WorkerGroup（负责具体的业务处理） //这两个线程组都是无限循环执行的，线程组中的线程数量默认是当前CPU核的数量的2倍 /** * 默认的线程数量DEFAULT_EVENT_LOOP_THREADS=当前CPU核的数量的2倍 * private static final int DEFAULT_EVENT_LOOP_THREADS = Math.max(1, SystemPropertyUtil.getInt("io.netty.eventLoopThreads", NettyRuntime.availableProcessors() * 2)); * * protected MultithreadEventLoopGroup(int nThreads, Executor executor, Object... args) &#123; * super(nThreads == 0 ? DEFAULT_EVENT_LOOP_THREADS : nThreads, executor, args); * &#125; */ EventLoopGroup bossGroup = new NioEventLoopGroup(1); //指定bossGroup里的线程数量是1 EventLoopGroup workerGroup = new NioEventLoopGroup(); //没有指定的时候线程数量默认是系统CPU核心数的2倍 try &#123; //创建服务器启动对象 ServerBootstrap bootstrap = new ServerBootstrap(); //bossGroup在bootstrap对象的group成员中，workGroup在childGroup中 bootstrap.group(bossGroup, workerGroup) //设置两个线程组 .channel(NioServerSocketChannel.class) //设置服务器通道的类型 .option(ChannelOption.SO_BACKLOG, 128) //设置线程队列连接个数 .childOption(ChannelOption.SO_KEEPALIVE, true) //设置保持活动的连接状态 .childOption(ChannelOption.TCP_NODELAY,true) //关闭延迟发送 .childHandler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; //给WorkerGroup的Pipeline设置Handler @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; socketChannel.pipeline().addLast(new MyServerHandler()); &#125; &#125;); //绑定一个端口并且启动服务器 ChannelFuture channelFuture = bootstrap.bind(9999).sync(); System.out.println("Server started,listening on"+channelFuture.channel().localAddress()); //对关闭通道这件事进行监听 channelFuture.channel().closeFuture().sync(); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; //完美的关闭两个线程组 bossGroup.shutdownGracefully(); workerGroup.shutdownGracefully(); &#125; &#125;&#125;/** * 自定义Handler 必须继承Netty规定的某个HandlerAdapter,这样我们写的这个类才能被称为Handler */class MyServerHandler extends ChannelInboundHandlerAdapter &#123; /** * 通道有读取事件时时触发这个方法 * * @param ctx 上下文对象，内部封装了许多有用的信息 * @param msg 客户端发送过来的信息 * @throws Exception */ @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; try &#123; ByteBuf buf = (ByteBuf) msg; Channel channel = ctx.channel(); //pipeline的底层数据结构是双向链表 ChannelPipeline pipeline = ctx.pipeline(); System.out.println("pipleline中的channle是否和ctx中的channel一样"+(pipeline.channel()==channel)); System.out.println(channel.remoteAddress() + "发送过来数据：" + buf.toString(CharsetUtil.UTF_8)); ctx.flush(); &#125;finally &#123; //抛弃接受到的数据 ReferenceCountUtil.release(msg); &#125; &#125; /** * 通道的数据读取完毕后就会触发此方法 * * @param ctx 上下文对象，内部封装了许多有用的信息 * @throws Exception */ @Override public void channelReadComplete(ChannelHandlerContext ctx) throws Exception &#123; //将数据写入到缓存中并刷新 ctx.writeAndFlush(Unpooled.copiedBuffer("hello,Client~~", CharsetUtil.UTF_8)); &#125; /** * 发生通道断开时触发此事件 * @param ctx * @throws Exception */ @Override public void channelInactive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println("客户端"+ctx.channel().remoteAddress()+"断开连接..."); ctx.channel().close(); &#125; /** * 发生异常时触发此方法，当发生异常的时候会触发这个方法 * * @param ctx 上下文对象，内部封装了许多有用的信息 * @param cause 异常信息 * @throws Exception */ @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; System.out.println(cause.getMessage()); ctx.close(); &#125;&#125; 编写客户端程序NettyClient.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879package top.easyblog.netty.simple;import io.netty.bootstrap.Bootstrap;import io.netty.buffer.ByteBuf;import io.netty.buffer.Unpooled;import io.netty.channel.*;import io.netty.channel.nio.NioEventLoopGroup;import io.netty.channel.socket.SocketChannel;import io.netty.channel.socket.nio.NioSocketChannel;import io.netty.util.CharsetUtil;/** * @author HuangXin * @since 2020/1/1 21:59 */public class NettyClient &#123; public static void main(String[] args) &#123; EventLoopGroup works = new NioEventLoopGroup(); try&#123; Bootstrap bootstrap=new Bootstrap(); bootstrap.group(works) //设置线程组 .channel(NioSocketChannel.class) //设置客户端的的通道类型 .option(ChannelOption.SO_KEEPALIVE,true) .handler(new ChannelInitializer&lt;SocketChannel&gt;() &#123; //设置处理器 @Override protected void initChannel(SocketChannel socketChannel) throws Exception &#123; socketChannel.pipeline().addLast(new MyClientHandler()); &#125; &#125;); System.out.println("client started,connecting to Server......"); ChannelFuture channelFuture = bootstrap.connect("127.0.0.1", 9999).sync(); System.out.println("connected to server successfully"); //监听客户端的关闭事件 channelFuture.channel().closeFuture().sync(); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; //关闭客户端线程池 works.shutdownGracefully(); &#125; &#125;&#125;class MyClientHandler extends ChannelInboundHandlerAdapter&#123; /** * 当通道就绪的时候就会触发这个方法，可以用这个方法发送消息 * @param ctx 上下文对象，内部封装了许多有用的信息 * @throws Exception */ @Override public void channelActive(ChannelHandlerContext ctx) throws Exception &#123; System.out.println("channel is active"); ChannelFuture channelFuture = ctx.writeAndFlush(Unpooled.copiedBuffer("hello,Sever!", CharsetUtil.UTF_8)); channelFuture.addListener((ChannelFutureListener)-&gt;&#123; System.out.println("message send successfully!"); &#125;); ctx.flush(); &#125; @Override public void channelRead(ChannelHandlerContext ctx, Object msg) throws Exception &#123; System.out.println("Channel is readable"); ByteBuf buf= (ByteBuf) msg; System.out.println("服务器回复的消息:"+buf.toString(CharsetUtil.UTF_8)); System.out.println("服务器的地址："+ctx.channel().remoteAddress()); ctx.flush(); &#125; @Override public void exceptionCaught(ChannelHandlerContext ctx, Throwable cause) throws Exception &#123; System.out.println("caught Exception"); System.out.println(cause.getMessage()); ctx.channel().close(); &#125;&#125; 先后启动服务器端和客户端，运行结果在预料之中，服务器收到客户端的数据之后，给客户端响应了数据：]]></content>
      <categories>
        <category>Netty</category>
      </categories>
      <tags>
        <tag>Netty</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[记一次在云服务器上部署项目的实践经历]]></title>
    <url>%2F2020%2F01%2F02%2F%E8%AE%B0%E4%B8%80%E6%AC%A1%E5%9C%A8%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%B8%8A%E9%83%A8%E7%BD%B2%E9%A1%B9%E7%9B%AE%E7%9A%84%E5%AE%9E%E8%B7%B5%E7%BB%8F%E5%8E%86%2F</url>
    <content type="text"><![CDATA[一、Linux上Java的安装与配置由于使用 yum 或者 apt-get 命令 安装 openjdk 可能存在类库不全，从而导致用户在安装后运行相关工具时可能报错的问题，所以此处我们推荐采用手动解压安装的方式来安装 JDK。具体步骤如下： 1.下载 JDK近入 Oracle 官方网站 下载载合适的 JDK 版本，准备安装。 注意：不要下错了，需要下载 Linux 版本。这里以jdk-8u151-linux-x64.tar.gz为例，你下载的文件可能不是这个版本，这没关系，只要后缀(.tar.gz)一致即可。 2. 创建目录在/usr/local目录下创建java目录， 12mkdir /usr/local/javacd /usr/local/java 把下载的文件 jdk-8u151-linux-x64.tar.gz 放在/usr/local/java/目录下。 向Linux上传文件可以使用rz命令，非常方便，它会把文件默认放在执行命令的（当前）目录下。传送门：Linux下安装、使用rz和sz 3. 解压 JDKtar -zxvf jdk-8u151-linux-x64.tar.gz 4. 设置环境变量vim /etc/profile在 profile 文件中添加如下内容并保存： 123456set java environmentJAVA_HOME=/usr/local/java/jdk1.8.0_151 JRE_HOME=/usr/local/java/jdk1.8.0_151/jre CLASS_PATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar:$JRE_HOME/libPATH=$PATH:$JAVA_HOME/bin:$JRE_HOME/binexport JAVA_HOME JRE_HOME CLASS_PATH PATH 注意：其中 JAVA_HOME， JRE_HOME 请根据自己的实际安装路径及 JDK 版本配置。 让修改生效：source /etc/profile 5. 测试输入命令java -version显示 java 版本信息，则说明 JDK 安装成功： 123java version &quot;1.8.0_151&quot;Java(TM) SE Runtime Environment (build 1.8.0_151-b12)Java HotSpot(TM) 64-Bit Server VM (build 25.151-b12, mixed mode) 二、Linux上MySQL的安装和配置1. 下载安装包输入命令:rpm -ivh http://dev.mysql.com/get/mysql57-community-release-el7-8.noarch.rpm 输入命令:yum install -y mysql-server 2. 检查是否设置成功输入命令：systemctl list-unit-files | grep mysqld 3. 查看默认密码输入命令:grep &#39;temporary password&#39; /var/log/mysqld.log 如果不行（没有反应），则按一下步骤： 1.删除原来安装过的mysql残留的数据（这一步非常重要，问题就出在这）rm -rf /var/lib/mysql2.重启mysqld服务systemctl restart mysqld3.再去找临时密码grep &#39;temporary password&#39; /var/log/mysqld.log 4. 登录mysql输入命令:mysql -uroot -p，此时输入上一步查看的默认密码，进入MySQL 5. 修改密码等级登录数据库后的第一件是就是修改密码，因为如果你不修改密码也用不了~~ 1234#选择数据库use mysql #修改数据库密码sqlALTER USER ‘root’@'%' IDENTIFIED WITH mysql_native_password BY 'newpassword(你的密码)'; 如果输入的密码过于简单，则需要进行安全策略的修改，否则会出现以下的错误: Your password does not satisfy the current policy requirements 此时将密码的优先级设置为LOW，在mysql里面输入命令:set global validate_password_policy=0; 如果不行， 1、查看 mysql 的密码策略，输入命令 “ SHOW VARIABLES LIKE &#39;validate_password%&#39;;” 进行查看.2、首先需要设置密码的验证强度等级，设置 validate_password_policy 的全局参数为 LOW 即可，输入设值命令 “ set global validate_password_policy=LOW;” 进行设值在MySQL8.x中请执行set global validate_password.policy=LOW;3、当前密码长度为 8 ，如果不介意的话就不用修改了，按照通用的来讲，设置为 6 位的密码，设置 validate_password_length 的全局参数为 6 即可，输入命令 “set global validate_password_length=6; ” 进行设值在MySQL8.x中请执行set global validate_password_length=6; 开启远程授权登陆输入命令:GRANT ALL PRIVILEGES ON *.* TO &#39;root&#39;@&#39;%&#39; IDENTIFIED BY &#39;XXXXX&#39; WITH GRANT OPTION其中XXXXX是修改的密码 连接本地可视化数据库客户端在本地使用可视化数据库客户端连接测试数据库是否配置好，这里我使用的是Navicat，创建连接后成功与服务器上的MySQL连接上了 如果没有连接上，请耐心检查上免的配置，以及防火墙是否没有开放3306端口 1234567firewall-cmd --state#查看已开放的列表firewall-cmd --list-ports#添加要开放的列表firewall-cmd --zone=public --add-port=3306/tcp --permanent#重启防火墙firwall-cmd --reload 三、Linux上Redis的安装和配置由于我的项目中使用到了Redis，因此需要在服务器中安装Redis，安装配置也很就简单详请参考我的这篇博客：Linux上安装配置Redis这里特别需要注意最好不要使用Redis的默认端口连接，而且最好给Redis设置个密码，毕竟项目是要在真实的服务器上运行的，会面临各种意想不到的事（我就遇到了，项目刚上线运行3天就被”肉鸡”了，上网一查原因就是有Redis导致的。）。 四、Linux下安装Tomcat1. 下载在命令行输入命令：wget https://mirrors.aliyun.com/apache/tomcat/tomcat-8/v8.5.49/bin/apache-tomcat-8.5.49.tar.gz 2. 解压tar -zvxf apache-tomcat-8.5.49.tar.gz 解压后会在当前目录下得到解压后的得文件，把它移动到/usr/local/tomcat目录下mv apache-tomcat-8.5.49 /usr/local/tomcat/ 之后打开apache-tomcat-8.5.49下的conf文件夹中的server.xml文件 vim server.xml，配置第69行的Connector的port为80，表示监听80端口 简单配置后按Esc键后输入:wq保存配置 3. 部署项目我们的项目以war包的形式放在webapps目录下即可，然后到bin目录下执行./startup.sh启动tomcat，启动后就可以访问部署的项目了，访问的URL形式是：http://主机公网ip:端口/war包的名字/项目路径；如果想省去中间war包的名字可以直接把我的的war包命名为ROOT.war覆盖原来的ROOT目录，之后我访问项目的URL是：http://主机公网ip:端口/项目路径 工具安装Linux下安装、使用rz和szrzsz 官网入口：http://freecode.com/projects/lrzsz/lrzsz是一个unix通信套件提供的X，Y，和ZModem文件传输协议 windows 需要向centos服务器上传文件，可直接在centos上执行命令yum -y install lrzsz程序会自动安装好，然后如你要下载者sz [找到你要下载的文件] 如果你要上传，者rz 浏览找到你本机要上传的文件。需要注意的是这个命令无法在putty界面使用哦！ 安装与使用yum安装1[root@ecs-sn3-medium-2-linux-20191128162047 /]# yum -y install lrzsz 使用上传文件，执行命令rz，会跳出文件选择窗口，选择好文件，点击确认即可。 1[root@ecs-sn3-medium-2-linux-20191128162047 /]# rz 下载文件，执行命令sz 1[root@ecs-sn3-medium-2-linux-20191128162047 /]# sz Linux下Maven的安装和环境配置1. 下载maven输入命令下载安装包：wget http://mirrors.cnnic.cn/apache/maven/maven-3/3.3.9/binaries/apache-maven-3.3.9-bin.tar.gz输入解压命令：tar vxf apache-maven-3.3.9-bin.tar.gz在usr的local目录下创建maven3文件夹，切换到local目录，输入命令:cd /usr/local,在当前目录下创建maven3文件夹，输入命令:mkdir maven3将解压过后的文件夹移动到这个目录下，输入命令：mv apache-maven-3.3.9 /usr/local/maven3 2. 配置环境变量打开配置文件，输入命令:vim /etc/profile 123#Mavenexport MAVEN_HOME=/usr/local/maven3export PATH=$&#123;PATH&#125;:$&#123;MAVEN_HOME&#125;/apache-maven-3.6.3/bin 3. 生效环境变量输入命令:source /etc/profile 4. 查看安装配置是否成功输入命令:mvn -version如果提示一下信息，则表示安装成功： 提示：这一步要想成功，请务必确认你的Java环境是否配置正确，如果Java配置正确，这一步按流程来应该没有问题。]]></content>
      <categories>
        <category>运维</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[力扣：最接近的三数之和]]></title>
    <url>%2F2020%2F01%2F02%2FLeetCode%20%E7%AC%AC16%E9%A2%98%2F</url>
    <content type="text"><![CDATA[给定一个包括 n 个整数的数组 nums 和 一个目标值 target。找出 nums 中的三个整数，使得它们的和与 target 最接近。返回这三个数的和。假定每组输入只存在唯一答案。 例如，给定数组 nums = [-1，2，1，-4], 和 target = 1. 与 target 最接近的三个数的和为 2. (-1 + 2 + 1 = 2). 解题思路：双指针法 ，具体看下面的图解1. 2. 3. 4. 5. 6. 7. 8. 9. 10. 通过图解可以很清楚的看到本题的一个解决思路，先给给定的数组升序排序： 从头开始遍历数组，以遍历到的当前的下标为基准(i)，i+1定义为s(start)即双指针的开始，e初始在数组末尾； 当s和e没有重叠的时候，每次求nums[i]+nums[s]+nums[e]的和(sum)， 如果满足|target-ant|的差值大于|target-sum|的差值那就更新ant的值； 接下来判断当前sum和target的差距大小，如果sum&gt;target，那么就让尾指针-1（这样做又可以使得结果更好）否者让头指针s+1(同样的原因)。不断夹逼,最终当剩余的数&lt;3个的时候结束，并返回当前的ant的值。（无论第三步有没有执行这一步始终会执行） 源码实现：123456789101112131415161718192021222324class Solution &#123; public int threeSumClosest(int[] nums, int target) &#123; Arrays.sort(nums); int ant=nums[0]+nums[1]+nums[2]; //初始数据最前3个数的和 for(int i=0,len=nums.length;i&lt;len;i++)&#123; int s=i+1,e=len-1; while(s&lt;e)&#123; int sum=nums[i]+nums[s]+nums[e]; if(Math.abs(target-ant)&gt;Math.abs(target-sum))&#123; ant=sum; &#125; //根据结果计算下一步的操作是移动s指针还是移动e指针 if(sum&gt;target)&#123; e--; &#125;else if(sum&lt;target)&#123; s++; &#125;else&#123; return ant; &#125; &#125; &#125; return ant; &#125;&#125; 整个过程，对数组排序的时间复杂度是O(nlogn)，固定值为 n 次，双指针为 n 次，时间复杂度为 O(n^2)，总的时间复杂度是O(n^2)]]></content>
      <categories>
        <category>LetCode</category>
      </categories>
      <tags>
        <tag>LetCode</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis的Java客户端]]></title>
    <url>%2F2019%2F09%2F30%2FRedis%E7%9A%84%E5%AE%A2%E6%88%B7%E7%AB%AF%2F</url>
    <content type="text"><![CDATA[Jedis连接Redis1.添加Jedis依赖 12345&lt;dependency&gt; &lt;groupId&gt;redis.clients&lt;/groupId&gt; &lt;artifactId&gt;jedis&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt;&lt;/dependency&gt; 2.在虚拟机端配置：将bind注释掉，然后改protected-mode为no 改了之后保存并重启Redis。 3.使用Jedis提供的Jedis这个工具类来连接Jedis，首先在虚拟机使用ifconfig命令查看虚拟机的ip，然后向Redis发送一个ping命令，测试一下是否可以连接上远程的Redis: 1234567891011121314151617public class RedisTest &#123; private Jedis jedis = null; @Before public void getConnection() &#123; jedis = new Jedis("192.168.92.128", 6379); &#125; /** * 测试和虚拟机上的Redis的连通性 */ @Test public void pingTest() &#123; System.out.println(jedis.ping()); &#125;&#125; 可以连接上Redis的标志是程序运行后打印”PONG“ 如果程序运行出现了JedisConnectionException，这种情况要么是你代码中把ip或端口写错了，要不就是由于Linux的防火墙导致的，在你确定你没有写错ip或端口的前提下，你可以直接关闭防火墙或者为了安全你可以开放6379这个端口给远程，Centos 7上开放端口有关的命令操作如下： 12345678# 开放6379端口firewall-cmd --permanent --add-port=6379/tcp# 查询端口是否开放，yes就是开放的firewall-cmd --query-port=6379/tcp# 重新加载配置firewall-cmd --reload# 移除指定开放的端口firewall-cmd --permanent --remove-port=6379/tcp Jedis常用APIJedis操作Redis的常用API几乎和Redis的命令是一样的，比如操作String： 1234567891011121314151617181920212223242526272829303132333435363738394041424344 /** * String类型的数据接的测试 */ @Test public void testString() &#123; //set 添加key和value 如果已经有了就覆盖 jedis.set("k1", "111"); jedis.set("k2", "222"); jedis.set("k3", "333"); //get 获取值 System.out.println(jedis.get("k1") + " " + jedis.get("k2") + " " + jedis.get("k3")); //set可以设置参数：EX（秒）/PX（毫秒）--&gt;过期时间 NX 不存在时操作 XX存才时操作 jedis.set("k4", "444", new SetParams().nx()); //key不存在的时候进行操作 jedis.set("k3", "123", new SetParams().xx()); //key存在的时候操作 jedis.set("k5", "345", new SetParams().ex(60)); //设置key的生命时间,单位s jedis.set("k6", "666", new SetParams().px(10000)); //设置key的生命时间,单位ms //append 追加内容 jedis.append("k1", "hello"); //追加 //STRLEN System.out.println(jedis.get("k1") + ",v1的长度：" + jedis.strlen("k1")); //INCR INCRBY DECR DECRBY jedis.incr("k6"); //加1 jedis.incrBy("k5", 100); //加任意增量 jedis.decr("k4"); //减1 jedis.decrBy("k3", 100); //减去任意减量 System.out.println(jedis.get("k3") + " " + jedis.get("k4") + " " + jedis.get("k5") + " " + jedis.get("k6") + " "); //GETRANGE 获得字符串的一部分 System.out.println(jedis.getrange("k1", 0, -1)); //SETRANGE 设置字符串的一部分 jedis.setrange("k1", 0, "redis"); System.out.println(jedis.get("k1")); jedis.mset("msg1", "hello", "msg2", "error", "msg3", "success"); System.out.println(jedis.mget("msg1", "msg2", "msg3"));&#125; 可以看到通过Jedis操作Redis所调用的API和Redis的命令是一样的，所以只要熟悉Redis的关于5大常用数据类型的命令，那么使用Jedis操作Redis就没有大的问题。如果你还不是熟悉Redis的关于5大常用数据类型的命令，可以参考我的这篇笔记：Redis五大常用数据类型 Jedis事务Redis中和事务有关的命令：mulit、exec，discard，watch和unwatch，然而Jedis中操作Redis事务的API也和这几个命令是一样的，比如我们实现一个简单的事务： 1234567891011121314@Test public void tx()&#123; Jedis jedis=new Jedis("192.168.92.128", 6379); Transaction transaction = jedis.multi();//开启事务 //命令入队 transaction.set("k1","v1"); transaction.set("k2","v2"); transaction.get("k1"); //执行事务 List&lt;Object&gt; exec =transaction.exec(); //transaction.discard(); //取消事物 //打印执行事务后的返回结果 exec.forEach(ele-&gt;System.out.println(ele)); &#125; 有两个关键字balance表示信用卡的余额（初始值为1000），debt表示信用卡的欠额（初始值为0），使用redis提供的乐观锁watch来实现对消费的记录 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253package com.xust.iot;import redis.clients.jedis.Jedis;import redis.clients.jedis.Transaction;import java.util.List;public class TxTest &#123; private Integer balance; //账户余额 private Integer debt; //账户欠额 private static Jedis jedis = new Jedis("192.168.92.128", 6379); private static final int autoDECR = 10; //模拟每次消费的金额 public boolean coustmer() &#123; try &#123; String balance = jedis.watch("balance");//开启监控 //jedis.mset("balance","100","debt","400"); //模拟另一个线程在本线程开启了对balance监控以后改变了balance的值 this.balance = Integer.parseInt(jedis.get("balance")); List&lt;Object&gt; exec =null; if (this.balance &gt; autoDECR) &#123; Transaction transaction = jedis.multi(); //开启事务 transaction.decrBy("balance", autoDECR); transaction.incrBy("debt", autoDECR); exec = transaction.exec(); //提交事务,执行事务后会自动unwatch &#125; else &#123; jedis.unwatch(); &#125; if(null!=exec)&#123; System.out.println("操作成功："); System.out.println("余额："+jedis.get("balance") + " 欠额：" + jedis.get("debt")); return true; &#125;else&#123; System.out.println("操作失败，监控到balance发生改动"); return false; &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; jedis.close(); //关闭连接 &#125; return false; &#125; public static void main(String[] args) &#123; TxTest txTest = new TxTest(); while (!txTest.coustmer()); //自旋，直到执行成功为止 &#125;&#125; 正常情况下（就是没有别的线程干扰）： 异常情况下： 解释一下这两种不同的结果：当开启监控后，如果期间别的线程把监控的关键字的值改变了，那么Redis就会在本次事务期间不执行任何操作，即使使用exec提交事务了，也不会执行（这时返回exec的返回值是null），这种基于CAS的监控，不仅保证了共享数据的安全，而且还提高了响应速速。这也正是程序所体现的，当jedis.mset(“balance”,”100”,”debt”,”400”); 这条语句被注释掉以后，程序可以正常执行，执行后返回true,程序结束；当jedis.mset(“balance”,”100”,”debt”,”400”);语句没有注释以后，在开启watch以后，相当于别的进程改变了监控关键字的值，那么这时Redis就不会在执行事务了，exec就会返回false，然后 while (!txTest.coustmer()); 就又再次调用方法，直到执行成功，然后结束程序。 JediaPool连接池类似于mysql的数据库连接池c3p0、Durid等，JedisPool是java连接Redis的连接池，基本的使用方式如下： 123456789101112131415161718public class RedisTest2 &#123; public static void main(String[] args) &#123; // 比较特殊的是，redis连接池的配置首先要创建一个连接池配置对象 JedisPoolConfig config = new JedisPoolConfig(); // 当然这里还有设置属性的代码 // 创建Jedis连接池对象 JedisPool jedisPool = new JedisPool(config,"localhost",6379); // 获取连接 Jedis jedis = jedisPool.getResource(); // 使用 // 关闭，归还连接到连接池 jedis.close(); &#125;&#125; 一般我们可以各种配置的代码抽取出来写一个工具类，下面是一个基于单例模式的JedisPoolUtils：首先我们需要一个redis.properties的配置文件，用于配置JedisPool的一些属性： 1234redis.host=192.168.92.128redis.port=6379redis.maxTotal=50redis.maxIdle=10 JedisPoolUtils.java 1234567891011121314151617181920212223242526public class JedisPoolUtils &#123; private static volatile JedisPool jedisPool=null; public JedisPoolUtils()&#123;&#125; public static JedisPool getJedisPool()&#123; if(null==jedisPool)&#123; synchronized (JedisPoolUtils.class)&#123; if(null==jedisPool)&#123; try &#123; //设置各种属性 JedisPoolConfig poolConfig = new JedisPoolConfig(); ResourceBundle rs = ResourceBundle.getBundle("redis"); poolConfig.setMaxIdle(Integer.parseInt(rs.getString("redis.maxIdle"))); poolConfig.setMaxTotal(Integer.parseInt(rs.getString("redis.maxTotal"))); jedisPool = new JedisPool(poolConfig, rs.getString("redis.host"),Integer.parseInt(rs.getString("redis.port"))); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125; &#125; &#125; &#125; return jedisPool; &#125;&#125; 然后测试一下我们的JedisPoolUtils工具类： 12345678910public class JedisPoolTest &#123; public static void main(String[] args)&#123; JedisPool jedisPool = JedisPoolUtils.getJedisPool(); Jedis jedis = jedisPool.getResource(); jedis.set("msg","jedisPopl test success!"); System.out.println(jedis.get("msg")); jedis.close(); //把jedis放回池子 &#125;&#125; 测试结果： SpringBoot连接Redis导入redis的相关依赖1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; 在application.properties/yml中配置redis的有关连接信息123456789101112spring: #Redis的有关配置 redis: host: 192.168.92.128 port: 6379 password: jedis: pool: max-wait: 200 max-idle: 10 max-active: 10 timeout: 2000 自定义RedisTemplate&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SpringBoot自动帮我们在容器中生成了一个RedisTemplate和一个StringRedisTemplate。我们可以使用RedisTemplate来像Jedis一样操作Redis。但是，这个RedisTemplate的泛型是&lt;Object,Object&gt;，写代码不方便，需要写好多类型转换的代码；我们需要一个泛型为&lt;String,Object&gt;形式的RedisTemplate。并且，这个RedisTemplate没有设置数据存在Redis时，key及value的序列化方式。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 看到这个@ConditionalOnMissingBean注解后，就知道如果Spring容器中有了RedisTemplate对象了，这个自动配置的RedisTemplate不会实例化。因此我们可以直接自己写个配置类，配置RedisTemplate。 RedisConfig.java 1234567891011121314151617181920212223242526272829@Configurationpublic class RedisConfig &#123; /*** * 自定义的redisTemplate * @param factory * @return */ @Bean public RedisTemplate&lt;Object, String&gt; redisTemplate(RedisConnectionFactory factory) &#123; RedisTemplate&lt;Object, String&gt; redisTemplate = new RedisTemplate&lt;&gt;(); redisTemplate.setConnectionFactory(factory); Jackson2JsonRedisSerializer jackson2JsonRedisSerializer = new Jackson2JsonRedisSerializer(Object.class); ObjectMapper om = new ObjectMapper(); om.setVisibility(PropertyAccessor.ALL, JsonAutoDetect.Visibility.ANY); om.enableDefaultTyping(ObjectMapper.DefaultTyping.NON_FINAL); jackson2JsonRedisSerializer.setObjectMapper(om); //默认的序列化方式:jackson redisTemplate.setDefaultSerializer(jackson2JsonRedisSerializer); redisTemplate.setKeySerializer(RedisSerializer.string()); //设置了默认的序列化就不需要在设置下面的了，因为afterPropertiesSet()中会设置为默认的序列化方式 //redisTemplate.setValueSerializer(jackson2JsonRedisSerializer); //redisTemplate.setHashKeySerializer(jackson2JsonRedisSerializer); //redisTemplate.setHashValueSerializer(jackson2JsonRedisSerializer); redisTemplate.afterPropertiesSet(); return redisTemplate; &#125;&#125; Redis工具类我们大家接触过Redis的都知道，Redis有5大常用数据类型，String、List、Hash、Set和ZSet。SpringBoot集成redis的RedisTemplate,也分别提供的对这些数据类型的操作。也有5大类： redisTemplate.opsForValue() //操作字符串 redisTemplate.opsForList() //操作List redisTemplate.opsForHash //操作hash redisTemplate.opsForSet //操作Set redisTemplate.opsForZet //操作Zset 但是对于Redis的具体类型的操作，SpringBoot提供的API并没有完全和Redis的命令统一，用起来有一点不爽，因此为了和Redis的命令保持统一（就像Jedis那样），我们可以对SpringBoot提供的Template中的API进行再次分装，写一个工具类，目的：一是保持和Redis命令的统一，二是练习一下以加深对RedisTemplate以及Redis命令的记忆和理解。 由于太多了所以我只展示部分代码，完整的代码大家可以到我的GitHub上查看。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312@Componentpublic class RedisUtils &#123; @Autowired private RedisTemplate&lt;Object, String&gt; redisTemplate; /** * 设置某个key的过期时间 * * @param key * @param timeout * @return */ public boolean expire(String key, long timeout) &#123; if (timeout &gt; 0) &#123; try &#123; redisTemplate.expire(key, timeout, TimeUnit.SECONDS); return true; &#125; catch (Exception e) &#123; return false; &#125; &#125; return false; &#125; /*** * 查看某个key的过期时间 * @param key * @return 过期时间 （秒/s） */ public long ttl(String key) &#123; if (null != key) &#123; Long expire = redisTemplate.getExpire(key, TimeUnit.SECONDS); if (Objects.nonNull(expire)) &#123; return expire; &#125; return -2L; &#125; return -2L; //key不存在，返回-2 &#125; /** * 判断是否存在某个key * * @param key * @return */ public boolean exists(String key) &#123; if (null != key) &#123; Boolean exists = redisTemplate.hasKey(key); return Objects.nonNull(exists); &#125; return false; &#125; /** * 获得某个key的类型 * * @param key * @return */ public DataType type(String key) &#123; if (null != key) &#123; return redisTemplate.type(key); &#125; return null; &#125; /** * 获得当前数据库中的所有key * * @param patten * @return */ public Set&lt;Object&gt; allKeys(Object patten) &#123; return redisTemplate.keys(patten); &#125; /** * 把当前库中的一个key移动到dbID这个数据库中 * @param key * @param dbID * @return */ public boolean move(String key, int dbID) &#123; if (null == key || dbID &lt; 0) &#123; return false; &#125; Boolean move = redisTemplate.move(key, dbID); return Objects.nonNull(move); &#125; /** * 删除一个或多个key * * @param key */ public void del(String... key) &#123; if (Objects.nonNull(key) &amp;&amp; key.length &gt; 0) &#123; if (key.length == 1) &#123; redisTemplate.delete(key); &#125; else &#123; String s=append(key); if(Objects.nonNull(s)) &#123; redisTemplate.delete(s); &#125; &#125; &#125; &#125; /** * 设置字符串 * * @param key * @param value * @return */ public boolean set(String key, String value) &#123; if (Objects.nonNull(key) &amp;&amp; Objects.nonNull(value)) &#123; redisTemplate.opsForValue().set(key, value); return true; &#125; return false; &#125; public boolean set(String key, String value, String command, long timout) &#123; if (Objects.nonNull(key) &amp;&amp; Objects.nonNull(value) &amp;&amp; Objects.nonNull(command) &amp;&amp; timout &gt; 0) &#123; if ("ex".equals(command.toLowerCase())) &#123; redisTemplate.opsForValue().set(key, value, timout, TimeUnit.SECONDS); &#125; else if ("px".equals(command.toLowerCase())) &#123; redisTemplate.opsForValue().set(key, value, timout, TimeUnit.MILLISECONDS); &#125; return true; &#125; return false; &#125; public boolean set(String key, String value, String absent) &#123; Boolean res=null; if (Objects.nonNull(key) &amp;&amp; Objects.nonNull(value) &amp;&amp; Objects.nonNull(absent)) &#123; if ("nx".equals(absent.toLowerCase())) &#123; res = redisTemplate.opsForValue().setIfAbsent(key, value); &#125; else if ("xx".equals(absent.toLowerCase())) &#123; res = redisTemplate.opsForValue().setIfPresent(key, value); &#125; &#125; return Objects.nonNull(res); &#125; public boolean set(String key, String value, String command, long timout, String absent) &#123; if (Objects.nonNull(command)) &#123; boolean res = this.set(key, value, absent); if (res) &#123; this.set(key, key, command, timout); return true; &#125; &#125; else if (Objects.nonNull(absent)) &#123; return this.set(key, value, absent); &#125; return false; &#125; /** * 为多个键分别设置它们的值 * * @param map */ public void mset(Map&lt;String, String&gt; map) &#123; if (Objects.nonNull(map) &amp;&amp; map.size() &gt; 0) &#123; redisTemplate.opsForValue().multiSet(map); &#125; &#125; /** * 为多个键分别设置它们的值，仅当键不存在时 * * @param map */ public void msetnx(Map&lt;String, String&gt; map) &#123; if (Objects.nonNull(map)) &#123; redisTemplate.opsForValue().multiSetIfAbsent(map); &#125; &#125; /** * 获得指定key的value * * @param key * @return */ public String get(String key) &#123; if (Objects.nonNull(key)) &#123; return redisTemplate.opsForValue().get(key); &#125; return null; &#125; /** * 获取所有给定键的值 * * @param keys * @return */ public List&lt;String&gt; mget(Collection&lt;String&gt; keys) &#123; if (Objects.nonNull(keys) &amp;&amp; keys.size() &gt; 0) &#123; return redisTemplate.opsForValue().multiGet(Collections.singleton(keys)); &#125; return null; &#125; /** * 截取指定key的value的部分 * * @param key * @param start 开始的下标 * @param stop 结束的下标 * @return */ public String getRange(String key, long start, long stop) &#123; if (Objects.nonNull(key)) &#123; return redisTemplate.opsForValue().get(key, start, stop); &#125; return null; &#125; /** * key--&gt;value对value的长度 * * @param key * @return */ public long strlen(String key) &#123; if (Objects.nonNull(key)) &#123; Long size = redisTemplate.opsForValue().size(key); return Objects.isNull(size) ? 0L : size; &#125; return 0L; &#125; /** * 字符串追加 * * @param key * @param s * @return 执行key追加后的 */ public long append(String key, String s) &#123; if (Objects.nonNull(key)) &#123; Integer length = redisTemplate.opsForValue().append(key, s); return Objects.isNull(length) ? strlen(key) : length; &#125; return 0L; &#125; public long incr(String key) &#123; return incrBy(key, 1); &#125; public long incrBy(String key, long increment) &#123; if (Objects.nonNull(key)) &#123; try &#123; Long value = redisTemplate.opsForValue().increment(key, increment); return Objects.isNull(value) ? 0L : value; &#125; catch (NumberFormatException ex) &#123; throw new NumberFormatException("非数字不可加"); &#125; &#125; return 0L; &#125; public long decr(String key) &#123; return this.decrBy(key, 1); &#125; public long decrBy(String key, long decrement) &#123; if (Objects.nonNull(key)) &#123; try &#123; Long value = redisTemplate.opsForValue().decrement(key, decrement); return Objects.isNull(value) ? 0L : value; &#125; catch (NumberFormatException ex) &#123; throw new NumberFormatException("非数字不可减"); &#125; &#125; return 0L; &#125; /** * 在指定偏移处开始的键处覆盖字符串的一部分 * * @param key * @param offset * @param value */ public void setRange(String key, long offset, String value) &#123; if (Objects.nonNull(key)) &#123; redisTemplate.opsForValue().set(key, value, offset); &#125; &#125; //省略....&#125;]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis之主从复制]]></title>
    <url>%2F2019%2F09%2F28%2FRedis%E4%B8%BB%E4%BB%8E%E5%A4%8D%E5%88%B6%2F</url>
    <content type="text"><![CDATA[主从复制概述&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master)，后者称为从节点(salve)。数据的复制是单向的，只能从主节点到从结点。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;默认情况下，每台Redis服务器都是主节点，且一个主节点可以有多个从结点（或没有从结点），但是一个从结点只能有一个主节点。 主从复制的作用 数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。 故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。 负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。 读写分离：可以用于实现读写分离，主库写、从库读，读写分离不仅可以提高服务器的负载能力，同时可根据需求的变化，改变从库的数量； 高可用的基石：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。 主从复制启用前面提到过，默认情况下每台Redis服务器都是主节点（master）,而且如果没有配置的话，是没有从服务器的。（可以使用info replication命令查看一个Redis服务器的复制有关的信息） 有三种方式可以开启主从： 配置文件：在从服务器的配置文件中加入slaveof &lt;主节点ip&gt; &lt;主节点port&gt;。 启动命令：redis-server启动命令后面加入--slaveof &lt;主节点ip&gt; &lt;主节点port&gt;。 客户端命令：Redis服务器启动后，直接通过客户端执行命令slaveof &lt;主节点ip&gt; &lt;主节点port&gt;，返回OK后该Redis实例就成为了从节点。 Redis常用的主从拓扑1主N从所谓的1主N从指的是一个主Redis服务器（master）可以有一个或多个从Redis服务器（salve）,这种拓扑关系的特点是： 只有一个主节点，有一个或多个从结点； 主节点可读可写，从结点只能从主节点读数据，不能自己写数据； 当主服务节点宕机后（无论各种原因，反正主节点不能正常运行了），从服务节点不会自动变成主节点，而是保持自己从结点的身份继续运行（而且他从主节点复制的数据不会丢失，可以继续对外提供服务），直到主节点恢复后这些从结点又可一继续从主节点读数据； 当一以从服务器结点“挂掉”以后，再次重启后，他与先前的主节点没有任何关系了（在没有在配置文件中配置的前提下），除非在配置文件中配置过或者再次使用命令slaveof &lt;主节点ip&gt; &lt;主节点port&gt;连上主节点。 演示一：在客户端使用命令行在127.0.0.1:3679开启master，然后在127.0.0.1:3680/3681开启两个salve 然后关闭master节点，查看从服务节点，发现从服务节点没有自动升级为master，并且他之前从主节点复制来的数据还在，还可以向外提供服务： 之后重新启动master，查看从服务节点，发现从服务节点有重新连接上主服务节点了： 演示二：恢复到127.0.0.1:3679是master，127.0.0.1:3680/3681是127.0.0.1:3679的两个salve的状态，然后任意重启一个从服务器，观察发现这个服务器结点如果之前没有在配置文件中配置过，那么他将和master没有任何关系了： 薪火相传所谓”薪火相传“，指的是那种一个master连接了一个slave，然后这个slave结点又作为另一个slave的master节点…….依次向链表一样传递下去，这种拓扑的特点是： 只有这个传递链上的第一个master结点具有写的权限，其他的结点都是由读的权限； 这种模式下，减轻了master结点的压力，但是与之而来的问题是越往后的结点同步延时越大； 如果其中一个节点“挂了”，那么他后面的结点就无法同步到最新的数据了 演示：让127.0.0.1:3679作为127.0.0.1:3680的master,然后让127.0.0.1:3680作为127.0.0.1:3681的master: 反客为主“反客为主”说的就是当主服务器结点“挂了”以后，我们可以手动将一个从服务器节点指定为主服务器节点，然后让其他的从服务节点从这个新的master上复制： 演示：在客户端使用命令行在127.0.0.1:3679开启master，然后在127.0.0.1:3680/3681开启两个salve 然后主服务节点突然“挂了”，手动使用命令slaveof no one将原本的 slave 转成 master，停止与其他数据库的同步，然后将其他的slave和这个新的master交互： 这种模式下，在之后以前的主服务器再次启动后，它就与这个新建立的主从关系没有任何关系了。 Redis哨兵模式&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Sentinel(哨兵)是用于监控redis集群中Master状态的工具，是Redis 的高可用性解决方案。Sentinel可以让redis实现主从复制，当一个集群中的master失效之后，sentinel可以选举出一个新的master用于自动接替master的工作，集群中的其他redis服务器自动指向新的master同步数据。一般建议sentinel采取奇数台，防止某一台sentinel无法连接到master导致误切换。其结构如下: &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Redis-Sentinel是Redis官方推荐的高可用性(HA)解决方案，当用Redis做Master-slave的高可用方案时，假如master宕机了，Redis本身(包括它的很多客户端)都没有实现自动进行主备切换，而Redis-sentinel本身也是一个独立运行的进程，它能监控多个master-slave集群，发现master宕机后能进行自动切换。Sentinel由一个或多个Sentinel 实例 组成的Sentinel 系统可以监视任意多个主服务器，以及这些主服务器属下的所有从服务器，并在被监视的主服务器进入下线状态时，自动将下线主服务器属下的某个从服务器升级为新的主服务器。说的简单点，哨兵模式就是监控+自动版“反客为主”下图演示了哨兵的工作过程： 演示：首先我们在新建一个sentinel.conf配置文件，配置有关哨兵监控的信息，然后保存退出 让127.0.0.1:3679作为127.0.0.1:3680的master,然后让127.0.0.1:3680作为127.0.0.1:3681的master 一切设置好后，使用redis-sentinel sentinel.conf配置文件路径启动哨兵，让他监控master的状态： 之后关闭master，模拟服务器突然宕机等情况，发现哨兵自动通过投票选举出了新的master，并且把其他从服务器（slave）都拉到了这个新的master“旗下”： 那么如果之前的master重启回来，会不会有两个master冲突？ 不会，之前的master会在哨兵模式下变为slave从机： 主从复制的原理Redis主从复制的过程大体可以分成3个阶段：建立连接阶段 、数据同步阶段和命令传播阶段。 建立连接step1：保存主节点信息从节点服务器内部维护了两个字段，即masterhost和masterport字段，用于存储主节点的ip和port信息。(用info replication命令就可以查看) slaveof是异步命令，从节点完成主节点ip和port的保存后，向发送slaveof命令的客户端直接返回OK，实际的复制操作在这之后才开始进行。 step2：建立socket连接&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从节点（slave）每秒1次调用复制定时函数replicationCron()，如果发现了有主节点可以连接，便会根据主节点的ip和port，创建socket连接。如果连接成功： 从节点（slave）：为该socket建立一个专门处理复制工作的文件事件处理器，负责后续的复制工作，如接收RDB文件、接收命令传播等。 主节点（master）：接收到从节点的socket连接后（即accept之后），为该socket创建相应的客户端状态，并将从节点看做是连接到主节点的一个客户端，后面的步骤会以从节点向主节点发送命令请求的形式来进行。 step3：发送ping命令&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;从节点（slave）成为主节点（master）客户端之后，发送ping命令进行首次请求，目的是：检查socket连接是否可用，以及主节点当前是否能够处理请求。从节点发送ping命令后，可能出现3种情况： （1）返回pong：说明socket连接正常，且主节点当前可以处理请求，复制过程继续。 （2）超时：一定时间后从节点仍未收到主节点的回复，说明socket连接不可用，则从节点断开socket连接，并重连。 （3）返回pong以外的结果：如果主节点返回其他结果，如正在处理超时运行的脚本，说明主节点当前无法处理命令，则从节点断开socket连接，并重连。 step4：身份验证如果从节点中设置了masterauth选项，则从节点需要向主节点进行身份验证；没有设置该选项，则不需要验证。 从节点进行身份验证是通过向主节点发送auth命令进行的，auth命令的参数即为配置文件中的masterauth的值。 如果主节点设置密码的状态，与从节点masterauth的状态一致（一致是指都存在，且密码相同，或者都不存在），则身份验证通过，复制过程继续；如果不一致，则从节点断开socket连接，并重连。 step5：发送从节点端口信息身份验证之后，从节点会向主节点发送其监听的端口号，主节点将该信息保存到该从节点对应的客户端的slave_listening_port字段中；该端口信息除了在主节点中执行info Replication时显示以外，没有其他作用。 数据同步阶段&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;主从节点之间的连接建立以后，便可以开始进行数据同步，该阶段可以理解为从节点数据的初始化。redis 同步有 2 个命令：sync 和psync，前者是 redis 2.8 之前的同步命令，后者是 redis 2.8 为了优化 sync 新设计的命令。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据同步阶段是主从复制最核心的阶段，根据主从节点当前状态的不同，可以分为全量复制和部分复制。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在数据同步阶段之前，从节点是主节点的客户端，主节点不是从节点的客户端；而到了这一阶段及以后，主从节点互为客户端。原因在于：在此之前，主节点只需要响应从节点的请求即可，不需要主动发请求，而在数据同步阶段和后面的命令传播阶段，主节点需要主动向从节点发送请求（如推送缓冲区中的写命令），才能完成复制。 全量复制和增量复制&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;在Redis 2.8以前，从结点向主节点发送的是sync命令同步数据的，这种同步方式是全量复制；但是在Redis 2.8 以后，从结点可以发送psync命令请求同步数据，此时根据主节点当前状态的不同，同步方式可能是全量复制和增量复制： 全量复制：用于初次复制或其他无法进行部分复制的情况，将主节点中的所有数据都发送给从节点，这是一个非常耗费资源的操作。 流程如下： 发送 psync 命令（spync ？ -1） 主节点根据命令返回 FULLRESYNC 从节点记录主节点 ID 和 offset 主节点 bgsave 并保存 RDB 到本地 主节点发送 RBD 文件到从节点 从节点收到 RDB 文件并加载到内存中 主节点在从节点接受数据的期间，将新数据保存到“复制客户端缓冲区”，当从节点加载 RDB 完毕，再发送过去。（如果从节点花费时间过长，将导致缓冲区溢出，最后全量同步失败） 从节点清空数据后加载 RDB 文件，如果 RDB 文件很大，这一步操作仍然耗时，如果此时客户端访问，将导致数据不一致，可以使用配置slave-server-stale-data 关闭. 从节点成功加载完 RBD 后，如果开启了 AOF，会立刻做bgrewriteaof。以上红色字体的部分是整个全量同步耗时的地方。 增量复制：当从节点正在复制主节点时，如果出现网络闪断和其他异常，从节点会让主节点补发丢失的命令数据，主节点只需要将复制缓冲区的数据发送到从节点就能够保证数据的一致性，相比较全量复制，成本小很多。需要注意的是，如果网络中断时间过长，导致主节点没有能够完整地保存中断期间执行的写命令，则无法进行增量复制，仍使用全量复制。 当从节点出现网络中断，超过了 repl-timeout 时间，主节点就会中断复制连接。 主节点会将请求的数据写入到“复制积压缓冲区”，默认 1MB。 当从节点恢复，重新连接上主节点，从节点会将 offset 和主节点 id 发送到主节点。 主节点校验后，如果偏移量的数后的数据在缓冲区中，就发送 cuntinue 响应 —表示可以进行部分复制。 主节点将缓冲区的数据发送到从节点，保证主从复制进行正常状态。 psync命令的执行 首先从节点根据当前的状态，决定如何调用psync命令 如果从结点之前未执行过slavof或最近执行了slaveof no one 命令，则从结点发送命令pysnc ? -1，向主节点请求全量复制； 如果从结点之前执行了slaveof，则发送命令psync &lt;runid&gt; &lt;offset&gt;，其中runid为上次复制主节点的runid,offset为上次复制截止时从结点保存的复制偏量。 主节点根据收到的psync命令，及当前服务器状态，决定执行全量复制还是部分复制： 如果主节点版本低于Redis2.8，则返回-ERR回复，此时从节点重新发送sync命令执行全量复制； 如果主节点版本够新，且runid与从节点发送的runid相同，且从节点发送的offset之后的数据在复制积压缓冲区中都存在，则回复+CONTINUE，表示将进行部分复制，从节点等待主节点发送其缺少的数据即可； 如果主节点版本够新，但是runid与从节点发送的runid不同，或从节点发送的offset之后的数据已不在复制积压缓冲区中(在队列中被挤出了)，则回复+FULLRESYNC ，表示要进行全量复制，其中runid表示主节点当前的runid，offset表示主节点当前的offset，从节点保存这两个值，以备使用。 命令传播阶段&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据同步阶段完成后，主从节点进入命令传播阶段；在这个阶段主节点将自己执行的写命令发送给从节点，从节点接收命令并执行，从而保证主从节点数据的一致性。在命令传播阶段，除了发送写命令，主从节点还维持着心跳机制：PING和REPLCONF ACK。 心跳机制主从节点在建立复制后，他们之间维护着长连接并彼此发送心跳命令。 心跳的关键机制如下： 主从都有心跳检测机制，各自模拟成对方的客户端进行通信，通过 client list 命令查看复制相关客户端信息，主节点的连接状态为 flags = M，从节点的连接状态是 flags = S。 主节点默认每隔 10 秒对从节点发送 ping 命令，可修改配置 repl-ping-slave-period 控制发送频率。 从节点在主线程每隔一秒发送replconf ack{offset} 命令，给主节点上报自身当前的复制偏移量。 主节点收到 replconf 信息后，判断从节点超时时间，如果超过 repl-timeout 60 秒，则判断节点下线。 总结一下：主-&gt;从：PING每隔指定的时间，主节点会向从节点发送PING命令，这个PING命令的作用，主要是为了让从节点进行超时判断。 PING发送的频率由 repl-ping-slave-period 参数控制，单位是秒，默认值是10s。 从-&gt;主：REPLCONF ACK在命令传播阶段，从节点会向主节点发送REPLCONF ACK命令，频率是每秒1次；命令格式为：REPLCONF ACK {offset}，其中offset指从节点保存的复制偏移量。 注意事项：&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;延迟与不一致：命令传播是异步的过程，即主节点发送写命令后并不会等待从节点的回复；因此实际上主从节点之间很难保持实时的一致性，延迟在所难免。数据不一致的程度，与主从节点之间的网络状况、主节点写命令的执行频率、以及主节点中的repl-disable-tcp-nodelay配置等有关。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;repl-disable-tcp-nodelay no：该配置作用于命令传播阶段，控制主节点是否禁止与从节点的TCP_NODELAY；默认no，即不禁止TCP_NODELAY。当设置为yes时，TCP会对包进行合并从而减少带宽，但是发送的频率会降低，从节点数据延迟增加，一致性变差；具体发送频率与Linux内核的配置有关，默认配置为40ms。当设置为no时，TCP会立马将主节点的数据发送给从节点，带宽增加但延迟变小。一般来说，只有当应用对Redis数据不一致的容忍度较高，且主从节点之间网络状况不好时，才会设置为yes；多数情况使用默认值no。]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis之事务]]></title>
    <url>%2F2019%2F09%2F26%2FRedis%E4%B9%8B%E4%BA%8B%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[Redis的事物 事务是一个单独的隔离操作：事务中的所有命令都会序列化、按顺序地执行。事务在执行的过程中，不会被其他客户端发来的命令请求打断。 事务是一个原子操作：事务中的命令要么全部执行，要么全部不执行。 Redis事务相关的几个命令 multi：MULTI 命令用于开启一个事务，它总是返回 OK 。 MULTI 执行之后， 客户端可以继续向服务器发送任意多条命令， 这些命令不会立即被执行， 而是被放到一个队列中， 当 EXEC命令被调用时， 所有队列中的命令才会被执行。 exec ：执行所有的事物命令，EXEC 命令的回复是一个数组， 数组中的每个元素都是执行事务中的命令所产生的回复。 其中， 回复元素的先后顺序和命令发送的先后顺序一致。当客户端处于事务状态时， 所有传入的命令都会返回一个内容为 QUEUED 的状态回复（status reply）， 这些被入队的命令将在 EXEC 命令被调用时执行。 discard： 通过调用 DISCARD ， 客户端可以清空事务队列， 并放弃执行事务。 watch key [key ...]：监视一个或多个key(类似于乐观锁) unwatch：取消watch对所有key的监视 Redis事务的三个阶段 开始事务：使用multi命令开启一个事务，当一个事务被exec或discard后，改事务就宣告结束（无论有没有成功执行），下次在向开启事务就必须在使用这个命令开启事务。 命令入队：简单点说就是，开启事务后输入的命令不会立即执行，而是先入队，执行当exec后在一次性执行。 执行事务：使用exec命令执行事务 Redis事务使用示例：1、正常执行 2、取消事务 3、事务在执行 EXEC 之前，入队的命令可能会出错(语法上就是错误的)，执行exec时，整个事务都会失败。 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;对于发生在 EXEC 执行之前的错误，客户端以前的做法是检查命令入队所得的返回值：如果命令入队时返回 QUEUED ，那么入队成功；否则，就是入队失败。如果有命令在入队时失败，那么大部分客户端都会停止并取消这个事务。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;不过，从 Redis 2.6.5 开始，服务器会对命令入队失败的情况进行记录，并在客户端调用 EXEC 命令时，拒绝执行并自动放弃这个事务。 4、事命令可能在 EXEC 调用之后失败（语法上没有错误，但是调用执行的时候出错了），在执行exec命令时，其他正确的命令可以正确执行，错误命令抛出错误 为什么Redis不支持回滚？通过上面的案例我们可以看到redis在事务中发生错误后是没有回滚的，而是继续执行余下的命令，那么redis为什么不支持事务回滚呢？从各方面考虑有以下两点原因： Redis命令只会因为错误的语法而失败，或是命令用在了错误类型的键上面，也就是说，从实用的角度来说，失败的命令是由编程错误造成的，而这些错误应该在开发过程中别发现，而不应出现在生产环境中。而且需要注意的是在通常情况下， 回滚并不能解决编程错误带来的问题。 因为redis不需要支持事务回滚，所以他可以在内部保持简单和快捷。 5、使用watch监控WATCH 命令可以为 Redis 事务提供 check-and-set （CAS）行为。被 WATCH 的键会被监视，并会发觉这些键是否被改动过了。 如果有至少一个被监视的键在 EXEC 执行之前被修改了， 那么整个事务都会被取消， EXEC 返回nil-reply来表示事务已经失败。下面使用很典型的账户和消费问题来展示一下watch的作用。案例一：使用watch检测balance，事务期间balance数据未变动，事务执行成功 案例二：使用watch检测balance，在开启事务后（标注1处），在新窗口执行标注2中的操作，更改balance的值，模拟其他客户端在事务执行期间更改watch监控的数据，然后再执行标注1后命令，执行EXEC后，事务未成功执行。]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis持久化之RDB和AOF]]></title>
    <url>%2F2019%2F09%2F25%2FRedis%E6%8C%81%E4%B9%85%E5%8C%96RDB%E5%92%8CAOF%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;众所周知，Redis是一种内存数据库，但是存在内存中的数据一断电后就消失了，Redis肯定没有这么弱。Redis也支持数据的持久化，Redis中有两种持久化方式RDB（Redis DataBase）和AOF（Append Only File）。 RDB（Redis DataBase）详解&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;RDB持久化是将当前进程中的数据生成快照保存到硬盘，默认会在当前工作目录下生成dump.rdb文件，当Redis重启的时候会读取快照文件来恢复数据。RDB是Redis的默认持久化方式。有两种触发的方式：第一种是：手动在客户端使用save命令和bgsave命令触发；第二种是：在redis.conf配置文件中使用save &lt;seconds&gt; &lt;changes&gt;来配置后自动触发。 手动触发save命令和bgsave命令都可以生成RDB文件。 save命令会阻塞Redis服务器进程，直到RDB文件被创建出来为止，在Redis服务器阻塞期间，服务器无法处理任何请求。 bgsave命令会创建一个子进程（拷贝一份父进程），由子进程负责创建RDB文件，父进程（Redis主进程）可以继续处理请求。bgsave命令执行过程中，只有fork父进程时才会阻塞服务器进程，而对于save命令，整个执行过程都会阻塞服务器，因此在生产环境下要杜绝使用save的使用。而且在自动触发RDB持久化的时候，Redis也会选择bgsave而不是save。 自动触发设置自动触发 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;自动触发最常见的情况是在配置文件中通过`save `来配置，即只要在自定的seconds秒内只要发生了changes变化时，就会触发`bgsave`。redis默认的配置有三个： 123save 900 1 //当时间到900秒时，在此期间如果redis数据发生了至少1次变化，则执行bgsavesave 300 10 //当时间到300秒时，在此期间如果redis数据发生了至少10次变化，则执行bgsavesave 60 10000 //当时间到900秒时，在此期间如果redis数据发生了至少1次变化，则执行bgsave 自动触发的原理Redis的自动触发是通过serverCron函数、dirty计数器和lastave时间戳来实现的。 serverCron是Redis服务器的周期性操作函数，默认每隔100ms执行一次；该函数对服务器的状态进行维护，其中一项工作就是检查save &lt;seconds&gt; &lt;changes&gt; 配置的条件是否满足，如果满足就执行bgsave。 dirty计数器是Redis服务器维持的一个状态，记录了上一次执行bgsave/save命令后，服务器状态进行了多少次修改(包括增删改)；而当save/bgsave执行完成后，会将dirty重新置为0。 lastsave时间戳也是Redis服务器维持的一个状态，记录的是上一次成功执行save/bgsave的时间。 也就是每隔100ms，执行serverCron函数；在serverCron函数中，遍历save &lt;seconds&gt; &lt;changes&gt; 配置的保存条件，只要有一个条件满足，就进行bgsave。对于每一个save &lt;seconds&gt; &lt;changes&gt; 条件，只有下面两条同时满足时才算满足：&nbsp;&nbsp;&nbsp;&nbsp;（1）当前时间-lastsave &gt; seconds&nbsp;&nbsp;&nbsp;&nbsp;（2）dirty &gt;= changes 其他自动触发机制除了在配置文件中配置save &lt;seconds&gt; &lt;changes&gt; 来触发bgsave以外，还有别的情况会触发bgsave： 在主从复制场景下，如果从结点执行全量复制操作，则主结点回执性bgsave命令，并将dump.rdb文件发送给从结点。 在执行shutdown命令时，会自动执行rdb持久化，这一点通过redis的日志看到 RDB文件RDB的文件格式RDB文件是经过压缩的二进制文件，RDB的的文件格式如下图所示 其中各个字段的含义说明如下： REDIS：常量，保存着”REDIS”5个字符。 db_version：RDB文件的版本号，注意不是Redis的版本号。 SELECTDB 0 pairs：表示一个完整的数据库(0号数据库)，同理SELECTDB 3 pairs表示完整的3号数据库；只有当数据库中有键值对时，RDB文件中才会有该数据库的信息(上图所示的Redis中只有0号和3号数据库有键值对)；如果Redis中所有的数据库都没有键值对，则这一部分直接省略。其中：SELECTDB是一个常量，代表后面跟着的是数据库号码；0和3是数据库号码；pairs则存储了具体的键值对信息，包括key、value值，及其数据类型、内部编码、过期时间、压缩信息等等。 EOF：常量，标志RDB文件正文内容结束。 check_sum：前面所有内容的校验和；Redis在载入RBD文件时，会计算前面的校验和并与check_sum值比较，判断文件是否损坏。 RDB的存储路径RDB文件的存储路径既可以在redis.conf配置文件中配置，也可以在客户端通过命令动态设定： 在配置文件中可以设置dir参数来指定RDB文件的存放路径（AOF文件的默认的保存路径也是这个），redis默认是存放在当前工作目录下。也可以在配置文件中通过设置dbfilename指定RDB文件的名字，redis默认的文件名是dump。 动态设定：Redis启动后也可以在客户端使用config set dir /path来动态的改变RDB的存放路径，当然也可以通过config set dbfilename newfilenaem来设置RDB文件的名字。 RDB文件的压缩&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Redis默认采用LZF算法对RDB文件进行压缩。虽然压缩会有一定的性能消耗，但是这样可以大大减小RDB文件的大小。但是需要特别注意的是：RDB文件的压缩并不是针对整个文件进行的，而是对数据库中的字符进行的，且只有在字符串达到一定长度(20字节)时才会进行。 启动时加载&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;RDB文件的载入工作是在服务器启动的时候自动进行的，并没有专门的命令。但是当开启AOF后，Redis会优先加载AOF文件来恢复数据，只有当AOF关闭时，才会在Redis服务器启动的时候检测RDB文件，并自动加载。服务器载入RDB文件期间处于阻塞状态，直到加载完毕阻塞解除。Redis载入RDB文件时，会对RDB文件进行校验，如果文件损坏，则日志中会打印错误，Redis启动失败。此时可以使用redis-check-rdb来修复RDB文件。 RDB优缺点总结最后以一幅图的方式总结RDB的优缺点： AOF（Append Only File）详解&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;RDB持久化是将进程数据写入文件，而AOF用了和RDB完全不同的做法，AOF将Redis每次写操作记录到一个日志文件中，当Redis重启的时候会优先加载AOF（如果开启了AOF）文件，然后执行文件中的命令恢复数据，与RDB相比较AOF具有更好的实时性，也是当前主流的持久化方案。 开启AOFRedis服务器默认开启的是RDB，美哦与开启AOF，要开启AOF，需要在redis.conf中修改appendonly为yes，还可以在配置文件中修改AOF文件的名字等等，具体的可以参考我的这篇笔记：Redis配置文件redis.conf详解 AOF的执行流程由于需要记录Redis的每条写命令，因此AOF不需要触发，AOF的执行流程包括： 命令追加（append）:将Redis的写操作追加到缓冲区aof_buf 文件写入（write）和文件同步（sync）:根据不同的同步策略将aof_buf中的内容同步带硬盘 文件重写（rewrite）：定期重写AOF文件，达到压缩的目的。 命令追加(append)Redis先将写命令追加到缓冲区，而不是直接写入文件，主要是为了避免每次有写命令都直接写入硬盘，导致硬盘IO成为Redis负载的瓶颈。命令追加的格式是Redis命令请求的协议格式，它是一种纯文本格式，具有兼容性好、可读性强、容易处理、操作简单避免二次开销等优点；具体格式略。在AOF文件中，除了用于指定数据库的select命令（如select 0 为选中0号数据库）是由Redis添加的，其他都是客户端发送来的写命令。 文件写入（write）和文件同步（sync）Redis提供了多种AOF缓存区的同步文件策略，策略涉及到操作系统的write函数和fsync函数： write函数：为了提高文件写入效率，在现代操作系统中，当用户调用write函数将数据写入文件时，操作系统通常会将数据暂存到一个内存缓冲区里，当缓冲区被填满或超过了指定时限后，才真正将缓冲区的数据写入到硬盘里。这样的操作虽然提高了效率，但也带来了安全问题：如果计算机停机，内存缓冲区中的数据会丢失 fsync函数：为了解决write函数数据丢失的问题，因此系统提供了fsync、fdatasync等同步函数，可以强制操作系统立刻将缓冲区中的数据写入到硬盘里，从而确保数据的安全性。 AOF缓存的同步文件策略有appendfsync控制，Redis提供了三种策略： always：命令写入aof_buf后立即调用系统的fsync函数同步到AOF文件，fsync完成后线程返回。这种情况下，每次有写命令都要同步到AOF文件，硬盘IO成为性能瓶颈，Redis只能支持大约几百TPS写入，严重降低了Redis的性能；即便是使用固态硬盘（SSD），每秒大约也只能处理几万个命令，而且会大大降低SSD的寿命。 no：命令写入aof_buf后调用系统的wirte函数，不对AOF文件做fsync同步，同步操作由系统负责，通常同步周期为30s。这种情况下，文件同步的时间不可控，且缓冲区中堆积的数据会很多，数据安全性无法保证。 everysec：命令写入aof_buf后调用系统的write函数，write完成后返回，fsync同步文件操作，有专门的线程每一秒调用一次。everysec是前面两种策略的折中，兼顾了性能和数据安全，也是Redis的默认配置。 文件重写（rewrite）AOF文件重写主要的作用就是对AOF文件进行压缩，文件重写就会定期重写AOF文件，减小AOF文件的体积。需要注意的是，AOF重写只是把Redis进程内的数据转化为写命令，同步到新的AOF文件；不会对旧的AOF文件进行任何读取，写入操作。 为什么文件重写可以压缩AOF文件？ 过期的数据不需要再写入文件 无效的命令不再写入文件 多条命令可以合并为一条命令，比如sadd stu v1, sadd stu v2 ,sadd stu v2，这三条操作可以合并为一条sadd stu v1 v2 v3。不过为了防止单条命令过大造成客户端缓冲区溢出，对于list、set、hash、zset类型的key，并不一定只使用一条命令；而是以某个常量为界将命令拆分为多条。这个常量在redis.h/REDIS_AOF_REWRITE_ITEMS_PER_CMD中定义 总之压缩的原理就是通过重写减小命令的数量从而减少了文件的大小。 文件重写的触发文件重写的触发有两种方式：第一种是在客户端使用bgrewriteaof命令触发；第二种是在配置文件中设置auto-aof-rewrite-min-size和auto-aof-rewrite-percentage，以及aof_current_size和aof_base_size状态确定触发时机。 手动触发：直接调用bgrewriteaof命令，该命令的执行与bgsave有些类似—都是fork子进程进行具体的工作，且都只有在fork时阻塞。使用bgrewriteaof后，可以看到服务器的日志如下： 自动触发：只是通过配置文件自动的触发重写，但是还是要使用bgrewirteaof这个命令，主要配置的参数如下： auto-aof-rewrite-min-size：执行AOF重写时，文件体积最小体积，默认为64MB。 uto-aof-rewrite-percentage：执行AOF重写时，当前AOF大小和上一次重写AOF大小的比值，默认大小100。这些参数都可通过config get 参数来查看。 文件重写的流程 对照上图，文件重写的流程如下： 1、Redis父进程首先判断当前是否存在正在执行 bgsave/bgrewriteaof的子进程，如果存在则bgrewriteaof命令直接返回，如果存在bgsave命令则等bgsave执行完成后再执行。 2、父进程执行fork操作创建子进程，这个过程中父进程是阻塞的。 3.1、父进程fork后，bgrewriteaof命令返回”Background append only file rewrite started”信息并不再阻塞父进程，此时可以响应其他命令。Redis的所有写命令依然写入AOF缓冲区，并根据appendfsync策略同步到硬盘，保证原有AOF机制的正确。 3.2、由于fork操作使用写时复制技术，子进程只能共享fork操作时的内存数据。由于父进程依然在响应命令，因此Redis使用AOF重写缓冲区(图中的aof_rewrite_buf)保存这部分数据，防止新AOF文件生成期间丢失这部分数据。也就是说，bgrewriteaof执行期间，Redis的写命令同时追加到aof_buf和aof_rewirte_buf两个缓冲区。 4、子进程根据内存快照，按照命令合并规则写入到新的AOF文件。 5.1、子进程写完新的AOF文件后，向父进程发信号，父进程更新统计信息，具体可以通过info persistence查看。 5.2、 父进程把AOF重写缓冲区的数据写入到新的AOF文件，这样就保证了新AOF文件所保存的数据库状态和服务器当前状态一致。 5.3、 使用新的AOF文件替换老文件，完成AOF重写。 AOF文件启动加载当开启AOF后，Redis重启会默认优先加载AOF文件来恢复数据；只有当AOF关闭时参会加载RDB文件。Redis加载AOF文件时，会对AOF文件进行校验，如果文件损坏，则日志中就会打印错误，并且Redis会启动失败。当AOF文件损坏后，我们可以使用redis-check-aof 这个工具来修复AOF文件。 AOF优缺点总结最后以一幅图片总结AOF的优缺点：]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis配置文件redis.conf详解]]></title>
    <url>%2F2019%2F09%2F24%2FRedis%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp; Redis脚本简介在我们介绍Redis的配置文件之前，我们先来说一下Redis安装完成后生成的几个可执行文件： redis-server 、redis-cli 、redis-benchmark 、redis-stat 、redis-check-dump、redis-check-aof : 1234567891011redis-server：Redis服务器的daemon启动程序。redis-cli：Redis命令行执行工具。当然，你也可以用telnet根据其纯文本协议来操作。redis-benchmark：Redis性能检测工具，测试Redis在你的系统及你的配置下的读写性能。redis-stat：Redis态检测工具，可以检测 Redis 当前状态参数及延迟状况（高版本的Redis将没有这个脚本）。redis-check-dump：Redis dump 数据文件的修复工具。redis-check-aof：Redis aof 日志文件修复工具。 &nbsp;&nbsp; Redis配置文件详解&nbsp;&nbsp;开头说明 开头说明中主要就是要注意在redis中内存大小写k和kb是不一样的，前者是1000的倍数，后者是1024的倍数。 &nbsp;&nbsp; INCLUDES &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;INCLUDES的作用就是把其他关于redis的配置文件引入到redis.conf文件中使其生效，redis.conf就作为一个总闸一样，配置的方法是使用include来引入一个路径下配置文件（比如：include /path/aaa/other.conf）。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;需要注意的是，如果将此配置写在redis.conf 文件的开头，那么后面的配置会覆盖引入文件的配置，如果想以引入文件的配置为主，那么需要将 include 配置写在 redis.conf 文件的末尾。 &nbsp;&nbsp;MODULES 这个部分是用来引入自定义的模块的。通过这里的 loadmodule 配置将引入自定义模块来新增一些功能。 &nbsp;&nbsp;NETWORK bind： 绑定redis服务器网卡IP，默认为127.0.0.1，即本地回环地址。这样的话访问redis服务只能通过本机的客户端连接，而无法通过远程连接。如果bind被注掉了或者为空时会接收所有来自于可用网络的连接。 port： 指定redis运行的端口，默认的是6379。由于redis是单线程模型，因此单机开多个redis运行的时候会修改端口，除此而外一般保持默认的即可。 protected-mode：是否开启保护模式，默认是yes表示开启保护模式 timeout：设置客户端连接时的超时时间，单位：秒。当客户端在这段时间没有任何操作（空闲的），那么就会关闭连接。默认为0，表示永不关闭。 tcp-backlog: 设置tcp的backlog, backlog其实是一个连接队列，backlog队列总和=未完成三次握手队列+已完成三次握手队列。在高并发环境下需要该backlog值来避免客户端连接问题。注意Linux内核会将这个值减小到/proc/sys/net/core/somaxconn的值，所以需要确认增大somaxconn和tcp_max_syn_backlog两个值来达到想要的效果。 tcp-keepalive：表示将周期性的使用SO_KEEPALIVE检测客户端是否还处于健康状态，避免服务器一直阻塞，官方默认是300s，如果设置为0，表示不周期性检测。 &nbsp;&nbsp;GENERAL daemonize：设置为yes表示指定Redis以守护进程的方式启动（后台启动）。默认为no pidfile：配置pid文件路径，当Redis作为守护进程运行的时候，会把pid默认写到/var/redis/run/redis_6379.pid 文件里面 loglevel：定义日志级别。默认为notice。Redis中有4个日志级别： debug ：记录详细的日志，使用与开发、测试阶段 varbose：较多的日志 notice：适量的日志信息，适用于生产环境 warning：仅有部分重要、关键的才会被记录 logfile：配置日志文件默认存放的位置，默认会直接打印在终端的屏幕上 databases：设置数据库的数目。默认的数据库是DB0，有16个，可以使用select &lt;dbid&gt;命令选择不同的数据库。 always-show-logo：是否在启动的时候显示Redis的logo，默认为yes，即显示logo。 &nbsp;&nbsp;SNAPSHOTTING Snapshotting：快照。主要是用来配置持久化策略的。这一块的配置牵扯到Redis默认的持久化方案RDB，关于RDB的细节可以参考我的这篇笔记：Redis 持久化之RDB和AOF。 save：用来配置触发Redis的做持久化的条件，也就是什么时候将内存中的数据保存到硬盘中。默认配置如下： save 900 1：表示900s内如果有1个key变化，到时间（900s）后就把这段时间内的变化保存到磁盘 save 300 10： 表示300s内如果有10个key变化，到时间（300s）后就把这段时间内的变化保存到磁盘 save 60 10000 ：表示60s内如果有10000个key变化，到时间（60s）后就把这段时间内的变化保存到磁盘当然如果只是使用Redis的缓存功能，不需要持久化，那么可以把这些save注释掉，然后使用一个空字符串实现停用：save &quot;&quot; stop-writes-on-bgsave-error：当启用了RDB且最火一次后台保存数据失败，Redsi是否停止接收数据。默认值为yes，这会让用户意识到数据没有正确持久化到硬盘上，从而可以排错，否者没有人会注意到灾难发生了。 rdbcompression：对于存储到磁盘中的快照，可以设置时候惊进行压缩存储。默认值是yes，redis会使用LZF算法进行压缩。但是压缩会带来一定的CPU消耗，如果关闭后存储在磁盘上的快照将会非常大。 rdbchecksum：在存储快照后，我们还可以让Redis使用CRC64算法来进行数据校验。默认是yes，这样会带来10%的性能消耗。 dbfilename：设置快照的文件名，默认名字是dump.rdb。 dir：设置快照文件的存放路径，这个配置项必须自定的是一个目录，而不能是一个文件名。保存的是上面dbfilename，默认保存到当前目录下。 &nbsp;&nbsp;REPLICATION slave-serve-stale-data：当一个slave和一个master失去联系，或者复正在进行的时候，slave可能会有两种表现： 如果是yes，slave任然会应答客户端请求，但是返回的数据是过时的。 如果是no，在执行除了info he salvaof之外的其他命令时，slave都将返回一个“SYNC with master in progress”错误 slave-read-only：配置Redis的Slave示例是否接受写操作，即Slave是否为只读Redis。默认值是yes，Slave为只读。 repl-diskless-sync：主从复制是否使用无硬盘复制功能。默认值为no。 repl-disless-sync-delay：当启用无硬盘备份，服务器等待一段时间后才会通过套接字向从站传送RDB文件，这个等待时间是可配置的。 这一点很重要，因为一旦传送开始，就不可能再为一个新到达的从站服务。从站则要排队等待下一次RDB传送。因此服务器等待一段 时间以期更多的从站到达。延迟时间以秒为单位，默认为5秒。要关掉这一功能，只需将它设置为0秒，传送会立即启动。默认值为5。 repl-disalbe-tcp-nodelay：同步之后是否禁用从站上TCP_NODELAY。如果yes，表示redis会使用较少的TCP包和带宽向从站发送数据。但是这回导致从站增加数据延时；如果选择no，从站的数据延时不会那么多，但备份需要的带宽相对较多。Redis默认设置是no。 &nbsp;&nbsp;SECURITY rename-command：从命名命令。例如对于一些危险的命令： flushdb ：清空当前数据库 flushall：清空所有数据库 config：客户端连接后可配置服务器 keys：查看数据库中所有的键 requirepass：设置Redis连接密码，如果配置了连接密码，客户端在连接Redis的时候需要通过auth &lt;password&gt;命令来验证。默认是关闭的。 作为服务端redis-server，常常需要禁用以上命令来使得服务器更加安全，禁用的具体做法是：(比如禁用FLUSHALL命令)： rename-command FLUSHALL &quot;&quot; 也可以保留这个命令但是把它重命名，这样不知道重命名后的命令的人将无法使用这些危险的命令，从而可以保证系统数据的安全： rename-command FLUSHALL sfr443g432 这样，重启服务器后则需要使用新命令来执行操作，否则服务器会报错unknown command。 &nbsp;&nbsp;CLIENTS maxclients：设置客户端最大的连接数，默认是10000个连接。当客户端连接数到达限制是，Redis会关闭新的连接并向客户端返回max number of clients reached错误信息。如果设置为0，表示不作限制。 &nbsp;&nbsp;MEMORY MANAGEMENT maxmemory：指定Redis最大内存限制，Redis在启动时会把数据加载到内存中，达到最大内存后，Redis会先尝试清除已到期或即将到期的Key，当此方法处理 后，仍然到达最大内存设置，将无法再进行写入操作，但仍然可以进行读取操作。Redis新的vm机制，会把Key存放内存，Value会存放在swap区 maxmemory-policy：当内存使用达到最大值时，redis应该采用的内存清理策略。有以下几种可以选择：volatile-lru：利用LRU算法移除设置过过期时间并且最近很少使用过的key allkeys-lru：利用LRU算法移除任何最近很少使用过的key volatile-random：随机移除设置过过期时间的key allkeys-random：随机移除任何key volatile-ttl：移除即将过期的key noeviction：不移除任何key，返回写错误。 maxmemory-samples：设置样本数量，LRU算法和最小TTL算法都不是精确的算法，而是估算值，所以可以设置样本的大小。默认值是5，即，使用5个样本。 &nbsp;&nbsp; APPEND ONLY MODE 具体的原理可以参考我的另一篇笔记：Redis 持久化之RDB和AOF appendonly：默认redis使用的是RDB方式持久化，这种方式在许多应用中已经足够用了。但是对于数据一致性要求很高的应用，如果还是只使用RDB,一旦redis宕机，会导致可能有几分钟的数据丢失，这种场景下就需要使用AOF（另一种持久化方式），可以提供更好的持久化特性以及更高的数据一致性。将appendonly置为yes开启AOF，Redis将会把每次写入的数据在接收后都写入appendonly.aof文件（默认的文件名），每次启动的时候会优先加载appendonly.aof这个文件到内存中。默认值是no。 appendfilename：aof文件的默认文件名，默认值是appendonly.aof appendfsync：aof持久化化策略配置。有三个值可以选： no：不执行fsync，由操作系统保证数据同步到磁盘，速度最快 always：每次写入都执行fsync，以保证数据同步到磁盘，速度最慢 everysec：每秒执行一次fsync，这样aof就可能会对时1s的数据 （默认值，通常来说能在速度和数据安全性之间取得比较好的平衡。） no-appendfsync-on-rewirite：设置为yes表示rewrite期间对新写操作不fsync,暂时存在内存中,等rewrite完成后再写入.官方文档建议如果你有特殊的情况可以配置为’yes’。但是配置为’no’是最为安全的选择。 auto-aof-rewrite-percentage: aof自动重写配置，当目前aof文件大小超过上一次重写的aof文件大小的百分之多少进行重写，即当aof文件增长到一定大小的时候，Redis能够调用bgrewriteaof对日志文件进行重写。默认值是100 auto-aof-rewrite-min-size：AOF文件到达重写的阈值，避免了达到约定百分比但尺寸仍然很小的情况还要重写，默认64m，这点内存啥都干不了，一般设置都是以GB为单位。 aof-load-truncated：如果设置为yes，如果一个因异常被截断的AOF文件被redis启动时加载进内存，redis将会发送日志通知用户；如果设置为no，redis将会拒绝启动。此时需要用”redis-check-aof”工具修复文件。 aof-use-rdb-preamble：默认为yes，就是使用RDB文件格式来保存AOF文件，设置为no就会使用AOF默认的键值的方式保存客户端的所有写操作。 &nbsp;&nbsp; LUA SCRIPTING lua-time-limit：一个lua脚本执行的最大时间，单位：ms。默认值5000。 &nbsp;&nbsp; REDIS CLUSTER cluster-enable：是否开启集群，默认是不开启的。 cluster-config-file：集群配置文件名称，每个节点都有一个集群相关的配置文件，持久化保存集群的信息。这个文件不需要手动配置，它由redis生成并更新。默认配置为nodes-6379.conf cluster-node-timeout：可以设置值为15000。节点互连超时的阈值，集群节点超时毫秒数。 cluster-slave-validity-factor：在进行故障转移的时候，全部slave都会请求申请为master，但是有些slave可能与master断开连接一段时间了， 导致数据过于陈旧，这样的slave不应该被提升为master。该参数就是用来判断slave节点与master断线的时间是否过长。判断方法是：比较slave断开连接的时间和(node-timeout * slave-validity-factor) + repl-ping-slave-period 如果节点超时时间为三十秒, 并且slave-validity-factor为10,假设默认的repl-ping-slave-period是10秒，即如果超过310秒slave将不会尝试进行故障转移。 cluster-migration-barrier：master的slave数量大于该值，slave才能迁移到其他孤立master上，如这个参数若被设为2，那么只有当一个主节点拥有2 个可工作的从节点时，它的一个从节点会尝试迁移。 cluster-require-full-coverage：默认情况下，集群全部的slot有节点负责，集群状态才为ok，才能提供服务。 设置为no，可以在slot没有全部分配的时候提供服务。不建议打开该配置，这样会造成分区的时候，小分区的master一直在接受写请求，而造成很长时间数据不一致。]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis五大常用数据类型]]></title>
    <url>%2F2019%2F09%2F23%2FRedis%E4%BA%94%E5%A4%A7%E5%B8%B8%E7%94%A8%E6%95%B0%E6%8D%AE%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[redis命令参考：http://redisdoc.com/ Redis 键(key)的有关命令keys *&nbsp;查看当前数据库中的所有键 exists key&nbsp;判断是否存在某个key，如果存在返回1,不存在返回0 move key dbId&nbsp;把某个key移动到指定的数据库中 expire key seconds&nbsp;为某个key设置过期时间，时间单位：秒 ttl key&nbsp; 查看某个key离过期还有多久，单位：秒 type key&nbsp;查看某个key的数据类型 Redis String有关命令SET key value将字符串value关联到键key。如果 key 已经持有其他值， SET 就覆写旧值， 无视类型。可选参数： EX seconds ： 将键的过期时间设置为 seconds 秒。 执行 SET key value EX seconds 的效果等同于执行 SETEX key seconds value 。 PX milliseconds ： 将键的过期时间设置为 milliseconds 毫秒。 执行 SET key value PX milliseconds 的效果等同于执行 PSETEX key milliseconds value 。 NX ： 只在键不存在时， 才对键进行设置操作。 执行 SET key value NX 的效果等同于执行 SETNX key value 。 XX ： 只在键已经存在时， 才对键进行设置操作。 当 SET 命令对一个带有生存时间（TTL）的键进行设置之后， 该键原有的 TTL 将被清除。 GET key返回与键 key 相关联的字符串值，如果没有这个key，返回nil。 1234567891011121314151617181920212223242526127.0.0.1:6379&gt; set user1 wangwu ex 60 #设置键user1的值为wangwu,存活时间是60sOK127.0.0.1:6379&gt; ttl user1(integer) 55127.0.0.1:6379&gt; get user1"wangwu"127.0.0.1:6379&gt; ttl user1(integer) 38127.0.0.1:6379&gt; ttl user1(integer) -2127.0.0.1:6379&gt; get user1 #60s后user1销毁(nil)127.0.0.1:6379&gt; set user1 lisi px 5000 #设置user1的存活时间是5000ms（5s）OK127.0.0.1:6379&gt; ttl user1(integer) -2127.0.0.1:6379&gt; get user1 #5s后user1销毁(nil) 127.0.0.1:6379&gt; set user1 lisi NX #当user1这个主键不存在的时候才设置值OK127.0.0.1:6379&gt; get user1"lisi"127.0.0.1:6379&gt; set user1 xiaoming XX #当user1这个主键存在的时候才设置值OK127.0.0.1:6379&gt; get user1"xiaoming" APPEND key value如果键 key 已经存在并且它的值是一个字符串， APPEND 命令将把 value 追加到键 key 现有值的末尾。如果 key 不存在， APPEND 就简单地将键 key 的值设为 value ， 就像执行 SET key value 一样。执行成功后会返回当前value的长度。 STRLEN key 返回与key关联的value的字符串的长度，当key不存在的时候返回0，当key不是字符串的时候使用这个命令会报错。 INCR key为键 key 储存的数字值加上一。如果键 key 不存在， 那么它的值会先被初始化为 0 ， 然后再执行 INCR 命令。如果键 key 储存的值不能被解释为数字， 那么 INCR 命令将返回一个错误。 INCRBY key increment为键 key 储存的数字值加上增量 increment 。如果键 key 不存在， 那么键 key 的值会先被初始化为 0 ， 然后再执行 INCRBY 命令。如果键 key 储存的值不能被解释为数字， 那么 INCRBY 命令将返回一个错误 DECR key为键 key 储存的数字值减去一。如果键 key 不存在， 那么键 key 的值会先被初始化为 0 ， 然后再执行 DECR 操作。如果键 key 储存的值不能被解释为数字， 那么 DECR 命令将返回一个错误。 DECRBY key decrement将键 key 储存的整数值减去减量 decrement 。如果键 key 不存在， 那么键 key 的值会先被初始化为 0 ， 然后再执行 DECRBY 命令。如果键 key 储存的值不能被解释为数字， 那么 DECRBY 命令将返回一个错误。 注意：上面这4个命令只能用于value是数字值的，而且这些操作执行后都会返回加/减操作后的值，且仅仅支持 64 位(bit)有符号数字表示之内。 GETRANGE key start end返回键key 储存的字符串值的指定部分， 字符串的截取范围介于start 和 end 两个偏移量。 SETRANGE key offset value从偏移量 offset 开始， 用 value 参数覆写(overwrite)键 key 储存的字符串值。不存在的键 key 当作空白字符串处理。Redis允许的字符串最大的512M，即：能够使用的最大偏移量为 2^29-1(536870911)，但是请别这样做，除非你想上午还在写码，下午就被开除！！！ MSET key value [key value …]同时为多个键设置值。如果某个给定键已经存在， 那么 MSET 将使用新值去覆盖旧值。MSET 是一个原子性(atomic)操作， 所有给定键都会在同一时间内被设置， 不会出现某些键被设置了但是另一些键没有被设置的情况。 MGET key [key …]返回给定的一个或多个字符串键的值。如果给定的字符串键里面， 有某个键不存在， 那么这个键的值将以特殊值 nil 表示 MSETNX key value [key value …]当且仅当所有给定键都不存在时， 为所有给定键设置值。即使只有一个给定键已经存在， MSETNX 命令也会拒绝执行对所有键的设置操作。MSETNX 是一个原子性(atomic)操作， 所有给定键要么就全部都被设置， 要么就全部都不设置， 不可能出现第三种状态。 Redis List常用命令LPUSH key value [value …]将一个或多个值 value 插入到列表key的表头。如果有多个 value 值，那么各个value值按从左到右的顺序依次插入到表头，List中允许有重复的值。 RPUSH key value value …]将一个或多个值value 插入到列表key 的表尾(最右边)。如果有多个 value值，那么各个 value值按从左到右的顺序依次插入到表尾 LRANGE key start end返回列表key 中指定区间内的元素，区间以偏移量 start 和end指定。下标(index)参数 start和end都以 0 为底，也就是说，以 0 表示列表的第一个元素，以 1 表示列表的第二个元素，以此类推。也可以使用负数下标，以 -1 表示列表的最后一个元素， -2 表示列表的倒数第二个元素，以此类推。 LPUSHX key value当且仅当 key存在并且是一个列表时才将值 value 插入到列表 key 的表头。 RPUSH key value当且仅当 key存在并且是一个列表时才将值 value 插入到列表key 的表尾。 123456789101112131415161718192021222324252627282930127.0.0.1:6379&gt; lpush mylist1 a b c d e f g #a,b,c,d,e,f依次圧桟的效果(integer) 7 127.0.0.1:6379&gt; rpush mylist2 1 2 3 4 5 6 7 #1,2,3,4,5,6,7依次入队的效果(integer) 7127.0.0.1:6379&gt; lrange mylist1 0 -11) "g"2) "f"3) "e"4) "d"5) "c"6) "b"7) "a"127.0.0.1:6379&gt; lrange mylist2 0 31) "1"2) "2"3) "3"4) "4"127.0.0.1:6379&gt; lpushx language java python php #对一个不存在的list使用lpush不会成功的(integer) 0127.0.0.1:6379&gt; lrange language 0 -1(empty list or set)127.0.0.1:6379&gt; lpush language java(integer) 1127.0.0.1:6379&gt; lpushx language python php js(integer) 4127.0.0.1:6379&gt; lrange language 0 -11) "js"2) "php"3) "python"4) "java" LPOP key移除并返回列表 key 的头元素。当元素不存在时返回nil。 RPOP key移除并返回列表 key 的尾元素。当元素不存在时返回nil。 RPOPLPUSH source destination将 source弹出的元素插入到列表 destination ，作为destination 列表的的头元素。如果 source 和 destination 相同，则列表中的表尾元素被移动到表头，并返回该元素，可以把这种特殊情况视作列表的旋转(rotation)操作。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849127.0.0.1:6379&gt; lrange mylist1 0 -1 #查看mylist1列表中的所有元素1) "g"2) "f"3) "e"4) "d"5) "c"6) "b"7) "a"127.0.0.1:6379&gt; lpop mylist1 #相当于mylist1栈顶元素出栈"g"127.0.0.1:6379&gt; lpop mylist1 "f"127.0.0.1:6379&gt; rpop mylist1 #相当于mylist1队首元素出队"a"127.0.0.1:6379&gt; rpop mylist1"b"#rpoplpush测试27.0.0.1:6379&gt; lrange mylist2 0 -11) "1"2) "2"3) "3"4) "4"5) "5"6) "6"7) "7"127.0.0.1:6379&gt; rpoplpush mylist1 mylist2 #mylist1栈顶元素出栈的元素入栈到mylist2"c"127.0.0.1:6379&gt; lrange mylist2 0 -11) "c"2) "1"3) "2"4) "3"5) "4"6) "5"7) "6"8) "7"127.0.0.1:6379&gt; rpoplpush mylist2 mylist2 #mylist2栈顶元素出栈的元素入栈到mylist2,形成列表的旋转"7"127.0.0.1:6379&gt; lrange mylist2 0 -11) "7"2) "c"3) "1"4) "2"5) "3"6) "4"7) "5"8) "6"127.0.0.1:6379&gt; LLEN key返回列表 key 的长度。如果 key 不存在，则 key 被解释为一个空列表，返回 0 。如果 key 不是列表类型，返回一个错误。 LREM key count value 当count&gt;0表示从表头开始搜索并删除count个和value相等的元素 当count&lt;0表示从表尾开始搜索并删除count个和vlaue相等的元素 当count=0表示删除表中所有的和vlaue相等的元素 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657127.0.0.1:6379&gt; lpush list 1 2 3 4 4 3 2 1 5 6 7 8 3 3 (integer) 14127.0.0.1:6379&gt; lrange list 0 -1 #查看所有的元素 1) "3" 2) "3" 3) "8" 4) "7" 5) "6" 6) "5" 7) "1" 8) "2" 9) "3"10) "4"11) "4"12) "3"13) "2"14) "1"127.0.0.1:6379&gt; lrem list 2 3 #删除列表中从开头的2个3(integer) 2127.0.0.1:6379&gt; lrange list 0 -1 1) "8" 2) "7" 3) "6" 4) "5" 5) "1" 6) "2" 7) "3" 8) "4" 9) "4"10) "3"11) "2"12) "1"127.0.0.1:6379&gt; lrem list -2 1 #删除列表中从结尾开始的2个1(integer) 2127.0.0.1:6379&gt; lrange list 0 -1 1) "8" 2) "7" 3) "6" 4) "5" 5) "2" 6) "3" 7) "4" 8) "4" 9) "3"10) "2"127.0.0.1:6379&gt; lrem list 0 4 #删除列表中全部的4(integer) 2127.0.0.1:6379&gt; lrange list 0 -11) "8"2) "7"3) "6"4) "5"5) "2"6) "3"7) "3"8) "2"127.0.0.1:6379&gt; trim start end对一个列表进行截取，让列表只保留指定区间内的元素，不在指定区间之内的元素都将被删除。 12345678910111213141516127.0.0.1:6379&gt; lrange list 0 -11) "8"2) "7"3) "6"4) "5"5) "2"6) "3"7) "3"8) "2"127.0.0.1:6379&gt; ltrim list 0 3 #截取0-3,即列表中前4个元素，其余元素全部删除OK127.0.0.1:6379&gt; lrange list 0 -11) "8"2) "7"3) "6"4) "5" LINDEX key index返回列表 key 中，下标为 index 的元素。下标(index)参数以 0 表示列表的第一个元素，以 1 表示列表的第二个元素，以此类推。也可以使用负数下标，以 -1 表示列表的最后一个元素， -2 表示列表的倒数第二个元素，以此类推。 123456789101112127.0.0.1:6379&gt; lrange list 0 -1 #列表中的所有元素1) "8"2) "7"3) "6"4) "5"127.0.0.1:6379&gt; lindex list 0 #查看列表中的第一个元素"8"127.0.0.1:6379&gt; lindex list 1 #查看列表中的第二个元素"7"127.0.0.1:6379&gt; lindex list -1 #查看列表中的倒数第一个元素"5"127.0.0.1:6379&gt; LINSERT key BEFORE|AFTER pivot value将值 value 插入到列表 key 当中，位于值 pivot 之前或之后。当 pivot 不存在于列表 key 时，不执行任何操作。当 key 不存在时， key 被视为空列表，不执行任何操作 1234567891011121314151617181920212223127.0.0.1:6379&gt; lrange list 0 -1 #查看list中的所有元素1) "8"2) "7"3) "6"4) "5"127.0.0.1:6379&gt; linsert list before 7 java #在7前面插入java(integer) 5127.0.0.1:6379&gt; lrange list 0 -11) "8"2) "java"3) "7"4) "6"5) "5"127.0.0.1:6379&gt; linsert list after 7 js #在7后面插入js(integer) 6127.0.0.1:6379&gt; lrange list 0 -11) "8"2) "java"3) "7"4) "js"5) "6"6) "5"127.0.0.1:6379&gt; LSET key index vlaue将列表 key 下标为 index 的元素的值设值为 value 。当 index 参数超出范围，或对一个空列表( key 不存在)进行 LSET 时，返回一个错误。 1234567891011121314151617127.0.0.1:6379&gt; lrange list 0 -11) "8"2) "java"3) "7"4) "js"5) "6"6) "5"127.0.0.1:6379&gt; lset list 0 phone #设置列表的第一个元素为phoneOK #设置成功了127.0.0.1:6379&gt; lrange list 0 -1 1) "phone"2) "java"3) "7"4) "js"5) "6"6) "5"127.0.0.1:6379&gt; Redis Set常用命令SADD key member [member …]将一个或多个member 元素加入到集合 key 当中，已经存在于集合的 member元素将被忽略。假如 key 不存在，则创建一个只包含 member元素作成员的集合。会返回被添加到集合中元素的个数，不包括重复的元素。 SMEMBERS key返回集合key中的所有成员，不存在的 key 被视为空集合。 SISMEMBERS key member判断 member元素是否集合 key 的成员。如果 member 元素是集合的成员，返回 1 。 如果 member 元素不是集合的成员，或 key 不存在，返回 0 。 12345678910111213141516171819202122127.0.0.1:6379&gt; sadd myset a b c d e #向集合中添加成员a,b,c,d,e(integer) 5127.0.0.1:6379&gt; smembers myset #查看集合中的所有成员1) "d"2) "b"3) "c"4) "a"5) "e"127.0.0.1:6379&gt; sadd myset d e f g #集合中是没有重复值的，如果sadd的值在集合中已经有了，那就会被忽略(integer) 2127.0.0.1:6379&gt; smembers myset1) "e"2) "f"3) "b"4) "d"5) "g"6) "a"7) "c"127.0.0.1:6379&gt; sismember myset g #判断元素g是否是myset中的成员(integer) 1127.0.0.1:6379&gt; sismember myset sdsds(integer) 0 SCARD key返回集合 key 的基数(集合中元素的数量)。 SREM key [key ...]移除集合key 中的一个或多个member元素，不存在的 member元素会被忽略。 12345678910111213141516127.0.0.1:6379&gt; smembers myset1) "e"2) "f"3) "b"4) "d"5) "g"6) "a"7) "c"127.0.0.1:6379&gt; srem myset e f #删除集合中的e,f(integer) 2127.0.0.1:6379&gt; smembers myset1) "b"2) "d"3) "g"4) "a"5) "c" SRANDMEMBER key count如果命令执行时，只提供了 key 参数，那么返回集合中的一个随机元素。从 Redis 2.6 版本开始， SRANDMEMBER 命令接受可选的count 参数： 如果count 为正数，且小于集合基数，那么命令返回一个包含count 个元素的数组，数组中的元素各不相同。如果 count大于等于集合基数，那么返回整个集合。 如果 count为负数，那么命令返回一个数组，数组中的元素可能会重复出现多次，而数组的长度为 count的绝对值。 1234567891011121314151617181920212223242526272829303132333435363738394041424344127.0.0.1:6379&gt; sadd set01 1 2 3 4 5 6 7 8 9 10 (integer) 10127.0.0.1:6379&gt; smembers set01 1) "1" 2) "2" 3) "3" 4) "4" 5) "5" 6) "6" 7) "7" 8) "8" 9) "9"10) "10"127.0.0.1:6379&gt; srandmember set01 5 #从set01这个集合中随机抽取5个数组成数组，这些数没有重复的1) "2"2) "1"3) "5"4) "8"5) "3"127.0.0.1:6379&gt; srandmember set01 51) "1"2) "8"3) "6"4) "10"5) "9"127.0.0.1:6379&gt; srandmember set01 51) "7"2) "4"3) "8"4) "10"5) "9"127.0.0.1:6379&gt; srandmember set01 -5 #从set01这个集合中随机抽取5个数组成数组，这些数有可能会重复1) "5"2) "1"3) "5"4) "7"5) "7"127.0.0.1:6379&gt; srandmember set01 -51) "6"2) "5"3) "5"4) "2"5) "9"127.0.0.1:6379&gt; SPOP key count移除并返回集合中的一个或多个随机元素。 12345678910111213141516171819202122232425127.0.0.1:6379&gt; smembers set01 1) "1" 2) "2" 3) "3" 4) "4" 5) "5" 6) "6" 7) "7" 8) "8" 9) "9"10) "10"127.0.0.1:6379&gt; spop set01 1 #随机移除一个元素并返回这个元素1) "3"127.0.0.1:6379&gt; spop set01 5 #随机移除5个元素并返回元素1) "2"2) "5"3) "8"4) "6"5) "1"127.0.0.1:6379&gt; smembers set011) "4"2) "7"3) "9"4) "10"127.0.0.1:6379&gt; SMOVE source destination member将 member 元素从 source 集合移动到 destination 集合。SMOVE 是原子性操作。 如果 source 集合不存在或不包含指定的 member 元素，则 SMOVE 命令不执行任何操作，仅返回 0 。否则， member 元素从 source 集合中被移除，并添加到 destination 集合中去。 当 destination 集合已经包含 member 元素时， SMOVE 命令只是简单地将 source 集合中的 member 元素删除。 12345678910111213141516127.0.0.1:6379&gt; keys *1) "set01"127.0.0.1:6379&gt; sadd set02 a b c d e f(integer) 6127.0.0.1:6379&gt; keys *1) "set01"2) "set02"127.0.0.1:6379&gt; smove set02 set01 a(integer) 1127.0.0.1:6379&gt; smembers set011) "9"2) "7"3) "10"4) "4"5) "a"127.0.0.1:6379&gt; Set集合的数学操作命令SDIFF key [key …]返回一个集合的全部成员，该集合是所有给定集合之间的差集。不存在的 key 被视为空集。 123456789101112127.0.0.1:6379&gt; sadd A 1 2 3 4 5(integer) 5127.0.0.1:6379&gt; sadd B 1 2 3 a c d(integer) 6127.0.0.1:6379&gt; sdiff A B #求A-B,即A有B没有的成员1) "4"2) "5"127.0.0.1:6379&gt; SDIFF B A #求B-A，即B有A没有的成员1) "d"2) "c"3) "a"127.0.0.1:6379&gt; SINTER key [key ...]返回一个集合的全部成员，该集合是所有给定集合的交集。不存在的 key 被视为空集。当给定集合当中有一个空集时，结果也为空集(根据集合运算定律)。 123456789127.0.0.1:6379&gt; sinter A B #求A∩B，即A,B公有的成员1) "1"2) "2"3) "3"127.0.0.1:6379&gt; sinter B A #求B∩A1) "1"2) "2"3) "3"127.0.0.1:6379&gt; SUNION key [key ...]返回一个集合的全部成员，该集合是所有给定集合的并集。不存在的 key 被视为空集。 12345678910111213141516171819127.0.0.1:6379&gt; SUNION A B #求A∪B，即A，B中的所有元素1) "2" 2) "1"3) "4"4) "3"5) "5"6) "d"7) "c"8) "a"127.0.0.1:6379&gt; SUNION B A1) "1"2) "2"3) "4"4) "3"5) "5"6) "d"7) "c"8) "a"127.0.0.1:6379&gt; Redis Hash常用命令HSET key filed vlaue [filed value ...]将哈希表 key中域 field 的值设置为 value 。如果给定的哈希表并不存在， 那么一个新的哈希表将被创建并执行 HSET 操作。如果域 field 已经存在于哈希表中， 那么它的旧值将被新值 value 覆盖。 HGET key filed返回哈希表中给定域的值。如果给定的域或者hash表不存在，返回nil。 HGETALL key返回哈希表 key 中，所有的域和值。在返回值里，紧跟每个域名(field name)之后是域的值(value)，所以返回值的长度是哈希表大小的两倍。 HMSET key filed value [filed value ...]同时将多个 field-value (域-值)对设置到哈希表 key 中。此命令会覆盖哈希表中已存在的域。如果 key 不存在，一个空哈希表会被创建并执行 HMSET 操作。这个的使用和HSET 的用法一样。 HMGET key filed回哈希表 key 中，一个或多个给定域的值。如果给定的域不存在于哈希表，那么返回一个 nil 值。这个命令的作用和HEGT的作用一样。 123456789101112131415127.0.0.1:6379&gt; hset student name zhansan age 20 gender M #hash以key-value的形式存值(integer) 3127.0.0.1:6379&gt; hget student name #获得student的name属性的值"zhansan"127.0.0.1:6379&gt; hget student age #获得student的age属性的值"20"127.0.0.1:6379&gt; hget student gender #获得student的gender属性的值"M"127.0.0.1:6379&gt; hgetall student 1) "name" 2) "zhansan" 3) "age" 4) "20" 5) "gender" 6) "M" HSETNX key filed value当且仅当域field 尚未存在于哈希表key中的情况下， 将它的值设置为 value 。如果给定域已经存在于哈希表当中， 那么命令将放弃执行设置操作。如果哈希表 hash 不存在， 那么一个新的哈希表将被创建并执行 HSETNX 命令 HEXISTS key filed检查给定域 field 是否存在于哈希表 hash 当中。存在返回1，不存在返回0。 123456789101112131415161718192021222324127.0.0.1:6379&gt; hgetall student #得到hash表中所有student的属性（奇数）和值（偶数） 1) "name" 2) "zhansan" 3) "age" 4) "20" 5) "gender" 6) "M"127.0.0.1:6379&gt; hsetnx student name lisi #给一个存在的属性设值，是不会成功的(integer) 0127.0.0.1:6379&gt; hset student class IOT(integer) 1127.0.0.1:6379&gt; hsetnx student address aabbcc #给一个不存在的属性设值会成功(integer) 1127.0.0.1:6379&gt; HEXISTS student address #原先没有的属性address现在已经有了(integer) 1127.0.0.1:6379&gt; hgetall student 1) "name" 2) "zhansan" 3) "age" 4) "20" 5) "gender" 6) "M" 7) "address" 8) "aabbcc" HLEN key返回哈希表 key 中域的数量。 12345678910111213127.0.0.1:6379&gt; hgetall student 1) "name" 2) "zhansan" 3) "age" 4) "20" 5) "gender" 6) "M" 7) "class" 8) "IOT" 9) "address"10) "aabbcc"127.0.0.1:6379&gt; hlen student #返回hash表student中属性的个数(integer) 5 HSTRLEN key filed返回哈希表 key 中， 与给定域 field 相关联的值的字符串长度（string length）。如果给定的键或者域不存在， 那么命令返回 0 。 12345678910111213141516127.0.0.1:6379&gt; hgetall student 1) "name" 2) "zhansan" 3) "age" 4) "20" 5) "gender" 6) "M" 7) "class" 8) "IOT" 9) "address"10) "aabbcc"127.0.0.1:6379&gt; hstrlen student name #返回student表中name属性的vlaue的长度(integer) 7127.0.0.1:6379&gt; hstrlen student address #返回student表中address属性的vlaue的长度(integer) 6127.0.0.1:6379&gt; HINCRBY key filed increment为哈希表key中的域field的值加上增量increment。增量也可以为负数，相当于对给定域进行减法操作。如果 key 不存在，一个新的哈希表被创建并执行 HINCRBY 命令。如果域 field 不存在，那么在执行命令前，域的值被初始化为 0 。 HINCRBYFLOAT key filed increment和HINCRBY key filed increment的作用一样，都是哈希表key中的域field的值加上增量increment，但是这里的增量是浮点数。 1234567891011127.0.0.1:6379&gt; hincrby student age 2 #给studnet表中的age属性增加2(integer) 22127.0.0.1:6379&gt; hincrby student age 2(integer) 24127.0.0.1:6379&gt; hincrby student age 2(integer) 26 127.0.0.1:6379&gt; hget student age"26"127.0.0.1:6379&gt; hincrbyfloat student age 0.5 #给studnet表中的age属性增加0.5"26.5"127.0.0.1:6379&gt; HKEYS key返回哈希表key中的所有域。 HVALS key返回哈希表key中的所有域的值。 12345678910111213127.0.0.1:6379&gt; hkeys student #得到hash表中的所有属性（域）1) "name"2) "age"3) "gender"4) "class"5) "address"127.0.0.1:6379&gt; hvals student #得到hash表中的所有属性对应的值1) "zhansan"2) "26.5"3) "M"4) "IOT"5) "aabbcc"127.0.0.1:6379&gt; Redis ZSet常用命令ZADD key score member [score member ...]将一个或多个 member 元素及其 score值加入到有序集key 当中。如果某个 member 已经是有序集的成员，那么更新这个member的 score值，并通过重新插入这个 member元素，来保证该member在正确的位置上。score 值可以是整数值或双精度浮点数。如果 key 不存在，则创建一个空的有序集并执行ZADD 操作。 ZRANGE key start end [withscore]返回有序集 key 中，指定区间内的成员。其中成员的位置按 score 值递增(从小到大)来排序。具有相同 score 值的成员按字典序(lexicographical order )来排列。如果需要成员按 score 值递减(从大到小)来排列，可以使用 ZREVRANGE key start end withscore ZREVRANGE key start end [withscores]返回有序集key中，指定区间内的成员。其中成员的位置按 score值递减(从大到小)来排列。 具有相同 score 值的成员按字典序的逆序(reverse lexicographical order)排列。 123456789101112131415161718192021222324252627127.0.0.1:6379&gt; zadd stu 70 v1 80 v2 90 v3 100 v4 #和set大致类似，只是这里每一个score和member是一个整体，按照score的大小排序(integer) 4127.0.0.1:6379&gt; ZRANGE stu 0 -1 #默认升序排列1) "v1"2) "v2"3) "v3"4) "v4"127.0.0.1:6379&gt; zrange stu 0 -1 withscores #使用withscores可以打印出score1) "v1"2) "70"3) "v2"4) "80"5) "v3"6) "90"7) "v4"8) "100"#逆序打印有序集的成员127.0.0.1:6379&gt; zrevrange stu 0 -1 withscores1) "v4"2) "100"3) "v3"4) "90"5) "v2"6) "80"7) "v1"8) "70" ZRANGEBYSCORE key min max [withscores] [limit offset count]返回有序集 key中，所有 score 值介于min和max之间(包括等于 min 或 max )的成员。有序集成员按 score 值递增(从小到大)次序排列。具有相同 score 值的成员按字典序(lexicographical order)来排列(该属性是有序集提供的，不需要额外的计算)。 可选的 LIMIT 参数指定返回结果的数量及区间(就像SQL中的SELECT LIMIT offset, count )，注意当 offset 很大时，定位offset的操作可能需要遍历整个有序集，此过程最坏复杂度为 O(N) 时间。 可选的 WITHSCORES 参数决定结果集是单单返回有序集的成员，还是将有序集成员及其 score 值一起返回。 1234567891011121314151617181920212223242526272829303132333435#打印出score介于[60 90]的值127.0.0.1:6379&gt; zrangebyscore stu 60 90 1) "v1"2) "v2"3) "v3" #打印出score介于[60 90]的值并且打印出对应的score127.0.0.1:6379&gt; zrangebyscore stu 60 90 withscores 1) "v1"2) "70"3) "v2"4) "80"5) "v3"6) "90"#打印出score介于[60 90)的值，并且打印出score127.0.0.1:6379&gt; zrangebyscore stu 60 (90 withscores 1) "v1"2) "70"3) "v2"4) "80"#打印出score介于(60 90)的值，并且打印出score127.0.0.1:6379&gt; ZRANGEBYSCORE stu (60 (90 withscores1) "v1"2) "70"3) "v2"4) "80"#打印出score介于[60 90]并且是从0（第一个元素）开始的2个元素127.0.0.1:6379&gt; zrangebyscore stu 60 90 limit 0 21) "v1"2) "v2"#打印出score介于[60 90]并且是从0（第一个元素）开始的2个元素，并且打印出score127.0.0.1:6379&gt; ZRANGEBYSCORE stu 60 90 withscores limit 0 21) "v1"2) "70"3) "v2"4) "80" ZREM key member [menber ...]移除有序集key中的一个或多个成员，不存在的成员将被忽略。 12345678910111213141516171819127.0.0.1:6379&gt; zrange stu 0 -1 withscores1) "v1"2) "70"3) "v2"4) "80"5) "v3"6) "90"7) "v4"8) "100"#删除有序集stu中的v1127.0.0.1:6379&gt; zrem stu v1 (integer) 1127.0.0.1:6379&gt; zrange stu 0 -1 withscores1) "v2"2) "80"3) "v3"4) "90"5) "v4"6) "100" ZCARD stu当 key 存在且是有序集类型时，返回有序集的基数。 当 key不存在时，返回 0 。 ZCOUNT stu start end返回有序集 key中， score值在 min和max 之间(默认包括score 值等于min 或 max )的成员的数量。 12345678910111213127.0.0.1:6379&gt; zrange stu 0 -1 withscores1) "v2"2) "80"3) "v3"4) "90"5) "v4"6) "100"#统计有序集中成员的总个数127.0.0.1:6379&gt; ZCARD stu(integer) 3#统计大于80，小于等于100的成员127.0.0.1:6379&gt; ZCOUNT stu (80 100(integer) 2 ZRANK key member返回有序集key中成员member的排名。其中有序集成员按 score 值递增(从小到大)顺序排列。排名以 0 为底，也就是说，score 值最小的成员排名为 0 。 ZREVRANK key member返回有序集key中成员member 的排名。其中有序集成员按 score值递减(从大到小&lt;和默认的逆序&gt;))排序。排名以 0 为底，也就是说， score 值最大的成员排名为 0 。 12345678910111213141516171819202122127.0.0.1:6379&gt; zrange stu 0 -1 withscores 1) "v0" 2) "50" 3) "v1" 4) "60" 5) "v2" 6) "80" 7) "v3" 8) "90" 9) "v4"10) "100"#成员v3的排名127.0.0.1:6379&gt; zrank stu v3(integer) 3#成员v4的排名127.0.0.1:6379&gt; zrank stu v4(integer) 4#成员逆序排序127.0.0.1:6379&gt; zrevrank stu v3(integer) 1127.0.0.1:6379&gt; zrevrank stu v4(integer) 0 ZRANGEBYSOCRE key min max [withscores] [limit offset count]返回有序集 key中，所有score 值介于min和 max 之间(包括等于 min或 max )的成员。有序集成员按 score值递增(从小到大)次序排列。具有相同 score值的成员按字典序(lexicographical order)来排列： 可选的LIMIT参数指定返回结果的数量及区间(就像SQL中的 SELECT LIMIT offset, count )，注意当 offset 很大时，定位 offset 的操作可能需要遍历整个有序集，此过程最坏复杂度为 O(N) 时间。 可选的WITHSCORES 参数决定结果集是单单返回有序集的成员，还是将有序集成员及其 score 值一起返回。 ZREVRANGESCORE key min max [withsocres] [limit offset count]使用方法和ZRANGEBYSOCRE的用法一样，还是这个是前者的逆序 123456789101112131415161718192021#返回stu有序集中[90 100]的score和值127.0.0.1:6379&gt; zrangebyscore stu 90 100 withscores1) "v3"2) "90"3) "v4"4) "100"#返回stu有序集中（90 100]的score和值127.0.0.1:6379&gt; zrangebyscore stu (90 100 withscores1) "v4"2) "100"#返回stu有序集中[90 100]的score和值，只是是以逆序打印127.0.0.1:6379&gt; zrevrangebyscore stu 100 90 withscores1) "v4"2) "100"3) "v3"4) "90"#返回stu有序集中（90 100]的score和值，只是是以逆序打印127.0.0.1:6379&gt; zrevrangebyscore stu 100 (90 withscores1) "v4"2) "100"127.0.0.1:6379&gt;]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis快速入门]]></title>
    <url>%2F2019%2F09%2F22%2FRedis%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[什么是Redis？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Redis是Remote Dictionary Severy(远程字典服务器)的缩写，它是一个基于C语言编写的完全开源免费，并且遵循BSD协议的一个高性能的key-value型分布式内存数据库。Redis使用key-value的形式保存值，常用的数据类型有String、list、hash、set、zset等数据结构，因此也被人们称为数据结构服务器。当然他也是NoSQL的一种典型产品。 Redis的特性 1、Redis支持数据的持久化，可以将内存中的数据保存到磁盘上，重启后可已再次加载数据 2、Redis不仅仅支持简单的key-value类型的数据，同时还支持list、set、zset、hash等存储数据结构 3、Redis支持数据的备份，即master-slave模式的数据备份。 4、Redis的性能极高-官方宣称Redis的读速度可以达到110000次/s，写的速度是81000次/s. 5、原子操作—Redis的所有操作都是原子的，即要么成功执行要么失败完全不执行。单个操作是原子性的。多个操作也支持事务。 在Linux（CentOS 7）上安装Redis首先去Redis的官方网站下载需要redisredis官网的镜像网址：http://download.redis.io/releases/，在这里有redis的各个版本： 在Liunx上使用wget命令下载（我这个下载它当前的最新的镜像redis-5.0.5-tar.gz版本）：wget http://download.redis.io/releases/redis-5.0.5.tar.gz 下载好后解压tar -zxvf redis-5.0.5.tar.gz 安装使用make命令编译解压完成后，cd 到解压后文件中，执行make命令，这一步可能会报错（在较低版本的Linux发行系统中可能会报错提示没有GCC环境，那就去安装一下GCC,然后执行make destclean命令清除失败的安装产生的文件，之后再次执行nake命令） make install PREFIX=/usr/local/redismake执行成功后文件夹找就会多一个src文件夹，进入src文件夹，执行 make install PREFIX=/usr/local/redis命令，把redis安装到/usr/local/redis/ 有关的配置把redis配置文件copy到安装目录下 配置redis为后台启动将刚在复制到安装目录的那个redis.conf打开，并把其中的daemonize no改成daemonize yes 设置redis开机自动启动打开/etc/rc.local 在里面添加：/usr/local/redis/bin/redis-server /usr/local/redis/redis.conf(rc.local这个脚本会在开机的时候执行） 启动redis服务使用redis-server /usr/local/redis/redis.conf启动redis服务。注意：如果按照上面的正常的流程安装下来，但是在执行redis-server启动redis的时候提示redis-server不是命令，不要慌张，这是由于这个redis-server不是全局的命令不能在每一个目录下使用，当在别的目录下使用的时候系统在/usr/bin/找不到这个命令，因此我们需要把安装目录下的redis-server移动到到/usr/bin目录下就可以了。比如我的安装目录是/home/myredis/redis/redis-5.0.5/src/redis-server，那就可以执行下面的命令：ln -s /home/myredis/redis/redis-5.0.5/src/redis-server /usr/bin/redis-server 解决问题后再来执行上面那个命令启动redis服务,启动后我们可以使用ps -ef | grep redis来查看服务有没有启动： redis启动成功了，之后执行redis-cli -p 6379 进入redis的客户端 redis-benchmarkredis自带了一个性能测试工具redis-benchmark，他有丰富的模拟组件和指令可以使用。Redis-benchmark的官方中文链接： 。redis-benchmark 程序模拟 N 个客户端同时发出 M 个请求来测试在本机上redis可以达到的吞吐量从而间接的计算出你的机器性能高低。 表现为Response time和完成request的数量等等。 redis-benchmark可以使用到的参数： 12345-t 选择你想测试的命令，比如redis-benchmark -t set -p 指定port redis-benchmark -p 6379 -l 一直循环 -c 指定客户端数量 -n 指定request数量 redis常识性知识点redis的默认端口是6379redis的常用五大数据类型Redis的五大常用数据类型是：String（字符串）、List（列表）、Hash（散列表）、Set（集合）、ZSet（sorted Set，有序集合）。这五大数据类型在我的另一篇笔记Redis五大常用数据类型中有详细的介绍。 redis是单进程的来处理客户端的请求。对读写等事件的响应式通过对epoll函数的包装来实现到的。Redis的实际处理速度完全依靠主进程的执行效率。epoll是Linux内核为处理大批量文件描述符伟做了改进的epoll，是Linux下多路复用IO接口select/poll的增强版本，他能显著提高程序在大量并发连接中只有少量活跃的情况下的系统CPU利用率。 默认有16个数据库。默认的数据库从DB0开始（一进入redis客户端默认使用的也是0号库），切换可以使用select &lt;dbid&gt;,这些在redis.conf这个文件中有详细的说明： SELECT 命令切换数据库使用select &lt;dbid&gt;，比如select 1就可以切换到1号库： DBSIZE 命令查看数据库key的数量 KEYS 命令查看数据库中的key123456789101112131415127.0.0.1:6379&gt; DBSIZE(integer) 7 #7个key127.0.0.1:6379&gt; keys * #查看本库中的所有key1) "mylist"2) "k3"3) "myset:__rand_int__"4) "key:__rand_int__"5) "k2"6) "counter:__rand_int__"7) "k1"127.0.0.1:6379&gt; keys k? #查看以`k`打头的key1) "k3"2) "k2"3) "k1"127.0.0.1:6379&gt; 但我们不想要数据库中的key的时候可以使用FLUSHDB清空当前数据库的所有key，FLUSHALL清空所有数据库中所有key]]></content>
      <categories>
        <category>NoSQL</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker进阶之Dockerfile和容器数据卷（Volume）]]></title>
    <url>%2F2019%2F09%2F20%2Fdocker%E8%BF%9B%E9%98%B6%E4%B9%8B%E6%95%B0%E6%8D%AE%E5%8D%B7%2F</url>
    <content type="text"><![CDATA[什么是数据卷？什么是容器数据卷？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据卷就是一个文件或者文件夹。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Docker的理念之一是将应用与其运行的环境打包，docker容器的生命周期是与其运行的程序一致的，而对数据的要求是持久化，docker容器之间也需要有共享数据的渠道。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据卷是特殊的目录，可以绕过联合文件系统，为一个或多个容器提供访问。数据卷设计的目的是数据的持久化，是完全独立于容器的生命周期，不会在容器删除时删除其挂载的数据卷，也不会存在类似垃圾收集机制，对容器引用的数据卷进行处理。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;数据卷存在于宿主机中，独立于容器，和容器的生命周期是分离的，数据卷存在于宿主机的文件系统中，数据卷可以是目录也可以是文件，容器可以利用数据卷与宿主机进行数据共享，实现了容器间的数据共享和交换。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;通俗地来说，docker容器数据卷可以看成使我们生活中常用的u盘，它存在于一个或多个的容器中，由docker挂载到容器，但不属于联合文件系统，Docker不会在容器删除时删除其挂载的数据卷。 Docker添加数据的两种方式使用命令的方式添加数据卷在使用docker run的时候我们可以通过 -v 来创建一个数据卷并挂载到容器上，在一次run中多次使用可以挂载多个容器。命令语法：docker run -it -v /宿主机绝对路径:/容器绝对路径 镜像名 打开命令行终端，使用docker命令以交互式的方式来运行centos 1234567[root@localhost /]# docker run --name centos -it -v /home/huangxin/hostdata/:/dataVolmeContainer --privileged=true 67fa590cfc1c /bin/bash [root@aa29e3790769 /]# lsanaconda-post.log bin dataVolmeContainer dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var[root@aa29e3790769 /]# cd dataVolmeCOntainer[root@localhost /]# docker run -it -v /home/huangxin/hostdata:/dataVolmeContainer centos [root@0504f3b67b95 /]# ls #进入到容器内部，容器内部的目录创建好了anaconda-post.log bin dataVolmeContainer dev etc home lib lib64 如果发现挂载在容器中的目录没有访问权限，可以加上--privileged=true这个参数。启动成功后我们可以用前面我们学过一个命令docker inspect 容器名/容器ID来查看关于一个容器的有关细节，打开我们发现主机和容器之间的共享已经建立起来了，而且默认都是可读可写的： 接下来测试一下容器和主机之间互相共享数据：打开另一个终端中，来到/home/huangxin/hostdata目录下，新建text1.txt,然后在里面写点东西： 12345[huangxin@localhost ~]$ cd /home/huangxin/hostdata[root@localhost hostdata]# touch text1.txt[root@localhost hostdata]# lstext1.txt[root@localhost hostdata]# vim text1.txt 随便写点东西： 然后来到容器里，就可以看到主机在主机端的共享文件夹中写的数据在容器中可以看到了： 接着我们反向操作看看在容器中写的数据能不能在主机可以共享到。 1234[root@aa29e3790769 dataVolmeContainer]# touch Demo1.txt[root@aa29e3790769 dataVolmeContainer]# vi Demo1.txt[root@aa29e3790769 dataVolmeContainer]# lsDemo1.txt text1.txt 还是随便写了点东西在新建的Demo1.text中，然后在主机端去看看有没有。 1234[root@localhost hostdata]# lsDemo1.txt text1.txt[root@localhost hostdata]# cat Demo1.txtHere is container!!!Hello Host. 可以看到主机和容器之间可以相互共享文件了；而且对这些文件都具有读写的权限。而且即使容器停止后，这些共享的数据还是同步的。然而有时我们不需要让容器写数据，那么我们就可以用带权限的命令：docker run -it -v /宿主机绝对路径:/容器绝对路径:ro 镜像名 ，ro表示read only。 使用DockerFile添加数据卷（这里先大概了解一下，下面会有Dockerfile详细的介绍）编写自定义的Dockerfile，可以使用VOLUME []命令可以挂载任意多个共享目录，以json的格式，多个目录逗号隔开。 1234FROM centosVOLUME ["/data1","/data2"]CMD echo "finished-----SUCCESS"CMD /bin/bash 使用docker build命令通过Dockerfile构建一个镜像docker build的基本语法：docker build [OPTIONS] PATH | URL | - -f,--file 指定Dockerfile的路径名 -t,--tag 指定镜像的REPOSITORY 和标签 常用的写法：docker build -f /Dcokerfile文件的路径 -t 仓库:标签 123456789101112131415161718192021[root@localhost docker]# docker build -f /home/huangxin/docker/Dockerfile -t xust-hx/centos .Sending build context to Docker daemon 2.048 kBStep 1/4 : FROM centos ---&gt; 67fa590cfc1cStep 2/4 : VOLUME /data1 /data2 ---&gt; Running in 296561fadbc5 ---&gt; da4cfb9f98d5Removing intermediate container 296561fadbc5Step 3/4 : CMD echo "finished-----SUCCESS" ---&gt; Running in 668697ef3ba4 ---&gt; ec2bf3c54a54Removing intermediate container 668697ef3ba4Step 4/4 : CMD /bin/bash ---&gt; Running in 5b3d43b5114a ---&gt; e61c27683817Removing intermediate container 5b3d43b5114aSuccessfully built e61c27683817[root@localhost docker]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZExust-hx/centos latest e61c27683817 13 seconds ago 202 MBxust/tomcat 1.0.0 71a1320815f5 19 hours ago 506 MB 可以看到我们的镜像构建成功了，下来我们来启动基于我们构建镜像的一个容器。 1[root@localhost docker]# docker run -it e61c27683817 /bin/bash 使用ls查看，发现容器中自动就挂载了两个文件夹data1,data2 但是这两个文件夹对应在主机上的什么地方呢？使用docker inspect来看看这个运行中的容器的详细信息 可以看到，docker对于使用VOLUME挂载的共享目录，在主机中会有一个默认的文件夹——&quot;/var/lib/docker/volumes/。在这个文件夹下你有挂载几个，docker就默认给你生成几个对应的共享目录。 1234[root@localhost huangxin]# cd /var/lib/docker/volumes/402caff5bb629320e524e8239b4ca121be7d11ce4df4b55b657bdcfdc549b543/_data[root@localhost _data]# pwd/var/lib/docker/volumes/402caff5bb629320e524e8239b4ca121be7d11ce4df4b55b657bdcfdc549b543/_data[root@localhost _data]# vim Demo1.txt 还是一样随便写点东西，然后去容器中的data1目录看看有没有Demo1.txt以及内容。 12345[root@6f062b92cccb /]# cd data1[root@6f062b92cccb data1]# lsDemo1.txt[root@6f062b92cccb data1]# cat Demo1.txtHello,this is host of data1! 容器之间共享数据让容器之间共享数据首先启动一个父容器(启动我们刚才制作的那个镜像) 12345[root@localhost docker]# docker run -it --name centos01 e61c27683817 [root@a5c471c5b738 /]# lsanaconda-post.log bin data1 data2 dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var//在data1目录下新建centos01.txt[root@a5c471c5b738 /]# vi centos01.txt 在centos01.txt中随便写点东西，然后在启动同样容器时候使用命令参数：--volumes-from来和父容器共享数据: 1234567891011121314[root@localhost docker]# docker run -it --name centos02 --volumes-from centos01 e61c27683817 [root@fec297cd7c00 /]# ls anaconda-post.log bin data1 data2 dev etc home lib lib64 media mnt opt proc root run sbin srv sys tmp usr var[root@fec297cd7c00 /]# cd data1[root@fec297cd7c00 data1]# vim centos02.txt//在centos02.txt中随便写点东西//再启动另一个容器挂载到centos01上[root@fec297cd7c00 data1]# [root@localhost docker]# docker run -it --name centos03 --volumes-from centos01 e61c27683817 [root@1a8862870583 /]# cd data1[root@1a8862870583 data1]# lscentos01.txt centos02.txt[root@1a8862870583 data1]# vi centos03.txt//同样在centos03.txt中随便写点东西 最终达到的效果：父子容器都可以互相共享各自的数据： 那么如果我们删除了父容器，父容器以前共享的数据还在吗？子容器之间的共享还会有吗？来，一张图回答这个问题： Volume的作用/特点最后通过这几个示例可以终结出docker提供的数据卷的特点如下： 通过数据卷可以在容器之间实现数据的共享和重用 对数据卷的修改会立马生效(非常适合作为开发环境) 对数据卷的更新,不会影响镜像 数据卷会一直存在,直到没有容器使用才会被清除 Dockerfile基础Dockerfile是什么？Dockerfile是一个包含用于创建镜像的命令的文本文档。Docker通过读取Dockerfile中的指令自动生成镜像。Docker build命令用于从Dockerfile构建镜像。可以在docker build命令中使用-f参数指向文件系统中任何位置的Dockerfile。 Dockerfile的解析过程？1.Dockerfile中第一条指令必须是FROM 指令，它的作用是指定将要生成的镜像的基础镜像，类似于java中的继承。因此Dockerfile执行的第一步就是加载基础镜像；2.加载完基础镜像后，后面的指令按照定义的顺序从上到下依次执行，每执行一条指令都会对容器做一些修改；3.执行类似docker commit的操作提交一个新的镜像层；4.docker再基于刚提交的镜像运行一个新容器；5.执行Dockerfile中的下一条指令直到所有指令都执行完成； Dockerfile、Docker镜像、Docker容器三者的关系 从应用软件的角度来看，Dockerfile、Docker镜像与Docker容器分别代表软件的三个不同阶段： Dockerfile是软件的原材料 Docker镜像是软件的交付品 Docker容器则可以认为是软件的运行态。 Dockerfile面向开发，Docker镜像成为交付标准，Docker容器则涉及部署与运维，三者缺一不可，合力充当Docker体系的基石。 Dockerfile保留字指令FROM &nbsp;&nbsp;指定基础镜像,要建立的新镜像是基于那个镜像的,必须是Dockerfile中的第一个命令 12345格式： FROM &lt;image&gt;[:&lt;tag&gt;] FROM &lt;image&gt;[@&lt;digest&gt;]示例： FROM tomcat:8.5.3 MAINTAINER &nbsp;&nbsp;镜像维护者的信息 12345格式： MAINTAINTER &lt;info&gt;示例： MAINTAINTER zhangsan@163.com MAINTAINTER 张三 RUN &nbsp;&nbsp;容器构建是需要运行的命令 12345格式： RUN &lt;command&gt; #shell执行 RUN ["executable", "param1", "param2"] #exec执行示例： RUN yum install -y vim EXPOSE &nbsp;&nbsp;容器运行后对外暴露的端口 1234格式： EXPOSE &lt;port&gt; [&lt;port&gt;...]示例： EXPOSE 8080 3306 WORKDIR &nbsp;&nbsp; 指定容器创建后，终端默认登录进来的工作目录,类似于cd命令 123456格式： WORKDIR /path示例： WORKDIR / #此时工作目录为容器的根目录 WORKDIR /tmp #此时工作目录为容器的/tmp目录 WORKDIR /aaa #此时工作目录为容器的/tmp/aaa ENV &nbsp;&nbsp;用来在构建镜像的过程中设置环境变量 123456格式： ENV &lt;key&gt; &lt;value&gt; #&lt;key&gt;之后的所有内容均会被视为其&lt;value&gt;的组成部分，因此，一次只能设置一个变量 ENV &lt;key&gt;=&lt;value&gt; ... #可以设置多个变量，每个变量为一个"&lt;key&gt;=&lt;value&gt;"的键值对，如果&lt;key&gt;中包含空格，可以使用\来进行转义，也可以通过""来进行标示；另外，反斜线也可以用于续行示例： ENV JAVA_HOME /usr/local/jdk1.8.0_171 ENV CLASSPATH=$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar ADD &nbsp;&nbsp;该命令将复制指定本地目录(src)中的文件到容器中的指定目录(det)中，src可以是是一个绝对路径，也可以是一个URL或一个tar文件，tar文件会自动解压为目录。 123456格式： ADD &lt;src&gt; &lt;dest&gt; ADD ["&lt;src&gt;","&lt;dest&gt;"] #用于支持包含空格的路径示例： ADD jdk-8u171-linux-x64.tar.gz /usr/local #ADD ["jdk-8u171-linux-x64.tar.gz","/usr/local"] 和上面的作用一样 COPY &nbsp;&nbsp;功能类似ADD，但是是不会自动解压文件，也不能访问网络资源VOLUME &nbsp;&nbsp;容器数据卷，用于数据保存和持久化，不多说上面有详细的介绍 1234格式： VOLUME ["/path/to/dir"] #可以写多个挂载目录，中间用逗号隔开示例： VOLUME ["dataVolume1","dataVolume2"] CMD &nbsp;&nbsp;指定一个容器启动时要执行的命令 ，Dockerfile中可以有多个CMD指令，但是只有最后一个CMD命令会生效，并且Dockerfile中的CMD命令会被docker run命令之后的参数替换 12345678格式： CMD ["executable","param1","param2"] (执行可执行文件，优先) CMD ["param1","param2"] (设置了ENTRYPOINT，则直接调用ENTRYPOINT添加参数) CMD command param1 param2 (执行shell内部命令)示例： CMD ["/usr/local/apache-tomcat-9.0.8/bin/catalina.sh","run"] CMD ["/bin/bash"] CMD cd /bin/bash ENTRYPOINT &nbsp;&nbsp;指定一个容器启动时要执行的命令，和CMD一样，都是在指定容器动程序以及参数，但是他和CMD的区别是他会追加docker run后面的命令而不是覆盖。 123456格式： ENTRYPOINT ["executable", "param1", "param2"] (可执行文件, 优先) ENTRYPOINT command param1 param2 (shell内部命令)示例： ENTRYPOINT ["/usr/local/apache-tomcat-9.0.8/bin/catalina.sh","run"] ENTRYPOINT /bin/bash ONBUILD &nbsp;&nbsp;用于设置镜像触发器 1234格式： ONBUILD [INSTRUCTION]示例： ONBUILD ADD . /app/src/ 小试牛刀：使用Dockerfile的保留字构建一个可以构建tomcat的镜像的Dockerfile 12345678910111213141516171819202122232425262728293031#加载基础镜像FROM centos#维护者的信息MAINTAINER Huangxin#赋值jdk和tomcat到目标路径ADD jdk-8u212-linux-x64.tar.gz /usr/local/ADD apache-tomcat-8.5.37.tar.gz /usr/local/#在容器中安装vimRUN yum -y install vim#设置工作路径，就是登陆目录ENV workspace /usr/localWORKDIR $workspace#设置tomcat的环境ENV JAVA_HOME /usr/local/java/jdk1.8.0_212ENV CLASSPATH $JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jarENV CATALINTA_HOME /usr/local/tomcat_home/apache-tomcat-8.5.37ENV CATALINTA_BASE /usr/local/tomcat_home/apache-tomcat-8.5.37ENV PATH $PATH:$JAVA_HOME/bin:$CATALINA_HOME/lib:$CATALINA_HOME/bin#端口号默认为8080EXPOSE 8080#构建成功后打印成功信息CMD echo "&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;Successful!&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;"#最后启动tomcatENTRYPOINT ["/usr/local/apache-tomcat-8.5.37/bin/catalina.sh"] 编写好后使用dcoker命令：docker build -t xust/tomcat:8.5.37 .来构建镜像(docker build默认使用当前目录下的Dockerfile来构建镜像，命令中最后那个点表示当前目录)： 中间经过很多个步骤，一层一层的叠加，最后构建成功了： 使用docker images查看我们构建的镜像：]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Docker核心技术（基础篇）]]></title>
    <url>%2F2019%2F09%2F18%2FCentOS7%E9%85%8D%E7%BD%AEDocker%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp; 什么是Docker?&nbsp;&nbsp;&nbsp;&nbsp;Docker是一个开源的应用容器引擎，基于 Go 语言 并遵从Apache2.0协议开源。&nbsp;&nbsp;&nbsp;&nbsp;Docker可以让开发者打包他们的应用以及依赖包到一个轻量级、可移植的容器中，然后发布到任何流行的 Linux 机器上，也可以实现虚拟化。容器是完全使用沙箱机制，相互之间不会有任何接口（类似 iPhone 的 app）,更重要的是容器性能开销极低。&nbsp;&nbsp;&nbsp;&nbsp;Docker 从 17.03 版本之后分为 CE（Community Edition: 社区版） 和 EE（Enterprise Edition: 企业版），我们用社区版就可以了。&nbsp;&nbsp;&nbsp;&nbsp;简单的说，Docker就是一个开源的应用容器引擎；是一个轻量级的容器技术。使用Docker我们可以把软件打包成一个镜像，在镜像中做好软件的相关配置，然后把镜像发布出去，其他使用者就可以直接使用我们的这个镜像而不需要其他的配置就可是我们的应用跑起来。 &nbsp;&nbsp; Docker三大组成Docker的三大基本组成（要素）：镜像（images）,容器（container）和仓库（repository）。 镜像（Images）Docker镜像就是一个只读的模板。镜像可以用来创建Docker容器，一个镜像可以重复创建多个容器。用java中的有关概念来解释就是：镜像类似于java中的类，而容器就是这个类的具体的实例。 容器（Container）Docker利用容器独立运行一个或一组应用。容器是用镜像创建的运行实例。它可以被启动、开始、停止、甚至删除，每个容器都是相互隔离的。我们可以把容器看作是一个简易版的Linux环境（包括root用户权限、进程空间、用户空间和网络空间等）以及运行在其中的应用程序。 仓库（Repository）仓库是集中存放镜像文件的场所。仓库和仓库组成服务器是有区别的。仓库组成服务器上往往存放着多个仓库，每个仓库中有包含了多个镜像，每个镜像又有不同的标签（tag）.仓库分为公开仓库（Public）和私有仓库（Private）两种形式。最大的公开仓库是Docker Hub,这里面存放了数量庞大的的镜像。 镜像/容器/仓库三者的关系总结起来就是：Docker本身是一个容器运行载体（管理引擎）。我们把应用程序和配置依赖打包好形成一个可交付的运行环境，这个打包好的运行环境就是image镜像文件。只有通过这个镜像文件才能生成Docker容器。images文件可以看做是容器的模板。Docker根据image文件生成容器的实例。至于仓库，就是存放了一堆镜像的地方，我们可以把镜像发布到仓库存储起来，需要的时候从仓库拉取下拉就可以使用了。 &nbsp;&nbsp; CentOS 7安装配置Docker1、在安装前一定要先检查一下你对CentOS的版本：Docker 运行在 CentOS 7 上，要求系统为64位、系统内核版本为 3.10 以上。查看的命令如下： 12345[root@localhost huangxin]# uname -r3.10.0-862.el7.x86_64[root@localhost huangxin]# cat /etc/redhat-releaseCentOS Linux release 7.5.1804 (Core) 2、使用yum命令安装docker 1[root@localhost huangxin]# yum install docker 期间会有一个确认提示，直接输入y确认。3、启动Docker,并设置以后开机自动启动 12[root@localhost huangxin]# systemctl start docker #启动[root@localhost huangxin]# systemctl enable docker #设置开始自动启动 4、这时我们可以查看一下docker的有关配置 12[root@localhost huangxin]# docker -v #查看docker的版本[root@localhost huangxin]# docker info #查看docker的详细信息 5、配置阿里云的镜像源这个配置不是必须的，只是配置一下以后使用的时候下载的速度会快很多，而且有时候如果直接使用国外的镜像会导致下载失败的情况也可以这么来配置。具体的方法是：&nbsp;&nbsp;&nbsp;&nbsp;1）、到阿里云的官网直接搜索容器镜像服务&nbsp;&nbsp;&nbsp;&nbsp;2）、点开后一顿注册设置后点击最下面的镜像加速器，然后复制加速器地址&nbsp;&nbsp;&nbsp;&nbsp;3）、复制后来到虚拟机使用命令vim /etc/docker/daemon.json添加刚才阿里云上的加速地址，格式如下： 123&#123; "registry-mirrors": ["https://xxxxxx.mirror.aliyuncs.com"]&#125; 注意：这里格式一定要正确，标准的json格式,不然服务不能启动 配置后保存并退出vim界面，输入以下命令重新加载配置并重启Docker 12[root@localhost huangxin]# systemctl daemon-reload[root@localhost huangxin]# systemctl restart docker 6、停止docker如果我们想停止docker，可以使用命令systemctl stop docker 1[root@localhost huangxin]# systemctl stop docker &nbsp;&nbsp; Docker常用命令和操作Docker常用的帮助命令docker version &nbsp;&nbsp;&nbsp;&nbsp;查看Docker的版本信息12345678910111213141516171819[root@localhost huangxin]# docker versionClient: Version: 1.13.1 API version: 1.26 Package version: docker-1.13.1-102.git7f2769b.el7.centos.x86_64 Go version: go1.10.3 Git commit: 7f2769b/1.13.1 Built: Mon Aug 5 15:09:42 2019 OS/Arch: linux/amd64Server: Version: 1.13.1 API version: 1.26 (minimum version 1.12) Package version: docker-1.13.1-102.git7f2769b.el7.centos.x86_64 Go version: go1.10.3 Git commit: 7f2769b/1.13.1 Built: Mon Aug 5 15:09:42 2019 OS/Arch: linux/amd64 Experimental: false docker info &nbsp;&nbsp;&nbsp;&nbsp;显示系统范围的信息123456789101112131415161718192021222324252627282930[root@localhost huangxin]# docker infoContainers: 5 Running: 5 Paused: 0 Stopped: 0Images: 8Server Version: 1.13.1Storage Driver: overlay2 Backing Filesystem: xfs Supports d_type: true Native Overlay Diff: trueLogging Driver: journaldCgroup Driver: systemdPlugins: Volume: local Network: bridge host macvlan null overlaySwarm: inactiveRuntimes: docker-runc runcDefault Runtime: docker-runcInit Binary: /usr/libexec/docker/docker-init-currentcontainerd version: (expected: aa8187dbd3b7ad67d8e5e3a15115d3eef43a7ed1)runc version: 9c3c5f853ebf0ffac0d087e94daef462133b69c7 (expected: 9df8b306d01f59d3a8029be411de015b7304dd8f)init version: fec3683b971d9c3ef73f284f176672c44b448662 (expected: 949e6facb77383876aeff8a6944dde66b3089574)Security Options: seccomp WARNING: You're not using the default seccomp profile Profile: /etc/docker/seccomp.json selinuxKernel Version: 3.10.0-862.el7.x86_64....... docker -&nbsp;-help &nbsp;&nbsp;&nbsp;&nbsp;docker的命令帮助123456789101112131415161718192021222324252627282930313233343536373839404142[root@localhost huangxin]# docker --helpUsage: docker COMMANDA self-sufficient runtime for containersOptions: --config string Location of client config files (default "/root/.docker") -D, --debug Enable debug mode --help Print usage -H, --host list Daemon socket(s) to connect to (default []) -l, --log-level string Set the logging level ("debug", "info", "warn", "error", "fatal") (default "info") --tls Use TLS; implied by --tlsverify --tlscacert string Trust certs signed only by this CA (default "/root/.docker/ca.pem") --tlscert string Path to TLS certificate file (default "/root/.docker/cert.pem") --tlskey string Path to TLS key file (default "/root/.docker/key.pem") --tlsverify Use TLS and verify the remote -v, --version Print version information and quitManagement Commands: container Manage containers image Manage images network Manage networks node Manage Swarm nodes plugin Manage plugins secret Manage Docker secrets service Manage services stack Manage Docker stacks swarm Manage Swarm system Manage Docker volume Manage volumesCommands: attach Attach to a running container build Build an image from a Dockerfile commit Create a new image from a container's changes cp Copy files/folders between a container and the local filesystem create Create a new container diff Inspect changes on a container's filesystem events Get real time events from the server exec Run a command in a running ........ ...... 包括我们还可以在具体的命令后面使用--help参数,来获得关于这个命令的详细帮助例如我们可使用docker info -&nbsp;-help来查看关于docker info的命令帮助： 123456789[root@localhost huangxin]# docker info --helpUsage: docker info [OPTIONS]Display system-wide informationOptions: -f, --format string Format the output using the given Go template --help Print usage 可以看到docker info 还可以带-f/-format 和–help参数 镜像操作检索关键字（镜像）使用docker search命令后docker会去Docker Hub去查找镜像，并罗列出在Docker Hub上所有有关的镜像。 12345678910111213141516171819202122232425262728[root@localhost huangxin]# docker search mysqlINDEX NAME DESCRIPTION STARS OFFICIAL AUTOMATEDdocker.io docker.io/mysql MySQL is a widely used, open-source relati... 8596 [OK] docker.io docker.io/mariadb MariaDB is a community-developed fork of M... 2985 [OK] docker.io docker.io/mysql/mysql-server Optimized MySQL Server Docker images. Crea... 632 [OK]docker.io docker.io/centos/mysql-57-centos7 MySQL 5.7 SQL database server 62 docker.io docker.io/centurylink/mysql Image containing mysql. Optimized to be li... 61 [OK]docker.io docker.io/mysql/mysql-cluster Experimental MySQL Cluster Docker images. ... 51 docker.io docker.io/deitch/mysql-backup REPLACED! Please use http://hub.docker.com... 41 [OK]docker.io docker.io/tutum/mysql Base docker image to run a MySQL database ... 34 docker.io docker.io/bitnami/mysql Bitnami MySQL Docker Image 33 [OK]docker.io docker.io/schickling/mysql-backup-s3 Backup MySQL to S3 (supports periodic back... 28 [OK]docker.io docker.io/prom/mysqld-exporter 22 [OK]docker.io docker.io/linuxserver/mysql A Mysql container, brought to you by Linux... 21 docker.io docker.io/centos/mysql-56-centos7 MySQL 5.6 SQL database server 16 docker.io docker.io/circleci/mysql MySQL is a widely used, open-source relati... 14 docker.io docker.io/mysql/mysql-router MySQL Router provides transparent routing ... 12 docker.io docker.io/arey/mysql-client Run a MySQL client from a docker container 11 [OK]docker.io docker.io/imega/mysql-client Size: 36 MB, alpine:3.5, Mysql client: 10.... 7 [OK]docker.io docker.io/openshift/mysql-55-centos7 DEPRECATED: A Centos7 based MySQL v5.5 ima... 6 docker.io docker.io/yloeffler/mysql-backup This image runs mysqldump to backup data u... 6 [OK]docker.io docker.io/fradelg/mysql-cron-backup MySQL/MariaDB database backup using cron t... 4 [OK]docker.io docker.io/genschsa/mysql-employees MySQL Employee Sample Database 2 [OK]docker.io docker.io/ansibleplaybookbundle/mysql-apb An APB which deploys RHSCL MySQL 1 [OK]docker.io docker.io/jelastic/mysql An image of the MySQL database server main... 1 docker.io docker.io/monasca/mysql-init A minimal decoupled init container for mysql 0 docker.io docker.io/widdpim/mysql-client Dockerized MySQL Client (5.7) including Cu... 0 [OK][root@localhost huangxin]# docker search命令可以使用-s参数筛选出STARS数不小于指定数的镜像 123456[root@localhost huangxin]# docker search -s 100 mysqlFlag --stars has been deprecated, use --filter=stars=3 insteadINDEX NAME DESCRIPTION STARS OFFICIAL AUTOMATEDdocker.io docker.io/mysql MySQL is a widely used, open-source relati... 8596 [OK] docker.io docker.io/mariadb MariaDB is a community-developed fork of M... 2985 [OK] docker.io docker.io/mysql/mysql-server Optimized MySQL Server Docker images. Crea... 632 [OK] 可以看到，下面那些小于100START的镜像就不会显示出来 拉取镜像命令的基本语法是：docker pull [参数] 镜像名[:标签|@DIGEST] 1[root@localhost huangxin]# docker pull redis 这个命令中的tag缺省，在缺省情况下默认下载最新版本的镜像。 查看本地所有的镜像基本的语法：docker images [参数] [REPOSITORY[:TAG]] 1234[root@localhost huangxin]# docker imagesREPOSITORY（仓库） TAG(标签名) IMAGE ID（镜像ID） CREATED（创建日期） SIZE（镜像的大小）docker.io/tomcat latest 96c4e536d0eb 3 weeks ago 506 MBdocker.io/redis latest f7302e4ab3a8 4 weeks ago 98.2 MB docker images命令后面还可以跟一些参数: -a 查看本地的所有的镜像（包含中间层镜像） -q 只显示镜像ID --digest 显示镜像的摘要信息 12345678910111213[root@localhost huangxin]# docker images -aREPOSITORY TAG IMAGE ID CREATED SIZEdocker.io/tomcat latest 96c4e536d0eb 3 weeks ago 506 MBdocker.io/redis latest f7302e4ab3a8 4 weeks ago 98.2 MB[root@localhost huangxin]# docker images -qeb0a013292232fb79bc1163c[root@localhost huangxin]# docker images --digestsREPOSITORY TAG DIGEST IMAGE ID CREATED SIZEdocker.io/tomcat latest sha256:80db17f3efd9cdcd9af7c799097fe0d223bbee8f25aa36234ab56292e3d8bd7b 96c4e536d0eb 3 weeks ago 506 MBdocker.io/redis latest sha256:9755880356c4ced4ff7745bafe620f0b63dd17747caedba72504ef7bac882089 f7302e4ab3a8 4 weeks ago 98.2 MB 删除指定的本地镜像基本的命令语法：docker rmi [参数] 镜像名1/镜像ID1 [镜像名2/镜像ID2...] 1[root@localhost huangxin]# docker rmi tomcat 一次删除多个镜像：docker rmi -f 多个镜像名/镜像ID ,其中-f表示强制删除，多个镜像之间空格隔开。 123456789101112[root@localhost huangxin]# docker rmi -f a00bc560660a 2fb79bc1163cUntagged: docker.io/rabbitmq:latestUntagged: docker.io/rabbitmq@sha256:dc853667e768ad1f35625f0337eede5de81ddcca452cf85436c9be2da8657723Deleted: sha256:a00bc560660a5519eee2356f87b76091f39c27ae2d3e595169b4ef97bec4c9fbUntagged: docker.io/rabbitmq:managementUntagged: docker.io/rabbitmq@sha256:f20a3a019241e53aaf98d4133f7781b6d9811d256ff1d755b5aab00855007d5bDeleted: sha256:2fb79bc1163c8003dc25438c32d472ac3034900b86bd5a17b421abdd32fb4496Deleted: sha256:9222d87e80ed54151a186ba2a1e2702008c1e0fce425b7e671e6de0751b005bcDeleted: sha256:2093e80d5f422868e454b8551a268d5892702b74e1e82326f015f6e68c0e2400Deleted: sha256:462c555fe32ac61371c4d1dba2ea30d51e3e803b7c4b0e9d84bf0afa4d938969Deleted: sha256:e0f0f24c7303048f18ce79f408f83ba1ecb49f0c94dc38c0c47e6aa7a38b6b2cDeleted: sha256:742c3e7ab1e9c7242d735106cd62e9efba28105c82b50b06b5a4a8f3a60a5b4f 删除本地的所有镜像：docker rmi -f ${docker images -q} 容器操作新建并启动容器命令的基本语法：docker run [操作参数] 镜像名/镜像ID [指令] [参数...]docker run 命令常用的参数有： --name 容器的新名字 给容器起一个名字，没有指定时会默认生成一个随机的字符串 -d 后台运行运行容器，并返回容器的ID -i 以交互式的方式运行容器 -t 为容器重新分配一个伪输入终端，通常会与-i配合使用 -P 随机端口映射 -p 指定端口映射，有以下四种格式：&nbsp;&nbsp;&nbsp;1.ip:hostPort:containerPort&nbsp;&nbsp;&nbsp;2.ip::containerPort&nbsp;&nbsp;&nbsp;3.hostPort:containerPort (常用的格式)&nbsp;&nbsp;&nbsp;4.containerPort 例如：在后台启动tomcat,并把虚拟机的25050端口映射到容器的8080端口 12[root@localhost huangxin]# docker run --name Tomcat -d -p 25050:8080 tomcat:latest239057353cedab1dfc26b921b237580f72009d7710008772d5a2a3befd539324 查看容器命令的基本语法：docker ps [操作参数]docker ps 常用的命令参数有： -a docker ps命令默认显示当前运行中的容器，加上-a参数会显示会有所有的容器（包括停止的、退出的） -l 显示最近一次启动的容器 -n 值 显示最近指定值次数启动的容器，比如 docker ps -n 2 ,表示显示最近两次启动的容器 -q 仅仅显示所有运行中的容器容器ID -s 显示所有运行中的容器的文件大小 示例： 123456789101112131415161718192021222324252627282930313233343536373839[root@localhost huangxin]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESff15f2f20b32 eb0a01329223 "/docker-entrypoin..." 3 days ago Up 3 days 2888/tcp, 3888/tcp, 0.0.0.0:2181-&gt;2181/tcp, 8080/tcp zookeeper015e68d3980e15 5acf0e8da90b "/docker-entrypoin..." 5 days ago Up 5 days 0.0.0.0:9200-&gt;9200/tcp, 0.0.0.0:9300-&gt;9300/tcp ESeea2f65ecd70 90cce17c1af8 "docker-entrypoint..." 6 days ago Up 6 days 4369/tcp, 5671/tcp, 0.0.0.0:5672-&gt;5672/tcp, 15671/tcp, 25672/tcp, 0.0.0.0:15672-&gt;15672/tcp rabbitmq16fe5da80056 redis:latest "docker-entrypoint..." 8 days ago Up 8 days 0.0.0.0:6379-&gt;6379/tcp redis-servere3a6146e9ee4 mysql:latest "docker-entrypoint..." 8 days ago Up 8 days 0.0.0.0:3306-&gt;3306/tcp, 33060/tcp mysql[root@localhost huangxin]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESff15f2f20b32 eb0a01329223 "/docker-entrypoin..." 3 days ago Up 3 days 2888/tcp, 3888/tcp, 0.0.0.0:2181-&gt;2181/tcp, 8080/tcp zookeeper015e68d3980e15 5acf0e8da90b "/docker-entrypoin..." 5 days ago Up 5 days 0.0.0.0:9200-&gt;9200/tcp, 0.0.0.0:9300-&gt;9300/tcp ESeea2f65ecd70 90cce17c1af8 "docker-entrypoint..." 6 days ago Up 6 days 4369/tcp, 5671/tcp, 0.0.0.0:5672-&gt;5672/tcp, 15671/tcp, 25672/tcp, 0.0.0.0:15672-&gt;15672/tcp rabbitmq16fe5da80056 redis:latest "docker-entrypoint..." 8 days ago Up 8 days 0.0.0.0:6379-&gt;6379/tcp redis-servere3a6146e9ee4 mysql:latest "docker-entrypoint..." 8 days ago Up 8 days 0.0.0.0:3306-&gt;3306/tcp, 33060/tcp mysql[root@localhost huangxin]# docker ps -lCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESff15f2f20b32 eb0a01329223 "/docker-entrypoin..." 3 days ago Up 3 days 2888/tcp, 3888/tcp, 0.0.0.0:2181-&gt;2181/tcp, 8080/tcp zookeeper01[root@localhost huangxin]# docker ps -n 2CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESff15f2f20b32 eb0a01329223 "/docker-entrypoin..." 3 days ago Up 3 days 2888/tcp, 3888/tcp, 0.0.0.0:2181-&gt;2181/tcp, 8080/tcp zookeeper015e68d3980e15 5acf0e8da90b "/docker-entrypoin..." 5 days ago Up 5 days 0.0.0.0:9200-&gt;9200/tcp, 0.0.0.0:9300-&gt;9300/tcp ES[root@localhost huangxin]# docker ps -qff15f2f20b325e68d3980e15eea2f65ecd7016fe5da80056e3a6146e9ee4[root@localhost huangxin]# docker ps -sCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES SIZEff15f2f20b32 eb0a01329223 "/docker-entrypoin..." 3 days ago Up 3 days 2888/tcp, 3888/tcp, 0.0.0.0:2181-&gt;2181/tcp, 8080/tcp zookeeper01 37.2 kB (virtual 225 MB)5e68d3980e15 5acf0e8da90b "/docker-entrypoin..." 5 days ago Up 5 days 0.0.0.0:9200-&gt;9200/tcp, 0.0.0.0:9300-&gt;9300/tcp ES 32.8 kB (virtual 486 MB)eea2f65ecd70 90cce17c1af8 "docker-entrypoint..." 6 days ago Up 6 days 4369/tcp, 5671/tcp, 0.0.0.0:5672-&gt;5672/tcp, 15671/tcp, 25672/tcp, 0.0.0.0:15672-&gt;15672/tcp rabbitmq 123 B (virtual 179 MB)16fe5da80056 redis:latest "docker-entrypoint..." 8 days ago Up 8 days 0.0.0.0:6379-&gt;6379/tcp redis-server 0 B (virtual 98.2 MB)e3a6146e9ee4 mysql:latest "docker-entrypoint..." 8 days ago Up 8 days 0.0.0.0:3306-&gt;3306/tcp, 33060/tcp mysql 62 B (virtual 445 MB) 停止/退出运行中的容器 退出容器：exit（停止容器并退出）或使用快捷键Ctrl+P+Q（容器不停止并退出，相当于让容器后台运行） 停止容器：docker stop [操作参数] 容器名1/容器ID1 [容器名2/容器ID2...] 强制停止容器: docker kill [操作参数] 容器名1/容器ID1 [容器名2/容器ID2...]例如：停止ES可以这么写：123456[root@localhost huangxin]# docker stop ESES[root@localhost huangxin]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESff15f2f20b32 eb0a01329223 "/docker-entrypoin..." 3 days ago Up 3 days 2888/tcp, 3888/tcp, 0.0.0.0:2181-&gt;2181/tcp, 8080/tcp zookeeper015e68d3980e15 5acf0e8da90b "/docker-entrypoin..." 5 days ago Exited (143) 15 seconds ago ES 启动容器基本的命令语法：docker start [操作参数] 容器名1/容器ID1 [容器名2/容器ID2...]这里的启动这个docker run的功能不太一样，docker start是指启动一个已经停止的容器，而docker run是指创建出一个容器（这个容器还不存在）并启动它。示例：启动刚才停止的ES 123456[root@localhost huangxin]# docker start ESES[root@localhost huangxin]# docker ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESff15f2f20b32 eb0a01329223 "/docker-entrypoin..." 3 days ago Up 3 days 2888/tcp, 3888/tcp, 0.0.0.0:2181-&gt;2181/tcp, 8080/tcp zookeeper015e68d3980e15 5acf0e8da90b "/docker-entrypoin..." 5 days ago Up 17 seconds 0.0.0.0:9200-&gt;9200/tcp, 0.0.0.0:9300-&gt;9300/tcp ES 重启容器基本的命令语法：docker restart [操作参数] 容器名1/容器ID1 [容器名2/容器ID2...]示例：重启zookeeper 123456[root@localhost huangxin]# docker restart zookeeper01zookeeper01[root@localhost huangxin]# docker ps -aCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMESff15f2f20b32 eb0a01329223 "/docker-entrypoin..." 3 days ago Up 9 seconds 2888/tcp, 3888/tcp, 0.0.0.0:2181-&gt;2181/tcp, 8080/tcp zookeeper015e68d3980e15 5acf0e8da90b "/docker-entrypoin..." 5 days ago Up 6 minutes 0.0.0.0:9200-&gt;9200/tcp, 0.0.0.0:9300-&gt;9300/tcp ES 删除容器基本语法是：docker rm [操作参数] 容器名1/容器ID1 [容器名2/容器ID2...]注意：docker rm 删除的容器必须是不在运行状态的容器，如果想直接删除一个运行中的容器可以使用-f参数执行强制删除。 1234[root@localhost huangxin]# docker rm ESError response from daemon: You cannot remove a running container 5e68d3980e15f41d97662241c3bd022b3fcb9c4912761f50212c2ce2d6213e9f. Stop the container before attempting removal or use -f[root@localhost huangxin]# docker rm -f ESES docker rm支持一次删除多个容器，例如批量删除本地所有的容器： 1[root@localhost huangxin]# docker rm $&#123;docker ps -aq&#125; 解释一下这个组合命令:docker ps -aq可以返回本地所有的容器ID，然后把它传给docker rm执行批量删除。 查看容器的日志基本语法是：docker logs [操作参数] 容器名/容器IDdocker logs命令常用的参数：-t 加入时间戳-f 跟随最新的日志打印--tail 值 显示最后多少条日志 1[root@localhost huangxin]# docker logs 239057353ced 打印的日志： 查看容器内运行的进程命令：docker top 容器名/容器ID [ps OPTIONS] 1234[root@localhost huangxin]# docker top mysqlUID PID PPID C STIME TTY TIME CMDpolkitd 6565 6548 0 Sep17 ? 00:16:43 mysqldroot 6895 6879 0 Sep17 pts/1 00:00:00 bash 获取容器/镜像的元数据命令：docker inspect [操作参数] 容器名1|容器ID1 [容器名2|容器ID2...]使用这个命令可以查看容器内部的各种信息，docker会以json串的形式返回结果,例如查看mysql这个容器的内部细节： 123456789101112[root@localhost huangxin]# docker inspect mysql[ &#123; "Id": "e3a6146e9ee47230bb6f6df49f23db31cbd570c40e8125654443de42e02c4b79", "Created": "2019-09-10T10:48:43.201901131Z", "Path": "docker-entrypoint.sh", "Args": [ "mysqld" ], "State": &#123; "Status": "running",..... 进入容器并且在容器中以命令行的方式交互 命令1：docker exec [操作参数] 容器名/容器ID COMMAND [ARG...] 命令2：docker attach [操作参数] 容器名/容器ID 这两个命令的区别是：docker exec是在容器中打开新的终端并且启动新的线程，docker attach 是直接进入容器并启动终端，不会启动新的线程。示例：使用docker exec命令进入到mysql容器的命令行界面： 1234567891011121314151617181920212223242526[root@localhost huangxin]# docker exec -it mysql mysql -uroot -pEnter password: #输入数据库密码Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 14Server version: 8.0.17 MySQL Community Server - GPLCopyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.mysql&gt; show databases;+--------------------+| Database |+--------------------+| information_schema || mysql || performance_schema || sys |+--------------------+4 rows in set (0.13 sec)mysql&gt; 容器与主机之间的数据拷贝命令：把容器的数据拷贝到主机上：docker cp [操作参数] 容器名/容器ID:源路径 目的路径|-把主机上的数据拷贝到容器：docker cp [操作参数] 源路径|- 容器名/容器ID:目的路径示例：把mysql的一个库中的数据拷贝到主机的/Desktop 123456789101112131415161718192021222324252627282930313233343536373839[root@localhost huangxin]# docker exec -it mysql /bin/bash #相当于windows上打开mysql的安装目录root@e3a6146e9ee4:/# mysql -uroot -p 密码 #进入数据库Enter password: Welcome to the MySQL monitor. Commands end with ; or \g.Your MySQL connection id is 15Server version: 8.0.17 MySQL Community Server - GPLCopyright (c) 2000, 2019, Oracle and/or its affiliates. All rights reserved.Oracle is a registered trademark of Oracle Corporation and/or itsaffiliates. Other names may be trademarks of their respectiveowners.Type 'help;' or '\h' for help. Type '\c' to clear the current input statement.mysql&gt; create database xust; #创建一个数据库xustQuery OK, 1 row affected (0.12 sec)#之后借助数据库工具创建了一张Students表mysql&gt; select * from students;+-------------+----------+----------+---------+| s_id | s_name | major_in | s_class |+-------------+----------+----------+---------+| 20190808001 | zhangsan | aas | casss 1 || 20190808002 | lisi | dad | casss 1 || 20190808003 | wangwu | ad | casss 3 || 20190808004 | lixiaoer | ad | casss 4 || 20190808005 | tom | ad | casss 5 |+-------------+----------+----------+---------+5 rows in set (0.00 sec)#使用Ctrl+P+Q快捷键退出数据库root@e3a6146e9ee4:/# mysqldump -u root -p 'xust'&gt;xust.sql #导出数据库数据Enter password: #之后使用ls命令就可以看到导出的脚本文件,使用pwd xust.sql查看一下他的路径,我的xust.sql文件的路径是/# 退出容器后将容器内文件拷贝到宿主机[root@localhost huangxin]# docker cp mysql:/xust.sql /Desktop/ #将容器中的xust.sql脚本文件复制到主机的/Desktop/目录下 导出的数据表： 由容器实例生成镜像（container-&gt;image）命令语法：docker commit [操作参数] 容器名/容器ID [仓库名[:标签名]]docker commit命令常用的参数： -a 指定作者名 -m 提交描述 示例：在tomcat容器中部署自己的网页,然后把它打包成一个镜像1.首先把一个项目www拷贝到CentOS的/home/huangxin/Desktop/目录下,然后进入运行中的tomcat的容器内部 1234[root@localhost Desktop]# docker exec -it 6f1bb2d2118d /bin/bashroot@6f1bb2d2118d:/usr/local/tomcat# ls #使用ls会看到我熟悉的目录，比如webappsBUILDING.txt LICENSE README.md RUNNING.txt conf lib native-jni-lib webappsCONTRIBUTING.md NOTICE RELEASE-NOTES bin include logs temp work 2.进入webapps，使用pwd得到webapps的路径记下来 12root@6f1bb2d2118d:/usr/local/tomcat# pwd/usr/local/tomcat/webapps 3.退出容器使用docker的复制命令把/home/huangxin/Desktop/www复制到容器中 1[root@localhost Desktop]# docker cp www 6f1bb2d2118d:/usr/local/tomcat/webapps 可以在虚拟机的localhost:25050/www来访问我们定制的网页： 接下来我们把这个定制的Tomcat容器打包成一个镜像4.把我们定制的这个tomcat打包成一个镜像 1234567891011[root@localhost Desktop]# docker commit -m="A tomcat with my site" -a="Huangxin" 6f1bb2d2118d xust/tomcat:1.0.0sha256:71a1320815f58ac6f71d8fbf8823dfff091f1561ce9cec7e9cac2bc32f2fe619[root@localhost Desktop]# docker imagesREPOSITORY TAG IMAGE ID CREATED SIZExust/tomcat 1.0.0 71a1320815f5 11 seconds ago 506 MB #这个是我们的tomcatdocker.io/zookeeper latest eb0a01329223 5 days ago 225 MBdocker.io/rabbitmq 3.8-rc-management 90cce17c1af8 9 days ago 179 MBdocker.io/tomcat latest 96c4e536d0eb 4 weeks ago 506 MBdocker.io/redis latest f7302e4ab3a8 5 weeks ago 98.2 MBdocker.io/mysql latest 62a9f311b99c 5 weeks ago 445 MBdocker.io/elasticsearch latest 5acf0e8da90b 12 months ago 486 MB 5.在虚拟机80端口启动我们定制的tomcat，然后访问localhost:/www 1234567891011[root@localhost Desktop]# docker run --name mytomcat -d -p 80:8080 71a1320815f5292830f2988b094ebd720aa438311f26e9a756bd6bdfca50abd01d7b81a2c228[root@localhost Desktop]# docker psCONTAINER ID IMAGE COMMAND CREATED STATUS PORTS #我们定制的tomcat启动了并映射在虚拟机的80端口 NAMES292830f2988b 71a1320815f5 "catalina.sh run" 12 seconds ago Up 11 seconds 0.0.0.0:80-&gt;8080/tcp mytomcat6f1bb2d2118d tomcat:latest "catalina.sh run" 2 hours ago Up 2 hours 0.0.0.0:25050-&gt;8080/tcp cranky_aryabhataff15f2f20b32 eb0a01329223 "/docker-entrypoin..." 3 days ago Up 6 hours 2888/tcp, 3888/tcp, 0.0.0.0:2181-&gt;2181/tcp, 8080/tcp zookeeper01eea2f65ecd70 90cce17c1af8 "docker-entrypoint..." 7 days ago Up 7 days 4369/tcp, 5671/tcp, 0.0.0.0:5672-&gt;5672/tcp, 15671/tcp, 25672/tcp, 0.0.0.0:15672-&gt;15672/tcp rabbitmq16fe5da80056 redis:latest "docker-entrypoint..." 9 days ago Up 9 days 0.0.0.0:6379-&gt;6379/tcp redis-servere3a6146e9ee4 mysql:latest "docker-entrypoint..." 9 days ago Up 9 days 0.0.0.0:3306-&gt;3306/tcp, 33060/tcp mysql 后记&nbsp;&nbsp;&nbsp;&nbsp;至此，docker的基本常用命令就介绍到这里了，使用后我个人的直观的感受是这个东西确实非常方便。然而这里仅仅是介绍了一些常用的命令，Docker中还有许多的命令这里没有介绍到，具体的可以参考Docker技术文档，而且我们也可以参考docker.hub上每个镜像官方给出的配置方法，方法很多这里就不一&nbsp;一介绍了。]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>Docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot + Eureka 实现微服务负载均衡]]></title>
    <url>%2F2019%2F09%2F17%2FSpring%20Boot%20%2B%20Eureka%20%E5%AE%9E%E7%8E%B0%E5%BE%AE%E6%9C%8D%E5%8A%A1%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp; 什么是Eureka？&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Eureka这个单词原本的意思就是“我发现了，我找到了”，然而他在Spring中的功能也和他的本意是一样的。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Eureka是netflix的一个子模块，也是核心模块之一，Eureka是一个基于REST的服务，用于定位服务，以实现云端中间层服务发现和故障转移。服务注册与发现对于微服务架构来说是非常重要的，有了服务发现和注册，只需要使用服务的标识符，就可以访问到服务，而不需要修改服务，而不需要修改服务调用的配置文件了，功能类似于dubbo的注册中心，比如zookeeper。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SpringCloud封装了Netflix公司开发的Eureka模块来实现服务注册时和发现。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Eureka采用了C-S的设计架构。Eureka Server作为服务注册功能的服务器，它是服务注册时中心。而系统中的其他微服务，使用eureka的客户端连接到eureka server并维持心跳连接。这样系统的维护人员就可以通过eureka server来监控系统中各个微服务是否正常运行。SpringCloud的一些其他模块就可以通过eureka server来发现系统中的其他微服务，并执行相关的逻辑。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Eureka包含两个组件：Eureka Server和Eureka Client。Eureka Server提供服务注册服务。各个节点启动后，会在Eureka Server中进行注册，这样Eureka server中的服务注册表中将会存储所有可用服务节点的信息，服务节点的信息可以在界面中直观的看到。&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Eureka client是一个java客户端，用于简化eureka server的交互，客户端同时也具备一个内置的，使用轮询负载算法的负载均衡器。在应用启动后，将会向Eureka Server发送心跳。如果Eureka Server在多个心跳周期内没有接收到某个节点的心跳，Eureka Server将会从服务注册表把这个服务节点移除。Eureka的三大角色： Eureka server提供服务注册和发现 Service Provider服务提供方将自身服务注册到Eureka，从而使服务消费方能够找到。 Service Consumer服务消费方从Eureka获取注册服务列表，从而能够消费服务。 总结起来就是说： Eureka是Netflix开源的一个RESTful服务，主要用于服务的注册发现。 Eureka由两个组件组成：Eureka服务器和Eureka客户端。Eureka服务器用作服务注册服务器。 Eureka客户端是一个java客户端，用来简化与服务器的交互、作为轮询负载均衡器，并提供服务的故障切换支持。 Netflix在其生产环境中使用的是另外的客户端，它提供基于流量、资源利用率以及出错状态的加权负载均衡。 &nbsp;&nbsp; 搭建一个基于Spring Boot + Eureka的微服务工程工程的搭建我使用IDEA，首先新建一个空工程【Empty project】,选择空工程点击【next】，之后我们需要在这个工程中建立三个子模块，分别是euraka-server注册中心，poervider服务提供者，customer消费者。新建一个空工程 在新建项目的时候我们可以使用【Spring Initializr】，在新建eurake-server模块的时候选上Eureka Server，新建provider和customer模块的时候可以选上Web的satrter和Eurake Discovery Client的satrter 建好后的项目结构： &nbsp;&nbsp; Eureka Server—注册中心的配置12345678910server: port: 8761eureka: instance: hostname: eureka-service #配置Eureka的主机名 client: register-with-eureka: false #不把自己注册到Eureka fetch-registry: false #不从Eureka获取注册信息 service-url: defaultZone: http://localhost:8761/eureka/ 在Eureka Server的启动类上使用@EnableEurekaServer开启Eureka服务 1234567891011121314151617181920package com.xust.iot.eureka.service;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.cloud.netflix.eureka.server.EnableEurekaServer;/** * 注册中心：服务提供把服务注册到注册中心，消费者可以在注册中心发现他需要的服务 * 1.在application.yml文件中配置Eureka有关的配置 * 2.使用@EnableEurekaServer 注解开启Eureka服务 */@EnableEurekaServer //开启Eureka服务@SpringBootApplicationpublic class EurekaServiceApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(EurekaServiceApplication.class, args); &#125;&#125; 配置好后启动enureka-server，它将会在配置的端口8761启动，输入http://localhost:8761就可一个看到enureka-server的管理界面： &nbsp;&nbsp; Service Provider—服务提供方的配置在服务提供方的配置文件中配置如下信息： 1234567891011121314debug: trueserver: port: 8080 #服务的端口eureka: instance: prefer-ip-address: true #注册时使用ip进行注册 client: service-url: defaultZone: http://localhost:8761/eureka/ #服务将会按照这个路径注册到eureka server中spring: application: name: provider #服务的名字 实现一个服务，TicketService 12345678910@Servicepublic class TicketService &#123; private Logger log= LoggerFactory.getLogger(TicketService.class); public String order(int num)&#123; log.info("8080卖出"+num+"张票"); return "现在 ——G8888次——&gt; 未来"; &#125;&#125; Eureka的底层还是基于HTTP协议的，在消费者端要调用服务提供方的服务时，实际是通过HTTP请求的方式来调用的，因此需要在服务提供方给对应的service提供对应的controller。TicketController如下： 123456789101112@Controllerpublic class TicketController &#123; @Autowired TicketService ticketService; @ResponseBody @RequestMapping(value = "/ticket",method = RequestMethod.GET) public String getTicket(@RequestParam(value = "num",defaultValue = "1") int num)&#123; return ticketService.order(num); &#125;&#125; 最后在服务提供方的启动类上使用@EnableEurekaClient来告诉Spring这是Eureka的Cilent端，这个服务要注册到注册中心上去。（也可以使用@EnableDiscoveryClient注解，这两个注解的作用是相同的，但是还是有差别的，具体的可以参考@EnableDiscoveryClient与@EnableEurekaClient 区别）。 1234567891011/** * 服务提供者 */@EnableEurekaClient@SpringBootApplicationpublic class ProviderApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(ProviderApplication.class, args); &#125;&#125; 配置完成后启动Server Provider（注意在启动Client端的服务时Eureka Server要保持运行），启动后可以正常访问http://localhost:8080/ticket,并且在注册中心可以看到8080端口的PROVIDER实例已经注册了就算是成功了。 我们可以开启多个服务提供方，方法是把当前的provider使用Maven命令(mvn install)打包成可执行jar包，然后在把server.port改成另一个端口再使用Maven命令打包后运行…下面是我启动了两个provider，分别在8080和8081端口 &nbsp;&nbsp; Service Customer—服务消费方的配置在服务消费方的配置文件中配置如下内容： 12345678910111213debug: truespring: application: name: customereureka: instance: prefer-ip-address: true #使用ip地址注册实例 client: service-url: defaultZone: http://localhost:8761/eureka/server: port: 8020 在服务消费方的启动类上使用@EnableDiscoveryClient注解告诉SpringBoot把这个服务注册到注册中心。并且注册RestTemplate到IoC容器中，可以使用他来远程调用服务提供方的服务。 12345678910111213141516171819/** * 消费者发现服务,并消费这些服务 */@EnableDiscoveryClient //开启发现服务的功能@SpringBootApplicationpublic class CustomerApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(CustomerApplication.class, args); &#125; @LoadBalanced //开启负载均衡 @Bean public RestTemplate restTemplate()&#123; return new RestTemplate(); &#125;&#125; 编写一个controller使用 RestTemplate来调用服务提供方的注册在服务中心的服务。 123456789101112131415161718@Controllerpublic class UserController &#123; @Autowired RestTemplate restTemplate; @ResponseBody @RequestMapping(value = "/buy",method = RequestMethod.GET) public String sellTicket(@RequestParam(value="num",defaultValue = "1") int num, @RequestParam(value = "name",defaultValue = "") String name)&#123; //使用RestTemplate提供的方法来获得目标服务，第一个参数是目标服务的url：http://服务提供者名/请求的服务 //这里使用getForObject通过http获得目标服务，与之相同的还有getForEntity(),这两个都是用get请求获得目标服务 //使用postForObject、postForEntity、postForLocation可以使用post请求的方式获的目标服务 String s = restTemplate.getForObject("http://PROVIDER/ticket?num=" + num, String.class); return name+"买了"+num+"张票"+"\n"+s; &#125;&#125; 最后启动服务消费方看看效果吧！ 首先我们可以访问http://localhost:8761/，可以在注册中心看到消费方也在注册中心注册了： 我们接着访问http://localhost:8020/buy?name=李四&amp;num=6就可以看到下面的页面： 微服务负载均衡的体现把另一个打包的可执行jar包在命令行使用java -jar 命令运行，注意不要让端口冲突。让两个服务提供方同时运行，然后我们访问http://localhost:8020/buy?name=李四&amp;num=6，不断改变num的值查看控制台的打印 发现这两个端口交替工作的，从而达到了一个负载均衡的作用。]]></content>
      <categories>
        <category>Spring Boot框架</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Security—认证和授权]]></title>
    <url>%2F2019%2F09%2F16%2FSpringSecurity%2F</url>
    <content type="text"><![CDATA[认证（Authentication）：建立声明主体的过程。一般也就是指用户登录，表示让系统知道你的存在。授权（Authorization）：确定一个主体是否允许在你的应用程序里执行一个运动的过程，也就是赋予你用户能干什么。 引入必要的pom文件这一步可以使用Spring Boot的初始化向导在新建工程的时候选上需要的starter，然后初始化向导就会自定引入选择的starter。或者你也可以在你已经建好的项目上直接粘贴复制下面的pom依赖到你的项目的pom文件中。 12345678910111213141516&lt;!--spring security--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--thymeleaf模板引擎--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--thymeleaf对spring-security的支持包--&gt;&lt;dependency&gt; &lt;groupId&gt;org.thymeleaf.extras&lt;/groupId&gt; &lt;artifactId&gt;thymeleaf-extras-springsecurity5&lt;/artifactId&gt; &lt;version&gt;3.0.4.RELEASE&lt;/version&gt;&lt;/dependency&gt; 配置使用Spring Security首先我们先搭建实验环境。 导入HTML页面具体的页面由于比较多而且又很简单的那种，所以这里就不贴出来了，这里仅仅是用于演示效果。 编写一个controller用于控制页面之间的跳转KufuController.java 12345678910111213141516171819202122232425262728293031323334353637383940package com.xust.iot.security.controller;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;@Controllerpublic class KufuController &#123; private static final String PREFIX=&quot;pages&quot;; @RequestMapping(value = &quot;/&quot;) public String index() &#123; return &quot;welcome&quot;; &#125; @RequestMapping(value = &quot;/userlogin&quot;) public String login()&#123; return PREFIX+&quot;/login&quot;; &#125; @RequestMapping(value = &quot;/level1/&#123;page&#125;&quot;) public String toLevel11(@PathVariable(&quot;page&quot;)int page) &#123; return PREFIX+&quot;/Level1/&quot;+page; &#125; @RequestMapping(value = &quot;/level2/&#123;page&#125;&quot;) public String toLevel24(@PathVariable(&quot;page&quot;)int page) &#123; return PREFIX+&quot;/Level2/&quot;+page; &#125; @RequestMapping(value = &quot;/level3/&#123;page&#125;&quot;) public String toLevel37(@PathVariable(&quot;page&quot;)int page) &#123; return PREFIX+&quot;/Level3/&quot;+page; &#125;&#125; 这是我的项目结构： 启动SpringBoot看看效果：启动后在浏览器地址栏中输入https://localhost:8080来到welcome页面 ##### 配置Spring Security &nbsp;&nbsp;&nbsp;&nbsp;Spring Boot中对Security有很多自动配置，我们要使用它只要编写一个配置类，并且让这个配置类继承自`WebSecurityConfigurerAdapter`，然后在配置类上使用`EnableWebSecurity`注解告诉Spring开启WebSecurity功能。以后我们需要定制有关认证和授权的功能的时候只需要重写`WebSecurityConfigurerAdapter`中的方法，下面是一个例子： 一个简单的Spring Security配置 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172package com.xust.iot.security.config;import org.springframework.context.annotation.Bean;import org.springframework.security.config.annotation.authentication.builders.AuthenticationManagerBuilder;import org.springframework.security.config.annotation.web.builders.HttpSecurity;import org.springframework.security.config.annotation.web.builders.WebSecurity;import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;import org.springframework.security.config.annotation.web.configuration.WebSecurityConfigurerAdapter;import org.springframework.security.crypto.password.Pbkdf2PasswordEncoder;/** * 1、引入spring security的starter * 2、编写配置类继承WebSecurityConfigurerAdapter * 3、在配置类上标注@EnableWebSecurity开启WebSecurity */@EnableWebSecurity //开启Web Securitypublic class SecurityConfig extends WebSecurityConfigurerAdapter &#123; @Override public void configure(WebSecurity web) &#123; //防止静态资源被拦截 web.ignoring().antMatchers("/config/**", "/css/**", "/fonts/**", "/img/**", "/js/**"); &#125; @Override protected void configure(HttpSecurity http) throws Exception &#123; //设置Http安全规则 http.authorizeRequests().antMatchers("/").permitAll() //配置认证规则 .antMatchers("/level1/**").hasRole("VIP1") .antMatchers("/level2/**").hasRole("VIP2") .antMatchers("/level3/**").hasRole("VIP3"); //开启自动配置的登录功能 http.formLogin() .usernameParameter("username") //指定提交的表单中的用户名参数 .passwordParameter("password") //指定提交的表单中的密码参数 .loginPage("/userlogin") //指定自定义的登录页面 .loginProcessingUrl("/login") //指定处理登录请求的url .permitAll(); //开启自动配置的注销功能：注销后来到登录页面 http.logout() .deleteCookies() .logoutSuccessUrl("/userlogin") //注销成功后跳转的页面 .permitAll() .invalidateHttpSession(true); //记住我功能 http.rememberMe().rememberMeParameter("remember").tokenValiditySeconds(60 * 60 * 24 * 7); //关闭Spring提供的CSRF攻击保护，一般不建议这么做 /*http.csrf().disable();*/ &#125; //定义认证规则 @Override protected void configure(AuthenticationManagerBuilder auth) throws Exception &#123; auth.inMemoryAuthentication() /*Spring Security 5.0开始必须要设置加密方式*/ .withUser("张三").password(passwordEncoder().encode("123456")).roles("VIP1", "VIP2", "VIP3") .and() .withUser("李四").password(passwordEncoder().encode("123456")).roles("VIP1"); &#125; //配置passwordEncoder @Bean public Pbkdf2PasswordEncoder passwordEncoder() &#123; return new Pbkdf2PasswordEncoder(); &#125;&#125; 注意：1、formLogin系统会自动配置/login请求去Spring内部默认的登录页面，如果想改成自己的实现，可以参考上面的配置2、如果登录失败系统默认会重定向到/login/error页面3、如果没有配置允许登录页面任何人可以访问，那么SpringBoot默认的登录页面的username是username，密码会在SpringBoot启动启动的时候自动生成，打印在控制台中。然而还有一种办法即使我们可以配置初始的用户密码，下面是一个配置示例： 123#spring boo默认会对所有的资源进行拦截，所以可以在这里配置个初始的用户名个密码spring.security.user.name=adminspring.security.user.password=123456 然而我们完全不必要这么做，我们可以对公共的资源放开权限就好了，具体的配置方法参照上面的配置。4、SpringBoot2.x抛弃了原来的NoOpPasswordEncoder，要求用户保存的密码必须要使用加密算法后存储，在登录验证的时候Security会将获得的密码在进行编码后再和数据库中加密后的密码进行对比，如果强行使用明码会报错： 在Web页面(HTML中)获得用户的身份、授权信息主要就是利用sec提供的方法。 sec:authorize=”isAuthenticated()”：是否授权成功 sec:authentication=”principal.authorities”：获取用户身份 sec:authentication=”name”：获取用户名字 sec:authorize=”hasRole()”：判断当前身份 要使用这些功能，需要先引入sec的名称空间 1234&lt;html xmlns="http://www.w3.org/1999/xhtml" xmlns:th="http://www.thymeleaf.org" &lt;!--引入sec名称空间，注意版本冲突的问题--&gt; xmlns:sec="http://www.thymeleaf.org/thymeleaf-extras-springsecurity5"&gt; 不同授权的用户会有不同的操作权限，包括可以通过sec提供的这几个方法，动态的获取用户是否授权成功，用户有哪些身份…… 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;!DOCTYPE html&gt;&lt;html xmlns="http://www.w3.org/1999/xhtml" xmlns:th="http://www.thymeleaf.org" xmlns:sec="http://www.thymeleaf.org/thymeleaf-extras-springsecurity5"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Welcome&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;center&gt; &lt;h1&gt;欢迎光临武林秘籍管理系统&lt;/h1&gt; &lt;div sec:authorize="!isAuthenticated()"&gt; &lt;h2&gt;游客你好，如果想看武林秘籍&lt;a href="" th:href="@&#123;/userlogin&#125;" style="text-decoration: none"&gt;请登录&lt;/a&gt;&lt;/h2&gt; &lt;/div&gt; &lt;div sec:authorize="isAuthenticated()"&gt; &lt;h2&gt;&lt;span sec:authentication="name"&gt;&lt;/span&gt;,你好，你的角色有 &lt;span sec:authentication="principal.authorities"&gt;&lt;/span&gt; &lt;/h2&gt; &lt;/div&gt;&lt;/center&gt;&lt;form action="/logout" th:action="@&#123;/logout&#125;" method="post"&gt; &lt;!--解决SpringBoot由于CSFR保护而对空post请求的拦截问题--&gt; &lt;!--&lt;input type="hidden" name="$&#123;_csrf.parameterName&#125;" value="$&#123;_csrf.token&#125;"/&gt;--&gt; &lt;button type="submit"&gt;注销&lt;/button&gt;&lt;/form&gt;&lt;hr/&gt;&lt;div sec:authorize="hasRole('VIP1')"&gt;&lt;h3&gt;普通武林秘籍(限VIP1)&lt;/h3&gt;&lt;ul&gt; &lt;li&gt;&lt;a href="" th:href="@&#123;/level1/1&#125;" style="text-decoration: none"&gt;罗汉拳&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="" th:href="@&#123;/level1/2&#125;" style="text-decoration: none"&gt;全真剑法&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="" th:href="@&#123;/level1/3&#125;" style="text-decoration: none"&gt;武当长拳&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div sec:authorize="hasRole('VIP2')"&gt;&lt;h3&gt;高级武林秘籍(限VIP2)&lt;/h3&gt;&lt;ul&gt; &lt;li&gt;&lt;a href="" th:href="@&#123;/level2/4&#125;" style="text-decoration: none"&gt;太极拳&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="" th:href="@&#123;/level2/5&#125;" style="text-decoration: none"&gt;七伤拳&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="" th:href="@&#123;/level2/6&#125;" style="text-decoration: none"&gt;梯云纵&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div sec:authorize="hasRole('VIP3')"&gt;&lt;h3&gt;绝世武林秘籍(限VIP3)&lt;/h3&gt;&lt;ul&gt; &lt;li&gt;&lt;a href="" th:href="@&#123;/level3/7&#125;" style="text-decoration: none"&gt;葵花宝典&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="" th:href="@&#123;/level3/8&#125;" style="text-decoration: none"&gt;龟派气功&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="" th:href="@&#123;/level3/9&#125;" style="text-decoration: none"&gt;孤独九剑&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 启动Spring Boot看看最终的效果：如果你没有登录，那么你将没有任何操作权限，登录后页面可以根据不同的用户的不同授权显示不同的操作权限可以操作的资源。 #### Demo的Github地址 https://github.com/LoverITer/spring-security-test]]></content>
      <categories>
        <category>Spring Boot框架</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot之异步任务、定时服务和邮件服务]]></title>
    <url>%2F2019%2F09%2F14%2FSpringBoot%E4%B9%8B%E4%BB%BB%E5%8A%A1%2F</url>
    <content type="text"><![CDATA[SpringBoot—异步任务&nbsp;&nbsp;&nbsp;&nbsp;异步调用是相对于同步调用而言的，同步调用是指程序按预定顺序一步步执行，每一步必须等到上一步执行完后才能执行，异步调用则无需等待上一步程序执行完即可执行。&nbsp;&nbsp;&nbsp;&nbsp;实现异步处理任务的方式有很多，我们可以自己通过多线程来实现或者也可以使用SpringBoot提供的@EableAysnc和@Aysnc这两个注解来实现。 通过多线程来实现异步处理任务直接在需要异步任务处理的方法中开启新的线程来处理任务。 12345678910111213141516171819202122@Servicepublic class AsyncService &#123; private Logger log= LoggerFactory.getLogger(AsyncService.class); /** * 手动开启一个线程来处理异步任务 */ public void async()&#123; log.info("开始处理任务"); //开启一个新新线程方式来异步处理任务 new Thread(() -&gt; &#123; try &#123; log.info("处理中，请稍等..."); Thread.sleep(3000); //处理过程中 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;).start(); log.info("任务提前返回，交给另一个线程处理"); &#125;&#125; 执行结果如下： 使用SpringBoot提供的注解处理异步任务首先在需要异步任务处理的方法上加上@Async注解告诉SpringBoot这个方法需要异步处理 123456789101112131415161718@Servicepublic class AsyncService &#123; private Logger log= LoggerFactory.getLogger(AsyncService.class); @Async //开启异步任务 public void async()&#123; log.info("开始处理"); try &#123; log.info("处理中，请稍等..."); Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; log.info("处理完成....."); &#125;&#125; 然后在主配置类使用@EnableAsync注解开启异步注解功能 1234567891011121314package com.xust.iot.task;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.scheduling.annotation.EnableAsync;@EnableAsync //开启异步注解功能@SpringBootApplicationpublic class SpringBootTaskApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringBootTaskApplication.class, args); &#125;&#125; 执行结果如下，SpringBoot也是开启了一个新的线程task-1来处理这个任务的： SpringBoot—定时任务定时任务就是提前设置好时间点，然后每到这个时间点就会执行的任务。SpringBoot中可以通过@Scheduled和@EableScheduled这两个注解来实现定时任务。同样在需要定时任务对方法上标注@Scheduled注解，然后在主配置类上标注@EableScheduled注解开启定时注解功能 123456789101112131415161718192021222324252627@Servicepublic class ScheduledService &#123; private Logger log= LoggerFactory.getLogger(ScheduledService.class); //0 * * * * MON-FRI //秒 分 时 日 月 星期 @Scheduled(cron="0 * * * * 1-7") //星期一~星期天 每分钟的整秒（00秒）执行该任务 public void service1()&#123; log.info("执行定时任务service1@"+ LocalDateTime.now()); &#125; @Scheduled(cron="1,11,21,31,41,51 * * * * 1-7") //星期一~星期天 每分钟的1秒，11秒，21秒，31秒，41秒，51秒的时候执行该任务 public void service2()&#123; log.info("执行定时任务service2@"+ LocalDateTime.now()); &#125; @Scheduled(cron = "0-5 * * * * 1-7") //星期一~星期天 每分钟的00秒~05秒执行该任务 public void service3()&#123; log.info("执行定时任务service3@"+ LocalDateTime.now()); &#125; @Scheduled(cron = "0/5 * * * * 1-7") //星期一~星期天 从00秒开始每隔5秒执行该任务 public void service4()&#123; log.info("执行定时任务service4@"+ LocalDateTime.now()); &#125;&#125; 执行结果： 从上面这个例子中可以看到，对于定时任务使用主要就是对cron表达式的编写，cron允许的值可以有以下几种： 字段允许值允许的特殊字符 秒0-59, - * / 分0-59, - * / 小时0-23, - * / 日1-31, - * / ? L W C 月1-12, - * / 星期0-7或SUN-STA, - * / ? L W C # 解释： , ：表示枚举，可以用它在一个一段上枚举多个值 — ：表示一个区间 * ：表示任意 / ：步长 ？：日/星期冲突匹配 L ： 最后 W： 工作日 C ： 和Calendar联系后计算后的值 # :星期，例如4#2 表示第二个星期四 下面是几个用法示例： 12345678910111213141516171819202122232425262728293031@Servicepublic class ScheduledService &#123; private Logger log= LoggerFactory.getLogger(ScheduledService.class); @Scheduled(cron="0 0/5 14,18 * * ?") //每天14点整合18点整，每隔5分钟执行一次该任务 public void service5()&#123; log.info("执行定时任务service5@"+ LocalDateTime.now()); &#125; @Scheduled(cron="0 30 12 ? * 1-6") //每月的周一~周六12:30执行一次该任务 public void service6()&#123; log.info("执行定时任务service6@"+ LocalDateTime.now()); &#125; @Scheduled(cron = "0 0 12 ? * 6L") //每月的最后一个周六中午12点执行一次 public void service7()&#123; log.info("执行定时任务service7@"+ LocalDateTime.now()); &#125; @Scheduled(cron = "0 0 12 LW * ?") //每月的最后一个工作日的12点执行一次 public void service8()&#123; log.info("执行定时任务service8@"+ LocalDateTime.now()); &#125; @Scheduled(cron = "0 0 6/1 ? * 4#2") //每月的第二个星期四在六点整开始每隔一小时执行一次 public void service9()&#123; log.info("执行定时任务service9@"+ LocalDateTime.now()); &#125;&#125; SpringBoot—邮件任务 &nbsp; &nbsp; &nbsp; &nbsp;Spring Email 抽象的核心是 MailSender 接口，MailSender 的实现能够把 Email 发送给邮件服务器，由邮件服务器实现邮件发送的功能。 &nbsp; &nbsp; &nbsp; &nbsp;Spring 自带了一个 MailSender 的实现JavaMailSenderImpl，它会使用 JavaMail API 来发送 Email。Spring 或 SpringBoot 应用在发送 Email 之前，我们必须要把JavaMailSenderImpl 装配为 Spring应用上下文的一个 bean。 首先引入邮件服务的starter1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-mail&lt;/artifactId&gt;&lt;/dependency&gt; 邮件配置1234567spring: mail: host: smtp.qq.com #smpt主机 password: ceozdvepgtlydihg #这里的password是生成的授权码，不是账户密码 username: huangxin9830@qq.com #发送邮件的账户名 properties: #properties的值应该是一个Map mail.smpt.ssl: true #设置使用SSL安全协议 简单邮件服务—SimpleMessage使用简单邮件服务只能发送文本消息 1234567891011121314@AutowiredJavaMailSenderImpl mailSender;@Testpublic void contextLoads() &#123; //简单邮件服务 SimpleMailMessage message = new SimpleMailMessage(); message.setSubject("你好，这是SpringBootMail"); message.setFrom("2489868503@qq.com"); message.setText("Hello JMail!"); message.setTo("2489868503hx@gmail.com"); mailSender.send(message);&#125; 执行的结果，收到了邮件： 复杂邮件服务—MimeMessage使用复杂邮件服务可以发送文本消息、HTML语句、甚至支持上传附件 12345678910111213141516171819@Test public void test02()&#123; //复杂邮件服务 MimeMessage mimeMessage = mailSender.createMimeMessage(); try &#123; MimeMessageHelper helper = new MimeMessageHelper(mimeMessage, true); helper.setSubject("你好，陌生人！"); helper.setFrom("2489868503@qq.com"); //HTML语句 helper.setText("&lt;font color='red'&gt;你中奖啦！！！&lt;/font&gt;"，true); helper.setTo("2489868503hx@gmail.com"); //上传附件 helper.addAttachment("1.jpg",new File("D:\\pic\\1.jpg")); helper.addAttachment("2.jpg",new File("D:\\pic\\2.jpg")); &#125; catch (MessagingException e) &#123; e.printStackTrace(); &#125; mailSender.send(mimeMessage); &#125; 执行结果：在GMail收到了邮件，并且设置HTML样式起作用了，附件也上传成功了。]]></content>
      <categories>
        <category>Spring Boot框架</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot之缓存二（使用Redis作为缓存）]]></title>
    <url>%2F2019%2F09%2F11%2FSpringBoot%E4%B8%8E%E7%BC%93%E5%AD%98%E4%B9%8B%E6%95%B4%E5%90%88Redis%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;在我的上一篇笔记SpringBoot之缓存一（基本的缓存注解）中学习了一下SpringBoot对缓存的处理机制，重点介绍了SpringBoot提供的基于JCache的几个缓存注解的使用，这篇笔记跟随上篇对Redis做一下整合。首先在原有的pom文件的基础上引入Redis的pom依赖： 12345&lt;!--redis--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt;&lt;/dependency&gt; &nbsp;&nbsp;&nbsp;&nbsp;在我的上一篇笔记在我的上一篇笔记SpringBoot之缓存一（基本的缓存注解）中提到过，当我们没有导入其他第三方的缓存的时候，SpringBoot默认给我们实例化的缓存是SimpleCacheConfiguration的对象，如果我们导入了任何其他第三方的缓存，SpringBoot就会自动切换成第三方的缓存。所以在我们导入Redis的starter后要想正常使用缓存，就需要对他做配置在application.yml文件中添加如下基本的配置： 1234567891011121314#Redis配置spring: redis: host: 192.168.92.128 # redis主机 port: 6379 # redis端口 password: # redis密码，默认没有密码 database: 0 # Redis数据库索引，默认是0 jedis: pool: max-active: 8 # 连接池最大连接数，使用负值表示没有限制 max-wait: -1 # 连接池最大阻塞等待时间，默认是负值表示无限等待 max-idle: 5 # 连接池的最大空闲连接 min-idle: 0 # 连接池的最小空闲连接 timeout: 1200 # 连接超时时间(ms) 配置Redis缓存管理器&nbsp;&nbsp;&nbsp;&nbsp;通过配置Spring的CacheManager为redis，即可指定使用redis做缓存，具体的配置方式跟1.0也有所不同，在1.0中使用RedisTemplate即可实例化一个RedisCacheManager：RedisCacheManager cacheManager = new RedisCacheManager(redisTemplate);在2.0中删除了这个构造器，同时也不可以通过之前的setDefaultExpiration方法设置默认的缓存过期时间等，在新版本中可以通过以下的两种方式构造一个RedisCacheManager： 通过RedisCacheManager的静态方法create():123456@Beanpublic RedisCacheManager redisCacheManager(RedisConnectionFactory redisConnectionFactory)&#123; RedisCacheManager redisCacheManager =RedisCacheManager.create(redisConnectionFactory); return redisCacheManager; &#125; 通过Spring提供的RedisCacheConfiguration类构造一个自己的Redis配置类，从该配置类中可以设置一些初始化的缓存命名空间、及对应的默认过期时间等属性，再利用RedisCacheManager中的builder.build()的方式生成cacheManager： 123456789101112131415161718192021222324252627282930313233343536package com.xust.iot.learningspirngbootcache01.config;import com.xust.iot.learningspirngbootcache01.bean.User;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.Primary;import org.springframework.data.redis.cache.RedisCacheConfiguration;import org.springframework.data.redis.cache.RedisCacheManager;import org.springframework.data.redis.connection.RedisConnectionFactory;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.data.redis.serializer.Jackson2JsonRedisSerializer;import org.springframework.data.redis.serializer.RedisSerializationContext;import java.net.UnknownHostException;import java.time.Duration;@Configurationpublic class RedisCache &#123; @Bean public RedisCacheManager redisCacheManager(RedisConnectionFactory redisConnectionFactory) &#123; //生成默认配置 RedisCacheConfiguration redisCacheConfiguration = RedisCacheConfiguration.defaultCacheConfig().entryTtl(Duration.ofSeconds(60L)); //不缓存空值 redisCacheConfiguration = redisCacheConfiguration.disableCachingNullValues(); //设置序列化 RedisSerializationContext.SerializationPair&lt;User&gt; serializationPair = RedisSerializationContext.SerializationPair.fromSerializer(new Jackson2JsonRedisSerializer&lt;User&gt;(User.class)); //把User对象转成JSON格式 redisCacheConfiguration = redisCacheConfiguration.serializeValuesWith(serializationPair); RedisCacheManager cacheManager = RedisCacheManager.builder(redisConnectionFactory) // 使用自定义的缓存配置初始化一个cacheManager .cacheDefaults(redisCacheConfiguration) //这里一定要把我们的配置设置成默认的额缓存配置才会有效果 .build(); return cacheManager; &#125;&#125; 在设置的时候有一个坑要特别注意RedisCacheConfiguration是有返回值的，也就是说，每设置一次都要重新复制给RedisCacheConfiguration对应的那个对象，不然设置无效。 启动SpringBoot连续查询几次重复的查询1号User后发现第一次是查的数据库，以后都是去Redis中取得值，而且缓存在Redis中的数据也被格式化为JSON格式了：]]></content>
      <categories>
        <category>Spring Boot框架</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot之缓存一（基本的缓存注解）]]></title>
    <url>%2F2019%2F09%2F09%2FSpringBoot%E4%B8%8E%E7%BC%93%E5%AD%98%E6%B3%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp; JSR-107规范JSP-107是什么？ &nbsp;&nbsp;&nbsp;&nbsp;要回答这个问题，首先要知道JSR是什么，JSR是Java Specification Requests 的缩写 ，Java规范请求，故名思议就是Java规范，大家一同遵守这个规范的话，会让大家‘沟通’起来更加轻松。规范是很重要的 ，举个例子大家都知道红灯停，路灯行吧，如果每个城市的信号灯代表不一样，那就麻烦了，B城市红灯行，绿灯停，C城市甚至出现紫灯行，闪灯行，想想都知道，如果我们保证不出问题，必须知道每个城市的信号等代表的意义。我们一直使用的JDBC就一个访问数据库的一个规范的例子。 而 JSR-107呢就是关于如何使用缓存的规范。 JSR-107核心APIJava Caching定义了5个核心接口，分别是CachingProvider,CacheManager,Cache,Entry和Expiry。CachingProvider用于定义创建、配置、获取、管理和控制CacheManager。CacheManager用于定义了建立，配置，得到，管理和控制有着唯一名字的Cache ，一个CacheManager被包含在单一的CachingProvider。CacheCache是一个Map类型的数据结构，用来存储基于键的数据，很多方面都像java.util.Map数据类型。一个Cache 存在在单一的CacheManager。EntryEntry是一个存在于Cache的key-value键值对Expiry每一个存储在Cache中的条目有一个定义的有效期。一旦超过这个时间，条目为过期的状态。一旦过期，条目将不可访问、更新和删除。缓存有效期可以通过ExpiryPolicy来设置。这些接口之间的关系可以用下图表示： &nbsp;&nbsp; Spring缓存抽象Spring 从3.1版本开始在org.springframework.cache包下定义了Cache和CacheManager接口来统一不同的缓存技术，并使用JCache(JSR-107)注解简化我们的开发。 Cache接口为缓存的组件规范定义，包含缓存的各种操作集合 Cache接口下Spring提供了各种xxxCache的实现，如RedisCache、EncheCache、ConcurrentMapCache…… 每次调用需要缓存功能的方法是，Spring会检查指定的参数的是定目标方法时候已经被调用过，如果有就直接从缓存中获取方法调用后对结果，如果没有就调用方法去数据库查询并缓存结果后返回给用户，下次回直接从缓存中获取。 重要的缓存注解 注解功能 Cache缓存接口，定义缓存操作。 CacheManager缓存管理器。管理和中缓存组件 @Cacheable主要用于方法，能够根据方法的请求参数对其进行缓存 @CachePut方法被调用，并且在调用后结果被缓存，主要用于更新操作 @CacheEvict清除缓存 @EnableCaching开启基于注解的缓存 @Caching配置复杂对缓存策略 @CacheConfig同一配置本类的缓存注解额属性 serialize缓存数据的value序列haul策略 @Cacheable/@CachePut/@CacheEvict 主要的参数 参数解释 value/cacheNames缓存的名字。必须指定至少一个，可以配置多个例如：@Cacheable(value={"cache1","cache2"}) key缓存的key。可以为空，如果指定要使用SpEL。默认将方法的所有参数组合起来作为key。例如：@Cacheable(value="cache1",key="#id") keyGenerator定义自动生成主键的策略，使用的时候key和keyGenerator二选一 condition作缓存的条件。可以为空，使用SpEL表达式指定，返回true表示作缓存，否者不缓存。例如：@Cacheable(vlaue="cache",condition="#id&gt;0") unless也是作缓存的条件。当条件为true时，就不缓存（和condition的效果是反的）。例如：@Cacheable(value="cache",unless="#id&lt;0") sync(@Cacheable)是否使用异步支持，这是Spring 4.3以后才支持的,默认值false，不开启异步模式例如：@Cacheable(value="cache",sync=true) //开启异步模式 allEntries(@CacheEvict)是否清空所有缓存内容。默认为false,如果指定为true，则方法调用后将立即清空所有缓存。 beforeInvocation(@CacheEvict)是否在方法执行前清空缓存。默认为false，如果指定为true,则方法还没有执行的时候就清空缓存。默认情况下如果方法抛出异常，就没有办法清空缓存了。 SpEL上下文数据Spring 提供了一些供我们使用的SpEL表达式， 名称位置描述 用法示例 methodName(方法名) root对象 当前被调用的方法名 #root.methodname method(方法) root对象 当前被调用的方法 #root.method.name target(当前对象) root对象 当前被调用的目标对象实例 #root.target targetClass(目标类)root对象 当前被调用的目标对象的类 #root.targetClass args(参数列表) root对象 当前被调用的方法的参数列表 #root.args[0] caches(缓存列表)root对象 当前方法调用使用的缓存列表 #root.caches[0].name Argument Name(参数名)执行上下文 当前被调用的方法的参数，如findArtisan(Artisan artisan),可以通过#artsian.id获得参数 #artsian.id result(方法返回值) 执行上下文 方法执行后的返回值（仅当方法执行后的判断有效，如 unless cacheEvict的beforeInvocation=false） #result &nbsp;&nbsp; Spring缓存的配置和使用先把基本的实现环境搭建起来 首先引入需要的pom依赖12345678910111213141516171819202122232425&lt;!--springboot 缓存--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-cache&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--数据库连接--&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.11&lt;/version&gt;&lt;/dependency&gt;&lt;!--MyBatis--&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.0&lt;/version&gt;&lt;/dependency&gt;&lt;!--druid数据源--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.16&lt;/version&gt;&lt;/dependency&gt; 接下来依次配置数据库连接信息、配置Druid数据源，配置MyBatis，这些配置好后就可以使用SpringBoot默认配置的缓存(SimpleCacheConfiguration)了。如果要使用别的第三方缓存，直接在pom文件中导入相应的starter就可以了。SpringBoot默认配置的缓存是SimpleCacheConfiguration： 首先创建一个实体类User1234567public class User implements Serializable &#123; private Integer id; private String name; private Integer age; private String email; //getter 、setter....&#125; 创建Mapper接口(DAO层) UserMapper.java；123456789101112131415161718192021222324package com.xust.iot.learningspirngbootcache01.mapper;import com.xust.iot.learningspirngbootcache01.bean.User;import org.apache.ibatis.annotations.Param;import org.springframework.stereotype.Repository;import java.util.List;@Repositorypublic interface UserMapper &#123; //增加一个User Integer addOneUser(User usr); //根据id删除一个User boolean deleteUserById(Integer id); //根据id查询一个User User selectUserById(Integer id); //查询所有User List&lt;User&gt; selectAllUser(); //根据id更新一个User boolean updateUserById(@Param("id") Integer id,@Param("user") User user);&#125; 对应的mapper映射文件,UserMapper.xml： 1234567891011121314151617181920212223242526272829&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;mapper namespace="com.xust.iot.learningspirngbootcache01.mapper.UserMapper"&gt; &lt;insert id="addOneUser" useGeneratedKeys="true" keyProperty="id" &gt; insert into user(name,age,email) values (#&#123;name&#125;,#&#123;age&#125;,#&#123;email&#125;) &lt;/insert&gt; &lt;delete id="deleteUserById" parameterType="integer"&gt; delete from user where id=#&#123;id&#125; &lt;/delete&gt; &lt;select id="selectUserById" parameterType="integer" resultType="com.xust.iot.learningspirngbootcache01.bean.User"&gt; select * from user where id=#&#123;id&#125; &lt;/select&gt; &lt;select id="selectAllUser" parameterType="integer" resultType="com.xust.iot.learningspirngbootcache01.bean.User"&gt; select * from user &lt;/select&gt; &lt;update id="updateUserById" &gt; update user &lt;set&gt; name=#&#123;user.name&#125;,email=#&#123;user.email&#125;,age=#&#123;user.age&#125; &lt;/set&gt; &lt;/update&gt;&lt;/mapper&gt; 接下来就是今天的主角——service层。首先编写一个Service层的基接口ServiceBase&lt;T&gt;,在这个接口抽取了service层中通用的CRUD方法，如下： 123456789101112public interface ServiceBase&lt;T&gt; &#123; Integer register(T t); boolean delete(Integer id); User get(Integer id); List&lt;User&gt; getAll(); boolean update(Integer id, T t);&#125; 然后定义IUserService接口，让他去继承ServiceBase接口，由于IUserService接口中这里没有定义新的方法，只是个空类（但它任然有存在的意义），这里就不贴出来了。之后定义IUserService接口的实现类UserServiceImpl.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package com.xust.iot.learningspirngbootcache01.service.impl;import com.xust.iot.learningspirngbootcache01.bean.User;import com.xust.iot.learningspirngbootcache01.mapper.UserMapper;import com.xust.iot.learningspirngbootcache01.service.IUserService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.cache.annotation.*;import org.springframework.stereotype.Service;import org.springframework.transaction.annotation.Transactional;import java.util.List;/** * @Author: HuangXin * @Date: Created in 15:00 2019/9/9 2019 * @Description: */@Transactional //开启事务@Servicepublic class UserServiceImpl implements IUserService&lt;User&gt; &#123; @Autowired UserMapper userMapper; @Override public Integer register(User user) &#123; return userMapper.addOneUser(user); &#125; @Override public boolean delete(Integer id) &#123; return userMapper.deleteUserById(id); &#125; @Override public User get(Integer id) &#123; return userMapper.selectUserById(id); &#125; @Override public List&lt;User&gt; getAll() &#123; return userMapper.selectAllUser(); &#125; @Override public boolean update(Integer id, User user) &#123; return userMapper.updateUserById(id, user); &#125;&#125; 在SpringBoot的启动类头上添加注解@EnableCaching 开启开启基于注解的缓存配置或者使用@MapperScan(value = &quot;com.xust.iot.learningspirngbootcache01.mapper&quot;) 扫描com.xust.iot.learningspirngbootcache01.mapper路径下的所有Mapper接口 之后写一个controller,UserController.java 1234567891011121314151617181920212223242526272829303132@Controllerpublic class UserController &#123; @Autowired IUserService&lt;User&gt; iUserService; @ResponseBody @RequestMapping(value = "/user/&#123;id&#125;") public User selectUser(@PathVariable("id") Integer id) &#123; return iUserService.get(id); &#125; @ResponseBody @RequestMapping(value = "/user/add") public User register(User user) &#123; int id = iUserService.register(user); return user; &#125; @ResponseBody @RequestMapping(value = "/user/all") public List&lt;User&gt; showAllUser()&#123; return iUserService.getAll(); &#125; @ResponseBody @RequestMapping(value = "/user/del/&#123;id&#125;") public ResponseEntity delete(@PathVariable("id") Integer id)&#123; iUserService.delete(id); return new ResponseEntity(HttpStatus.OK); &#125;&#125; 这样搭建好环境后是没有缓存的，使用缓存的方法有很多种，这里就使用SpringBoot提供的注解来使用缓存 @Cacheable@Cacheable注解会先查询是否已经有缓存，有的话会使用缓存，没有则会执行方法并缓存。 12345@Cacheable(value="user",key = "#root.methodName+'('+#id+')'")@Overridepublic User get(Integer id) &#123; return userMapper.selectUserById(id);&#125; 在CacheAspectSupport这个类的findCachedItem方法上打上断点，观察发现我们配置的key是有效： 自定义主键生成策略1234567891011121314151617package com.xust.iot.learningspirngbootcache01.config;import org.springframework.cache.interceptor.KeyGenerator;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import java.util.Arrays;@Configurationpublic class CacheConfig &#123; @Bean("userKey") //bean的名字就是主键生成策略的名字 public KeyGenerator keyGenerator()&#123; //主键策略：方法的hashcode+@+[参数] return (target, method, params) -&gt; method.getName().hashCode()+"@"+ Arrays.toString(params); &#125;&#125; 在方法中可以这么使用： 12345@Cacheable(value="user",keyGenerator = "userKey")@Overridepublic User get(Integer id) &#123; return userMapper.selectUserById(id);&#125; 同样，通过打断点发现我们配置的主键生成也起作用了： 其他参数的用法可以参考下面的程序： 1234567891011121314151617181920212223242526 /** *自定义缓存策略，并且只有当返回值不是null的时候才缓存 */@Cacheable(value="user",keyGenerator = "userKey",condition = "#result!=null")@Overridepublic User get(Integer id) &#123; return userMapper.selectUserById(id);&#125; /** *自定义缓存策略，并且当返回值是null的时候不缓存，也就相当于上面的写法，只不过unless是判断为false的时候才做缓存 */@Cacheable(value="user",keyGenerator = "userKey",unless = "#result==null")@Overridepublic User get(Integer id) &#123; return userMapper.selectUserById(id);&#125; /** *自定义缓存策略，并且开启异步缓存 */@Cacheable(value="user",keyGenerator = "userKey",sync = true)@Overridepublic User get(Integer id) &#123; return userMapper.selectUserById(id);&#125; @CachePut&nbsp;&nbsp;&nbsp;&nbsp;@CachePut注解的作用主要用于对方法配置，能够根据方法的请求参数对其结果进行缓存，和 @Cacheable 不同的是，它每次都会触发真实方法的调用 。简单来说就是用户更新缓存数据。但需要注意的是该注解的value 和 key 必须与要更新的缓存相同，也就是与@Cacheable 相同。 123456//方法本调用后，总是会执行方法，返回后如果条件瞒住就来缓存@CachePut(value = "user",keyGenerator = "userKey",condition = "#result==true")@Overridepublic boolean update(Integer id, User user) &#123; return userMapper.updateUserById(id,user);&#125; @CachePut的其他参数的用法和一样@Cacheable参数的用法一样。这里不再赘述。 @CacheEvict@CachEvict 的作用主要用于方法的配置，能够根据一定的条件对缓存进行清空 。 123456789101112131415161718192021222324252627@CacheEvict(value = "user",beforeInvocation = false) //默认就是false,会在方法执行后清缓存public boolean delete(Integer id) &#123; int i/0; //这里发生异常了，缓存无法清空 return userMapper.deleteUserById(id);&#125; @CacheEvict(value = "user",beforeInvocation = true) //在方法执行前清除缓存@Overridepublic boolean delete(Integer id) &#123; int i/0; //即使这里会发生异常，还是会清空缓存，因为清除缓存是在方法执行前执行的 return userMapper.deleteUserById(id);&#125; @CacheEvict(value = "user",allEntries = true) //方法调用后清空所有缓存@Overridepublic boolean delete(Integer id) &#123; return userMapper.deleteUserById(id);&#125;@CacheEvict(value = "user",allEntries = false) //默认不清空所有缓存@Overridepublic boolean delete(Integer id) &#123; return userMapper.deleteUserById(id);&#125; @Caching有时候我们可能组合多个Cache注解使用，此时就需要@Caching组合多个注解标签了。 123456789101112131415 //组合缓存策略，Caching只有下面三个属性@Caching(cacheable = &#123; @Cacheable(value = "user", keyGenerator = "userKey") &#125;, put = &#123; @CachePut(value = "user", keyGenerator = "userKey") &#125;, evict = &#123; @CacheEvict(beforeInvocation = true, allEntries = true) &#125; ) @Override public boolean delete(Integer id) &#123; return userMapper.deleteUserById(id); &#125; @CachingConfig当我们需要缓存的地方越来越多，你可以使用@CacheConfig(cacheNames = {“cacheName”})注解来统一指定value/cacheNames的值，这时可省略value/cacheNames，如果你在你的方法依旧写上了value/cacheNames，那么依然以方法的@CacheConfig配置的值为准。使用方法如下： 12345678910111213141516171819@CacheConfig(cacheNames = "user") //在类名头上只用@CacheConfig来指定这个类全局的缓存的名字@Servicepublic class UserServiceImpl implements IUserService&lt;User&gt; &#123; @Autowired UserMapper userMapper; @Cacheable(keyGenerator = "userKey", sync = true) @Override public User get(Integer id) &#123; return userMapper.selectUserById(id); &#125; @CachePut(value = "user", keyGenerator = "userKey", condition = "#result==true") @Override public boolean update(Integer id, User user) &#123; return userMapper.updateUserById(id, user); &#125;&#125; @CacheConfig可以配置单的属性如下： 12345678910111213@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documentedpublic @interface CacheConfig &#123; String[] cacheNames() default &#123;&#125;; //缓存名字，它里面没有value String keyGenerator() default ""; //主键生成策略 String cacheManager() default ""; //指定缓存管理器 String cacheResolver() default ""; //缓存处理器&#125;]]></content>
      <categories>
        <category>Spring Boot框架</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot之自定义starter]]></title>
    <url>%2F2019%2F09%2F08%2FSpringBoot%E8%87%AA%E5%AE%9A%E4%B9%89starter%2F</url>
    <content type="text"><![CDATA[Spring Boot中提供了各种starter，starter可以理解为一个可拔插式的插件，当我们要使用的时候只用导入需要的starter即可。例如：你想使用jdbc插件，那么可以使用spring-boot-starter-jdbc；如果想使用mongodb，可以使用spring-boot-starter-data-mongodb。但是当我们需要的场景没有的时候我们可以来定制starter。 创建一个maven工程首先在IDEA中创建一个空工程，在其中创建两个Model，一个是hello-spring-boot-starter,另一个是hello-spring-boot-starter-configurer，目结构如下： 要特别注意artifactId的命名规则：Spring官方starter通常命名为spring-boot-starter-{name},如 spring-boot-starter-web Spring官方建议非官方Starter命名应遵循{name}-spring-boot-starter的格式, 如mybatis-spring-boot-starter。 一般我们不会直接在starter中写配置，starter一般只一个空项目，然后主要的配置写在这个starter对应的autoconfigurer中，让starer依赖configurer就可以了。 在starter中引入对应的configurer依赖starter一般是一个空模块，真正的实现放在configurer中，让starter依赖configurer，以后需要使用这个模块的时候只用引入starter就可以引入它所依赖的configurer。 12345678&lt;dependencies&gt; &lt;!--在自定义的start中引入对应的配置类--&gt; &lt;dependency&gt; &lt;groupId&gt;com.xust.iot&lt;/groupId&gt; &lt;artifactId&gt;hello-spring-boot-starter-configurer&lt;/artifactId&gt; &lt;version&gt;1.0.0-SNAPSHOT&lt;/version&gt; &lt;/dependency&gt;&lt;/dependencies&gt; 在hello-spring-boot-starter-configurer模块中写我们需要的配置XxxProperties123456789101112131415package com.xust.iot.starter;import org.springframework.boot.context.properties.ConfigurationProperties;/** * 用户的配置信息类 */@ConfigurationProperties(prefix = "com.xust.user")public class UserProperties &#123; private String username; //用户名 private Integer age; //用户年龄 private String gender="M"; //用户性别 //getter、setter。。。 核心业务类123456789101112131415161718192021package com.xust.iot.starter;/** * 核心服务类 */public class UserService &#123; private UserProperties userProperties; public UserService()&#123; &#125; public UserService(UserProperties userProperties) &#123; this.userProperties = userProperties; &#125; public String sayHello()&#123; return "大家好，我叫"+userProperties.getUsername()+",今年"+userProperties.getAge()+"岁，"+"性别："+userProperties.getGender(); &#125;&#125; 自动配置类XxxAutoConfigurer12345678910111213141516171819202122package com.xust.iot.starter;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.autoconfigure.condition.ConditionalOnWebApplication;import org.springframework.boot.context.properties.EnableConfigurationProperties;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;@Configuration //说明这是配置@ConditionalOnWebApplication //说明在Web环境下该类起作用@EnableConfigurationProperties(UserProperties.class) //自动配置UserProperties中的属性public class UserServiceAutoConfigurer &#123; @Autowired private UserProperties userProperties; @Bean public UserService userService() &#123; UserService userService = new UserService(userProperties); return userService; &#125;&#125; src/main/resources/META-INF/spring.factories然后需要在hello-spring-boot-starter-configurer的src/main/resources文件夹下新建META-INF文件夹然后新建spring.factories文件,配置这个类让他可以自动启动。 12org.springframework.boot.autoconfigure.EnableAutoConfiguration=\com.xust.iot.starter.UserServiceAutoConfigurer 打包mvn clean install使用Maven命令mvn clean install或直接使用IDEA提供的Maven插件执行install命令把我们的这个starter安装到本地Maven仓库。注意：如果提示没有找到pom文件的错误，那就使用命令行找到对应的项目执行Maven命令 测试一下之后我们再新建一个普通的Spring Boot项目，引入我们自定义的starter 123456&lt;!--在别的项目中引入我们自己的starter,只需要引入starter就可以了--&gt;&lt;dependency&gt; &lt;groupId&gt;com.xust.iot&lt;/groupId&gt; &lt;artifactId&gt;hello-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;&lt;/dependency&gt; 引入后的效果： 写一个controller来测试一下我们的starter是否有效 123456789101112@Controllerpublic class UserController &#123; @Autowired UserService userService; @ResponseBody @RequestMapping(value = "/user") public String hello()&#123; return userService.sayHello(); &#125;&#125; 可以在主配置文件中配置UserProperties中的属性（不配置将会使用默认值） 123com.xust.user.username=李四com.xust.user.age=21com.xust.user.gender=M 启动运行看看效果：]]></content>
      <categories>
        <category>Spring Boot框架</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot之MyBatis的配置和使用（注解和XML配置）]]></title>
    <url>%2F2019%2F09%2F07%2FSpirngBoot%E4%B9%8BMybatis%E7%9A%84%E9%85%8D%E7%BD%AE%E5%92%8C%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[关于MyBatis，大部分人都很熟悉。MyBatis 是一款优秀的持久层框架，它支持定制化 SQL、存储过程以及高级映射。这篇文章主要介绍了Spring Boot集成MyBatis的两种方式（注解和XML文件配置）,需要的朋友可以参考下 &nbsp;&nbsp; 使用XML配置MyBatis在pom.xml文件中引入MyBatis的依赖12345 &lt;dependency&gt; &lt;groupId&gt;org.mybatis.spring.boot&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;2.1.0&lt;/version&gt;&lt;/dependency&gt; 编写MyBatis的主配置文件Mybatis-config.xml在src/main/resources目录下新建mybatis文件夹，然后新建Mybatis-config.xml文件并配置如下： 123456789101112131415161718192021222324252627282930313233&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;configuration&gt; &lt;!--一些有关于mybatis运行时行为的设置--&gt; &lt;settings&gt; &lt;!--开启二级缓存--&gt; &lt;setting name="cacheEnabled" value="true"/&gt; &lt;!--开启懒加载--&gt; &lt;setting name="lazyLoadingEnabled" value="true"/&gt; &lt;!--aggressvieLazyLoading当这个参数为true的时候，对任意延迟属性都会完全的加载，当为false时会按需加载--&gt; &lt;setting name="aggressiveLazyLoading" value="false"/&gt; &lt;setting name="multipleResultSetsEnabled" value="true"/&gt; &lt;setting name="useColumnLabel" value="true"/&gt; &lt;setting name="useGeneratedKeys" value="true"/&gt; &lt;!--开启自动映射--&gt; &lt;setting name="autoMappingBehavior" value="PARTIAL"/&gt; &lt;!--开启驼峰--&gt; &lt;setting name="mapUnderscoreToCamelCase" value="true"/&gt; &lt;setting name="autoMappingUnknownColumnBehavior" value="WARNING"/&gt; &lt;setting name="defaultExecutorType" value="SIMPLE"/&gt; &lt;setting name="defaultStatementTimeout" value="25"/&gt; &lt;setting name="defaultFetchSize" value="100"/&gt; &lt;setting name="safeRowBoundsEnabled" value="false"/&gt; &lt;setting name="localCacheScope" value="SESSION"/&gt; &lt;setting name="jdbcTypeForNull" value="OTHER"/&gt; &lt;setting name="lazyLoadTriggerMethods" value="equals,clone,hashCode,toString"/&gt; &lt;/settings&gt;&lt;/configuration&gt; 编写Mapper接口以及对应的Mapper映射文件在src/main/java下新建mapper包，然后新建ArticleMapper接口如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051/***对article表的CRUD*/@Repository@Mapper //特别注意一定要加上@Mapper注解(或者也可以在启动类中使用@MapperScan)public interface ArticleMapper &#123; /** * 增加一片文章 * * @param article 文章对象 * @return */ Integer add(Article article) throws SQLException; /** * 删除一片文章 * * @param id 文章id * @return */ boolean delete(Integer id) throws SQLException; /** * 修改一片文章 * * @param id * @return * @throws SQLException */ boolean update(@Param("id") Integer id, @Param("article") Article article) throws SQLException; /** * 根据传入的参数查询文章 * * @param id * @return * @throws SQLException */ List&lt;Article&gt; getArticle(@Param("id") Integer id, @Param("title") String title) throws SQLException; /** * 查询所有的文章 * * @return * @throws SQLException */ List&lt;Article&gt; getAll() throws SQLException;&#125; 在src/main.resoures下新建mapper文件夹，然后在mapper文件夹中新建对应的Mapper映射文件ArticleMapper.xml如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;mapper namespace="com.xust.iot.springboot_db.mapper.ArticleMapper"&gt; &lt;insert id="add" parameterType="com.xust.iot.springboot_db.bean.Article" useGeneratedKeys="true" keyProperty="id"&gt; INSERT INTO article ( title, summary, content,level, ctimes, picture ) VALUES (#&#123;title&#125;,#&#123;summary&#125;,#&#123;content&#125;,#&#123;level&#125;,#&#123;ctimes&#125;,#&#123;picture&#125;) &lt;/insert&gt; &lt;delete id="delete" parameterType="integer"&gt; delete from article where id=#&#123;id&#125; &lt;/delete&gt; &lt;update id="update"&gt; update article &lt;if test="article!=null"&gt; &lt;set&gt; &lt;if test="article.title!=null"&gt;title=#&#123;article.title&#125;&lt;/if&gt; &lt;if test="article.summary!=null"&gt;summary=#&#123;article.summary&#125;&lt;/if&gt; &lt;if test="article.content!=null"&gt;content=#&#123;article.content&#125;&lt;/if&gt; &lt;if test="article.level!=null"&gt;level=#&#123;article.level&#125;&lt;/if&gt; &lt;if test="article.ctimes!=null"&gt;ctime=#&#123;article.times&#125;&lt;/if&gt; &lt;if test="article.picture!=null"&gt;picture=#&#123;article.picture&#125;&lt;/if&gt; &lt;/set&gt; &lt;/if&gt; &lt;where&gt; id=#&#123;id&#125; &lt;/where&gt; &lt;/update&gt; &lt;select id="getArticle" resultType="com.xust.iot.springboot_db.bean.Article"&gt; select * from article &lt;where&gt; &lt;choose&gt; &lt;when test="id!=null"&gt;id=#&#123;id&#125;&lt;/when&gt; &lt;/choose&gt; &lt;choose&gt; &lt;when test="title!=null"&gt;title=#&#123;title&#125;&lt;/when&gt; &lt;/choose&gt; &lt;/where&gt; &lt;/select&gt; &lt;select id="getAll" resultType="com.xust.iot.springboot_db.bean.Article"&gt; select * from article &lt;/select&gt;&lt;/mapper&gt; 然后在application.yml文件中配置mybatis这两个文件的位置： 123456mybatis: config-location: classpath:/mybatis/mybatis-config.xml #MyBatis主配置文件的位置 mapper-locations: classpath:/mybatis/mapper/*.xml #mapper文件的位置 这种写法就注册了所有mapper包下的mapper映射文件logging: level: com.xust.iot.learningspirngbootcache01.mapper: debug #对mapper包开启debug,可以看到MyBatis执行SQL的日志打印 编写一个controller，简单测试一下看看我们配置的MyBatis能不能用。这里为了简单就没有写对应的service。 1234567891011121314@Controllerpublic class ArticleController &#123; @Autowired ArticleMapper articleMapper; @ResponseBody @RequestMapping("/article/&#123;id&#125;") public List&lt;Article&gt; getArticle(@PathVariable("id") Integer id) &#123; List&lt;Article&gt; articles=articleMapper.getArticle(id,null); //articles.forEach(article -&gt; System.out.println("article"+article)); return articles; &#125;&#125; 测试结果： &nbsp;&nbsp; 使用注解配置MyBatis在src/main/java/mapper下新建CourseMapper接口 12345678910111213141516171819@Repositorypublic interface CourseMapper &#123; @Options(useGeneratedKeys = true,keyProperty = "id") @Insert("insert into course(cid,cname) values(#&#123;cid&#125;,#(cname))") int add(Course course); @Delete("delete from course where id=#&#123;id&#125;") boolean delete(Integer id); @Update("update course set cid=#&#123;course.cid&#125;,cname=#&#123;course.cname&#125;") boolean update(@Param("id") Integer id, @Param("course") Course course); @Select("select * from course where id=#&#123;id&#125;") Course getOne(Integer id); @Select("select * from course") List&lt;Course&gt; getAll();&#125; 在启动类上使用@MapperScan扫描mapper包下的所有的Mapper接口，这样做的好处是可以省去在每个Mapper接口上写@Mapper注解。 12345678@MapperScan(value = "com.xust.iot.springboot_db.mapper")@SpringBootApplicationpublic class SpringbootDbApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringbootDbApplication.class, args); &#125;&#125; 还可以写一个配置类彻底取代MyBatis的所有XML文件MyBatisConfig.java 12345678910111213141516@Configurationpublic class MybatisConfig &#123; /** * @return */ public ConfigurationCustomizer configurationCustomizern()&#123; return configuration -&gt; &#123; configuration.setMapUnderscoreToCamelCase(true); //开启驼峰命名 configuration.setAutoMappingBehavior(AutoMappingBehavior.FULL); configuration.setCacheEnabled(true); //.....在mybatis主配置文件可以设置的在这里都可以设置 &#125;; &#125;&#125; 编写一个controller，看看实际的效果： 1234567891011121314@Controllerpublic class CourseController &#123; @Autowired CourseMapper courseMapper; @ResponseBody @RequestMapping(value = "/course") public List&lt;Course&gt; show()&#123; List&lt;Course&gt; courses = courseMapper.getAll(); courses.forEach(course -&gt; System.out.println("course；"+course)); return courses; &#125;&#125; 测试结果：]]></content>
      <categories>
        <category>Spring Boot框架</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot 整合Druid数据源]]></title>
    <url>%2F2019%2F09%2F07%2FSpringboot%E9%85%8D%E7%BD%AEdruid%E7%9B%91%E6%8E%A7%2F</url>
    <content type="text"><![CDATA[java实现的数据库连接池有很多，c3p0,dbcp等，还有号称速度最快的HikariCP，并且springboot2.0.2版本默认使用的就是HikariCP。为什么选用Druid呢？ 性能够好，比c3p0,dbcp强一些 经过考验，毕竟是阿里开源出来的项目 最关键的是带一个强大的数据库监控 &nbsp;&nbsp; Druid能监控那些数据 1. 数据源 2. SQL监控 ，对执行的MySQL语句进行记录，并记录执行时间、事务次数等 3. SQL防火墙 ，对SQL进行预编译，并统计该条SQL的数据指标 4. Web应用， 对发布的服务进行监控，统计访问次数，并发数等全局信息 5. URI监控， 对访问的URI进行统计，记录次数，并发数，执行jdbc数等 6. Session监控， 对用户请求后保存在服务器端的session进行记录，识别出每个用户访问了多少次数据库等 7. Spring监控 ，（按需配置）利用aop对各个内容接口的执行时间、jdbc数进行记录 &nbsp;&nbsp; 如何配置使用Druid想达到的目标效果，监控sql，监控sql防火墙，监控url，监控session，监控spring 其中监控sql、监控url、基础信息，几乎不怎么需要配置，集成好druid，配置好监控页面，就可以显示。需要我们配置的大概分为3部分，基础连接池配置，基础监控配置，定制化监控配置 首先需要引入Druid的依赖123456&lt;!--这里最好引入spring提供的这个starter，在druid-spring-boot-starter这个pom文件中已经引入了源工程的pom文件--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.1.16&lt;/version&gt;&lt;/dependency&gt; 基础连接池配置主要配置用户名，密码，数据库驱动、数据库连接…..以及和连接池有关的配置 1234567891011121314151617181920212223242526272829303132spring: datasource: # 数据源基本配置 username: root password: 123456 url: jdbc:mysql://localhost:3306/xust?useSSL=false&amp;set global time_zone="+8:00" driver-class-name: com.mysql.cj.jdbc.Driver #使用type指定使用Druid type: com.alibaba.druid.pool.DruidDataSource # 数据源其他配置 # 初始化连接池的连接数量 大小，最小，最大 initialSize: 5 minIdle: 5 maxActive: 20 # 配置获取连接等待超时的时间 maxWait: 60000 # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 timeBetweenEvictionRunsMillis: 60000 # 配置一个连接在池中最小生存的时间，单位是毫秒 minEvictableIdleTimeMillis: 300000 validationQuery: SELECT 1 FROM DUAL testWhileIdle: true testOnBorrow: false testOnReturn: false # 是否缓存preparedStatement，也就是PSCache 官方建议MySQL下建议关闭 如果想用SQL防火墙 建议打开 poolPreparedStatements: true # 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙 filters: stat,wall,log4j maxPoolPreparedStatementPerConnectionSize: 20 useGlobalDataSourceStat: true # 通过connectProperties属性来打开mergeSql功能 connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=500 导入Druid数据源的其他属性上面的配置文件中和数据库连接池有关的配置属性在Spring Boot是没有的，因此我们需要告诉Spring Boot，让他在启动的时候去找加载这些属性，因此我们需要写一个配置类。没有写配置类之前的效果： 写一个配置类 12345678910@Configurationpublic class DruidConfig &#123; //配置Druid的其他属性 @Bean @ConfigurationProperties(prefix = "spring.datasource") //让Spring boot去加载这些属性，完成对连接池的初始化 public DataSource druid()&#123; return new DruidDataSource(); &#125;&#125; 写配置类后的效果，配置类起作用了： 配置Durid监控主要就是配置一个后台管理的Servlet—StarViewServlet和Web监控过滤器—WebStatFilter。具体有哪些初始化参数可以设置，可以参考这两个类以及他们的父类，都是以常量的方式出现的，配置的时候配置他们的值就可以了。 123456789101112131415161718192021222324252627282930313233@Configurationpublic class DruidConfig &#123; //配置Druid数据监控 //1.配置管理后台的Servlet @Bean public ServletRegistrationBean statViewServlet()&#123; ServletRegistrationBean bean=new ServletRegistrationBean(new StatViewServlet(),"/druid/*"); //设置后台管理的路径是/druid/* Map&lt;String,String&gt; initParams= new HashMap&lt;&gt;(); initParams.put("loginUsername","admin"); initParams.put("loginPassword","123456"); initParams.put("allow",""); //默认就是允许所有访问 initParams.put("deny","192.168.15.21"); //设置不允许访问ip initParams.put("resetEnable","false"); //是否手动清除监控数据 //设置一些初始化的参数 bean.setInitParameters(initParams); return bean; &#125; //2.配置一个Web监控的Filter @Bean public FilterRegistrationBean webStatFilter()&#123; FilterRegistrationBean bean=new FilterRegistrationBean(new WebStatFilter()); Map&lt;String,String&gt; initParams=new HashMap&lt;&gt;(); initParams.put("exclusions","*.js,*.css,/druid/*"); bean.setInitParameters(initParams); bean.setUrlPatterns(Arrays.asList("/*")); return bean; &#125;&#125; 写一个controller启动看看效果： 1234567891011121314@Controllerpublic class HelloController &#123; @Autowired JdbcTemplate jdbcTemplate; @ResponseBody @RequestMapping(value = "/query") public List&lt;Map&lt;String,Object&gt;&gt; hello()&#123; List&lt;Map&lt;String, Object&gt;&gt; maps = jdbcTemplate.queryForList("select * from article"); return maps; &#125;&#125; 启动后在浏览器地址栏输入localhost:8080/query，执行一次请求启动后在浏览器地址栏输入localhost:8080/druid，可以看到Druid后台管理的登录界面 输入刚刚设置的用户名个密码，来到后台管理页面，点击SQL监控就可以看到刚才执行的SQL被记录了。 上面Druid监控的配置还可以直接在properties/yml文件中配置，下面是关于Druid监控的配置片段： 123456789101112131415debug: truespring: datasource: # Druid监控配置 druid: stat-view-servlet: enabled: true #开启后台管理 ，默认也是true url-pattern: /druid/* #后台管理页面的路径 login-password: 123456 login-username: admin reset-enable: false #禁止手动清除监控数据 web-stat-filter: enabled: true exclusions: .js,.css,.html,/druid/* url-pattern: /*]]></content>
      <categories>
        <category>Spring Boot框架</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot配置外部Servlet容器（Tomcat）]]></title>
    <url>%2F2019%2F09%2F04%2FSpringBoot%E9%85%8D%E7%BD%AE%E5%A4%96%E7%BD%AEServlet%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[嵌入式Servlet容器：将应用打成可执行的jar包 ​优点：简单、便携； ​缺点：默认不支持JSP、优化定制比较复杂； 外置的Servlet容器：在外面安装Tomcat(或者使用外部已经安装好的Tomcat)，项目完成后把项目打包成war包，然后放到外部Tomcat容器中运行。 &nbsp;&nbsp; 配置步骤修改打包的方式修改的方法有两种：一种是在使用【Spring Initializr】新建项目的时候选择Packing为war；另一种是在Maven pom.xml文件中修改&lt;packaging&gt;jar&lt;/packaging&gt;使用【Spring Initializr】新建项目的时候选择Packing为war pom.xml文件中修改 1234&lt;artifactId&gt;springboot_servlet_contanier&lt;/artifactId&gt;&lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt;&lt;!--修改为war的打包方式--&gt;&lt;packaging&gt;war&lt;/packaging&gt; 修改原有嵌入式的Tomcat的作用域为provided&lt;/&gt;123456&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;!--provided的意思是告诉Spring Boot 外部提供了，使用外部提供的这个。--&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt; 添加servlet-api依赖1234567891011121314151617181920212223242526&lt;!--添加原生tomcat依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt;&lt;/dependency&gt;&lt;!--使用jsp还要添加下面对依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;taglibs&lt;/groupId&gt; &lt;artifactId&gt;standard&lt;/artifactId&gt; &lt;version&gt;1.1.2&lt;/version&gt; &lt;type&gt;jar&lt;/type&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/javax.servlet/jstl --&gt;&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;type&gt;jar&lt;/type&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;javax.servlet.jsp&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet.jsp-api&lt;/artifactId&gt; &lt;version&gt;2.2.1&lt;/version&gt;&lt;/dependency&gt; 编写一个SpringBootServletInitializer的子类，并调用configure方法【必须】12345678public class ServletInitializer extends SpringBootServletInitializer &#123; @Override protected SpringApplicationBuilder configure(SpringApplicationBuilder application) &#123; //参数是当前项目的启动类的class return application.sources(SpringbootServletContanierApplication.class); &#125;&#125; 如果使用的是【Spring Initializr】创建的项目，正常操作后就会自动生成这个类。 最后在项目中新建webapp目录，启动服务器就可以使用了。 注意：如果发生使用JSP EL表达式无法解析的情况时，可以在jsp页面写上&lt;%@ page isELIgnored=&quot;false&quot; %&gt;这条语句就可以了。]]></content>
      <categories>
        <category>Spring Boot框架</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot之嵌入式Servlet容器的配置、切换和启动原理]]></title>
    <url>%2F2019%2F09%2F04%2FSpringBoot%E5%B5%8C%E5%85%A5%E5%BC%8FServer%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[注意：以下的所有操作、原理、源码全部是建立在Spring Boot 2.1.7基础上的。 &nbsp;&nbsp; 修改SpringBoot对嵌入式Server容器的默认配置&nbsp;&nbsp;&nbsp;&nbsp;Spring Boot默认使用Tomcat作为嵌入式的Servlet容器。实际应用中我们需要对他进行专门的定制。定制的方式不外乎两种：application.proeprties(yml)或在配置类中注册组件的方式，但是这里介绍了3种方法，其实后面两种方法大同小异，原理都是一样的。 方式1：直接在application.properties/application.xml文件中配置和server有关的属性配置方式是server.属性名=值，下面是ServerProperties类中定义的绝大多数可以配置的属性 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273server配置server.address 指定server绑定的地址server.compression.enabled 是否开启压缩，默认为false.server.compression.excluded-user-agents 指定不压缩的user-agent，多个以逗号分隔，默认值为:text/html,text/xml,text/plain,text/cssserver.compression.mime-types 指定要压缩的MIME type，多个以逗号分隔.server.compression.min-response-size 执行压缩的阈值，默认为2048server.context-parameters.[param name] 设置servlet context 参数server.context-path 设定应用的context-path.server.display-name 设定应用的展示名称，默认: applicationserver.jsp-servlet.class-name 设定编译JSP用的servlet，默认: org.apache.jasperservlet.JspServlet)server.jsp-servlet.init-parameters.[param name] 设置JSP servlet 初始化参数.server.jsp-servlet.registered 设定JSP servlet是否注册到内嵌的servlet容器，默认trueserver.port 设定http监听端口server.servlet-path 设定dispatcher servlet的监听路径，默认为: /cookie、session配置server.session.cookie.comment 指定session cookie的commentserver.session.cookie.domain 指定session cookie的domainserver.session.cookie.http-only 是否开启HttpOnly.server.session.cookie.max-age 设定session cookie的最大age.server.session.cookie.name 设定Session cookie 的名称.server.session.cookie.path 设定session cookie的路径.server.session.cookie.secure 设定session cookie的“Secure” flag.server.session.persistent 重启时是否持久化session，默认falseserver.session.timeout session的超时时间server.session.tracking-modes 设定Session的追踪模式(cookie, url, ssl).ssl配置server.ssl.ciphers 是否支持SSL ciphers.server.ssl.client-auth 设定client authentication是wanted 还是 needed.server.ssl.enabled 是否开启ssl，默认: trueserver.ssl.key-alias 设定key store中key的别名.server.ssl.key-password 访问key store中key的密码.server.ssl.key-store 设定持有SSL certificate的key store的路径，通常是一个.jks文件.server.ssl.key-store-password 设定访问key store的密码.server.ssl.key-store-provider 设定key store的提供者.server.ssl.key-store-type 设定key store的类型.server.ssl.protocol 使用的SSL协议，默认: TLSserver.ssl.trust-store 持有SSL certificates的Trust store.server.ssl.trust-store-password 访问trust store的密码.server.ssl.trust-store-provider 设定trust store的提供者.server.ssl.trust-store-type 指定trust store的类型.tomcat配置server.tomcat.access-log-enabled 是否开启access log ，默认: false)server.tomcat.access-log-pattern 设定access logs的格式，默认: commonserver.tomcat.accesslog.directory 设定log的目录，默认: logsserver.tomcat.accesslog.enabled 是否开启access log，默认: falseserver.tomcat.accesslog.pattern 设定access logs的格式，默认: commonserver.tomcat.accesslog.prefix 设定Log 文件的前缀，默认: access_logserver.tomcat.accesslog.suffix 设定Log 文件的后缀，默认: .logserver.tomcat.background-processor-delay 后台线程方法的Delay大小: 30server.tomcat.basedir 设定Tomcat的base 目录，如果没有指定则使用临时目录.server.tomcat.internal-proxies 设定信任的正则表达式，默认:“10\.\d&#123;1,3&#125;\.\d&#123;1,3&#125;\.\d&#123;1,3&#125;| 192\.168\.\d&#123;1,3&#125;\.\d&#123;1,3&#125;| 169\.254\.\d&#123;1,3&#125;\.\d&#123;1,3&#125;| 127\.\d&#123;1,3&#125;\.\d&#123;1,3&#125;\.\d&#123;1,3&#125;| 172\.1[6-9]&#123;1&#125;\.\d&#123;1,3&#125;\.\d&#123;1,3&#125;| 172\.2[0-9]&#123;1&#125;\.\d&#123;1,3&#125;\.\d&#123;1,3&#125;|172\.3[0-1]&#123;1&#125;\.\d&#123;1,3&#125;\.\d&#123;1,3&#125;”server.tomcat.max-http-header-size 设定http header的最小值，默认: 0server.tomcat.max-threads 设定tomcat的最大工作线程数，默认为: 0server.tomcat.port-header 设定http header使用的，用来覆盖原来port的value.server.tomcat.protocol-header 设定Header包含的协议，通常是 X-Forwarded-Proto，如果remoteIpHeader有值，则将设置为RemoteIpValve.server.tomcat.protocol-header-https-value 设定使用SSL的header的值，默认https.server.tomcat.remote-ip-header 设定remote IP的header，如果remoteIpHeader有值，则设置为RemoteIpValveserver.tomcat.uri-encoding 设定URI的解码字符集.undertow配置server.undertow.access-log-dir 设定Undertow access log 的目录，默认: logsserver.undertow.access-log-enabled 是否开启access log，默认: falseserver.undertow.access-log-pattern 设定access logs的格式，默认: commonserver.undertow.accesslog.dir 设定access log 的目录.server.undertow.buffer-size 设定buffer的大小.server.undertow.buffers-per-region 设定每个region的buffer数server.undertow.direct-buffers 设定堆外内存server.undertow.io-threads 设定I/O线程数.server.undertow.worker-threads 设定工作线程数 配置示例： 12345678910server: port: 80 #端口 servlet: context-path: /crud #项目的context-path tomcat: uri-encoding: UTF-8 #tomcat URI的字符编码 basedir: localhost/crud #tomcat基路径 compression: #是否开启压缩文件 enabled: true #true是开启 mime-types: text/html,text/css,text/javascript #压缩的文件类型 方式2：向IoC容器中添加servlet容器工厂定制器 WebServerFactoryCustomizer123456789101112131415161718@Configurationpublic class ServerConfig &#123; @Bean //注册到IOC容器中 public WebServerFactoryCustomizer&lt;TomcatServletWebServerFactory&gt; webServerFactoryCustomizer()&#123; return factory -&gt; &#123; //在这里设置server有关对属性 factory.setPort(8085); factory.setContextPath("/crud"); factory.setUriEncoding(Charset.forName("utf-8")); Compression compression = new Compression(); compression.setEnabled(true); String []mimes=&#123;"text/html","text/css"&#125;; compression.setMimeTypes(mimes); factory.setCompression(compression); &#125;; &#125;&#125; 运行结果： 如果使用的是Spring Boot 1.x版本可以参考下面的方法来使用配置 123456789101112public class ServerConfig extends WebMvcConfigurerAdapter &#123; public EmbeddedServletContainerCustomizer embeddedServletContainerCustomizer() &#123; return new EmbeddedServletContainerCustomizer() &#123; @Override public void customize(ConfigurableEmbeddedServletContainer container) &#123; //配置server属性 container.setPort(8083); ... &#125; &#125;; &#125;&#125; 方式3：向IoC容器中添加可配置的servlet容器工厂 ConfigurableServletWebServerFactory123456789101112131415161718@Configurationpublic class ServerConfig &#123; @Bean public ConfigurableServletWebServerFactory configurableServletWebServerFactory() &#123; TomcatServletWebServerFactory factory = new TomcatServletWebServerFactory(); //设置属性 factory.setPort(8089); factory.setContextPath("/springboot"); factory.setUriEncoding(Charset.forName("utf-8")); Compression compression = new Compression(); compression.setEnabled(true); String[] mimes = &#123;"text/html", "text/css"&#125;; compression.setMimeTypes(mimes); factory.setCompression(compression); return factory; &#125;&#125; 运行自然是没有什么问题，在地址栏输入localhost:8089/springboot/也来到了目标页面： 在Spring Boot中注册Servlet三大组件【Servlet、Filter、Listener】以前注册这些组件都是在web.xml中配置，由于SpringBoot默认是以jar包的方式启动嵌入式的Servlet容器来启动Spring Boot的web应用，默认就没有web.xml文件了。那怎么办呢？Spring Boot给的解决办法很简单，就是使用对应的XxxRegistrationBean来注册，具体的方法参考下面示例 注册三大组件用以下方式： 1、借助ServletRegistrationBean注册自定义Servlet组件； 自定义MyServlet.java： 12345678public class MyServlet extends HttpServlet &#123; //重写service方法 @Override protected void service(HttpServletRequest req,HttpServletResponse resp)&#123; resp.getWriter().write("Hello Spring Boot!"); &#125;&#125; 借助ServletRegistrationBean来注册一个Servlet并放入容器中： 12345@Beanpublic ServletRegistrationBean myServlet()&#123; ServletRegistrationBean registrationBean = new ServletRegistrationBean(new MyServlet(),"/myServlet"); return registrationBean;&#125; 2、借助FilterRegistrationBean注册自定义Filter组件(自定义的MyFilter忽略) 1234567@Beanpublic FilterRegistrationBean myFilter()&#123; FilterRegistrationBean registrationBean = new FilterRegistrationBean(); registrationBean.setFilter(new MyFilter()); registrationBean.setUrlPatterns(Arrays.asList("/hello","/myServlet")); return registrationBean;&#125; 3、借助ServletListenerRegistrationBean注册自定义Listener组件(自定义的MyListener忽略) 12345@Beanpublic ServletListenerRegistrationBean myListener()&#123; ServletListenerRegistrationBean&lt;MyListener&gt; registrationBean = new ServletListenerRegistrationBean&lt;&gt;(new MyListener()); return registrationBean;&#125; &nbsp;&nbsp; 嵌入式Servlet容器切换三大容器比较 容器 优点 缺点 默认 tomcat 功能齐全 庞大，荣泽 true jetty 轻量 功能不全 false undertow 异步，高效 不支持jsp false 容器切换 Tomcat Spring Boot引入web模块默认就是使用嵌入式的Tomcat作为Servlet容器。 1234 &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt;&lt;/dependency&gt; Jetty 123456789101112131415161718&lt;!-- 引入web模块 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;!--排除tomcat--&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!--引入jetty容器--&gt;&lt;dependency&gt; &lt;artifactId&gt;spring-boot-starter-jetty&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;/dependency&gt; undertow 1234567891011121314151617&lt;!-- 引入web模块 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;artifactId&gt;spring-boot-starter-tomcat&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!--引入其他的Servlet容器--&gt;&lt;dependency&gt; &lt;artifactId&gt;spring-boot-starter-undertow&lt;/artifactId&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt;&lt;/dependency&gt; &nbsp;&nbsp; 嵌入式Servlet容器自动配置原理主要的三个类： ServletWebServerFactoryConfiguration ServletWebServerFactoryAutoConfiguration ServletWebServerFactoryCustomizer ServletWebServerFactoryConfiguration首先从ServletWebServerFactoryConfiguration这个配置类说起，在它里面主要有三个嵌入式的Web容器：EmbeddedUndertow ，EmbeddedJetty，EmbeddedTomcat以及@Conditionalxxx 标注的类（条件检查，只有条件满足才向容器中添加组件）。这个类的作用就是根据配置的环境，产生一个对应容器的工厂类。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647@Configurationclass ServletWebServerFactoryConfiguration &#123; //默认配置的就是Tomcat @Configuration //条件检查：类路径下存在servlet.class(存在servlet依赖) tomcat.class(tomcat依赖) 才会执行向容器中添加组件 @ConditionalOnClass(&#123; Servlet.class, Tomcat.class, UpgradeProtocol.class &#125;) //判断容器中有没有用户自定义的ServletWeServerbFactory @ConditionalOnMissingBean(value = ServletWebServerFactory.class, search = SearchStrategy.CURRENT) public static class EmbeddedTomcat &#123; //向IOC容器中添加tomcat工厂，之后由工厂产生嵌入式的tomcat实例 @Bean public TomcatServletWebServerFactory tomcatServletWebServerFactory() &#123; return new TomcatServletWebServerFactory(); &#125; &#125; /** * 如果配置了Jetty就会自动配置jetty */ @Configuration @ConditionalOnClass(&#123; Servlet.class, Server.class, Loader.class, WebAppContext.class &#125;) @ConditionalOnMissingBean(value = ServletWebServerFactory.class, search = SearchStrategy.CURRENT) public static class EmbeddedJetty &#123; @Bean public JettyServletWebServerFactory JettyServletWebServerFactory() &#123; return new JettyServletWebServerFactory(); &#125; &#125; /** * 如果配置了Undertow就会自动配置Undertow */ @Configuration @ConditionalOnClass(&#123; Servlet.class, Undertow.class, SslClientAuthMode.class &#125;) @ConditionalOnMissingBean(value = ServletWebServerFactory.class, search = SearchStrategy.CURRENT) public static class EmbeddedUndertow &#123; @Bean public UndertowServletWebServerFactory undertowServletWebServerFactory() &#123; return new UndertowServletWebServerFactory(); &#125; &#125;&#125;&#125; ServletWebServerFactory：嵌入式Servlet工厂。作用：创建嵌入式Servlet容器 1234567@FunctionalInterfacepublic interface ServletWebServerFactory &#123; //ServletWebServerFactory只有一个接口方法getWebServer，他会拿到Spring Boot在启动的时候初始化的参数 WebServer getWebServer(ServletContextInitializer... initializers);&#125; 在判断@ConditionalOnClass({Servlet.class, Tomcat.class, UpgradeProtocol.class})是否导入依赖，满足条件后return new TomcatServletWebServerFactory(); 添加对应的Servlet容器工厂；通过工厂的唯一方法getWebServer 获取对应的Servlet容器TomcatServer. TomcatServletWebServerFactory 123456789101112131415161718192021222324252627282930313233public class TomcatServletWebServerFactory extends AbstractServletWebServerFactory implements ConfigurableTomcatWebServerFactory, ResourceLoaderAware &#123; public WebServer getWebServer(ServletContextInitializer... initializers) &#123; // 1. 创建Tomcat对象 Tomcat tomcat = new Tomcat(); //设置tomcat的基路径 File baseDir = this.baseDirectory != null ? this.baseDirectory : this.createTempDir("tomcat"); tomcat.setBaseDir(baseDir.getAbsolutePath()); // 2.完成tomct 配置的基本操作 Connector connector = new Connector(this.protocol); tomcat.getService().addConnector(connector); this.customizeConnector(connector); tomcat.setConnector(connector); tomcat.getHost().setAutoDeploy(false); this.configureEngine(tomcat.getEngine()); Iterator var5 = this.additionalTomcatConnectors.iterator(); while(var5.hasNext()) &#123; Connector additionalConnector = (Connector)var5.next(); tomcat.getService().addConnector(additionalConnector); &#125; this.prepareContext(tomcat.getHost(), initializers); 3.将tomcat 传入方法：getTomcatWebServer() return this.getTomcatWebServer(tomcat); &#125;&#125; TomcatWebServer 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class TomcatWebServer implements WebServer &#123; //TomcatWebServer的构造器中真正的实例化tomcat，并且启动tomcat public TomcatWebServer(Tomcat tomcat, boolean autoStart) &#123; this.monitor = new Object(); this.serviceConnectors = new HashMap(); Assert.notNull(tomcat, "Tomcat Server must not be null"); this.tomcat = tomcat; this.autoStart = autoStart; this.initialize(); &#125; //initialize方法执行初始化 private void initialize() throws WebServerException &#123; logger.info("Tomcat initialized with port(s): " + getPortsDescription(false)); synchronized (this.monitor) &#123; try &#123; addInstanceIdToEngineName(); Context context = findContext(); context.addLifecycleListener((event) -&gt; &#123; if (context.equals(event.getSource()) &amp;&amp; Lifecycle.START_EVENT.equals(event.getType())) &#123; //服务启动的时候执行 removeServiceConnectors(); &#125; &#125;); //启动tomcat this.tomcat.start(); // We can re-throw failure exception directly in the main thread rethrowDeferredStartupExceptions(); try &#123; ContextBindings.bindClassLoader(context, context.getNamingToken(), getClass().getClassLoader()); &#125; catch (NamingException ex) &#123; // Naming is not enabled. Continue &#125; // Unlike Jetty, all Tomcat threads are daemon threads. We create a // blocking non-daemon to stop immediate shutdown startDaemonAwaitThread(); &#125; catch (Exception ex) &#123; stopSilently(); destroySilently(); throw new WebServerException("Unable to start embedded Tomcat", ex); &#125; &#125; &#125;&#125; ServletWebServerFactoryAutoConfiguration修改定制嵌入式Servlet 容器的方法:&nbsp;&nbsp;&nbsp;1、配置文件中添加配置。&nbsp;&nbsp;&nbsp;2、ServerProperties 绑定/修改定制组件 WebServerFactoryCustomizer 他们的本质是一样的：在ServletWebServerFactoryAutoConfiguration配置类中@EnableConfigurationProperties({ServerProperties.class})。导入了BeanPostProcessorsRegistrar，在这个类的方法中添加了组件WebServerFactoryCustomizerBeanPostProcessor(定制器后置处理器)。也就是说一旦容器中添加任何组件都会启动定制后置处理器，进行Servlet的赋值。 ServletWebServerFactoryCustomizer在这个配置类中使用customize(ConfigurableServletWebServerFactory factory)这个方法 完成了Tomcat的各项配置的修改和定制 1234567891011121314151617181920public class ServletWebServerFactoryCustomizer implements WebServerFactoryCustomizer&lt;ConfigurableServletWebServerFactory&gt;, Ordered &#123; //具体对Tomcat的配置细节 @Override public void customize(ConfigurableServletWebServerFactory factory) &#123; PropertyMapper map = PropertyMapper.get().alwaysApplyingWhenNonNull(); map.from(this.serverProperties::getPort).to(factory::setPort); map.from(this.serverProperties::getAddress).to(factory::setAddress); map.from(this.serverProperties.getServlet()::getContextPath).to(factory::setContextPath); map.from(this.serverProperties.getServlet()::getApplicationDisplayName).to(factory::setDisplayName); map.from(this.serverProperties.getServlet()::getSession).to(factory::setSession); map.from(this.serverProperties::getSsl).to(factory::setSsl); map.from(this.serverProperties.getServlet()::getJsp).to(factory::setJsp); map.from(this.serverProperties::getCompression).to(factory::setCompression); map.from(this.serverProperties::getHttp2).to(factory::setHttp2); map.from(this.serverProperties::getServerHeader).to(factory::setServerHeader); map.from(this.serverProperties.getServlet()::getContextParameters).to(factory::setInitParameters); &#125;&#125; 配置修改定制原理(以tomcat为例)1、Spring Boot根据根据导入依赖的情况，给容器中添加相应的ServletWebServerFactory（比如tomcat就会添加TomcatServletWebServerFactory） 2、如果使用的是通过application.properties 修改配置，那么server 相关的配置修改是与ServerProperties 类绑定的，所以相关的修改会直接通过ServerProperties 的方法实现【相关的配置类：ServletWebServerFactoryCustomizer】 3、如果使用的是修改定制器 WebServerFactoryCustomizer的方法来配置server，那么定制器会创建ConfigurableWebServerFactory对象，这样一来就会触发WebServerFactoryCustomizerBeanPostProcessor 后置处理器，判断是否为WebServerFactory 类型；满足条件后，就会获取容器中的所有定制器（customizer.cutomize(bean)），为Servlet容器修改和定制配置【相关的配置类ServletWebServerFactoryAutoConfiguration，导入了定制处理器】 &nbsp;&nbsp; 嵌入式Servlet 容器启动的原理（tomcat）几个重要的回调机制：配置在META-INF/spring.factories ApplicationContextInitializer SpringApplicationRunListener 只需要放在ioc容器中 ApplicationRunner CommandLineRunner 1、SpringBoot 应用启动，运行run()方法跟随源码我们来到SpringApplication类中发现他对run方法进行了几次封装 1234567891011121314151617181920212223242526272829303132333435//这是我们在启动类中调用的run()方法public static ConfigurableApplicationContext run(Class&lt;?&gt; primarySource, String... args) &#123; //调用了本类中的另一个run()方法,也就是紧跟着下面的这个方法 return run(new Class[]&#123;primarySource&#125;, args);&#125;public static ConfigurableApplicationContext run(Class&lt;?&gt;[] primarySources, String[] args) &#123; //调用了SpringApplication中的构造器创建了一个SpringAapplication的对象，并最终调用了真正的run方法 return (new SpringApplication(primarySources)).run(args);&#125;//最终执行初始化SpringApplication的构造器public SpringApplication(ResourceLoader resourceLoader, Class... primarySources) &#123; this.sources = new LinkedHashSet(); this.bannerMode = Mode.CONSOLE; this.logStartupInfo = true; //默认开启命令行参数 this.addCommandLineProperties = true; this.addConversionService = true; this.headless = true; this.registerShutdownHook = true; //多profiles初始化，使用的是HashSet来保存 this.additionalProfiles = new HashSet(); this.isCustomEnvironment = false; this.resourceLoader = resourceLoader; Assert.notNull(primarySources, &quot;PrimarySources must not be null&quot;); this.primarySources = new LinkedHashSet(Arrays.asList(primarySources)); this.webApplicationType = WebApplicationType.deduceFromClasspath(); //设置初始化参数 this.setInitializers(this.getSpringFactoriesInstances(ApplicationContextInitializer.class)); //设置监听器 this.setListeners(this.getSpringFactoriesInstances(ApplicationListener.class)); //从多个主配置类中找到有main方法的的主配置类（启动类） this.mainApplicationClass = this.deduceMainApplicationClass();&#125; 运行run()方法 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950public ConfigurableApplicationContext run(String... args) &#123; StopWatch stopWatch = new StopWatch(); stopWatch.start(); ConfigurableApplicationContext context = null; Collection&lt;SpringBootExceptionReporter&gt; exceptionReporters = new ArrayList&lt;&gt;(); configureHeadlessProperty(); //获取SpringApplictionRunListeners对象，从META-INF/factroies下加载 SpringApplicationRunListeners listeners = getRunListeners(args); //回调所有的SpringApplicationRunListeners的startings方法 listeners.starting(); try &#123; //封装命令行参数 ApplicationArguments applicationArguments = new DefaultApplicationArguments(args); //准备环境，在这个方法内部当环境创建完成后会调用SpringApplicationRunListener的environmentPrepared()方法表示环境准备完成 ConfigurableEnvironment environment = prepareEnvironment(listeners, applicationArguments); configureIgnoreBeanInfo(environment); //Spring Boot一启动打印Spring图标就是在这里完成的 Banner printedBanner = printBanner(environment); //创建ioc容器 context = createApplicationContext(); exceptionReporters = getSpringFactoriesInstances(SpringBootExceptionReporter.class, new Class[] &#123; ConfigurableApplicationContext.class &#125;, context); //准备上下文环境：将environment保存到ioc容器中 prepareContext(context, environment, listeners, applicationArguments, printedBanner); //刷新容器：扫描、加载、创建所有组件的地方（如果Web环境默认还会创建嵌入式的tomcat容器） refreshContext(context); //从ioc容器中获取所有的ApplicationRunner和CommandLineRunner进行回调。ApplicationRunner先回调，CommandLineRunner再回调 afterRefresh(context, applicationArguments); stopWatch.stop(); if (this.logStartupInfo) &#123; new StartupInfoLogger(this.mainApplicationClass).logStarted(getApplicationLog(), stopWatch); &#125; listeners.started(context); callRunners(context, applicationArguments); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, listeners); throw new IllegalStateException(ex); &#125; try &#123; listeners.running(context); &#125; catch (Throwable ex) &#123; handleRunFailure(context, ex, exceptionReporters, null); throw new IllegalStateException(ex); &#125; //Spring Boot引用启动完成后返回ioc容器 return context; &#125; 2、SpringApplication类中的run方法中调用refreshContext(context) 刷新IOC容器【创建IOC容器对象，并初始化容器，创建容器中的每一个组件】,如果是web应用创建AnnotationConfigEmbeddedWebApplicationContext，否则普通应用创建AnnotationConfigApplicationContext 1234567891011121314151617private void refreshContext(ConfigurableApplicationContext context) &#123; //直接调用的是本类中的refresh方法 refresh(context); if (this.registerShutdownHook) &#123; try &#123; context.registerShutdownHook(); &#125; catch (AccessControlException ex) &#123; // Not allowed in some environments. &#125; &#125; &#125; //在这里真正调用AbstractApplicationContext类中的refersh方法来刷新容器 protected void refresh(ApplicationContext applicationContext) &#123; Assert.isInstanceOf(AbstractApplicationContext.class, applicationContext); ((AbstractApplicationContext) applicationContext).refresh(); &#125; 3、refresh()刷新刚才创建好的ioc容器AbstractApplicationContext 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748@Override public void refresh() throws BeansException, IllegalStateException &#123; synchronized (this.startupShutdownMonitor) &#123; // Prepare this context for refreshing. prepareRefresh(); // Tell the subclass to refresh the internal bean factory. ConfigurableListableBeanFactory beanFactory = obtainFreshBeanFactory(); // Prepare the bean factory for use in this context. prepareBeanFactory(beanFactory); try &#123; // Allows post-processing of the bean factory in context subclasses. postProcessBeanFactory(beanFactory); // Invoke factory processors registered as beans in the context. invokeBeanFactoryPostProcessors(beanFactory); // Register bean processors that intercept bean creation. registerBeanPostProcessors(beanFactory); // Initialize message source for this context. initMessageSource(); // Initialize event multicaster for this context. initApplicationEventMulticaster(); // Initialize other special beans in specific context subclasses. onRefresh(); // Check for listener beans and register them. registerListeners(); // Instantiate all remaining (non-lazy-init) singletons. finishBeanFactoryInitialization(beanFactory); // Last step: publish corresponding event. finishRefresh(); &#125; catch (BeansException ex) &#123; if (logger.isWarnEnabled()) &#123; logger.warn("Exception encountered during context initialization - " + "cancelling refresh attempt: " + ex); &#125; // Destroy already created singletons to avoid dangling resources. destroyBeans(); // Reset 'active' flag. cancelRefresh(ex); // Propagate exception to caller. throw ex; &#125; finally &#123; // Reset common introspection caches in Spring's core, since we // might not ever need metadata for singleton beans anymore... resetCommonCaches(); &#125; &#125; &#125; 4、Web模块的IOC容器重写了onRefresh()方法，创建了嵌入式的Servlet容器5、获取嵌入式工厂容器组件：ServletWebServerFactory factory = this.getServletWebServerFactory (); TomcatServletWebServerFactory 对象被创建，触发后置处理器，配置类中：@EnableConfigurationProperties({ServerProperties.class}) 根据配置文件，获取所有的定制器为Servlet容器赋值6、TomcatServerWebServletFactory 获取后使用这个容器工厂获取Servlet容器TomcatWebServer(其他容器类似) 完成自启动7、嵌入式的Servlet容器创建对象并启动Servlet容器 IOC容器启动创建嵌入式的Servlet容器，再启动嵌入式的Servlet容器，再将IOC容器中剩下没有创建出的对象获取出来]]></content>
      <categories>
        <category>Spring Boot框架</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot 错误处理机制]]></title>
    <url>%2F2019%2F09%2F02%2FSpringBoot%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86%E6%9C%BA%E5%88%B6%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp; Spring Boot默认的错误处理机制（现象）&nbsp;&nbsp;&nbsp;&nbsp;当我们使用Spring Boot发生错误的时候，如果我们没有配置错误的处理规则，那么Spring Boot就会启用内部的默认错误处理办法。比如当发生404错误的时候，网页端的效果如下： 而在别的客户端访问的时候如果出现了404错误，默认会给客户端发送一串错误消息的JSON数据 客户端的测试使用到了一个工具：Postman,感兴趣的小伙伴可以去Postman官网下载后来测试。 &nbsp;&nbsp; Spring Boot默认的错误处理机制（原理）&nbsp;&nbsp;&nbsp;&nbsp;看到这些现象我们不禁会有疑问，Spring Boot的底层是如何生成不同错误的默认错误页面的？还有他是如何区分浏览器和普通客户端的？带着疑问我们继续往下看。&nbsp;&nbsp;&nbsp;&nbsp;我们参照源码来分析一下（Spring Boot 2.1.7版本），具体在ErrorMvcAutoConfiguration这个错误处理自动配置类,下面是在这个类中注册的几个重要的组件的源码： ErrorMvcAutoConfiguration源码片段 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253@Configuration@ConditionalOnWebApplication(type = Type.SERVLET)@ConditionalOnClass(&#123; Servlet.class, DispatcherServlet.class &#125;)// Load before the main WebMvcAutoConfiguration so that the error View is available@AutoConfigureBefore(WebMvcAutoConfiguration.class)@EnableConfigurationProperties(&#123; ServerProperties.class, ResourceProperties.class, WebMvcProperties.class &#125;)public class ErrorMvcAutoConfiguration &#123; //注册DefaultErrorAttributs @Bean @ConditionalOnMissingBean(value = ErrorAttributes.class, search = SearchStrategy.CURRENT) public DefaultErrorAttributes errorAttributes() &#123; return new DefaultErrorAttributes(this.serverProperties.getError().isIncludeException()); &#125; //注册BaseErrorController @Bean @ConditionalOnMissingBean(value = ErrorController.class, search = SearchStrategy.CURRENT) public BasicErrorController basicErrorController(ErrorAttributes errorAttributes) &#123; return new BasicErrorController(errorAttributes, this.serverProperties.getError(), this.errorViewResolvers); &#125; //注册ErrorPageCustomizer @Bean public ErrorPageCustomizer errorPageCustomizer() &#123; return new ErrorPageCustomizer(this.serverProperties, this.dispatcherServletPath); &#125; //配置DefaultErrorViewResolver内部类 @Configuration static class DefaultErrorViewResolverConfiguration &#123; private final ApplicationContext applicationContext; private final ResourceProperties resourceProperties; DefaultErrorViewResolverConfiguration(ApplicationContext applicationContext, ResourceProperties resourceProperties) &#123; this.applicationContext = applicationContext; this.resourceProperties = resourceProperties; &#125; //在这个静态内部内中配置了DefaultErrorViewResolver @Bean @ConditionalOnBean(DispatcherServlet.class) @ConditionalOnMissingBean public DefaultErrorViewResolver conventionErrorViewResolver() &#123; return new DefaultErrorViewResolver(this.applicationContext, this.resourceProperties); &#125; &#125;&#125; 可以看到，ErrorMvcAutoConfiguration这个错误处理类中配置了几个重要的组件： DefaultErrorAttributs ：翻译这个类的名字：默认的错误属性，他就是和错误信息的填充有关。 BasicErrorController ：他是Spring Boot中默认处理/error请求的Controller ErrorPageCustomizer ：系统出现错误以后来到error请求进行处理 DefaultErrorViewResolver ：默认的错误视图解析器 继续跟踪源码 DefaultErrorAttributs源码片段 12345678910111213141516171819@Order(Ordered.HIGHEST_PRECEDENCE)public class DefaultErrorAttributes implements ErrorAttributes, HandlerExceptionResolver, Ordered &#123; //获得错误的属性信息，在页面上默认显示的错误信息都由这来的 @Override public Map&lt;String, Object&gt; getErrorAttributes(WebRequest webRequest, boolean includeStackTrace) &#123; //new了一个Map Map&lt;String, Object&gt; errorAttributes = new LinkedHashMap&lt;&gt;(); //产生错误放生的时间戳 errorAttributes.put("timestamp", new Date()); //产生错误的状态码 addStatus(errorAttributes, webRequest); //错误的细节 addErrorDetails(errorAttributes, webRequest, includeStackTrace); //错误的路径 addPath(errorAttributes, webRequest); return errorAttributes; &#125;&#125; BasicErrorController源码片段 12345678910111213141516171819202122232425262728293031@Controller@RequestMapping("$&#123;server.error.path:$&#123;error.path:/error&#125;&#125;")public class BasicErrorController extends AbstractErrorController &#123; //浏览器的错误请求用这个处理方法来处理，产生HTML数据 @RequestMapping(produces = MediaType.TEXT_HTML_VALUE) public ModelAndView errorHtml(HttpServletRequest request, HttpServletResponse response) &#123; //得到状态码 HttpStatus status = getStatus(request); //把ErrorAttributs中的错误信息填充到model中 Map&lt;String, Object&gt; model = Collections .unmodifiableMap(getErrorAttributes(request, isIncludeStackTrace(request, MediaType.TEXT_HTML))); //设置响应码 response.setStatus(status.value()); //去哪个页面作为错误页面,包含页面地址和页面内容 ModelAndView modelAndView = resolveErrorView(request, response, status, model); //如果没有映射到可以去的错误页面就会去默认的错误页面(就是看到的那个白板页面) return (modelAndView != null) ? modelAndView : new ModelAndView("error", model); &#125; //返回JSON格式的数据，非浏览器访问后错误的处理方法 @RequestMapping public ResponseEntity&lt;Map&lt;String, Object&gt;&gt; error(HttpServletRequest request) &#123; Map&lt;String, Object&gt; body = getErrorAttributes(request, isIncludeStackTrace(request, MediaType.ALL)); HttpStatus status = getStatus(request); //返回Json数据 return new ResponseEntity&lt;&gt;(body, status); &#125;&#125; BasicErrorController中调用了它父类AbstractErrorControlle的方法resolveErrorView来处理ModelAndViewAbstractErrorController源码片段 123456789101112public abstract class AbstractErrorController implements ErrorController &#123;protected ModelAndView resolveErrorView(HttpServletRequest request, HttpServletResponse response, HttpStatus status,Map&lt;String, Object&gt; model) &#123; //遍历所有的错误视图处理器 for (ErrorViewResolver resolver : this.errorViewResolvers) &#123; ModelAndView modelAndView = resolver.resolveErrorView(request, status, model); if (modelAndView != null) &#123; return modelAndView; &#125; &#125; return null; &#125;&#125; ErrorPageCustomizer源码片段 123456789101112131415161718192021222324252627 /** *ErrorMvcAutoConfiguration的内部类 * &#123;@link WebServerFactoryCustomizer&#125; that configures the server's error pages. */private static class ErrorPageCustomizer implements ErrorPageRegistrar, Ordered &#123; private final ServerProperties properties; private final DispatcherServletPath dispatcherServletPath; protected ErrorPageCustomizer(ServerProperties properties, DispatcherServletPath dispatcherServletPath) &#123; this.properties = properties; this.dispatcherServletPath = dispatcherServletPath; &#125; @Override public void registerErrorPages(ErrorPageRegistry errorPageRegistry) &#123; ErrorPage errorPage = new ErrorPage( this.dispatcherServletPath.getRelativePath(this.properties.getError().getPath())); errorPageRegistry.addErrorPages(errorPage); &#125; @Override public int getOrder() &#123; return 0; &#125;&#125; DefaultErrorViewResolver源码片段 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455public class DefaultErrorViewResolver implements ErrorViewResolver, Ordered &#123; private static final Map&lt;Series, String&gt; SERIES_VIEWS; //错误状态码 static &#123; Map&lt;Series, String&gt; views = new EnumMap&lt;&gt;(Series.class); views.put(Series.CLIENT_ERROR, "4xx"); views.put(Series.SERVER_ERROR, "5xx"); SERIES_VIEWS = Collections.unmodifiableMap(views); &#125; @Override public ModelAndView resolveErrorView(HttpServletRequest request, HttpStatus status, Map&lt;String, Object&gt; model) &#123; // 这里如果没有拿到精确状态码(如404)的视图，则尝试拿4XX(或5XX)的视图 ModelAndView modelAndView = resolve(String.valueOf(status.value()), model); if (modelAndView == null &amp;&amp; SERIES_VIEWS.containsKey(status.series())) &#123; modelAndView = resolve(SERIES_VIEWS.get(status.series()), model); &#125; return modelAndView; &#125; private ModelAndView resolve(String viewName, Map&lt;String, Object&gt; model) &#123; //默认情况下Spring Boot会在error/目录下去找视图，比如error/404.html或error/4xx String errorViewName = "error/" + viewName; //如果模板引擎可以解析就有模板引擎来解析 TemplateAvailabilityProvider provider = this.templateAvailabilityProviders.getProvider(errorViewName, this.applicationContext); if (provider != null) &#123; //模板引擎可用的情况下返回到errorViewName指定的视图地址 return new ModelAndView(errorViewName, model); &#125; //模板引擎不可用，就在静态资源文件夹下找errorViewName对应的页面 error/404.html return resolveResource(errorViewName, model); &#125; //从静态资源文件夹下面找错误页面 private ModelAndView resolveResource(String viewName, Map&lt;String, Object&gt; model) &#123; //遍历所有静态资源文件到的路径来看看有没有和viewName同名的视图名（网页名） for (String location : this.resourceProperties.getStaticLocations()) &#123; try &#123; Resource resource = this.applicationContext.getResource(location); resource = resource.createRelative(viewName + ".html"); if (resource.exists()) &#123; //如果有就返回该视图的ModelAndView return new ModelAndView(new HtmlResourceView(resource), model); &#125; &#125; catch (Exception ex) &#123; &#125; &#125; //没有就返回null return null; &#125;&#125; &nbsp;&nbsp;&nbsp;&nbsp;大致分析源码后可以总结Spring Boot对错误的处理流程如下：如果系统出现4xx或者5xx之类的错误，ErrorPageCustomizer就会生效（定制错误的响应规则），就会发出/error请求，然后就会被BasicErrorController处理并返回ModelAndView（网页）或者JSON（客户端）。 &nbsp;&nbsp; 使用Spring Boot默认的错误处理机制来处理我们程序中的错误情况&nbsp;&nbsp;&nbsp;&nbsp;通过分析源码我们可以发现，如果要使用Spring Boot默认的错误处理机制，我们可以把我们定制的错误页面放在/templates/error目录下的，交给模板引擎来处理；或者不使用模板引擎那就放在static/error目录下。并且给这些错误页面命名为错误码.html或4xx.html、5xx.html。Spring Boot就可以自动帮我们映射到错误页面。例如，处理404错误：在/templates/error目录下放404.html &nbsp;&nbsp;&nbsp;&nbsp;访问浏览器，在地址栏中随便输入一个地址让他发生404错误，结果来到了我们定制的404错误页面，而不是Spring Boot默认的那个难看的白板页面。 4xx.html 123456789101112131415161718192021&lt;!doctype html&gt;&lt;html lang="en"&gt; &lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="Generator" content="EditPlus®"&gt; &lt;meta name="Author" content=""&gt; &lt;meta name="Keywords" content=""&gt; &lt;meta name="Description" content=""&gt; &lt;title&gt;Document&lt;/title&gt; &lt;/head&gt; &lt;body&gt;&lt;main role="main" class="col-md-9 ml-sm-auto col-lg-10 pt-3 px-4"&gt; &lt;h1&gt;status:[[$&#123;status&#125;]]&lt;/h1&gt; &lt;h2&gt;timestamp:[[$&#123;timestamp&#125;]]&lt;/h2&gt; &lt;h2&gt;exception:[[$&#123;exception&#125;]]&lt;/h2&gt; &lt;h2&gt;message:[[$&#123;message&#125;]]&lt;/h2&gt; &lt;h2&gt;ext:[[$&#123;ext.code&#125;]]&lt;/h2&gt; &lt;h2&gt;ext:[[$&#123;ext.message&#125;]]&lt;/h2&gt;&lt;/main&gt; &lt;/body&gt;&lt;/html&gt; 测试结果： &nbsp;&nbsp; 定制自己的错误信息默认情况下，Spring Boot的错误页面中可以可得一下错误信息： 123456​timestamp：时间戳​status：状态码​error：错误提示exception：异常对象message：异常消息errors：JSR303数据校验的错误 第一种方式：使用Spring MVC的异常处理器12345678910111213@ControllerAdvicepublic class MyExceptionHandler &#123; @ResuestBody @ExceptionHandler(NullPointerException.class) public Map&lt;String,Object&gt; handleException(Exception e, HttpServletResponse response)&#123; Map&lt;String,Object&gt; map=new HashMap&lt;&gt;(); map.put("code",""); map.put("message",e.getMessage()); map.put("exception",e.getClass()); return map; &#125; &#125; 这样无论是浏览器还是别的客户端，只要出错了就全部返回的JSON数据。 ##### 第二种方式：转发到/error请求进行自适应效果处理 12345678910111213141516@ControllerAdvicepublic class MyExceptionHandler &#123; @ExceptionHandler(NullPointerException.class) public String handleException(Exception e,HttpServletResponse response, HttpServletRequest request)&#123; Map&lt;String,Object&gt; map=new HashMap&lt;&gt;(); //设置状态码【必须】 request.setAttribute("javax.servlet.error.status_code",500); map.put("code","null exception"); map.put("message",e.getMessage()); map.put("exception",e.getClass()); //转发到/error return "forward:/error"; &#125;&#125; 第三种方式：编写一个MyErrorAttributes继承自DefaultErrorAttributes重写其getErrorAttributes方法前两种虽然都可以解决错误，但是单当我们自己定义一个错误属性（比如上面的code属性）就没办法带到页面，因此我们设置的信息也就无法被带到页面显示。我们可以编写一个MyErrorAttributes继承自DefaultErrorAttributes重写其getErrorAttributes方法将我们的错误数据添加进去。 12345678910111213@Component //使用我们的ErrorAttributespublic class MyErrorAttributes extends DefaultErrorAttributes &#123; @Override public Map&lt;String, Object&gt; getErrorAttributes(WebRequest webRequest, boolean includeStackTrace) &#123; //得到原有的errorAttributes Map&lt;String,Object&gt; errorAttributes=super.getErrorAttributes(webRequest,includeStackTrace); errorAttributes.put("code","MyError"); errorAttributes.remove("exception"); errorAttributes.put("path",webRequest.getContextPath()); return errorAttributes; &#125;&#125; 最终的效果：响应是自适应的，以后可以通过定制ErrorAttributes改变需要返回的内容。]]></content>
      <categories>
        <category>Spring Boot框架</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot自动配置Spring MVC的原理]]></title>
    <url>%2F2019%2F08%2F29%2FSpringBootMVC%E8%87%AA%E5%8A%A8%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp; Spring MVC自动配置&nbsp;&nbsp;&nbsp;&nbsp;Spring Boot对Spring MVC自动配置的详细可以参考管方文档。Spring Boot为Spring MVC提供的AutoConfiguration适用于大多数应用场景，Spring Boot对Spring MVC做了以下默认的自动配置： 1.引入ContentNegotiatingViewResolver 和 BeanNameViewResolver 。 2.对静态资源的支持，包括对WebJars 的支持。 3.自动注册Converter，GenericConverter，Formatter。 4.对HttpMessageConverters 的支持。 5.自动注册MessageCodeResolver。 6.对静态index.html的支持。 7.对自定义Favicon的支持。 8.自动使用 ConfigurableWebBindingInitializer bean。 &nbsp;&nbsp;&nbsp;&nbsp;Spring Boot默认情况下是自动配置好Spring MVC的，可以直接使用，但是Spring Boot也支持我们修改Spring Boot对SpringMVC的配置。如果保留Spring Boot MVC特性，我们只需添加其他的MVC配置（拦截器，格式化处理器，视图控制器等）。我们可以添加自己的WebMvcConfigurerAdapter 类型的@Configuration类（配置类），而不需要注解@EnableWebMvc。如果希望使用自定义的RequestMappingHandlerMapping，RequestMappingHandlerAdapter，或ExceptionHandlerExceptionResolver，我们可以声明一个WebMvcRegistrationsAdapter实例提供这些组件。 &nbsp;&nbsp;&nbsp;&nbsp;但是如果想全面控制Spring MVC，我们可以添加自己的@Configuration类，并使用@EnableWebMvc注解。这样Spring Boot就不会对MVC进行配置了。然后我们就可以像刚开始使用Spring MVC那样对他进行配置。 &nbsp;&nbsp;Spring MVC自动配置原理细节&nbsp;&nbsp;&nbsp;&nbsp;Spring Boot对Spring MVC的自动配置主要是通过WebMvcAutoConfiguration这个类实现的，接下来我们就结合这个类来简单分析一下自动配置的细节。 ContentNegotiatingViewResolver 和 BeanNameViewResolver &nbsp;&nbsp;&nbsp;&nbsp;这两个一听名字就知道是和视图解析器有关，也确实是这样的，他们自动配置了ViewReslover，然后由ViewReslover得到View对象，View对象调用他的render方法渲染页面等等。其中BeanNameViewResolver 就是SpringMVC中的一个视图解析器，他可以通过视图名来获得视图解析器，而ContentNegotiatingViewResolver的作用就是组合所有的视图解析器，下面他们的源码： 12345678910111213141516171819202122232425262728293031@Configuration@ConditionalOnWebApplication(type = Type.SERVLET)@ConditionalOnClass(&#123; Servlet.class, DispatcherServlet.class, WebMvcConfigurer.class &#125;)@ConditionalOnMissingBean(WebMvcConfigurationSupport.class)@AutoConfigureOrder(Ordered.HIGHEST_PRECEDENCE + 10)@AutoConfigureAfter(&#123; DispatcherServletAutoConfiguration.class, ValidationAutoConfiguration.class &#125;)public class WebMvcAutoConfiguration &#123; @Bean @ConditionalOnBean(View.class) @ConditionalOnMissingBean //只会创建一个 public BeanNameViewResolver beanNameViewResolver() &#123; BeanNameViewResolver resolver = new BeanNameViewResolver(); //给这个视图解析器设置执行顺序order，他的级别是很低的 resolver.setOrder(Ordered.LOWEST_PRECEDENCE - 10); return resolver; &#125; @Bean @ConditionalOnBean(ViewResolver.class) @ConditionalOnMissingBean(name = "viewResolver", value = ContentNegotiatingViewResolver.class) public ContentNegotiatingViewResolver viewResolver(BeanFactory beanFactory) &#123; ContentNegotiatingViewResolver resolver = new ContentNegotiatingViewResolver(); resolver.setContentNegotiationManager(beanFactory.getBean(ContentNegotiationManager.class)); // ContentNegotiatingViewResolver uses all the other view resolvers to locate // a view so it should have a high precedence resolver.setOrder(Ordered.HIGHEST_PRECEDENCE); return resolver; &#125;&#125; 问题：ContentNegotiatingViewResolver是如何组合所有视图解析器的？ 1234567891011121314151617181920212223242526272829303132333435public class ContentNegotiatingViewResolver extends WebApplicationObjectSupport implements ViewResolver, Ordered, InitializingBean &#123; @Nullable private List&lt;ViewResolver&gt; viewResolvers; @Override protected void initServletContext(ServletContext servletContext) &#123; Collection&lt;ViewResolver&gt; matchingBeans = BeanFactoryUtils.beansOfTypeIncludingAncestors(obtainApplicationContext(), ViewResolver.class).values(); if (this.viewResolvers == null) &#123; this.viewResolvers = new ArrayList&lt;&gt;(matchingBeans.size()); //遍历BeanFactoryutils中的视图解析器 for (ViewResolver viewResolver : matchingBeans) &#123; if (this != viewResolver) &#123; //如果没有这个视图解析器，那就把它加入 this.viewResolvers.add(viewResolver); &#125; &#125; &#125;else &#123; for (int i = 0; i &lt; this.viewResolvers.size(); i++) &#123; ViewResolver vr = this.viewResolvers.get(i); if (matchingBeans.contains(vr)) &#123; continue; &#125; String name = vr.getClass().getName() + i; obtainApplicationContext().getAutowireCapableBeanFactory().initializeBean(vr, name); &#125; &#125; AnnotationAwareOrderComparator.sort(this.viewResolvers); this.cnmFactoryBean.setServletContext(servletContext); &#125;&#125; 因此，我们可以实现自己的视图解析器，然后ContentNegotiatingViewResolver把它注册到容器中。定制自己的视图解析器我们可以在启动类中实现ViewResolver接口，编写我们自己的视图解析器，然使用@Bean标签配置给IOC容器。 123456789101112131415161718192021222324252627282930313233343536package com.xust.iot;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.annotation.Bean;import org.springframework.web.servlet.View;import org.springframework.web.servlet.ViewResolver;import java.util.Locale;@SpringBootApplicationpublic class SpringBootWebApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringBootWebApplication.class, args); &#125; //直接在容器中添加我们的视图解析器 @Bean public ViewResolver myViewResolver()&#123; return new MyViewResolver(); &#125; /** * 实现ViewResolver */ public static class MyViewResolver implements ViewResolver&#123; @Override public View resolveViewName(String viewName, Locale locale) throws Exception &#123; //在这里面写我们自己的视图处理逻辑 return null; &#125; &#125;&#125; Converter，GenericConverter，Formatter 这些功能在Spring Boot中也有默认的自动配置，这里我们要了解的是如何扩展配置Converter和Formatter。源码： 1234567891011121314151617181920@Bean@ConditionalOnProperty(prefix = "spring.mvc", name = "date-format")//在文件中配置日期格式化的规则public Formatter&lt;Date&gt; dateFormatter() &#123; return new DateFormatter(this.mvcProperties.getDateFormat());//日期格式化组件&#125;//添加格式化组件@Overridepublic void addFormatters(FormatterRegistry registry) &#123; for (Converter&lt;?, ?&gt; converter : getBeansOfType(Converter.class)) &#123; registry.addConverter(converter); &#125; for (GenericConverter converter : getBeansOfType(GenericConverter.class)) &#123; registry.addConverter(converter); &#125; for (Formatter&lt;?&gt; formatter : getBeansOfType(Formatter.class)) &#123; registry.addFormatter(formatter); &#125;&#125; 我们也可以定制自己的转换器 12345678910111213141516171819202122232425262728293031323334package com.xust.iot;import com.xust.iot.bean.User;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;import org.springframework.context.annotation.Bean;import org.springframework.core.convert.converter.Converter;import org.springframework.web.servlet.View;import org.springframework.web.servlet.ViewResolver;import java.util.Locale;@SpringBootApplicationpublic class SpringBootWebApplication &#123; public static void main(String[] args) &#123; SpringApplication.run(SpringBootWebApplication.class, args); &#125; @Bean public Converter&lt;?,?&gt; userToStringConverter()&#123; return new UserToStringConverter(); &#125; //把User对象转换成String public static class UserToStringConverter implements Converter&lt;User,String&gt;&#123; @Override public String convert(User source) &#123; //写我们自己的转换规则 return null; &#125; &#125;&#125; HttpMessageConverters &nbsp;&nbsp;&nbsp;&nbsp;Spring MVC 使用HttpMessageConverter 接口转换HTTP 请求和响应，合适的默认配置可以开箱即用，例如对象自动转换为JSON（使用Jackson库）或XML（如果Jackson XML扩展可用，否则使用JAXB），字符串默认使用UTF-8编码。可以使用Spring Boot 的HttpMessageConverters 类添加或自定义转换类： 123456789101112131415161718192021222324@Configurationpublic class FastJsonHttpMessageConvertersConfig extends WebMvcConfigurerAdapter &#123; @Bean public FastJsonConfig fastJsonConfig() &#123; FastJsonConfig fastJsonConfig = new FastJsonConfig(); SerializerFeature writeMapNullValue = SerializerFeature.WriteMapNullValue; SerializerFeature WriteNullStringAsEmpty = SerializerFeature.WriteNullStringAsEmpty; SerializerFeature WriteNullNumberAsZero = SerializerFeature.WriteNullNumberAsZero; SerializerFeature WriteNullListAsEmpty = SerializerFeature.WriteNullListAsEmpty; fastJsonConfig.setSerializerFeatures(writeMapNullValue, WriteNullStringAsEmpty, WriteNullNumberAsZero, WriteNullListAsEmpty); return fastJsonConfig; &#125; @Bean public HttpMessageConverters fastJsonHttpMessageConverters( @Qualifier("fastJsonConfig") FastJsonConfig fastJsonConfig) &#123; FastJsonHttpMessageConverter4 fastConverter = new FastJsonHttpMessageConverter4(); fastConverter.setFastJsonConfig(fastJsonConfig); HttpMessageConverter&lt;?&gt; converter = fastConverter; return new HttpMessageConverters(converter); &#125;&#125; &nbsp;&nbsp;扩展Spring Boot对Spring MVC的配置&nbsp;&nbsp;&nbsp;&nbsp;想要扩展Spring Boot的MVC功能，我们要WebMvcConfigurer接口，但是这样太麻烦了，因此Spring Boot提供了一个适配器类WebMvcConfigurerAdapter，它里面全部是一些空方法，我们可以继承WebMvcConfigurerAdapter类，然后我们只需要按照我们的需要重写里面的方法就好了。（注：Spring Boot 2.0以后官方废除了WebMvcConfigurerAdapter类，而是推荐我们直接实现WebMvcConfigurer接口。） 12345678910111213141516171819202122232425262728293031323334353637package com.xust.iot.configurer;import org.springframework.context.annotation.Configuration;import org.springframework.web.servlet.HandlerExceptionResolver;import org.springframework.web.servlet.config.annotation.InterceptorRegistry;import org.springframework.web.servlet.config.annotation.ViewControllerRegistry;import org.springframework.web.servlet.config.annotation.WebMvcConfigurerAdapter;import java.util.List;@Configurationpublic class ApplicationMVCConfig extends WebMvcConfigurerAdapter &#123; //在这里可以配置拦截器，文件上传解析器，异常解析器....只要是在原本spring-mvc.xml文件中可以配置的在这里都可以配置 //视图映射 @Override public void addViewControllers(ViewControllerRegistry registry) &#123; //相当于&lt;mvc:view-controller path="/hello" view="success.html"/&gt; registry.addViewController("/hello").setViewName("success"); &#125; /** * 拦截器 拦截hello请求 * @param registry */ @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(new MyInterceptor()).addPathPatterns("/hello"); &#125; //异常解析处理器 @Override public void configureHandlerExceptionResolvers(List&lt;HandlerExceptionResolver&gt; exceptionResolvers) &#123; exceptionResolvers.add(new MyExceptionHandler()) ; &#125;&#125; &nbsp;&nbsp;全面接管Spring Boot对Spring MVC的自动配置&nbsp;&nbsp;&nbsp;&nbsp;官网中的一句话：”If you want to take complete control of Spring MVC, you can add your own @Configuration annotated with @EnableWebMvc.“意思就是我们可以配置类上加上EnableWebMvc来全面接管Spring MVC，这样一来Spring Boot就不会对Spring MVC进行配置了，一切都需要我们来配置。 123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.xust.iot.configurer;import org.springframework.context.annotation.Configuration;import org.springframework.web.servlet.config.annotation.*;import org.springframework.web.servlet.view.InternalResourceViewResolver;@EnableWebMvc@Configurationpublic class ApplicationMVCConfig implements WebMvcConfigurer &#123; //在这里可以配置拦截器，文件上传解析器，异常解析器....只要是在原本spring-mvc.xml文件中可以配置的在这里都可以配置 //配置视图解析器 @Override public void configureViewResolvers(ViewResolverRegistry registry) &#123; InternalResourceViewResolver resourceViewResolver=new InternalResourceViewResolver(); resourceViewResolver.setPrefix("/**"); resourceViewResolver.setSuffix("/.html"); registry.viewResolver(resourceViewResolver); registry.order(10); &#125; @Override public void configureDefaultServletHandling(DefaultServletHandlerConfigurer configurer) &#123; configurer.enable(); &#125; @Override public void addViewControllers(ViewControllerRegistry registry) &#123; registry.addViewController("/hello").setViewName("success.html"); &#125; /** * 拦截器 拦截hello请求 * @param registry */ @Override public void addInterceptors(InterceptorRegistry registry) &#123; registry.addInterceptor(new MyInterceptor()).addPathPatterns("/hello"); &#125; &#125;]]></content>
      <categories>
        <category>Spring Boot框架</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot—Thymeleaf模板引擎]]></title>
    <url>%2F2019%2F08%2F28%2FSpring%20Boot%E2%80%94Thymeleaf%E6%A8%A1%E6%9D%BF%E5%BC%95%E6%93%8E%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp; 引言&nbsp;&nbsp;&nbsp;&nbsp;在做WEB开发的时候，我们不可避免的要在前端页面之间进行跳转，中间进行数据的查询等等操作。我们在使用Spring Boot之前包括我在内其实大部分都是用的是JSP页面，可以说使用的已经很熟悉。但是我们在使用Spring Boot开发框架以后我们会发现一个致命的问题，就是SpringBoot对Jsp的支持可以说是惨不忍睹，因此官方推荐我们使用Thymeleaf模板引擎来解决问题。目前而言，当然模板引擎有很多，比如Velocity、Freemarker、等等，但是我这一直感觉thymeleaf相对于其他的来说好用的还是不少的。在这里我们就来了解一下thymeleaf这个模板引擎的用法！ &nbsp;&nbsp; 什么是模板引擎？&nbsp;&nbsp;&nbsp;&nbsp;模板引擎是为了使用户界面与业务数据（内容）分离而产生的，它可以生成特定格式的文档。用于网站的模板引擎（比如Thymeleaf模板引擎）就是将模板文件和数据通过模板引擎生成一个HTML代码。 简单说， Thymeleaf 是一个跟 Velocity、FreeMarker 类似的模板引擎，它可以完全替代 JSP 。 &nbsp;&nbsp; Spring Boot中使用Thymeleaf模板引擎使用的方法很简单，首先在pom.xml文件中引入thymeleaf的starter 引入Thymeleaf1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-thymeleaf&lt;/artifactId&gt;&lt;/dependency&gt; 一般Spring Boot引入的都是依赖文件的最新的版本，如果发现不是最新的依赖版本或者你想更改依赖的版本，可以在&lt;properties&gt;标签中修改，比如修改thymeleaf的版本为3.0.10版本 123456&lt;properties&gt; &lt;!--切换thymeleaf版本--&gt; &lt;thymeleaf.version&gt;3.0.10.RELEASE&lt;/thymeleaf.version&gt; &lt;!-- 布局功能的支持程序 thymeleaf3主程序 layout2以上版本 --&gt; &lt;thymeleaf-layout-dialect.version&gt;2.2.2&lt;/thymeleaf-layout-dialect.version&gt;&lt;/properties&gt; 使用Thymeleaf&nbsp;&nbsp;&nbsp;&nbsp;引入Thymeleaf的依赖后，我们就可以使用了。在学习Spring Boot时无论是啥新东西，我们都可以打开XxxxAutoConfigration和XxxxProperties，从中我们可以基本了解Spring Boot对这个东西的默认配置。好了我们来看看Thymeleaf的配置类 当然，我们也可以在Spring Boot的主配置文件中进行thymeleaf相关配置： 12345678#thymeleaf有关设置spring.thymeleaf.prefix=classpath:/templatesspring.thymeleaf.suffix=.htmlspring.thymeleaf.mode=HTML5spring.thymeleaf.encoding=UTF-8spring.thymeleaf.servlet.content-type=text/html#关闭模板缓存，避免更新无效spring.thymeleaf.cache=false 尝试使用1.在控制层写一个跳转到hello.html页面的处理器方法 123456789101112131415161718package com.xust.iot.controller;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.ResponseBody;import java.util.Map;@Controllerpublic class HelloController &#123; @RequestMapping("/hello") public String toHello(Model model)&#123; model.addAttribute("msg","Hello Thymeleaf!"); return "hello"; &#125;&#125; 2.在html页面中导入thymeleaf名称空间，名称空间的导入不是必须的，但是导入后可以有提示，提示还是挺好用的。 12&lt;html lang="en" xmlns="http://www.w3.org/1999/xhtml" xmlns:th="http://www.thymeleaf.org"&gt; 3.然后在页面只用Thymeleaf语法获取服务器响应的数据hello.html 123456789101112&lt;!DOCTYPE html&gt;&lt;html lang="en" xmlns="http://www.w3.org/1999/xhtml" xmlns:th="http://www.thymeleaf.org"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;hello&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;!--thymeleaf中的th:text 作用是将等号后面值写到标签体内，会覆盖原有的值--&gt;&lt;h1 th:text="$&#123;msg&#125;"&gt;这里显示欢迎信息&lt;/h1&gt;&lt;/body&gt;&lt;/html&gt; 测试结果： &nbsp;&nbsp; Thymelaf模板引擎的基本语法常用th属性下面列举一些常用的th属性，全部的属性还请参考官方手册。th属性执行的优先级从1~8，数字越低优先级越高。 1、th:text：设置当前元素的文本内容，相同功能的还用th:utext,两者的区别是前者会转义特殊字符，后者不会。order=7 2、th:value：设置当前元素的value值，类似修改指定属性的还有th:src、th:herf,order=6 3、th:each：遍历循环元素，和th:value或th:value一起使用。order=2 4、th:if：条件判断，类似的还有th:unless 、th:switch、th:case 。order=3 5、th:insert：代码块引入，类似的还有th:replace、th:include，三者的区别较大，若使用不恰当会破坏html结构，常用于公共代码块提取的场景。优先级最高：order=1 6、th:fragment：定义代码块，方便被th:insert、th:replace、th:include引用。优先级最低：order=8 7、th:object：声明变量，一般和*{}一起配合使用，达到偷懒的效果。优先级一般：order=4 8、th:attr：修改任意属性，实际开发中用的较少，因为有丰富的其他th属性帮忙，类似的还有th:attrappend，th:attrprepend。优先级一般：order=5 Thymeleaf标准表达式语法 ${.....} 变量表达式（Variable Expressions） #{.....} 消息表达式（Message Expressions） @{.....} 链接表达式（Link URL Expressions） ~{.....} 代码块表达式（Fragment Expressions） *{.....} 选择变量表达式（Selection Variable Expressions） ${…}变量表达式Thymeleaf的变量表达式使用的其实是OGNL表达式，这使得变量表达式的功能非常丰富。 1、可以获取对象的属性、调用方法等(OGNL可以做的事他都可以做) 2、可以使用内置对象。官方手册上给的可以使用的内置对象如下： 12345678#ctx : the context object. 上下文对象#vars: the context variables. 上下文变量 #locale : the context locale. 本地区域信息//下面的内置对象下web环境下才有效果的#request : (only in Web Contexts) the HttpServletRequest object. request对象#response : (only in Web Contexts) the HttpServletResponse object. response对象 #session : (only in Web Contexts) the HttpSession object. session对象#servletContext : (only in Web Contexts)the ServletContext object. ServletContext对象 3、可以使用一些内置的工具对象(方法)。 123456789101112131415#execInfo : 正在处理的模板信息#messages : 获取外部信息的内部变量的一个实用方法，同时也可以用#&#123;...&#125;获取#uris : 针对URL或URI进行一些转码的方法#conversions : 根据配置执行一些转换方法#dates : java.util.Date 的对象#calendars : java.util.Calendar 的对象#numbers : 数值格式化方法#strings : 字符串格式化方法，常用的Java方法它都有#objects : java中Object类的一些方法#bools : 布尔方法，常用的方法有：isTrue，isFalse等#arrays : 数组方法，常用的方法有：toArray，length，isEmpty，contains，containsAll等#lists ，#sets: 集合方法，常用的方法有：toList，size，isEmpty，contains，containsAll，sort等#maps : map对象方法，常用的方法有：size，isEmpty，containsKey，containsValue等#aggregates : 在数组或集合中创建聚合的一些实用方法.#ids : 用于处理可能重复的标识属性的使用方法，例如，作为迭代的变量。 *{…}选择表达式对于变量我们还可以使用*{...}来处理，它和${}在功能上是一样的。但是有一个重要的区别：*{}评估所选对象上的表达式而不是整个上下文。 也就是说，只要没有选定的对象，${}和*{}语法就会完全相同。下面是官网给的一个例子，可以说明这个问题： #{…}消息表达式用于处理国际化信息,下面是一个支持中英文的国际化登录页面 1234567891011121314151617181920212223242526272829303132333435363738&lt;!DOCTYPE html&gt;&lt;html lang="en" xmlns="http://www.w3.org/1999/xhtml" xmlns:th="http://www.thymeleaf.org"&gt; &lt;head&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"&gt; &lt;meta name="description" content=""&gt; &lt;meta name="author" content=""&gt; &lt;title&gt;[[#&#123;login.topic&#125;]]&lt;/title&gt; &lt;!-- Bootstrap core CSS --&gt; &lt;link rel="shortcut icon" th:href="@&#123;/favicon.ico&#125;"/&gt; &lt;link rel="bookmark" th:href="@&#123;/favicon.ico&#125;"/&gt; &lt;link href="assert/css/bootstrap.min.css" th:href="@&#123;/webjars/bootstrap/4.0.0/css/bootstrap.css&#125;" rel="stylesheet"&gt; &lt;link th:href="@&#123;/webjars/jquery/3.3.1-1/jquery.js&#125;"&gt; &lt;link href="assert/css/signin.css" th:href="@&#123;/assert/css/signin.css&#125;" rel="stylesheet"&gt; &lt;/head&gt; &lt;body class="text-center"&gt; &lt;form class="form-signin" action="dashboard" th:action="@&#123;/checkLogin&#125;" method="post"&gt; &lt;img class="mb-4" th:src="@&#123;/assert/img/bootstrap-solid.svg&#125;" alt="" width="72" height="72"&gt; &lt;h1 class="h3 mb-3 font-weight-normal" th:text="#&#123;login.topic&#125;"&gt;Please sign in&lt;/h1&gt; &lt;p style="color: red" th:text="$&#123;msg&#125;" th:if="$&#123;not #strings.isEmpty(msg)&#125;"&gt;&lt;/p&gt; &lt;label class="sr-only" th:text="#&#123;login.username&#125;"&gt;Username&lt;/label&gt; &lt;input type="text" name="username" class="form-control" placeholder="Username" th:placeholder="#&#123;login.username&#125;" required="" autofocus=""&gt; &lt;label class="sr-only"&gt;Password&lt;/label&gt; &lt;input type="password" name="password" class="form-control" placeholder="Password" th:placeholder="#&#123;login.password&#125;" required=""&gt; &lt;div class="checkbox mb-3"&gt; &lt;label&gt; &lt;input type="checkbox" value="remember-me"/&gt; [[#&#123;login.remeberme&#125;]] &lt;/label&gt; &lt;/div&gt; &lt;button class="btn btn-lg btn-primary btn-block" type="submit" th:text="#&#123;login.btn&#125;"&gt;Sign in&lt;/button&gt; &lt;p class="mt-5 mb-3 text-muted"&gt;© 2017-2018&lt;/p&gt; &lt;a class="btn btn-sm" th:href="@&#123;/index(locale=zh_CN)&#125;"&gt;中文&lt;/a&gt; &lt;a class="btn btn-sm" th:href="@&#123;/index(locale=en_US)&#125;"&gt;English&lt;/a&gt; &lt;/form&gt; &lt;/body&gt;&lt;/html&gt; 效果： @{…}链接表达式Thymeleaf中专门用于定义超链接的表达式。配合Thymeleaf中的th:href、th:src等凡是可以写链接、路径的标签一起使用(前缀th:)，下面是几个例子： 12345678910111213&lt;!--引入资源文件--&gt;&lt;link rel="shortcut icon" th:href="@&#123;/favicon.ico&#125;"/&gt;&lt;link rel="bookmark" th:href="@&#123;/favicon.ico&#125;"/&gt;&lt;link href="assert/css/bootstrap.min.css" th:href="@&#123;/webjars/bootstrap/4.0.0/css/bootstrap.css&#125;" rel="stylesheet"&gt;&lt;script type="text/javascript" src="assert/js/popper.min.js" th:src="@&#123;assert/js/popper.min.js&#125;"&gt;&lt;/script&gt;&lt;!--路径--&gt;&lt;a href="#" th:href="@&#123;/emp/&#125;+$&#123;emp.id&#125;" class="btn btn-sm btn-primary"&gt;编辑&lt;/a&gt;&lt;a href="/emp/del/" th:href="@&#123;/emp/del/&#125;+$&#123;emp.id&#125;" th:value="$&#123;emp.id&#125;" class="btn btn-sm btn-danger" &gt;删除&lt;/a&gt; &lt;!--表单--&gt;&lt;form action="/emp/save" th:action="@&#123;/emp/save&#125;" method="post" role="form"&gt; &lt;input type="hidden" name="id" th:value="$&#123;emp.getId()&#125;"/&gt; ~{…}代码块表达式Thymeleaf中专门用于引用代码片段的表达式。经常配合th:fragment和th:insert 、th:replace、th:include这四个属性使用（后三个属性中选一种，效果差不多，但是还是有细微的差别），例如： 12345678910&lt;!--使用th:fragement属性抽取公共页面：th:fragement="片段名"--&gt;&lt;nav class="navbar navbar-dark sticky-top bg-dark flex-md-nowrap p-0" th:fragment="topbar"&gt; &lt;a class="navbar-brand col-sm-3 col-md-2 mr-0 " style="align-content: center" href="#" th:href="@&#123;/main&#125;" &gt;[[$&#123;session.loggedUser&#125;]]&lt;/a&gt; &lt;input class="form-control form-control-dark w-100" type="text" placeholder="Search" th:placeholder="#&#123;main.search&#125;" aria-label="Search"&gt; &lt;ul class="navbar-nav px-3"&gt; &lt;li class="nav-item text-nowrap"&gt; &lt;a class="nav-link" href="#" th:href="@&#123;/signout&#125;" th:text="#&#123;main.logout&#125;"&gt;退出&lt;/a&gt; &lt;/li&gt; &lt;/ul&gt;&lt;/nav&gt; 在别的页面中就可以使用th:insert 、th:replace、th:include引入公共片段引入的就要用到~{} 表达式，具体的语法有两种： ~{templatename::selector}====&gt;模板名::选择器 ~{templatename::fragmentname}====&gt;模板名::片段名 其中模板名就是你引用的片段在templates/目录下的HTML文件名 12345678&lt;!--使用th:insert--&gt;&lt;div th:insert="~&#123;template :: topbar&#125;"&gt;&lt;/div&gt;&lt;!--使用th:replace--&gt;&lt;div th:replace="~&#123;template&#125; :: topbar"&gt;&lt;/div&gt;&lt;!--使用th:inclue--&gt;&lt;div th:include="~&#123;template :: topbar&#125;"&gt;&lt;/div&gt; 使用th:insert 、th:replace、th:include都可以引入公共的代码片段，但是他们有一点细微的差别th:insert：按上面的代码来说就是会在&lt;div&gt;&lt;/div&gt;内把整个公共片段插入，这样一来原有的片段就会被套在&lt;div&gt;&lt;/div&gt;内部th:replace：在声明使用的地方替换原有的标签为要引入的代码片段（就是把原生的代码片段发在要插入的地方）th:include：将被引入的片段的内容包含进这个标签中]]></content>
      <categories>
        <category>Spring Boot框架</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot 对静态文件的默认映射规则]]></title>
    <url>%2F2019%2F08%2F28%2FSpringBoot%E6%98%A0%E5%B0%84%E6%98%A0%E5%B0%84%E9%9D%99%E6%80%81%E6%96%87%E4%BB%B6%E7%9A%84%E8%A7%84%E5%88%99%2F</url>
    <content type="text"><![CDATA[Webjars(官网：http://www.webjars.org/)​ webjars：以jar包的方式引入静态资源；Spring Boot中所有 /webjars/** ，都会去 classpath:/META-INF/resources/webjars/ 找资源。推荐使用Webjars的三大理由： 将静态资源版本化，更利于升级和维护。 剥离静态资源，提高编译速度和打包效率。 实现资源共享，有利于统一前端开发。 使用方法首先来看一下源码是如何以jar包的方式引入静态资源的： 1234567891011121314151617181920@Overridepublic void addResourceHandlers(ResourceHandlerRegistry registry) &#123; if (!this.resourceProperties.isAddMappings()) &#123; logger.debug("Default resource handling disabled"); return; &#125; Duration cachePeriod = this.resourceProperties.getCache().getPeriod(); CacheControl cacheControl = this.resourceProperties.getCache().getCachecontrol().toHttpCacheControl(); if (!registry.hasMappingForPattern("/webjars/**")) &#123; customizeResourceHandlerRegistration(registry.addResourceHandler("/webjars/**") .addResourceLocations("classpath:/META-INF/resources/webjars/") .setCachePeriod(getSeconds(cachePeriod)).setCacheControl(cacheControl)); &#125; String staticPathPattern = this.mvcProperties.getStaticPathPattern(); if (!registry.hasMappingForPattern(staticPathPattern)) &#123; customizeResourceHandlerRegistration(registry.addResourceHandler(staticPathPattern) .addResourceLocations(getResourceLocations(this.resourceProperties.getStaticLocations())) .setCachePeriod(getSeconds(cachePeriod)).setCacheControl(cacheControl)); &#125;&#125; 原来是直接到jar包类路径/META-INF/resources/webjars/下来找静态资源的。使用方法很简单，只用引入Maven依赖就可以了。在Webjars官网找到需要的依赖，例如在pom.xml中引入jQuery和BootStrap 12345678910111213&lt;!--引入jquery--&gt;&lt;dependency&gt; &lt;groupId&gt;org.webjars&lt;/groupId&gt; &lt;artifactId&gt;jquery&lt;/artifactId&gt; &lt;version&gt;3.3.1-1&lt;/version&gt;&lt;/dependency&gt;&lt;!--引入BootStrap--&gt;&lt;dependency&gt; &lt;groupId&gt;org.webjars&lt;/groupId&gt; &lt;artifactId&gt;bootstrap&lt;/artifactId&gt; &lt;version&gt;4.0.0&lt;/version&gt;&lt;/dependency&gt; 引入之后我们可以尝试访问一下BootStrap里面的东西，在地址栏输入localhost/webjars/bootstrap/4.0.0/webjars-requirejs.js，如果能看到下面的页面那就没问题。 引入自己的静态资源文件自己的资源文件可以放在一下几个地方： 123456静态资源文件夹&quot;classpath:/META-INF/resources/&quot;, &quot;classpath:/resources/&quot;,&quot;classpath:/static/&quot;, //系统默认生成的&quot;classpath:/public/&quot; &quot;/&quot;：当前项目的根路径下 WebMvcAutoConfiguration.java 123456789@Beanpublic WelcomePageHandlerMapping welcomePageHandlerMapping(ApplicationContext applicationContext) &#123; //设置欢迎页（首页）的构造方法中大有乾坤，我们可以点进去看看 WelcomePageHandlerMapping welcomePageHandlerMapping = new WelcomePageHandlerMapping( new TemplateAvailabilityProviders(applicationContext), applicationContext, getWelcomePage(), this.mvcProperties.getStaticPathPattern()); welcomePageHandlerMapping.setInterceptors(getInterceptors()); return welcomePageHandlerMapping;&#125; WelcomePageHandlerMapping.java 12345678910111213//WelcomePageHandlerMapping唯一的一个构造方法WelcomePageHandlerMapping(TemplateAvailabilityProviders templateAvailabilityProviders, ApplicationContext applicationContext, Optional&lt;Resource&gt; welcomePage, String staticPathPattern) &#123; if (welcomePage.isPresent() &amp;&amp; "/**".equals(staticPathPattern)) &#123; //检查发现欢迎页面存在兵并且在静态资源文件夹下，默认就会forward到index.html页面 logger.info("Adding welcome page: " + welcomePage.get()); setRootViewName("forward:index.html"); &#125;else if (welcomeTemplateExists(templateAvailabilityProviders, applicationContext)) &#123; //检查发现欢迎页面没有，那就设置欢迎页面的视图名是index logger.info("Adding welcome page template: index"); setRootViewName("index"); &#125;&#125; 简单分析源码可以知道，Spring Boot欢迎页面的处理机制是如果没有欢迎页面那就默认叫index.html，如果有并且在静态资源文件夹中，那就以forward的方式请求转发过去。根据上面的分析，设置首页就简单了，把首页起名为index.html，然后把它放在任何一个静态文件夹中就可以不被映射到，之后直接访问localhost:8080/就可以访问到首页把静态资源放在classpath:/public/ 来看看效果 给网页设置小图标先来看看源码是如何做的。 1234567@Beanpublic SimpleUrlHandlerMapping faviconHandlerMapping() &#123; SimpleUrlHandlerMapping mapping = new SimpleUrlHandlerMapping(); mapping.setOrder(Ordered.HIGHEST_PRECEDENCE + 1); mapping.setUrlMap(Collections.singletonMap("**/favicon.ico", faviconRequestHandler())); return mapping;&#125; 从源码的倒数第二行可以看到，他会在映射到**/favicon.ico这个目录，那就简单了，我们只需要只需要将把我们的图标命名为favicon.ico，然后放在任一静态资源文件夹下即可。在classpath:/public/放一个我自己的图标 启动来看看效果： 很nice！我们的小图标被用上了。 使用spring.resources.static-locations改变静态资源文件夹在Spring Boot的主配置文件中，我们可以使用spring.resources.static-locations来指定静态资源文件的位置，可以指定多个，多个路径之间用”,”（逗号）隔开。需要注意的是，我们这么指定后，那些默认的资源文件夹就会失效。 123debug=trueserver.port=80spring.resources.static-locations=classpath:/webapps,classpath:/pages 在resources下新建webapps文件夹，把静态资源放在里面。 启动来看看效果：]]></content>
      <categories>
        <category>Spring Boot框架</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot与日志]]></title>
    <url>%2F2019%2F08%2F27%2FSpringBoot%E6%97%A5%E5%BF%97%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp; 日志框架分类目前，日志框架有很多，例如：JUL（java.util.logging）、JCL（Apache Jakarta Commons Logging）、Log4j、Log4j2、LogBack、SLF4J、jboss-logging等等。 日志门面日志实现 JCL（Apache Jakarta Commons Logging）SLF4J(Simple Logging Facade for Java)jboss-loggingLog4jJUL(java.util.logging)Log4j2Logback &nbsp;&nbsp;&nbsp;&nbsp;日志门面就是日志的抽象层，里面只是定义了日志的规范，日志实现就是来具体实现日志门面的。日志门面中这里重点来介绍一下SLF4J。 SLF4J&nbsp;&nbsp;&nbsp;&nbsp;slf4j是对所有日志框架制定的一种规范、标准、接口，并不是一个框架的具体的实现。因为接口并不能独立使用，需要和具体的日志框架实现配合使用（如log4j、logback）。 那么问题来了，我们有了日志的实现，为什么还需要日志门面（日志抽象层）？ &nbsp;&nbsp;&nbsp;&nbsp;我们都知道使用一个接口实际上使用的是这个接口的实现类，那好了，我只要在程序中使用接口中的API来操作日志，然后导入实现了这个日志接口的日志实现类，程序就可以正常的记录日志；下次我们导入了另一套基于这个接口实现的日志实现类，不用改我们在程序中写的任何日志代码程序还是可以正常的记录日志。原理很简单，日志实现类实现了日志接口的规范。因此这个问题的回答总结为一句话：使用日志框架接口更便于更换为其他的日志框架。 &nbsp;&nbsp;&nbsp;&nbsp;log4j、logback、log4j2都有SLF4J的具体实现，他们既可以单独使用，也可以结合SLF4J框架使用。 相关的Maven依赖写法： 1234567891011&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-simple&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; Log4J&nbsp;&nbsp;&nbsp;&nbsp;log4j是apache实现的一个开源日志组件。通过使用log4j，我们可以控制日志信息输送的目的地是控制台、文件、GUI组件、甚至是套接口服务器、NT的事件记录器、UNIX Syslog守护进程等；我们也可以控制每一条日志的输出格式；通过定义每一条日志信息的级别，我们能够更加细致地控制日志的生成过程。最令人感兴趣的就是，这些可以通过一个配置文件来灵活地进行配置，而不需要修改应用的代码。然而log4j已经很多年没有更新过了，小项目可以使用，大项目还是算了吧。 相关的Maven依赖写法： 123456789101112&lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.25&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; Logback&nbsp;&nbsp;&nbsp;&nbsp;logback同样是由log4j的作者设计完成的，拥有更好的特性，是用来取代log4j的一个日志框架，是slf4j的原生实现，所以logback与slf4j的结合最好。&nbsp;&nbsp;&nbsp;&nbsp;Logback，一个“可靠、通用、快速而又灵活的Java日志框架”。logback当前分成三个模块：logback-core，logback- classic和logback-access。logback-core是其它两个模块的基础模块。logback-classic是log4j的一个改良版本。此外logback-classic完整实现SLF4J API使你可以很方便地更换成其它日志系统如log4j或JDK Logging。logback-access访问模块与Servlet容器集成提供通过Http来访问日志的功能。 因此在log4j和logback之间选择的话，我们应该选择更强大的logback。理由如下： 1. logback比log4j要快大约10倍，而且消耗更少的内存。 2. logback-classic模块直接实现了SLF4J的接口，所以我们迁移到logback几乎是零开销的。 3. logback不仅支持xml格式的配置文件，还支持groovy格式的配置文件。相比之下，Groovy风格的配置文件更加直观，简洁。 4. logback-classic能够检测到配置文件的更新，并且自动重新加载配置文件。 5. logback能够优雅的从I/O异常中恢复，从而我们不用重新启动应用程序来恢复logger。 6. logback能够根据配置文件中设置的上限值，自动删除旧的日志文件。 7. logback能够自动压缩日志文件。 8. logback能够在配置文件中加入条件判断（if-then-else)。可以避免不同的开发环境（dev、test、uat…）的配置文件的重复。 9. logback带来更多的filter。 10. logback的stack trace中会包含详细的包信息。 11. logback-access和Jetty、Tomcat集成提供了功能强大的HTTP-access日志。 相关的Maven依赖写法： 123456789101112131415&lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-core&lt;/artifactId&gt; &lt;version&gt;1.1.11&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;1.1.11&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-access&lt;/artifactId&gt; &lt;version&gt;1.1.11&lt;/version&gt;&lt;/dependency&gt; log4j2引用官网的一句话Apache Log4j 2 is an upgrade to Log4j that provides significant improvements over its predecessor, Log4j 1.x, and provides many of the improvements available in Logback while fixing some inherent problems in Logback’s architecture.翻译过来就是说：Apache Log4j 2是对Log4j的升级，它比其前身Log4j 1.x提供了重大改进，并提供了Logback中可用的许多改进，同时修复了Logback架构中的一些固有问题。Log4j2的特性： 1. 插件式结构。Log4j 2支持插件式结构。我们可以根据自己的需要自行扩展Log4j2. 我们可以实现自己的appender、logger、filter。 2. 配置文件优化。在配置文件中可以引用属性，还可以直接替代或传递到组件。而且支持json格式的配置文件。不像其他的日志框架，它在重新配置的时候不会丢失之前的日志文件。 3. Java 5的并发性。Log4j 2利用Java 5中的并发特性支持，尽可能地执行最低层次的加锁。解决了在log4j 1.x中存留的死锁的问题。 4. 异步logger。Log4j2是基于LMAX Disruptor库的。在多线程的场景下，和已有的日志框架相比，异步的logger拥有10倍左右的效率提升。 相关的Maven依赖写法： 123456789101112131415161718192021222324&lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-api&lt;/artifactId&gt; &lt;version&gt;&#123;log4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-core&lt;/artifactId&gt; &lt;version&gt;&#123;log4j.version&#125;&lt;/version&gt; &lt;/dependency&gt; &lt;!-- log4j2异步日志需要加载disruptor-3.0.0.jar或者更高的版本 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.lmax&lt;/groupId&gt; &lt;artifactId&gt;disruptor&lt;/artifactId&gt; &lt;version&gt;3.3.6&lt;/version&gt; &lt;/dependency&gt; &lt;!--如果还要使用slf4j可以导入下面的依赖--&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.logging.log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j-slf4j-impl&lt;/artifactId&gt; &lt;version&gt;2.9.1&lt;/version&gt;&lt;/dependency&gt;&lt;/dependencies&gt; &nbsp;&nbsp; 日志框架的使用SLF4J 什么时候使用SLF4J比较合适呢？ &nbsp;&nbsp;&nbsp;&nbsp;如果你开发的是类库或者嵌入式组件，那么就应该考虑采用SLF4J，因为不可能影响最终用户选择哪种日志系统。在另一方面，如果是一个简单或者独立的应用，确定只有一种日志系统，那么就没有使用SLF4J的必要。 如何在系统中使用SLF4J?(官网:https://www.slf4j.org/manual.html)下面是官网给的一个使用实例，以后如果要是用SLF4J,那就不要直接调用实现类的API，而是应该调用SLF4J里面的API，当然只是使用日志实现类另当别论！ 12345678910import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class HelloWorld &#123; public static void main(String[] args) &#123; Logger logger = LoggerFactory.getLogger(HelloWorld.class); //输出一个info级别的日志 logger.info("Hello World"); &#125;&#125; Log4J&nbsp;&nbsp;&nbsp;&nbsp;log4j是Apache的一个开放源代码项目，通过使用Log4j，我们可以控制日志信息输送的目的地是控制台、文件、数据库等；我们也可以控制每一条日志的输出格式；通过定义每一条日志信息的级别，我们能够更加细致地控制日志的生成过程。 &nbsp;&nbsp;&nbsp;&nbsp;Log4j有7种不同的log级别，按照等级从低到高依次为：TRACE、DEBUG、INFO、WARN、ERROR、FATAL、OFF。如果配置为OFF级别，表示关闭log。 Log4j支持两种格式的配置文件：properties和xml。包含三个主要的组件：Logger、appender、Layout。 一个简单的log4j配置文件 1234567891011121314151617181920212223242526272829303132333435### set log levels ### log4j.rootLogger = INFO , console , debug , error ### console ### log4j.appender.console = org.apache.log4j.ConsoleAppender log4j.appender.console.Target = System.out log4j.appender.console.layout = org.apache.log4j.PatternLayout log4j.appender.console.layout.ConversionPattern = %-d&#123;yyyy-MM-dd HH\:mm\:ss&#125; [%p]-[%c] %m%n ### log file ### log4j.appender.debug = org.apache.log4j.DailyRollingFileAppender log4j.appender.debug.File = xzy_mybatis.log log4j.appender.debug.Append = true log4j.appender.debug.Threshold = INFO log4j.appender.debug.layout = org.apache.log4j.PatternLayout log4j.appender.debug.layout.ConversionPattern = %-d&#123;yyyy-MM-dd HH\:mm\:ss&#125; [%p]-[%c] %m%n ### exception ### log4j.appender.error = org.apache.log4j.DailyRollingFileAppender log4j.appender.error.File = xzy_mybatis.log log4j.appender.error.Append = true log4j.appender.error.Threshold = ERROR log4j.appender.error.layout = org.apache.log4j.PatternLayout log4j.appender.error.layout.ConversionPattern = %-d&#123;yyyy-MM-dd HH\:mm\:ss&#125; [%p]-[%c] %m%n # LOG4J配置log4j.rootCategory=INFO,stdout,jdbc# 数据库输出log4j.appender.jdbc=org.apache.log4j.jdbc.JDBCAppenderlog4j.appender.jdbc.driver=com.mysql.jdbc.Driverlog4j.appender.jdbc.URL=jdbc:mysql://127.0.0.1:3306/test?characterEncoding=utf8&amp;useSSL=truelog4j.appender.jdbc.user=rootlog4j.appender.jdbc.password=rootlog4j.appender.jdbc.sql=insert into log_icecoldmonitor(level,category,thread,time,location,note) values('%p','%c','%t','%d&#123;yyyy-MM-dd HH:mm:ss:SSS&#125;','%l','%m') 在Spring Boot中使用log4j&nbsp;&nbsp;&nbsp;&nbsp;首先创建一个Spring Boot工程，在创建Spring Boot工程时，我们引入了spring-boot-starter，其中包含了spring-boot-starter-logging，由于Spring Boot默认的日志框架是Logback，所以我们在引入log4j之前，需要先排除该包的依赖，再引入log4j的依赖。 1234567891011121314&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter&lt;/artifactId&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-log4j&lt;/artifactId&gt;&lt;/dependency&gt; 配置log4j-spring.properties &nbsp;&nbsp;&nbsp;&nbsp;配置文件的编写方法上面介绍的没有啥区别，但是配置文件的名字可以是log4j-spring.properties也可以是log4j.properties，但是Spring Boot官方推荐的命名方式是第一种方式。配置文件的内容参考上面。在Spring Boot主配置文件中指定日志文件的配置 1loggin.config=classpath:log4j-spring.properties Logback logblack的加载顺序SLF4J+Logback是Spring Boot默认的日志策略，logback支持xml和groovy形式的配置文件，而且还支持编程式地配置，它加载配置文件的顺序： 在 classpath 中寻找 logback-test.xml文件 如果找不到 logback-test.xml，则在 classpath 中寻找 logback.groovy 文件 如果找不到 logback.groovy，则在 classpath 中寻找 logback.xml文件 如果上述的文件都找不到，则 logback 会使用 JDK 的 SPI 机制查找 META-INF/services/ch.qos.logback.classic.spi.Configurator 中的 logback 配置实现类，这个实现类必须实现 Configuration 接口，使用它的实现来进行配置 如果上述操作都不成功，logback 就会使用它自带的 BasicConfigurator 来配置，并将日志输出到 console 在Spring Boot中使用LogBack(官网：https://logback.qos.ch/documentation.html)前面说过，logback是Spring Boot默认的日志系统，假如对日志没有特殊要求，可以完全零配置使用 SLF4J（Simple Logging Facade For Java）的logback来输出日志。LogBack的日志等级有ERROR、WARN、INFO、DEBUG、TRACE5级日志等级，等级由左至右等级又高到底。没有FATAL，他被分类到ERROR。 12345678910111213141516171819202122package com.jianeye.test;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;SpringBootApplicationpublic class TestApplication &#123; private static Logger logger = LoggerFactory.getLogger(TestApplication.class); public static void main(String[] args) &#123; logger.warn("logback --------------------------------\n"); SpringApplication.run(TestApplication.class, args); logger.trace("trace log**********\n"); logger.info("default log**************\n"); logger.debug("dubug log***********\n"); logger.wran("warn log**********\n"); logger.error("error log*******\n"); &#125;&#125; &nbsp;&nbsp;&nbsp;&nbsp;上面这段程序，不经过任何配置，默认的日志系统是完全可以正常运行的。但是Spring Boot也支持我们修改默认配置，修改的方式有两种，一种是在src/main/resources下新建logback-spring.xml文件（logback.xml也可以，但官方推荐前面的写法）；第二种是直接在Spring Boot主配置文件中配置，下面是简单的配置示例：logbac-spring.xml 1234567&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;configuration&gt; &lt;include resource="org/springframework/boot/logging/logback/base.xml" /&gt; &lt;logger name="org.springframework.web" level="INFO"/&gt; &lt;logger name="org.springboot.sample" level="TRACE" /&gt;&lt;/configuration&gt; application.properties 123456789101112131415161718192021222324252627debug=trueserver.port=80server.servlet.context-path=/book#指定配置文件的名字#logging.config.name=logback-spring.xml#配置文件的位置，#logging.config.location=classpath:logback-spring.xml#指定输出文件，当不指定路径时，默认将在当前项目路径下创建日志文件。#logging.file=logback-spring.log#也可以指定路径到硬盘的具体的某个路径，如果某及路径不存在就会创建logging.file=G://log/logback-spring.log#控制台输出的日期格式logging.pattern.console=%d&#123;yyyy-MM-dd&#125; [%thread] %-5level %logger&#123;50&#125; - %msg%n#日期输出格式logging.pattern.dateformat=HH:mm:ss.sss#指定输出到文件的日志格式logging.pattern.file=file-%d&#123;yyyy-MM-dd HH:mm:ss&#125; [%thread] %-5level %logger&#123;36&#125; -%msg%n#指定日志中日志级别输出的格式logging.pattern.level=custom-%5p#调整根目录级别的日志级别logging.level.root=WARN#调整特定文件的日志级别 logging.level.文件名=日志级别logging.level.com.xust=INFOlogging.level.org.springframework=DEBUG 扩展使用springProperty&nbsp;&nbsp;&nbsp;&nbsp;在logback-spring.xml中可以使用Spring Boot扩展的，使用它可以把在application.properties中定义的属性值映射为logback环境中的一个属性，从而可以在logback的上下文使用。 1234567891011&lt;springProfile name="staging"&gt; &lt;!-- configuration to be enabled when the "staging" profile is active --&gt; &lt;!--可以指定某段配置只在某个环境下生效--&gt;&lt;/springProfile&gt;&lt;springProfile name="dev | staging"&gt; &lt;!-- configuration to be enabled when the "dev" or "staging" profiles are active --&gt;&lt;/springProfile&gt;&lt;springProfile name="!production"&gt; &lt;!-- configuration to be enabled when the "production" profile is not active --&gt;&lt;/springProfile&gt; 举个例子：&nbsp;&nbsp;&nbsp;&nbsp;下面的配置中定义了属性appName对应于Spring Boot的Environment中的app.name（由source属性指定），当未指定时默认使用defaultValue属性指定的TEST；属性name对应于Spring Boot的Environment中的logging.path，未指定时使用/logs/${appName}.log，其中的${appName}又对应于变量appName的值。定义好的变量可以在logback的配置文件中以${varName}的形式进行引用。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748logback-spring.xml&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;configuration&gt; &lt;include resource="org/springframework/boot/logging/logback/base.xml" /&gt; &lt;logger name="org.springframework.web" level="INFO"/&gt; &lt;logger name="org.springboot.sample" level="TRACE" /&gt; &lt;springProfile name="dev"&gt; &lt;logger name="org.springboot.sample" level="DEBUG" /&gt; &lt;/springProfile&gt; &lt;springProfile name="staging"&gt; &lt;logger name="org.springboot.sample" level="INFO" /&gt; &lt;/springProfile&gt; &lt;!-- %d ：表示日期时间 %thread ：表示线程名 %-5level ：级别从左显示5个字符宽度，- 表示左对齐 %logger&#123;50&#125; ：表示 logger 名字最长为50个字符，否则按照句号分割 %msg ：表示日志消息 %n ：表示换行--&gt; &lt;springProfile&gt; &lt;appender name="stdOut" class="ch.qos.logback.core.ConsoleAppender"&gt; &lt;encoder&gt; &lt;pattern&gt;$&#123;dev&#125;-%d&#123;HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;36&#125; -%msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;appender name="fileOut" class="ch.qos.logback.core.rolling.RollingFileAppender"&gt; &lt;file&gt;$&#123;logPath&#125;&lt;/file&gt; &lt;rollingPolicy class="ch.qos.logback.core.rolling.TimeBasedRollingPolicy"&gt; &lt;fileNamePattern&gt;$&#123;logPath&#125;.%d&#123;yyyy-MM-dd&#125;.%i.log&lt;/fileNamePattern&gt; &lt;timeBasedFileNamingAndTriggeringPolicy class="ch.qos.logback.core.rolling.SizeAndTimeBasedFNATP"&gt; &lt;maxFileSize&gt;5MB&lt;/maxFileSize&gt; &lt;/timeBasedFileNamingAndTriggeringPolicy&gt; &lt;/rollingPolicy&gt; &lt;encoder&gt; &lt;pattern&gt;%d&#123;yyyy-MM-dd HH:mm:ss.SSS&#125; [%thread] %-5level %logger&#123;36&#125; -%msg%n&lt;/pattern&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!--log root的日志级别--&gt; &lt;root level="info"&gt; &lt;appender-ref ref="stdOut" /&gt; &lt;appender-ref ref="fileOut" /&gt; &lt;/root&gt; &lt;/springProfile&gt;&lt;/configuration&gt; &nbsp;&nbsp; 多个不同的日志框架兼容SLF4J&nbsp;&nbsp;&nbsp;&nbsp;经常在实际的开发环境中，我们会使用到不同的框架，而且不同的框架默认的日志系统不同，那么如何在Spring Boot中设置一下，让这些不同框架的默认日志系统可以借助于Spring Boot的默认日志系统来工作？这是可以办到的,具体的步骤如下：1、在pom.xml文件中导入依赖的时候排除所使用框架对默认日志系统的依赖2、用SLF4J提供的中间包替换原有日志框架下图有详细的配置方法：]]></content>
      <categories>
        <category>Spring Boot框架</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot自动配置原理（深入源码）]]></title>
    <url>%2F2019%2F08%2F26%2FSpringBoot%E8%87%AA%E5%8A%A8%E9%85%8D%E7%BD%AE%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp; 引言&nbsp;&nbsp;&nbsp;&nbsp;不论在工作中，亦或是求职面试，Spring Boot已经成为我们必知必会的技能项。除了某些老旧的政府项目或金融项目持有观望态度外，如今的各行各业都在飞速的拥抱这个已经不是很新的Spring启动框架。 &nbsp;&nbsp;&nbsp;&nbsp;当然，作为Spring Boot的精髓，自动配置原理的工作过程往往只有在“面试”的时候才能用得上，但是如果在工作中你能够深入的理解Spring Boot的自动配置原理，将无往不利。 &nbsp;&nbsp;&nbsp;&nbsp;Spring Boot的出现，得益于“习惯优于配置”的理念，没有繁琐的配置、难以集成的内容（大多数流行第三方技术都被集成），这是基于Spring 4.x提供的按条件配置Bean的能力。 &nbsp;&nbsp; Spring Boot自动配置原理配置文件到底能写什么？怎么写？自动配置原理？&nbsp;&nbsp;&nbsp;&nbsp;我们一接触Spring Boot的时候就了解到：Spring Boot有一个全局配置文件application.properties或application.yml。我们的各种属性都可以在这个文件中进行配置，最常配置的比如：server.port、logging.level.* 等等，然而我们实际用到的往往只是很少的一部分，而且可以在主配置文件中配置的属性都可以在官方文档中查找到：https://docs.spring.io/spring-boot/docs/2.1.0.RELEASE/reference/htmlsingle/#common-application-properties @EnableAutoConfiguration&nbsp;&nbsp;&nbsp;&nbsp;Spring Boot在从启动类启动，启动类上有@SpringBootApplication注解，这个注解是Spring Boot的核心注解，那么自动配置原理一定和这个注解有着千丝万缕的联系！ 1234567891011@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan(excludeFilters = &#123; @Filter(type = FilterType.CUSTOM, classes = TypeExcludeFilter.class), @Filter(type = FilterType.CUSTOM, classes = AutoConfigurationExcludeFilter.class) &#125;)public @interface SpringBootApplication &#123; //省略&#125; &nbsp;&nbsp;&nbsp;&nbsp;点开@SpringBootApplication源码，这里面最重要的就是@SpringBootConfiguration和@EnableAutoConfiguration，前者是Spring Boot的配置注解，底层使用的是@Configuration这个注解，后者翻译他的名字就知道这是开启自动配置，它是Spring Boot自动配置的核心。于是，让我们点进去看看里面的乾坤。 12345678910111213141516171819202122232425@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage@Import(AutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration &#123; String ENABLED_OVERRIDE_PROPERTY = "spring.boot.enableautoconfiguration"; /** * Exclude specific auto-configuration classes such that they will never be applied. * @return the classes to exclude */ Class&lt;?&gt;[] exclude() default &#123;&#125;; /** * Exclude specific auto-configuration class names such that they will never be * applied. * @return the class names to exclude * @since 1.3.0 */ String[] excludeName() default &#123;&#125;;&#125; &nbsp;&nbsp;&nbsp;&nbsp;可以看到，EnableAutoConfiguration注解内部的代码那是非常的简单，但是@Import(AutoConfigurationImportSelector.class)这个注解引起了我的好奇，@Import这个注解我们都不陌生，他的作用无外乎这几种：@Configuration注解的配置类、声明@Bean注解的bean方法、导入ImportSelector的实现类或导入ImportBeanDefinitionRegistrar的实现类。按照他的写法，他是导入了ImportSelector的实现类AutoConfigurationImportSelector。它的核心方法就是 selectImports(..)，它表明哪些自动配置类是要加入到容器中，在Spring Boot 2.1.7.RELEASE版本中得源码如下： 1234567891011@Overridepublic String[] selectImports(AnnotationMetadata annotationMetadata) &#123; if (!isEnabled(annotationMetadata)) &#123; return NO_IMPORTS; &#125; AutoConfigurationMetadata autoConfigurationMetadata = AutoConfigurationMetadataLoader .loadMetadata(this.beanClassLoader); AutoConfigurationEntry autoConfigurationEntry = getAutoConfigurationEntry(autoConfigurationMetadata, annotationMetadata); return StringUtils.toStringArray(autoConfigurationEntry.getConfigurations());&#125; 继续追踪源码，可以看到getAutoConfigurationEntry（..)这个方法，其中configurations存放的数据就是加入容器的自动配置类的完整包路径 12345678910111213141516171819protected AutoConfigurationEntry getAutoConfigurationEntry(AutoConfigurationMetadata autoConfigurationMetadata, AnnotationMetadata annotationMetadata) &#123; if (!isEnabled(annotationMetadata)) &#123; return EMPTY_ENTRY; &#125; AnnotationAttributes attributes = getAttributes(annotationMetadata); //扫描具有META-INF/spring.factories文件的jar包 List&lt;String&gt; configurations = getCandidateConfigurations(annotationMetadata, attributes); //去掉重复的配置 configurations = removeDuplicates(configurations); //删除需要排除的类 Set&lt;String&gt; exclusions = getExclusions(annotationMetadata, attributes); checkExcludedClasses(configurations, exclusions); configurations.removeAll(exclusions); configurations = filter(configurations, autoConfigurationMetadata); fireAutoConfigurationImportEvents(configurations, exclusions); return new AutoConfigurationEntry(configurations, exclusions);&#125; 而从getCandidateConfigurations(..)中，我们发现他调用SpringFactoriesLoader.loadFactoryNames产生了一个List，返回的东西是啥呢？继续往下看 1234567protected List&lt;String&gt; getCandidateConfigurations(AnnotationMetadata metadata, AnnotationAttributes attributes) &#123; List&lt;String&gt; configurations = SpringFactoriesLoader.loadFactoryNames(getSpringFactoriesLoaderFactoryClass(), getBeanClassLoader()); Assert.notEmpty(configurations, "No auto configuration classes found in META-INF/spring.factories. If you " + "are using a custom packaging, make sure that file is correct."); return configurations;&#125; 我们继续往下看，发现他确实最终在loadFactories方法中使用本类的一个私有静态方法loadSpringFactories加载了META-INF/spring.factories这个配置文件。 123456789101112131415161718192021222324252627282930313233343536373839404142434445public final class SpringFactoriesLoader &#123; /** * The location to look for factories. * &lt;p&gt;Can be present in multiple JAR files. */ public static final String FACTORIES_RESOURCE_LOCATION = "META-INF/spring.factories"; public static List&lt;String&gt; loadFactoryNames(Class&lt;?&gt; factoryClass, @Nullable ClassLoader classLoader) &#123; String factoryClassName = factoryClass.getName(); return loadSpringFactories(classLoader).getOrDefault(factoryClassName, Collections.emptyList()); &#125; private static Map&lt;String, List&lt;String&gt;&gt; loadSpringFactories(@Nullable ClassLoader classLoader) &#123; MultiValueMap&lt;String, String&gt; result = cache.get(classLoader); if (result != null) &#123; return result; &#125; try &#123; Enumeration&lt;URL&gt; urls = (classLoader != null ? classLoader.getResources(FACTORIES_RESOURCE_LOCATION) : ClassLoader.getSystemResources(FACTORIES_RESOURCE_LOCATION)); result = new LinkedMultiValueMap&lt;&gt;(); while (urls.hasMoreElements()) &#123; URL url = urls.nextElement(); UrlResource resource = new UrlResource(url); Properties properties = PropertiesLoaderUtils.loadProperties(resource); for (Map.Entry&lt;?, ?&gt; entry : properties.entrySet()) &#123; String factoryClassName = ((String) entry.getKey()).trim(); for (String factoryName : StringUtils.commaDelimitedListToStringArray((String) entry.getValue())) &#123; result.add(factoryClassName, factoryName.trim()); &#125; &#125; &#125; cache.put(classLoader, result); return result; &#125; catch (IOException ex) &#123; throw new IllegalArgumentException("Unable to load factories from location [" + FACTORIES_RESOURCE_LOCATION + "]", ex); &#125; &#125;&#125; 查看spring-boot-autoconfigure包下META-INF/spring.factories： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384......# Auto Configureorg.springframework.boot.autoconfigure.EnableAutoConfiguration=\org.springframework.boot.autoconfigure.admin.SpringApplicationAdminJmxAutoConfiguration,\org.springframework.boot.autoconfigure.aop.AopAutoConfiguration,\org.springframework.boot.autoconfigure.amqp.RabbitAutoConfiguration,\org.springframework.boot.autoconfigure.batch.BatchAutoConfiguration,\org.springframework.boot.autoconfigure.cache.CacheAutoConfiguration,\org.springframework.boot.autoconfigure.cassandra.CassandraAutoConfiguration,\org.springframework.boot.autoconfigure.cloud.CloudServiceConnectorsAutoConfiguration,\org.springframework.boot.autoconfigure.context.ConfigurationPropertiesAutoConfiguration,\org.springframework.boot.autoconfigure.context.MessageSourceAutoConfiguration,\org.springframework.boot.autoconfigure.context.PropertyPlaceholderAutoConfiguration,\org.springframework.boot.autoconfigure.couchbase.CouchbaseAutoConfiguration,\org.springframework.boot.autoconfigure.dao.PersistenceExceptionTranslationAutoConfiguration,\org.springframework.boot.autoconfigure.data.cassandra.CassandraDataAutoConfiguration,\org.springframework.boot.autoconfigure.data.cassandra.CassandraReactiveDataAutoConfiguration,\org.springframework.boot.autoconfigure.data.cassandra.CassandraReactiveRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.cassandra.CassandraRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseDataAutoConfiguration,\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseReactiveDataAutoConfiguration,\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseReactiveRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.couchbase.CouchbaseRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchAutoConfiguration,\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchDataAutoConfiguration,\org.springframework.boot.autoconfigure.data.elasticsearch.ElasticsearchRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.jdbc.JdbcRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.jpa.JpaRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.ldap.LdapRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.mongo.MongoDataAutoConfiguration,\org.springframework.boot.autoconfigure.data.mongo.MongoReactiveDataAutoConfiguration,\org.springframework.boot.autoconfigure.data.mongo.MongoReactiveRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.mongo.MongoRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.neo4j.Neo4jDataAutoConfiguration,\org.springframework.boot.autoconfigure.data.neo4j.Neo4jRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.solr.SolrRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.redis.RedisAutoConfiguration,\org.springframework.boot.autoconfigure.data.redis.RedisReactiveAutoConfiguration,\org.springframework.boot.autoconfigure.data.redis.RedisRepositoriesAutoConfiguration,\org.springframework.boot.autoconfigure.data.rest.RepositoryRestMvcAutoConfiguration,\org.springframework.boot.autoconfigure.data.web.SpringDataWebAutoConfiguration,\org.springframework.boot.autoconfigure.elasticsearch.jest.JestAutoConfiguration,\org.springframework.boot.autoconfigure.elasticsearch.rest.RestClientAutoConfiguration,\org.springframework.boot.autoconfigure.flyway.FlywayAutoConfiguration,\org.springframework.boot.autoconfigure.freemarker.FreeMarkerAutoConfiguration,\org.springframework.boot.autoconfigure.gson.GsonAutoConfiguration,\org.springframework.boot.autoconfigure.h2.H2ConsoleAutoConfiguration,\org.springframework.boot.autoconfigure.hateoas.HypermediaAutoConfiguration,\org.springframework.boot.autoconfigure.hazelcast.HazelcastAutoConfiguration,\org.springframework.boot.autoconfigure.hazelcast.HazelcastJpaDependencyAutoConfiguration,\org.springframework.boot.autoconfigure.http.HttpMessageConvertersAutoConfiguration,\org.springframework.boot.autoconfigure.http.codec.CodecsAutoConfiguration,\org.springframework.boot.autoconfigure.influx.InfluxDbAutoConfiguration,\org.springframework.boot.autoconfigure.info.ProjectInfoAutoConfiguration,\org.springframework.boot.autoconfigure.integration.IntegrationAutoConfiguration,\org.springframework.boot.autoconfigure.jackson.JacksonAutoConfiguration,\org.springframework.boot.autoconfigure.jdbc.DataSourceAutoConfiguration,\org.springframework.boot.autoconfigure.jdbc.JdbcTemplateAutoConfiguration,\org.springframework.boot.autoconfigure.jdbc.JndiDataSourceAutoConfiguration,\org.springframework.boot.autoconfigure.jdbc.XADataSourceAutoConfiguration,\org.springframework.boot.autoconfigure.jdbc.DataSourceTransactionManagerAutoConfiguration,\org.springframework.boot.autoconfigure.jms.JmsAutoConfiguration,\org.springframework.boot.autoconfigure.jmx.JmxAutoConfiguration,\org.springframework.boot.autoconfigure.jms.JndiConnectionFactoryAutoConfiguration,\org.springframework.boot.autoconfigure.jms.activemq.ActiveMQAutoConfiguration,\org.springframework.boot.autoconfigure.jms.artemis.ArtemisAutoConfiguration,\org.springframework.boot.autoconfigure.groovy.template.GroovyTemplateAutoConfiguration,\org.springframework.boot.autoconfigure.jersey.JerseyAutoConfiguration,\org.springframework.boot.autoconfigure.jooq.JooqAutoConfiguration,\org.springframework.boot.autoconfigure.jsonb.JsonbAutoConfiguration,\org.springframework.boot.autoconfigure.kafka.KafkaAutoConfiguration,\org.springframework.boot.autoconfigure.ldap.embedded.EmbeddedLdapAutoConfiguration,\org.springframework.boot.autoconfigure.ldap.LdapAutoConfiguration,\org.springframework.boot.autoconfigure.liquibase.LiquibaseAutoConfiguration,\org.springframework.boot.autoconfigure.mail.MailSenderAutoConfiguration,\org.springframework.boot.autoconfigure.mail.MailSenderValidatorAutoConfiguration,\org.springframework.boot.autoconfigure.mongo.embedded.EmbeddedMongoAutoConfiguration,\org.springframework.boot.autoconfigure.mongo.MongoAutoConfiguration,\org.springframework.boot.autoconfigure.mongo.MongoReactiveAutoConfiguration,\org.springframework.boot.autoconfigure.mustache.MustacheAutoConfiguration,\org.springframework.boot.autoconfigure.orm.jpa.HibernateJpaAutoConfiguration,\org.springframework.boot.autoconfigure.quartz.QuartzAutoConfiguration,\org.springframework.boot.autoconfigure.reactor.core.ReactorCoreAutoConfiguration...... 看到的非常多的xxxxAutoConfiguration类，这些类都是容器中的一个组件，加入到容器中，用他们做自动配置。 总结—Spring Boot自动配置的精髓&nbsp;&nbsp;&nbsp;&nbsp;Spring Boot启动的时候会加载大量的自动配置类xxxxAutoConfiguration（就如在spring.factories那些类），当我们需要的功能在Spring Boot中恰好有默认的自动配置类，那么这个自动配置类在Spring Boot中一定有一个对应的XxxPropertoes类（相当于对应自动配置类的配置文件），这个类中有很多的属性，我们可以使用人家Spring Boot默认的属性值，但是当这些默认值无法满足我们的需求的时候，我们也可以在主配置文件中来使用XxxPropertoes类中的属性来配置我们需求的值。 &nbsp;&nbsp; @Conditional派生注解然而，虽然Spring Boot在启动的时候加载了全部的自动配置类，但是不是所用的这些类都是可以使用的，只有符合条件的自动配置类才可以使用，用于判断的就是这些@ConditionalXxx注解 @Conditional扩展注解作用（判断是否满足当前指定条件） @ConditionalOnJava 系统的java版本是否符合要求 @ConditionalOnBean容器中存在指定Bean； @ConditionalOnMissingBean 容器中不存在指定Bean； @ConditionalOnExpression 满足SpEL表达式指定 @ConditionalOnClass 系统中有指定的类 @ConditionalOnMissingClass 系统中没有指定的类 @ConditionalOnSingleCandidate容器中只有一个指定的Bean，或者这个Bean是首选Bean @ConditionalOnProperty系统中指定的属性是否有指定的值 @ConditionalOnResource 类路径下是否存在指定资源文件 @ConditionalOnWebApplication当前是web环境 @ConditionalOnNotWebApplication当前不是web环境 @ConditionalOnJndiJNDI存在指定项 问：如何知道哪些自动配置类生效了，哪些配置类没有生效？我们可以通过在主配置文件中配置 debug=true属性；来让控制台打印自动配置报告，这样我们就可以很方便的知道哪些自动配置类生效。如下：]]></content>
      <categories>
        <category>Spring Boot框架</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringBoot配置文件详解]]></title>
    <url>%2F2019%2F08%2F25%2FSpringBoot%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[Spring Boot配置文件&nbsp;&nbsp;&nbsp;&nbsp;Spring Boot支持两种形式的配置文件，分别是.properties、和.yml，而且配置文件的名字是固定不可变的： application.properties application.yml &nbsp;&nbsp;&nbsp;&nbsp;配置文件的作用是修改Spring Boot自动配置的默认值。相对于properties文件而言，yml文件更年轻。当application.properties文件和application.yml同时存在的时候，application.properties会优先加载，application.yml则后加载，而且在applicatin.properties中已经加载的属性如果在application.yml中再次出现会被忽略，如果是application.yml中的独有的属性则会加载。这里面有很多的坑。下面我们就来一起学习一下吧。 YAML/YML文件简介什么是YAML/YML文件？&nbsp;&nbsp;&nbsp;&nbsp;YAML是”YAML Ain’t a Markup Language”（YAML不是一种置标语言）的递回缩写。YAML 是一个可读性高，用来表达资料序列的编程语言。YAML是一种直观的能够被电脑识别的的数据数据序列化格式，容易被人类阅读，容易和脚本语言交互的，可以被支持YAML库的不同的编程语言程序导入，比如： C/C++, Ruby, Python, Java, Perl, C#, PHP等。YAML以数据为中心，比json、xml等更适合做配置文件。 YAML/YML的基本语法 基本语法：key: value，key: 和value中间要有一个空格,而且key: value的形式可以写无限层。还有一下规则：1.大小写敏感2.使用缩进表示层级关系3.缩进时不允许使用Tab键，只允许使用空格。4.缩进的空格数目不重要，只要相同层级的元素左侧对齐即可5.只有一种注释方式，使用# YAML/YML支持的数据结构YML支持3中类型的数据结构类型 1.字面量2.对象（属性和值），Map（键值对）3.数组（List、Set） 1、字面量具体包括：字符串、布尔值、整数、浮点数、Null、时间、日期字面量可以直接使用，但是特别注意字符串的字面量在写的时候是不需要引号的（无论单引号还是双引号）。单/双引号在yml语法中有特殊的含义：​ “”：双引号；会转义字符串里面的特殊字符；特殊字符会作为本身想表示的意思​ name: “zhangsan \n lisi”：输出；zhangsan 换行 lisi ​ ”：单引号；不会转义特殊字符，特殊字符最终只是一个普通的字符串数据name: ‘zhangsan \n lisi’：输出；zhangsan \n lisi 2.对象（属性和值），Map（键值对）基本的语法还是key：value，以一个例子来说明： 123friends: lastName: zhangsan age: 20 对应的行内写法： 1friends: &#123;lastName: zhangsan,age: 18&#125; 3.数组（List、Set）用- 值表示数组中的一个元素 1234pets: - cat - dog - pig 行内写法 1pets: [cat,dog,pig] 举个栗子：配置一个Person的信息 123456789101112131415161718192021222324package com.xust.iot.bean;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.stereotype.Component;import java.util.List;import java.util.Map;/** * @ConfigurationProperties：告诉SpringBoot将本类中的所有属性和配置文件中相关的配置进行绑定； * 但是要特别注意:只有这个组件是容器中的组件，容器才能提供@ConfigurationProperties的功能； */@Component@ConfigurationProperties(prefix="person")public class Person &#123; private String name; private Integer age; private Address address; private Map&lt;String,Object&gt; map; private List&lt;String&gt; list; //省略getter setter和toStrig方法 123456789101112package com.xust.iot.bean;public class Address &#123; private String province; private String city; private String county; private String street; //省略getter setter和toStrig方法&#125; 我们可以导入配置文件处理器，编写配置的时候就有提示了 12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-configuration-processor&lt;/artifactId&gt; &lt;optional&gt;true&lt;/optional&gt;&lt;/dependency&gt; 在application.yml配置文件中配置preson信息： 12345678910111213141516#写yml配置的时候要特别注意key和value之间要有一个空格，同级属性左对齐person: name: 李四 age: 20 map: key1: value1 key2: value2 list: - hello - hi - bye address: province: 陕西 city: 西安 county: xx street: xx 在SpringBoot测试类中测试IOC是否可以拿到在配置文件中配置的信息 12345678910111213141516171819202122package com.xust.iot;import com.xust.iot.bean.Person;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.test.context.junit4.SpringRunner;@RunWith(SpringRunner.class)@SpringBootTestpublic class SpringBootConfigApplicationTests &#123; @Autowired Person person; @Test public void contextLoads() &#123; System.out.println(person); &#125;&#125; 测试结果： properties文件简介&nbsp;&nbsp;&nbsp;&nbsp;properties文件大家经常用，这里就简单介绍一下。其语法结构形如：key=value。注意中文乱码问题，需要转码成ASCII。在IDEA中可以设置自动转换把uft-8格式自动转成ASCII，设置方式是：依次点击【File】=&gt;【Other Settings】=&gt;【settigs for new projects】，搜索File Encodings，然后做如下配置： 上面Person信息的properties配置如下： 123456789person.name=小明person.age=20person.address.province=陕西person.address.city=西安person.address.county=xxperson.address.street=xxperson.map.key1=value1person.map.key2=value2person.list=hello,hi,bye 配置文件值注入@Value获取值和@ConfigurationProperties获取值比较&nbsp;&nbsp;&nbsp;&nbsp;Spring Boot通过ConfigurationProperties注解从配置文件中获取属性。从上面的例子可以看出ConfigurationProperties注解可以通过设置prefix指定需要批量导入的数据。支持获取字面值，集合，Map，对象等复杂数据。ConfigurationProperties注解还有其他特么呢？它和Spring的Value注解又有什么区别呢？带着这些问题，我们继续往下看。 比较@ConfigurationProperties @Value 功能 批量注入配置文件中的属性 一个个指定 松散绑定（松散语法） 支持 不支持 SpEL 不支持 支持 JSR303数据校验 支持 不支持 复杂类型封装 支持 不支持 何时使用@Value何时使用@ConfigrationProperties？ 如果说，我们只是在某个业务逻辑中需要获取一下配置文件中的某项值，使用@Value。 如果说，我们专门编写了一个javaBean来和配置文件进行映射，我们就直接使用@ConfigurationProperties。 配置文件注入值数据校验使用@Vaildatad可以给配置的属性数据校验功能。可以用在类、方法、参数上。可以加的验证注解如下： 12345678910111213141516@Null //限制只能为null@NotNull //限制必须不为null@AssertFalse //限制必须为false@AssertTrue //限制必须为true@DecimalMax(value) //限制必须为一个不大于指定值的数字@DecimalMin(value) //限制必须为一个不小于指定值的数字@Digits(integer,fraction) //限制必须为一个小数，且整数部分的位数不能超过integer，小数部分的位数不能超过fraction@Future //限制必须是一个将来的日期@Max(value) //限制必须为一个不大于指定值的数字@Min(value) //限制必须为一个不小于指定值的数字@Past //验证注解的元素值（日期类型）比当前时间早@Pattern(value) //限制必须符合指定的正则表达式@Size(max,min) //限制字符长度必须在min到max之间@NotEmpty //验证注解的元素值不为null且不为空（字符串长度不为0、集合大小不为0）@NotBlank //验证注解的元素值不为空（不为null、去除首位空格后长度为0），不同于@NotEmpty，@NotBlank //只应用于字符串且在比较时会去除字符串的空格@Email //验证注解的元素值是Email，也可以通过正则表达式和flag指定自定义的email格式 下面举个例子： 1234567891011121314151617181920212223242526272829@Component@ConfigurationProperties(prefix = "person")@Validatedpublic class Person &#123; @NotEmpty @Size(max = 5, min = 2) private String name; @Max(70) @Min(10) private Integer age; @Past private Date birth; @NotEmpty private Address address; @NotEmpty private Map&lt;String, Object&gt; map; @NotEmpty private List&lt;String&gt; list; //省略getter setter和toStrig方法 &#125; @PropertySource&amp;@ImportResource&amp;@Bean @PropertySource：加载指定的配置文件； person.properties 12345678910person.name=小明person.age=20person.address.province=陕西person.address.city=西安person.address.county=xxperson.address.street=xxperson.map.key1=value1person.map.key2=value2person.list=hello,hi,byeperson.birth=2019/04/5 123456789101112131415161718192021222324252627282930313233343536373839404142package com.xust.iot.bean;import org.springframework.boot.context.properties.ConfigurationProperties;import org.springframework.context.annotation.PropertySource;import org.springframework.stereotype.Component;import org.springframework.validation.annotation.Validated;import javax.validation.constraints.*;import java.util.Date;import java.util.List;import java.util.Map;//使用PropertySource注解指定配置文件的路径，SpringBoot就会在启动的时候加载，然后把配置中的值赋给这个配置类的对应属性。@PropertySource(value = &#123;"classpath:personInfo.properties"&#125;)@Component@ConfigurationProperties(prefix = "person")@Validatedpublic class Person &#123; @NotEmpty @Size(max = 5, min = 2) private String name; @Max(70) @Min(10) private Integer age; @Past private Date birth; private Address address; @NotEmpty private Map&lt;String, Object&gt; map; @NotEmpty private List&lt;String&gt; list; //省略getter setter和toStrig方法&#125; @ImportResource：导入Spring的配置文件，让配置文件里面的内容生效； 在src/main/resources下新建一个Spring配置文件applicationContext.xml 123456789101112&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;bean id="address" class="com.xust.iot.bean.Address"&gt; &lt;property name="province" value="陕西"/&gt; &lt;property name="city" value="汉中"/&gt; &lt;property name="county" value="xxx"/&gt; &lt;property name="street" value="xxx"/&gt; &lt;/bean&gt;&lt;/beans&gt; 在Spring Boot的主程序类中使用@ImportResource引入配置这个配置文件 然后在测试类中自动注入ApplicationContext来拿这个组件 1234567891011121314151617181920212223242526package com.xust.iot;import com.xust.iot.bean.Person;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.context.ApplicationContext;import org.springframework.test.context.junit4.SpringRunner;@RunWith(SpringRunner.class)@SpringBootTestpublic class SpringBootConfigApplicationTests &#123; @Autowired ApplicationContext ioc; @Test public void contextLoads() &#123; System.out.println(ioc.containsBean("address")); System.out.println(ioc.getBean("address").toString()); &#125;&#125; 测试结果： 虽然这种方式可以用，但是一般我们不这么用，而且Spring Boot也不推荐这么使用，Spring Boot推荐使用全注解的方式来添加配置文件。 1、配置类@Configuration——&gt;Spring配置文件 2、使用@Bean给容器中添加组件 接下类，我们在com.xust.iot基包下新建配置类ApplicationConfig.java 123456789101112131415161718192021222324package com.xust.iot;import com.xust.iot.bean.Address;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;//使用@Configuration告诉Spring这是配置@Configurationpublic class ApplicationConfig &#123; //@Bean注解相当于&lt;bean&gt;&lt;/bean&gt;标签,特别注意：方法名就是bean的id @Bean public Address address()&#123; System.out.println("在配置类中使用@Bean注解添加了组件"); Address address=new Address(); address.setProvince("陕西省"); address.setCity("西安"); address.setCounty("xxx"); address.setStreet("xxx"); return address; &#125;&#125; 运行后得到的效果一样： 配置文件占位符在application.properties和application.yml文件可以使用${random}来设置随机值 常用随机设值如下1234567$&#123;random.value&#125; //随机生成一个32位的字符串，如：b21d56d2f10d74f84608dfff01b25552$&#123;random.int&#125; //随机生成一个int范围的随机数$&#123;random.long&#125; //随机生成一个int范围的随机数$&#123;random.int(10)&#125; //随机生一个[0,10]之间的随机数$&#123;random.int[1024,65536]&#125; //随机生成一个[1024,65536]之间的随机数$&#123;对象.属性&#125; //使用某个已配置的属性的值$&#123;对象.属性:默认值&#125; //使用某个已配置的属性的值，如果没有就是用默认值 在application.yml文件中写如下配置： 12345678910111213141516person: name: 李四$&#123;random.uuid&#125; age: $&#123;random.int(45,70)&#125; birth: 2019/08/24 map: key1: 232424@qq.com key2: dad323@163.com list: - hello - hi - bye address: province: 陕西 city: 西安 county: $&#123;person.name&#125; street: $&#123;person.address.province&#125;-$&#123;person.address.city&#125; 在测试类中打印person的信息，结果如下： Spring Boot profile&nbsp;&nbsp;&nbsp;&nbsp;Spring支持对不同环境，提供不同配置，可以通过激活、指定参数等方式快速的切换环境 。环境profile可以是开发环境（develop）、测试环境（fuy）、生产环境（production）等 配置多个profile在主配置文件编写的时候，文件名可以是 application-{profile}.properties/yml 下面分别编写application-develop.properties和application-production.propertiesapplication-develop.properties 123debug=trueserver.port=8081server.servlet.acontext-path=/book application-production.properties 123debug=falseserver.port=80server.servlet.context-path=/book 目录结构： 在主配置文件application.properties中，使用spring.profiles.active=[profile]来激活不同的环境，如下激活develop环境： 启动Spring Boot观察Tomcat启动的端口 激活生产环境：spring.profiles.active=production 可以看到，配置的不同环境被激活后都起作用了。这在以后的开发中无疑是个十分强大而且方便的功能。 YML配置多个profile然而使用properties文件配置不同环境还是太麻烦了，YML对多profile的支持更加简单粗暴，配置示例： 123456789101112131415161718192021222324server: port: 8083spring: profiles: active: production #激活生产环境---#开发环境server: port: 8083 servlet: context-path: /bootdebug: truespring: profiles: develop #使用spring.profiles来指定这个环境名--- #使用连续的三个横线分隔不同的profile(文档区)#生产环境server: port: 80 servlet: context-path: /bootdebug: truespring: profiles: production 注意：Spring Boot启动的时候会优先加载.properties的文件，然后才来加载.yml文件，如果要想使applicaton.yml中配置的信息可以使用，那么.properties中不能有和.yml相同的配置。 总结激活指定profile的不同方式1、在配置文件中指定 spring.profiles.active=dev，上面的配置方式就是这种。 ​ 2、命令行：可以在IDEA中配置 –spring.profiles.active=develop 来启动开发环境，操作如下： 也可以在命令行中使用java -jar spring_boot_config-0.0.1-SNAPSHOT.jar --spring.profiles.active=develop来启动开发环境 3、虚拟机参数： 可以在IDEA中做如下配置：-Dspring.profiles.active=dev，示例如下： 配置文件的加载位置springboot 启动会扫描以下位置的application.properties或者application.yml文件作为Spring boot的默认配置文件 –file:./config/ –file:./ –classpath:/config/ –classpath:/ 这些位置的配置文件加载的优先级由高到底，而且高优先级的配置如果在低优先即中出现，那么低优先优先级中重复配置不会生效。但是低优先级中独有的配置还是会生效。也就是说SpringBoot会从这四个位置全部加载主配置文件；并且会互补配置； ==我们还可以通过spring.config.location来改变默认的配置文件位置== 比如：项目打包好以后，我们可以使用命令行参数的形式，启动项目的时候来指定配置文件的新位置；指定配置文件和默认加载的这些配置文件共同起作用形成互补配置；首先在硬盘的另一个地方(我这里在E://)创建application.properties。添加如下配置： 123debug=falseserver.port=8087server.servlet.context-path=/book 然后可以在命令行输入java -jar spring_boot_config-0.0.1-SNAPSHOT.jar --spring.config.location=E://application.properties 外部配置加载顺序SpringBoot也可以从以下位置加载配置，加载顺序的优先级从高到低；高优先级的配置会覆盖低优先级的配置，所有的配置会形成互补配置。 1.命令行参数 所有的配置都可以在命令行上进行指定 java -jar spring_boot_config-0.0.1-SNAPSHOT.jar –server.port=8087 –server.context-path=/abc 多个配置用空格分开；--配置项=值 2.来自java:comp/env的JNDI属性 3.Java系统属性（System.getProperties()） 4.操作系统环境变量 5.RandomValuePropertySource配置的random.*属性值 由jar包外向jar包内进行寻找； 优先加载带profile的配置文件 6.jar包外部的application-{profile}.properties或application.yml(带spring.profile)配置文件 7.jar包内部的application-{profile}.properties或application.yml(带spring.profile)配置文件 再来加载不带profile的配置文件 8.jar包外部的application.properties或application.yml(不带spring.profile)配置文件 9.jar包内部的application.properties或application.yml(不带spring.profile)配置文件 10.@Configuration注解类上的@PropertySource 11.通过SpringApplication.setDefaultProperties指定的默认属性 所有支持的配置加载来源参考官方文档。]]></content>
      <categories>
        <category>Spring Boot框架</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring Boot快速入门]]></title>
    <url>%2F2019%2F08%2F24%2FSpringBoot%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[SpringBoot 2.x 中文文档 入门环境准备&nbsp;&nbsp;&nbsp;&nbsp;在本地安装3.3版本以上的Maven，以及JDK1.7以上的java环境，然后在IDEA【settings】=&gt;【File | Settings | Build, Execution, Deployment】=&gt;【Maven】，设置如下内容： 创建SpringBoot HelloWord&nbsp;&nbsp;&nbsp;&nbsp;第一个程序我们先创建一个Maven工程。&nbsp;&nbsp;&nbsp;&nbsp;创建好Maven项目后，首先导入Spring Boot的依赖包，依赖可以在Spring Boot的官网：https://docs.spring.io/spring-boot/docs/1.5.22.RELEASE/reference/html/getting-started-installing-spring-boot.html#getting-started-maven-installation找到。 123456789101112131415161718192021222324&lt;!-- Inherit defaults from Spring Boot --&gt; &lt;parent&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-parent&lt;/artifactId&gt; &lt;version&gt;1.5.22.RELEASE&lt;/version&gt; &lt;/parent&gt; &lt;!-- Add typical dependencies for a web application --&gt; &lt;dependencies&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-web&lt;/artifactId&gt; &lt;/dependency&gt; &lt;/dependencies&gt; &lt;build&gt; &lt;plugins&gt; &lt;!--这个插件可以把我们的应用打包成一个可以运行的jar包，后面有详细的说明--&gt; &lt;plugin&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-maven-plugin&lt;/artifactId&gt; &lt;/plugin&gt; &lt;/plugins&gt; &lt;/build&gt; 注意：&nbsp;&nbsp;&nbsp;&nbsp;1.spring-boot-starter-parent的父项目是spring-boot-dependencies（Spring Boot的版本仲裁中心），他的作用是用来管理Spring Boot应用里面的所有依赖版本&nbsp;&nbsp;&nbsp;&nbsp;2.spring-boot-starter-web：spring-boot-starter我们称作spring-boot场景启动器，Spring Boot将所有的功能场景都抽取出来，做成一个个的starters（启动器），只需要在项目里面引入这些starter，相关场景的所有依赖都会导入进来（要用什么功能就导入什么场景的启动器）。spring-boot-starter-web的作用是帮我们导入了web模块正常运行所依赖的组件； 完成上面的操作后，在src/main/java下新建一个主程序类Application.java类 1234567891011121314package com.xust.iot;import org.springframework.boot.SpringApplication;import org.springframework.boot.autoconfigure.SpringBootApplication;/** * 使用@SpringBootApplication 来标注主程序 */@SpringBootApplicationpublic class Application &#123; public static void main(String[] args) &#123; SpringApplication.run(Application.class, args); &#125;&#125; 注意：&nbsp;&nbsp;&nbsp;&nbsp;1、主程序类必须位于项目基包的根目录（具体原因下面会说），而且要使用@SpringBootApplication来告诉Spring Boot这是一个主程序类（配置类），这么标注后Spring Boot就会从这个类的main方法启动并加载配置。&nbsp;&nbsp;&nbsp;&nbsp;2、@SpringBootApplication是基于Spring Boot基本注解的一个复合注解，源码片段如下： 12345678910111213141516@Target(&#123;ElementType.TYPE&#125;)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@SpringBootConfiguration@EnableAutoConfiguration@ComponentScan( excludeFilters = &#123;@Filter( type = FilterType.CUSTOM, classes = &#123;TypeExcludeFilter.class&#125;), @Filter( type = FilterType.CUSTOM, classes = &#123;AutoConfigurationExcludeFilter.class&#125;)&#125;)public @interface SpringBootApplication &#123;...... &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.1、@SpringBootConfiguration：标注在某个类上，表示这是一个Spring Boot的配置类；底层实际还是使用的是Spring的底层注解@Configuration&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.2、@ComponnetScan：标注在类上，就是我们熟悉的包扫描&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.3、@EnableAutoConfiguration：开启自动配置功能；以前我们需要配置的文件，在类上写上这个注解，Spring Boot帮我们自动配置。@EnableAutoConfiguration的源码片段如下： 12345678910111213@Target(ElementType.TYPE)@Retention(RetentionPolicy.RUNTIME)@Documented@Inherited@AutoConfigurationPackage@Import(AutoConfigurationImportSelector.class)public @interface EnableAutoConfiguration &#123; String ENABLED_OVERRIDE_PROPERTY = "spring.boot.enableautoconfiguration"; Class&lt;?&gt;[] exclude() default &#123;&#125;; String[] excludeName() default &#123;&#125;;&#125; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.3.1、@AutoConfigurationPackage：自动配置包&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;2.3.2、@Import(AutoConfigurationImportSelector.class)：借助AutoConfigurationImportSelector这个类@EnableAutoConfiguration可以帮助SpringBoot应用将所有符合条件的@Configuration配置都加载到当前SpringBoot创建并使用的IoC容器。 Spring Boot在启动的时候从类路径下的META-INF/spring.factories中获取EnableAutoConfiguration指定的值，将这些值作为自动配置类导入到容器中，自动配置类就生效，帮我们进行自动配置工作；以前我们需要自己配置的东西，自动配置类都帮我们； 然后在src/main/java包下新建controller包，在这个包下新建HelloWordController.java 123456789101112131415package com.xust.iot.controller;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.ResponseBody;@Controllerpublic class HelloWordController &#123; @ResponseBody @RequestMapping("/hello") public String hello()&#123; return "Hello word,hello Spring Boot!"; &#125;&#125; 这样一个简单的SpringBoot程序就写好了，在主程序类中点击运行按钮启动它。下面是运行后的结果： 运行结果说明：启动后我们访问http://localhost:8080，回车后就会出现Whitelable Error Page提示，这是Spring Boot默认的错误页面，由于我们没有指定初始页面，出错很正常，之后在地址栏中请求hello，就可以看到我们写的Hello word,hello Spring Boot! 部署应用&nbsp;&nbsp;&nbsp;&nbsp;部署应用需要spring-boot-maven-plugin这个插件（在上面有），在POM文件中导入后，我们在IDEA有侧边栏点击【Maven】=&gt;【项目名】=&gt;【Lifecycle】=&gt;【package】，双击package就会运行插件就可以我们的应用打包成一个可运行的jar包。打包后我们在target目录下可以找到他，然后复制在里一个目录中在命令行中cd到这个目录，执行java -jar jar包名这个命令可以执行打包后的应用。下面是执行后命令行的打印： 使用Spring Initializer快速创建Spring Boot项目在IDEA依次点击【New】=&gt;【Project】然后选择Spring Initializr 填写Group和Arifact,在填写Arifact时要注意不要出现大写字母 选择需要的模块 生成的Spring Boot项目 在默认生成的Spring Boot项目中 主程序类已经生成好了，我们只需要我们实现业务逻辑 resources文件夹中目录结构 static：保存所有的静态资源，如： js css images； templates：保存所有的模板页面，Spring Boot默认jar包使用嵌入式的Tomcat，默认不支持JSP页面，可以使用模板引擎（freemarker、thymeleaf）； application.properties：Spring Boot应用的配置文件；可以修改一些默认设置。这个文件也支持YML(YML)格式的文件，用YAML(YML)格式配置的文件结构更加简洁，清晰。]]></content>
      <categories>
        <category>Spring Boot框架</category>
      </categories>
      <tags>
        <tag>Spring Boot</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SSM三大框架整合（Spring+Spring MVC +MyBatis）]]></title>
    <url>%2F2019%2F08%2F22%2FSSM%E4%B8%89%E5%A4%A7%E6%A1%86%E6%9E%B6%E6%95%B4%E5%90%88%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;Spring是一个非常流行的轻量级框架，他是为了解决企业应用开发的复杂性而创建的，现在已经被广泛应用在各个领域。MyBatis的前身iBatis也是一个非常流行的ORM框架，因此在在iBatis时期，Spring官方便提供了对iBatis的支持。但是在MyBatis时期，Spring 3.0在MyBatis 3.0官方发布前就已经结束了，因为Spring开发团队不想发布一个基于非发布版MyBatis的整合支持，因此MyBatis不得不继续等待Spring官方的支持。&nbsp;&nbsp;&nbsp;&nbsp;因此现在我们要整合他们要获得MyBatis的一个子项目MyBatis-Spring来支持，MyBatis-Spring可以帮我们将MyBatis代码无缝整合到Spring中。使用这个类库的类，Spring将会加载必要的MyBatis工厂类和Session类。这个类库也提供了一个简单的方式将MyBatis数据映射器和SqlSession注入到业务层的bean中，而且还可以处理事务、翻译MyBatis的异常到Spring的DataAccessException数据访问异常中。&nbsp;&nbsp;&nbsp;&nbsp;MyBatis-Spring项目的地址：https://github.com//mybatis/spring。&nbsp;&nbsp;&nbsp;&nbsp;接下来我们来一步步把他们整合在一起。 创建基本的Maven Web项目在IDEA中创建一个基本的Maven项目。具体过程不是这里的重点，如有有不清楚，请自行百度或Google~。创建好项目后，在pom.xml文件中配置依赖（导包） 在pom.xml文件中添加依赖详细的依赖配置如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236&lt;properties&gt; &lt;project.build.sourceEncoding&gt;UTF-8&lt;/project.build.sourceEncoding&gt; &lt;maven.compiler.source&gt;1.7&lt;/maven.compiler.source&gt; &lt;maven.compiler.target&gt;1.7&lt;/maven.compiler.target&gt; &lt;spring.version&gt;5.1.2.RELEASE&lt;/spring.version&gt; &lt;slf4j.version&gt;1.7.7&lt;/slf4j.version&gt;&lt;/properties&gt;&lt;dependencies&gt;&lt;!--单元测试--&gt;&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;!--Spring Start：也不全是Spring的依赖，还包括Spirng能够正常运行的一些支持性的包--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!--Spring上下文核心依赖--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--上下文支持包--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--Spring Bean工厂--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--SpEL(Spring表达式)--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-expression&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--Spring面向切面编程--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aop&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--提供对AspectJ的支持，可以方便的将面向切面的功能集成进IDE中--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--aspectj的runtime外部依赖包(必须)--&gt;&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjrt&lt;/artifactId&gt; &lt;version&gt;1.9.1&lt;/version&gt;&lt;/dependency&gt;&lt;!--aspectjweaver是aspectj的织入包(必须)--&gt;&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.9.1&lt;/version&gt;&lt;/dependency&gt;&lt;!--字节码增强--&gt;&lt;dependency&gt; &lt;groupId&gt;cglib&lt;/groupId&gt; &lt;artifactId&gt;cglib&lt;/artifactId&gt; &lt;version&gt;3.1&lt;/version&gt;&lt;/dependency&gt;&lt;!--Spring JDBC--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--Spring事物管理--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--Spring 对象关系映射--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-orm&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--Spring web模块核心--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--Spring MVC模块--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--Spring Test：spring-test--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--Servlet原生API--&gt;&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;!--支持JSP--&gt;&lt;dependency&gt; &lt;groupId&gt;javax.servlet.jsp&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet.jsp-api&lt;/artifactId&gt; &lt;version&gt;2.2.1&lt;/version&gt;&lt;/dependency&gt;&lt;!--JSTL用于在控制器中将模型绑定到JSP中--&gt;&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;/dependency&gt;&lt;!--文件上传，依赖commons-io--&gt;&lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;version&gt;1.4&lt;/version&gt;&lt;/dependency&gt;&lt;!--增强版的java IO--&gt;&lt;dependency&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt;&lt;/dependency&gt;&lt;!--json数据绑定--&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.9.9&lt;/version&gt;&lt;/dependency&gt;&lt;!--json注解--&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-annotations&lt;/artifactId&gt; &lt;version&gt;2.9.9&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;net.sf.json-lib&lt;/groupId&gt; &lt;artifactId&gt;json-lib&lt;/artifactId&gt; &lt;version&gt;2.4&lt;/version&gt; &lt;classifier&gt;jdk15&lt;/classifier&gt;&lt;/dependency&gt;&lt;!--json核心--&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-core&lt;/artifactId&gt; &lt;version&gt;2.9.9&lt;/version&gt;&lt;/dependency&gt;&lt;!--Spring End=--&gt;&lt;!--MyBatis Start--&gt;&lt;!--mybatis核心--&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.5.2&lt;/version&gt;&lt;/dependency&gt;&lt;!--MyBatis与Spring整合的核心包：配置这个包的时候一定要注意你的MyBatis版本和Spring版本和这个包是否兼容--&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis-spring&lt;/artifactId&gt; &lt;version&gt;2.0.2&lt;/version&gt;&lt;/dependency&gt;&lt;!--Jdbc数据库驱动--&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.11&lt;/version&gt;&lt;/dependency&gt;&lt;!--Druid数据库连接池--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba&lt;/groupId&gt; &lt;artifactId&gt;druid&lt;/artifactId&gt; &lt;version&gt;1.0.9&lt;/version&gt;&lt;/dependency&gt;&lt;!--MyBatis通用分页插件pageHelper--&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;version&gt;5.1.6&lt;/version&gt;&lt;/dependency&gt;&lt;!--分页插件依赖的包--&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.jsqlparser&lt;/groupId&gt; &lt;artifactId&gt;jsqlparser&lt;/artifactId&gt; &lt;version&gt;0.9.5&lt;/version&gt;&lt;/dependency&gt;&lt;!--======MyBatis End=======--&gt;&lt;!--日志记录--&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;$&#123;slf4j.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt;&lt;/dependency&gt;&lt;/dependencies&gt; &nbsp;&nbsp;&nbsp;&nbsp;配置的时候要特别注意mybatis-spring这个包的版本和你使用的MyBatis以及Spring版本是否兼容，特别适当发生java.lang.AbstractMethodError: org.mybatis.spring.transaction.SpringManagedTransaction.getTimeout()错误的时候，还就更要怀疑是这个问题了： 12345678910111213141516171819202122232425262728293021-Aug-2019 23:47:32.939 涓ラ噸 [http-nio-80-exec-5] org.apache.catalina.core.StandardWrapperValve.invoke Servlet.service() for servlet [DispatcherServlet] in context with path [/ssm_merge_war_exploded] threw exception [Handler dispatch failed; nested exception is java.lang.AbstractMethodError: org.mybatis.spring.transaction.SpringManagedTransaction.getTimeout()Ljava/lang/Integer;] with root causejava.lang.AbstractMethodError: org.mybatis.spring.transaction.SpringManagedTransaction.getTimeout()Ljava/lang/Integer; at org.apache.ibatis.executor.SimpleExecutor.prepareStatement(SimpleExecutor.java:86) at org.apache.ibatis.executor.SimpleExecutor.doUpdate(SimpleExecutor.java:49) at org.apache.ibatis.executor.BaseExecutor.update(BaseExecutor.java:117) at org.apache.ibatis.executor.CachingExecutor.update(CachingExecutor.java:76) at org.apache.ibatis.session.defaults.DefaultSqlSession.update(DefaultSqlSession.java:197) at org.apache.ibatis.session.defaults.DefaultSqlSession.insert(DefaultSqlSession.java:184) at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method) at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at org.mybatis.spring.SqlSessionTemplate$SqlSessionInterceptor.invoke(SqlSessionTemplate.java:408) at com.sun.proxy.$Proxy17.insert(Unknown Source) at org.mybatis.spring.SqlSessionTemplate.insert(SqlSessionTemplate.java:254) at org.apache.ibatis.binding.MapperMethod.execute(MapperMethod.java:62) at org.apache.ibatis.binding.MapperProxy.invoke(MapperProxy.java:57) at com.sun.proxy.$Proxy18.addAccount(Unknown Source) at com.xust.iot.service.AccountService.addAccount(AccountService.java:20) at com.xust.iot.service.AccountService$$FastClassBySpringCGLIB$$b6e17b84.invoke(&lt;generated&gt;) at org.springframework.cglib.proxy.MethodProxy.invoke(MethodProxy.java:218) at org.springframework.aop.framework.CglibAopProxy$CglibMethodInvocation.invokeJoinpoint(CglibAopProxy.java:746) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:163) at org.springframework.transaction.interceptor.TransactionAspectSupport.invokeWithinTransaction(TransactionAspectSupport.java:294) at org.springframework.transaction.interceptor.TransactionInterceptor.invoke(TransactionInterceptor.java:98) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.interceptor.ExposeInvocationInterceptor.invoke(ExposeInvocationInterceptor.java:93) at org.springframework.aop.framework.ReflectiveMethodInvocation.proceed(ReflectiveMethodInvocation.java:186) at org.springframework.aop.framework.CglibAopProxy$DynamicAdvisedInterceptor.intercept(CglibAopProxy.java:688) at com.xust.iot.service.AccountService$$EnhancerBySpringCGLIB$$a5f30121.addAccount(&lt;generated&gt;) 适配的环境：mybatis-spring对JDK、mybatis、spring都有要求 配置环境&nbsp;&nbsp;&nbsp;&nbsp;配置文件的编写是SSM整合的关键，需要配置的东西主要有web.xml、Sprng配置文件applicationContext.xml、Spring MVC配置文件applicationContext-mvc.xml、MyBatis全局配置文件MyBatis-config.xml以及后面的Mapper映射文件的编写。 1.配置web.xml文件web.xml文件的基本配置如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app xmlns="http://xmlns.jcp.org/xml/ns/javaee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd" version="3.1"&gt; &lt;welcome-file-list&gt; &lt;welcome-file&gt;index.html&lt;/welcome-file&gt; &lt;welcome-file&gt;index.htm&lt;/welcome-file&gt; &lt;welcome-file&gt;index.jsp&lt;/welcome-file&gt; &lt;welcome-file&gt;index&lt;/welcome-file&gt; &lt;/welcome-file-list&gt; &lt;!--启动Spring容器--&gt; &lt;context-param&gt; &lt;param-name&gt;contextConfigLoaction&lt;/param-name&gt; &lt;param-value&gt;classpath:Spring/applicationContext.xml&lt;/param-value&gt; &lt;/context-param&gt; &lt;!--用于在Web容器启动的时候根据contextConfigLoaction配置的路径读取Spring配置文件，然后启动Spring--&gt; &lt;listener&gt; &lt;listener-class&gt; org.springframework.web.context.ContextLoaderListener &lt;/listener-class&gt; &lt;/listener&gt; &lt;!--配置前端控制器--&gt; &lt;servlet&gt; &lt;servlet-name&gt;DispatcherServlet&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:Spring/applicationContext-mvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt; &lt;/servlet&gt; &lt;servlet-mapping&gt; &lt;servlet-name&gt;DispatcherServlet&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt; &lt;/servlet-mapping&gt; &lt;!--配置字符编码过滤器,注意：字符编码过滤器应该配置在所有过滤器之前--&gt; &lt;filter&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;utf-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;CharacterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt; &lt;!--配置Restful过滤器--&gt; &lt;filter&gt; &lt;filter-name&gt;HiddenHttpMethodFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.HiddenHttpMethodFilter&lt;/filter-class&gt; &lt;/filter&gt; &lt;filter-mapping&gt; &lt;filter-name&gt;HiddenHttpMethodFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt; &lt;/filter-mapping&gt;&lt;/web-app&gt; 2.配置MyBatis-config.xml全局配置文件&nbsp;&nbsp;&nbsp;&nbsp;在MyBatis的全局配置文件中配置一些基本对settings,环境就不要在这里配置了，交给Spring管理就好了（本身MyBatis这个配置文件都是可有可无的，但是用它来写一个settings配置可以使结构清晰，方便修改）。 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;configuration&gt; &lt;!--一些有关于mybatis运行时行为的设置--&gt; &lt;settings&gt; &lt;!--开启二级缓存--&gt; &lt;setting name="cacheEnabled" value="true"/&gt; &lt;!--开启懒加载--&gt; &lt;setting name="lazyLoadingEnabled" value="true"/&gt; &lt;!--aggressvieLazyLoading当这个参数为true的时候，对任意延迟属性都会完全的加载，当为false时会按需加载--&gt; &lt;setting name="aggressiveLazyLoading" value="false"/&gt; &lt;setting name="multipleResultSetsEnabled" value="true"/&gt; &lt;setting name="useColumnLabel" value="true"/&gt; &lt;setting name="useGeneratedKeys" value="true"/&gt; &lt;!--开启自动映射--&gt; &lt;setting name="autoMappingBehavior" value="PARTIAL"/&gt; &lt;!--开启驼峰--&gt; &lt;setting name="mapUnderscoreToCamelCase" value="true"/&gt; &lt;setting name="autoMappingUnknownColumnBehavior" value="WARNING"/&gt; &lt;setting name="defaultExecutorType" value="SIMPLE"/&gt; &lt;setting name="defaultStatementTimeout" value="25"/&gt; &lt;setting name="defaultFetchSize" value="100"/&gt; &lt;setting name="safeRowBoundsEnabled" value="false"/&gt; &lt;setting name="localCacheScope" value="SESSION"/&gt; &lt;setting name="jdbcTypeForNull" value="OTHER"/&gt; &lt;setting name="lazyLoadTriggerMethods" value="equals,clone,hashCode,toString"/&gt; &lt;/settings&gt; &lt;typeAliases&gt; &lt;package name="com.xust.iot.bean"/&gt; &lt;/typeAliases&gt; &lt;!--配置分页插件--&gt; &lt;plugins&gt; &lt;plugin interceptor="com.github.pagehelper.PageInterceptor"&gt;&lt;/plugin&gt; &lt;/plugins&gt;&lt;/configuration&gt; 3.配置applicationContext-mvc.xml文件123456789101112131415161718192021222324252627282930313233&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:mvc="http://www.springframework.org/schema/mvc" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd"&gt; &lt;!--开启注解扫描--&gt; &lt;context:component-scan base-package="com.xust.iot" use-default-filters="false"&gt; &lt;context:include-filter type="annotation" expression="org.springframework.stereotype.Controller"/&gt; &lt;context:include-filter type="annotation" expression="org.springframework.web.bind.annotation.ControllerAdvice"/&gt; &lt;/context:component-scan&gt; &lt;!--开启扫描静态--&gt; &lt;mvc:default-servlet-handler/&gt; &lt;!--开启扫动态--&gt; &lt;mvc:annotation-driven/&gt; &lt;!--配置视图解析器--&gt; &lt;bean id="viewResolver" class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="prefix" value="WEB-INF/pages/"/&gt; &lt;property name="suffix" value=".jsp"/&gt; &lt;/bean&gt; &lt;!--配置文件上传解析器--&gt; &lt;bean id="multipartResolver" class="org.springframework.web.multipart.commons.CommonsMultipartResolver"&gt; &lt;property name="maxUploadSizePerFile" value="#&#123;1024*1024*5&#125;"/&gt; &lt;property name="maxUploadSize" value="#&#123;1024*1024*100&#125;"/&gt; &lt;property name="defaultEncoding" value="utf-8"/&gt; &lt;/bean&gt;&lt;/beans&gt; 4.配置applicationContext.xml文件12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:tx="http://www.springframework.org/schema/tx" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd"&gt; &lt;!--注解扫描--&gt; &lt;context:component-scan base-package="com.xust.iot"&gt; &lt;context:exclude-filter type="annotation" expression="org.springframework.stereotype.Controller"/&gt; &lt;context:exclude-filter type="annotation" expression="org.springframework.web.bind.annotation.ControllerAdvice"/&gt; &lt;/context:component-scan&gt; &lt;!--引入外部配置文件--&gt; &lt;context:property-placeholder location="classpath:jdbc.properties"/&gt; &lt;!--配置数据源--&gt; &lt;bean id="DruidDataSource" class="com.alibaba.druid.pool.DruidDataSource"&gt; &lt;property name="username" value="$&#123;jdbc.username&#125;"/&gt; &lt;property name="password" value="$&#123;jdbc.password&#125;"/&gt; &lt;property name="url" value="$&#123;jdbc.url&#125;"/&gt; &lt;property name="driverClassName" value="$&#123;jdbc.driver&#125;"/&gt; &lt;property name="initialSize" value="$&#123;jdbc.initialSize&#125;"/&gt; &lt;property name="minIdle" value="$&#123;jdbc.minIdle&#125;"/&gt; &lt;property name="maxActive" value="$&#123;jdbc.maxActive&#125;"/&gt; &lt;property name="maxWait" value="$&#123;jdbc.maxWait&#125;"/&gt; &lt;property name="timeBetweenEvictionRunsMillis" value="$&#123;jdbc.timeBetweenEvictionRunsMillis&#125;"/&gt; &lt;property name="minEvictableIdleTimeMillis" value="$&#123;jdbc.minEvictableIdleTimeMillis&#125;"/&gt; &lt;property name="validationQuery" value="$&#123;jdbc.validationQuery&#125;"/&gt; &lt;property name="testWhileIdle" value="$&#123;jdbc.testWhileIdle&#125;"/&gt; &lt;property name="testOnBorrow" value="$&#123;jdbc.testOnBorrow&#125;"/&gt; &lt;property name="testOnReturn" value="$&#123;jdbc.testOnReturn&#125;"/&gt; &lt;property name="poolPreparedStatements" value="$&#123;jdbc.poolPreparedStatements&#125;"/&gt; &lt;property name="maxPoolPreparedStatementPerConnectionSize" value="$&#123;jdbc.maxPoolPreparedStatementPerConnectionSize&#125;"/&gt; &lt;property name="filters" value="$&#123;jdbc.filters&#125;"/&gt; &lt;/bean&gt; &lt;!--配置MyBatis--&gt; &lt;bean id="SqlSessionFactoryBean" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;property name="dataSource" value="#&#123;DruidDataSource&#125;"/&gt; &lt;!--全局文件的位置--&gt; &lt;property name="configLocation" value="classpath:mybatis/mybatis-config.xml"/&gt; &lt;!--指定xml映射文件的位置--&gt; &lt;property name="mapperLocations" value="classpath:mybatis/mapper/*.xml"/&gt; &lt;/bean&gt; &lt;!-- 扫描DAO持久层接口 --&gt; &lt;bean class="org.mybatis.spring.mapper.MapperScannerConfigurer"&gt; &lt;property name="basePackage" value="com.xust.iot.mapper"/&gt; &lt;/bean&gt; &lt;!--配置事物管理器：MyBatis使用的是原生的jdbc,所以使用DataSourceTransactionManager来管理事物--&gt; &lt;bean id="transactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;!--两种配置数据源的方式--&gt; &lt;!-- &lt;property name="dataSource" value="#&#123;DruidDataSource&#125;"/&gt;--&gt; &lt;constructor-arg name="dataSource" value="#&#123;DruidDataSource&#125;"/&gt; &lt;/bean&gt; &lt;!--配置事物策略--&gt; &lt;tx:advice id="tx"&gt; &lt;tx:attributes&gt; &lt;tx:method name="*"/&gt; &lt;tx:method name="update*" isolation="REPEATABLE_READ" propagation="REQUIRED"/&gt; &lt;tx:method name="get*" read-only="true"/&gt; &lt;/tx:attributes&gt; &lt;/tx:advice&gt; &lt;aop:config&gt; &lt;aop:pointcut id="myPointCut" expression="execution(* com.xust.iot.service.*.*(..))"/&gt; &lt;aop:advisor advice-ref="tx" pointcut-ref="myPointCut"/&gt; &lt;/aop:config&gt; &lt;!--开启自动代理--&gt; &lt;aop:aspectj-autoproxy proxy-target-class="true"/&gt;&lt;/beans&gt; jdbc.properties资源文件 1234567891011121314151617jdbc.driver=com.mysql.cj.jdbc.Driverjdbc.url=jdbc:mysql://127.0.0.1:3306/tx?useSSL=falsejdbc.username=rootjdbc.password=95162437jdbc.initialSize=10jdbc.minIdle=10jdbc.maxActive=50jdbc.maxWait=60000jdbc.timeBetweenEvictionRunsMillis=60000jdbc.minEvictableIdleTimeMillis=300000jdbc.validationQuery=SELECT 'x' FROM DUALjdbc.testWhileIdle=truejdbc.testOnBorrow=falsejdbc.testOnReturn=falsejdbc.poolPreparedStatements=truejdbc.maxPoolPreparedStatementPerConnectionSize=20jdbc.filters=wall,stat 对于SSM的配置基本上完成了，下面将使用这个搭建好的框架对对book表进行简单的CRUD操作。 一个简单CRUD1.基本准备创建数据库和表：新建tx数据库，并在tx数据库中新建book表。具体的数据库脚本如下： 1234567891011121314151617181920212223242526272829303132/*!40101 SET NAMES utf8 */;/*!40101 SET SQL_MODE=''*/;/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;CREATE DATABASE /*!32312 IF NOT EXISTS*/`tx` /*!40100 DEFAULT CHARACTER SET gb2312 */;USE `tx`;/*Table structure for table `book` */DROP TABLE IF EXISTS `book`;CREATE TABLE `book` ( `isbn` varchar(50) NOT NULL, `book_name` varchar(100) DEFAULT NULL, `price` int(11) DEFAULT NULL, PRIMARY KEY (`isbn`)) ENGINE=InnoDB DEFAULT CHARSET=utf-8;/*Data for the table `book` */insert into `book`(`isbn`,`book_name`,`price`) values ('ISBN-001','book01',100),('ISBN-002','book02',200),('ISBN-003','book03',300),('ISBN-004','book04',400),('ISBN-005','book05',500);/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */; 2.开发Mapper层（DAO层）在src/main/resources目录下新建mapper目录，在mapper目录下新建BookMapper.xml文件。并在源码包的mappr包下新建对应的BookMapper.java接口。 BookMapper.xml文件 1234567&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE mapperPUBLIC "-//mybatis.org//DTD Mapper 3.0//EN""http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;mapper namespace="com.xust.iot.mapper.BookMapper"&gt;&lt;/mapper&gt; Mapper接口 1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.xust.iot.mapper;import com.xust.iot.bean.Book;import org.apache.ibatis.annotations.Param;import org.springframework.stereotype.Repository;import java.util.List;@Repositorypublic interface BookMapper &#123; /** * 根据图书的ISBN(主键)获得图书信息 * @param isbn * @return */ public Book getBookByISBN(@Param("isbn") String isbn); /** * 得到所有的书 * @return */ public List&lt;Book&gt; getAllBook(); /** * 添加一本书 * @param book * @return */ public void addBook(Book book); /** * 根据isbn更新书 * @param book */ public void updateBookByISBN(Book book); /** * 根据isbn删除一本书 * @param isbn */ public void deleteBookByISBN(@Param("isbn") String isbn);&#125; 这4个接口方法对应的XML代码如下。 1234567891011121314151617181920212223242526272829303132&lt;!--开启二级缓存，当然这里以后可以替换为第三方缓存，例如Enache、Redis...--&gt;&lt;cache&gt;&lt;/cache&gt;&lt;select id="getBookByISBN" resultType="com.xust.iot.bean.Book"&gt; select * from book &lt;where&gt; isbn=#&#123;isbn&#125; &lt;/where&gt;&lt;/select&gt; &lt;select id="getAllBook" resultType="com.xust.iot.bean.Book"&gt; select * from book&lt;/select&gt;&lt;insert id="addBook" parameterType="com.xust.iot.bean.Book"&gt; insert into book(isbn,book_name,price) values(#&#123;isbn&#125;,#&#123;bookName&#125;,#&#123;price&#125;)&lt;/insert&gt;&lt;update id="updateBookByISBN" parameterType="com.xust.iot.bean.Book"&gt; update book &lt;set&gt; book_name=#&#123;bookName&#125;, price=#&#123;price&#125; &lt;/set&gt; &lt;where&gt; isbn=#&#123;isbn&#125; &lt;/where&gt;&lt;/update&gt;&lt;delete id="deleteBookByISBN" parameterType="string"&gt; delete from book where isbn=#&#123;isbn&#125;&lt;/delete&gt; 3.开发业务层（Service层）虽然面向接口编程对于小项目来说并不重要，但是这里为了形式上的需要仍然需要提供Service接口。在src/main/java中新建com.xust.iot.sevice包，然后新建SeviceBase接口。 123456789101112131415package com.xust.iot.service;public interface ServiceBase&lt;T&gt; &#123; public T getById(Object param); public void deleteById(Object param); public void updateAndSave(T t); public void addAndSave(T t); public List&lt;T&gt; getAll();&#125; 在com.xust.iot.service包下新建impl包，然后新建BookService接口的实现类BookServiceImpl。 1234567891011121314151617181920212223242526272829303132333435363738394041package com.xust.iot.service.impl;import com.xust.iot.bean.Book;import com.xust.iot.mapper.BookMapper;import com.xust.iot.service.ServiceBase;import org.springframework.beans.factory.annotation.Autowired;@Servicepublic class BookServiceimpl implements ServiceBase&lt;Book&gt; &#123; @Autowired private BookMapper bookMapper; @Override public Book getById(Object param) &#123; Book book=bookMapper.getBookByISBN(param.toString()); return book; &#125; @Override public void deleteById(Object param) &#123; bookMapper.deleteBookByISBN((String)param); &#125; @Override public void updateAndSave(Book book) &#123; bookMapper.updateBookByISBN(book); &#125; @Override public void addAndSave(Book book) &#123; bookMapper.addBook(book); &#125; @Override public List&lt;Book&gt; getAll() &#123; List&lt;Book&gt; lists=bookMapper.getAllBook(); return lists; &#125;&#125; 4.开发控制层（Controller层）在com.xust.iot.controller包下新建BookController类 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485package com.xust.iot.controller;import com.xust.iot.bean.Book;import com.xust.iot.service.impl.BookServiceImpl;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.ModelAttribute;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;import org.springframework.web.bind.annotation.RequestParam;import java.util.List;@Controllerpublic class BookController &#123; @Autowired private BookServiceImpl bookService; private static boolean isNew = false; @RequestMapping(value = "/save", method = RequestMethod.POST) public String save(@ModelAttribute("book") Book book, Model model) &#123; System.out.println(book); if (isNew) &#123; bookService.addAndSave(book); model.addAttribute("msg", "添加成功！"); &#125; else &#123; bookService.updateAndSave(book); model.addAttribute("msg", "更新成功！"); &#125; return "forward:showAll"; &#125; @RequestMapping("/toUpdatePage") public String toUpdatePage(@ModelAttribute("book") Book book, Model model) &#123; model.addAttribute("book",book); return "edit"; &#125; @RequestMapping("/delete") public String delete(@RequestParam("isbn") String isbn, @RequestParam("pageNo")Integer pageNo, Model model) &#123; bookService.deleteById(isbn); model.addAttribute("msg", "删除成功！"); return "forward:showAll"; &#125; @RequestMapping("/showAll") public String showAllBook(@RequestParam("pageNo")Integer pageNo,Model model) &#123; //分页插件：从pageNo开始显示20条数据，这个语句一定要紧跟着查数据的那条语句，否者分页无效 PageHelper.startPage(pageNo,20); List&lt;Book&gt; lists = bookService.getAll(); //进一步封装数据，PageInfo的两个参数：（数据集合，连续显示的分页个数）,使用这个封装的数据可以拿到首页、末页、上/下一页....信息，非常强大的一个类 PageInfo info=new PageInfo(lists,10); model.addAttribute("info", info); return "bookInfo"; &#125; @ModelAttribute public void check(@RequestParam(value = "isbn", defaultValue = "") String isbn, @RequestParam(value = "bookName", defaultValue = "") String bookName, @RequestParam(value = "price", defaultValue = "") Integer price, Model model) &#123; System.out.println(isbn); Book book = bookService.getById(isbn); //数据库中没有这本书，那就添加一本书 if (null == book) &#123; Book book1 = new Book(); book1.setBookName(bookName); book1.setIsbn(isbn); book1.setPrice(price); model.addAttribute("book", book1); isNew = true; &#125; else &#123; //数据库中有这本书,那就直接拿出来更新信息 isNew = false; model.addAttribute("book", book); &#125; &#125;&#125; 5.开发视图层（View层）index.html 1234567891011&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;添加账户&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h3&gt;&lt;a href="toAdd"&gt;添加图书&lt;/a&gt;&lt;/h3&gt;&lt;h3&gt;&lt;a href="showAll"&gt;所有图书&lt;/a&gt;&lt;/h3&gt;&lt;/body&gt;&lt;/html&gt; 添加图书的页面：add.jsp 12345678910111213141516171819&lt;%@ taglib prefix="c" uri="http://java.sun.com/jsp/jstl/core" %&gt;&lt;%@ page contentType="text/html;charset=UTF-8" language="java" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;添加图书&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;form action="save" method="post"&gt; ISBN： &lt;input type="text" name="isbn"/&gt;&lt;br/&gt; 书名：&lt;input type="text" name="bookName"/&gt;&lt;br/&gt; 价格：&lt;select name="price"&gt; &lt;c:forEach begin="10" end="100" var="price" step="1"&gt; &lt;option &gt;$&#123;price&#125;&lt;/option&gt;元 &lt;/c:forEach&gt; &lt;/select&gt; &lt;button type="submit"&gt;保存&lt;/button&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 展示所有图书信息的页面：bookInfo.jsp 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;%@ taglib prefix="c" uri="http://java.sun.com/jsp/jstl/core" %&gt;&lt;%@ page contentType="text/html;charset=UTF-8" language="java" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;图书信息&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;center&gt;&lt;button &gt;&lt;a href="toAdd"&gt;添加图书&lt;/a&gt;&lt;/button&gt;&lt;table border="1px" cellspacing="0" cellpadding="0" align="center" width="50%"&gt; &lt;tr&gt; &lt;th&gt;图书ISBN编号&lt;/th&gt; &lt;th&gt;书名&lt;/th&gt; &lt;th&gt;价格&lt;/th&gt; &lt;th&gt;操作&lt;/th&gt; &lt;/tr&gt; &lt;c:forEach items="$&#123;info.list&#125;" var="book" varStatus="i"&gt; &lt;tr&gt; &lt;td&gt;$&#123;book.isbn&#125;&lt;/td&gt; &lt;td&gt;$&#123;book.bookName&#125;&lt;/td&gt; &lt;td&gt;$&#123;book.price&#125;&lt;/td&gt; &lt;td&gt;&lt;button&gt;&lt;a href="delete?isbn=$&#123;book.isbn&#125;"&gt;删除&lt;/a&gt;&lt;/button&gt;&lt;button&gt;&lt;a href="toUpdatePage?isbn=$&#123;book.isbn&#125;"&gt;修改&lt;/a&gt;&lt;/button&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/c:forEach&gt; &lt;tr style="align: center"&gt; &lt;td colspan="4" &gt; &lt;button&gt;&lt;a href="showAll?pageNo=1"&gt;首页&lt;/a&gt;&lt;/button&gt; &lt;button&gt;&lt;a href="showAll?pageNo=$&#123;info.getPrePage()&#125;"&gt;上一页&lt;/a&gt;&lt;/button&gt; &lt;span&gt; &lt;c:forEach items="$&#123;info.navigatepageNums&#125;" var="nav"&gt; &lt;c:if test="$&#123;nav==info.pageNum&#125;"&gt; &lt;span style="background-color: greenyellow;border-radius: 5px;width: 30px"&gt;&amp;nbsp;&amp;nbsp;$&#123;nav&#125;&amp;nbsp;&amp;nbsp;&lt;/span&gt; &lt;/c:if&gt; &lt;c:if test="$&#123;nav!=info.pageNum&#125;"&gt; &lt;a style="text-decoration: none" color="black" href="showAll?pageNo=$&#123;nav&#125;"&gt;$&#123;nav&#125;&lt;/a&gt; &lt;/c:if&gt; &lt;/c:forEach&gt; &lt;/span&gt; &lt;button&gt;&lt;a href="showAll?pageNo=$&#123;info.getNextPage()&#125;"&gt;下一页&lt;/a&gt;&lt;/button&gt; &lt;button&gt;&lt;a href="showAll?pageNo=$&#123;info.getPages()&#125;"&gt;末页&lt;/a&gt;&lt;/button&gt; &lt;/td&gt; &lt;/tr&gt;&lt;/table&gt;&lt;span&gt;$&#123;msg&#125;&lt;br/&gt;&lt;/span&gt;&lt;/center&gt;&lt;/body&gt;&lt;/html&gt; 修改图书信息的页面：edit.jsp 12345678910111213141516171819202122232425262728&lt;%@ taglib prefix="c" uri="http://java.sun.com/jsp/jstl/core" %&gt;&lt;%@ page contentType="text/html;charset=UTF-8" language="java" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;修改图书&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;form action="save" method="post"&gt; ISBN： $&#123;book.isbn&#125;&lt;br/&gt;&lt;input type="hidden" name="isbn" value="$&#123;book.isbn&#125;"/&gt; 书名：&lt;input type="text" name="bookName" value="$&#123;book.bookName&#125;"/&gt;&lt;br/&gt; 价格：&lt;select name="price"&gt;&lt;br/&gt; &lt;c:forEach begin="10" end="100" var="price" step="1"&gt; &lt;c:choose&gt; &lt;c:when test="$&#123;price==book.price&#125;"&gt; &lt;option selected&gt;$&#123;price&#125;&lt;/option&gt; &lt;/c:when&gt; &lt;c:when test="$&#123;price!=book.price&#125;"&gt; &lt;option&gt;$&#123;price&#125;&lt;/option&gt; &lt;/c:when&gt; &lt;/c:choose&gt; &lt;/c:forEach&gt;&lt;/select&gt; 元&lt;br/&gt;&lt;button type="submit"&gt;保存&lt;/button&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 最终的测试结果： 总结：经过几个小时的斗争，SSM三大框架的简单整合算是完成了，期间也遇到了这样那样的问题，但都一一解决了，从测试结果来看还是比较成功的。然而代码没有写几行，配置文件写了一大堆，我只想说SpringBoot真香！！！]]></content>
      <categories>
        <category>Spring框架</category>
      </categories>
      <tags>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring声明式事物控制]]></title>
    <url>%2F2019%2F08%2F20%2FSpring%E5%A3%B0%E6%98%8E%E5%BC%8F%E4%BA%8B%E7%89%A9%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;Spring支持编程式事务管理和声明式事务管理两种方式。 &nbsp;&nbsp;&nbsp;&nbsp;编程式事务管理使用TransactionTemplate或者直接使用底层的PlatformTransactionManager。对于编程式事务管理，Spring推荐使用TransactionTemplate。 &nbsp;&nbsp;&nbsp;&nbsp;声明式事务管理建立在AOP之上的。其本质是对方法前后进行拦截，然后在目标方法开始之前创建或者加入一个事务，在执行完目标方法之后根据执行情况提交或者回滚事务。 &nbsp;&nbsp;&nbsp;&nbsp;显然声明式事务管理要优于编程式事务管理，这正是Spring倡导的非侵入式的开发方式。声明式事务管理使业务代码不受污染，一个普通的POJO对象，只要加上注解就可以获得完全的事务支持。和编程式事务相比，声明式事务唯一不足地方是，后者的最细粒度只能作用到方法级别，无法做到像编程式事务那样可以作用到代码块级别。但是即便有这样的需求，也存在很多变通的方法，比如，可以将需要进行事务管理的代码块独立为方法等等。 &nbsp;&nbsp;&nbsp;&nbsp;声明式事务管理也有两种常用的方式，一种是基于tx和aop名字空间的xml配置文件，另一种就是基于@Transactional注解。显然基于注解的方式更简单易用，更清爽。 搭建实验环境首先新建一个Maven项目，导入需要的依赖： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788899091&lt;dependency&gt; &lt;!--单元测试--&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; &lt;!--数据库驱动的依赖包--&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.11&lt;/version&gt;&lt;/dependency&gt;&lt;!--Spring核心--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!--Spring IOC容器--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--Spring Bean工厂--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--SpEL(Spring表达式)--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-expression&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--Spring面向切面编程--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aop&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--提供对AspectJ的支持，以便可以方便的将面向切面的功能集成进IDE中--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--aspectj的runtime包(必须)--&gt;&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjrt&lt;/artifactId&gt; &lt;version&gt;1.9.1&lt;/version&gt;&lt;/dependency&gt;&lt;!--aspectjweaver是aspectj的织入包(必须)--&gt;&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.9.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;cglib&lt;/groupId&gt; &lt;artifactId&gt;cglib&lt;/artifactId&gt; &lt;version&gt;3.1&lt;/version&gt;&lt;/dependency&gt;&lt;!--Spring jdbc--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--Spring 事物--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--Spring 映射--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-orm&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt; 创建数据库和表：新建tx数据库，并在tx数据库中新建三张表account、book、book_stock。具体的数据库脚本如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/*!40101 SET NAMES utf8 */;/*!40101 SET SQL_MODE=''*/;/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;CREATE DATABASE /*!32312 IF NOT EXISTS*/`tx` /*!40100 DEFAULT CHARACTER SET gb2312 */;USE `tx`;/*Table structure for table `account` */DROP TABLE IF EXISTS `account`;CREATE TABLE `account` ( `username` varchar(50) NOT NULL, `balance` int(11) DEFAULT NULL, PRIMARY KEY (`username`)) ENGINE=InnoDB DEFAULT CHARSET=gb2312;/*Data for the table `account` */insert into `account`(`username`,`balance`) values ('Jerry',800),('Tom',100000);/*Table structure for table `book` */DROP TABLE IF EXISTS `book`;CREATE TABLE `book` ( `isbn` varchar(50) NOT NULL, `book_name` varchar(100) DEFAULT NULL, `price` int(11) DEFAULT NULL, PRIMARY KEY (`isbn`)) ENGINE=InnoDB DEFAULT CHARSET=gb2312;/*Data for the table `book` */insert into `book`(`isbn`,`book_name`,`price`) values ('ISBN-001','book01',100),('ISBN-002','book02',200),('ISBN-003','book03',300),('ISBN-004','book04',400),('ISBN-005','book05',500);/*Table structure for table `book_stock` */DROP TABLE IF EXISTS `book_stock`;CREATE TABLE `book_stock` ( `isbn` varchar(50) NOT NULL, `stock` int(11) DEFAULT NULL, PRIMARY KEY (`isbn`)) ENGINE=InnoDB DEFAULT CHARSET=gb2312;/*Data for the table `book_stock` */insert into `book_stock`(`isbn`,`stock`) values ('ISBN-001',1000),('ISBN-002',2000),('ISBN-003',3000),('ISBN-004',4000),('ISBN-005',5000);/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */; 导入后应该是这样的三张表： 基于Annotation的事物管理首先配置数据源，这里使用的阿里的Druid数据连接池 12345678910111213141516171819202122232425262728293031&lt;!--引入外部文件--&gt;&lt;context:property-placeholder location="classpath:jdbc.properties"/&gt;&lt;!--配置数据连接池--&gt;&lt;bean id="DruidDataSource" class="com.alibaba.druid.pool.DruidDataSource"&gt; &lt;property name="username" value="$&#123;jdbc.username&#125;"/&gt; &lt;property name="password" value="$&#123;jdbc.password&#125;"/&gt; &lt;property name="url" value="$&#123;jdbc.url&#125;"/&gt; &lt;property name="driverClassName" value="$&#123;jdbc.driver&#125;"/&gt; &lt;!-- 配置初始化大小、最小、最大 --&gt; &lt;property name="initialSize" value="$&#123;jdbc.initialSize&#125;"/&gt; &lt;property name="minIdle" value="$&#123;jdbc.minIdle&#125;"/&gt; &lt;property name="maxActive" value="$&#123;jdbc.maxActive&#125;"/&gt; &lt;!-- 配置获取连接等待超时的时间 --&gt; &lt;property name="maxWait" value="$&#123;jdbc.maxWait&#125;"/&gt; &lt;!-- 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 --&gt; &lt;property name="timeBetweenEvictionRunsMillis" value="$&#123;jdbc.timeBetweenEvictionRunsMillis&#125;" /&gt; &lt;!-- 配置一个连接在池中最小生存的时间，单位是毫秒 --&gt; &lt;property name="minEvictableIdleTimeMillis" value="$&#123;jdbc.minEvictableIdleTimeMillis&#125;" /&gt; &lt;property name="validationQuery" value="$&#123;jdbc.validationQuery&#125;" /&gt; &lt;property name="testWhileIdle" value="$&#123;jdbc.testWhileIdle&#125;" /&gt; &lt;property name="testOnBorrow" value="$&#123;jdbc.testOnBorrow&#125;" /&gt; &lt;property name="testOnReturn" value="$&#123;jdbc.testOnReturn&#125;" /&gt; &lt;!-- 打开PSCache，并且指定每个连接上PSCache的大小 如果用Oracle，则把poolPreparedStatements配置为true，mysql可以配置为false。--&gt; &lt;property name="poolPreparedStatements" value="$&#123;jdbc.poolPreparedStatements&#125;" /&gt; &lt;property name="maxPoolPreparedStatementPerConnectionSize" value="$&#123;jdbc.maxPoolPreparedStatementPerConnectionSize&#125;" /&gt; &lt;!-- 配置监控统计拦截的filters --&gt; &lt;property name="filters" value="$&#123;jdbc.filters&#125;" /&gt;&lt;/bean&gt; 数据库配置jdbc.properties如下： 1234567891011121314151617jdbc.driver=com.mysql.cj.jdbc.Driverjdbc.url=jdbc:mysql://127.0.0.1:3306/tx?useSSL=falsejdbc.username=rootjdbc.password=95162437jdbc.initialSize=10jdbc.minIdle=10jdbc.maxActive=50jdbc.maxWait=60000jdbc.timeBetweenEvictionRunsMillis=60000jdbc.minEvictableIdleTimeMillis=300000jdbc.validationQuery=SELECT 'x' FROM DUALjdbc.testWhileIdle=truejdbc.testOnBorrow=falsejdbc.testOnReturn=falsejdbc.poolPreparedStatements=truejdbc.maxPoolPreparedStatementPerConnectionSize=20jdbc.filters=wall,stat 配置JdbcTemplate，这里出于学习的目的先使用JdbcTemplate。 1234&lt;!--配置JdbcTemplate--&gt;&lt;bean id="JdbcTemplate" class="org.springframework.jdbc.core.JdbcTemplate"&gt; &lt;constructor-arg name="dataSource" value="#&#123;DruidDataSource&#125;"&gt;&lt;/constructor-arg&gt;&lt;/bean&gt; 配置事物管理器 1234&lt;!--DataSourceTransactionManager适用于使用JDBC来操作数据库的场景--&gt;&lt;bean id="TransactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" value="#&#123;DruidDataSource&#125;"&gt;&lt;/property&gt;&lt;/bean&gt; 配置开启注解事物管理 12&lt;!--开启注解事物管理--&gt;&lt;tx:annotation-driven transaction-manager="TransactionManager"/&gt; 完整的ApplicationContext.xml配置文件如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:aop="http://www.springframework.org/schema/aop" xmlns:tx="http://www.springframework.org/schema/tx" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd http://www.springframework.org/schema/tx http://www.springframework.org/schema/tx/spring-tx.xsd"&gt;&lt;context:component-scan base-package="com.xust.iot"/&gt;&lt;!--引入外部文件--&gt;&lt;context:property-placeholder location="classpath:jdbc.properties"/&gt;&lt;!--配置数据连接池--&gt;&lt;bean id="DruidDataSource" class="com.alibaba.druid.pool.DruidDataSource"&gt; &lt;property name="username" value="$&#123;jdbc.username&#125;"/&gt; &lt;property name="password" value="$&#123;jdbc.password&#125;"/&gt; &lt;property name="url" value="$&#123;jdbc.url&#125;"/&gt; &lt;property name="driverClassName" value="$&#123;jdbc.driver&#125;"/&gt; &lt;!-- 配置初始化大小、最小、最大 --&gt; &lt;property name="initialSize" value="$&#123;jdbc.initialSize&#125;"/&gt; &lt;property name="minIdle" value="$&#123;jdbc.minIdle&#125;"/&gt; &lt;property name="maxActive" value="$&#123;jdbc.maxActive&#125;"/&gt; &lt;!-- 配置获取连接等待超时的时间 --&gt; &lt;property name="maxWait" value="$&#123;jdbc.maxWait&#125;"/&gt; &lt;!-- 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒 --&gt; &lt;property name="timeBetweenEvictionRunsMillis" value="$&#123;jdbc.timeBetweenEvictionRunsMillis&#125;" /&gt; &lt;!-- 配置一个连接在池中最小生存的时间，单位是毫秒 --&gt; &lt;property name="minEvictableIdleTimeMillis" value="$&#123;jdbc.minEvictableIdleTimeMillis&#125;" /&gt; &lt;property name="validationQuery" value="$&#123;jdbc.validationQuery&#125;" /&gt; &lt;property name="testWhileIdle" value="$&#123;jdbc.testWhileIdle&#125;" /&gt; &lt;property name="testOnBorrow" value="$&#123;jdbc.testOnBorrow&#125;" /&gt; &lt;property name="testOnReturn" value="$&#123;jdbc.testOnReturn&#125;" /&gt; &lt;!-- 打开PSCache，并且指定每个连接上PSCache的大小 如果用Oracle，则把poolPreparedStatements配置为true，mysql可以配置为false。--&gt; &lt;property name="poolPreparedStatements" value="$&#123;jdbc.poolPreparedStatements&#125;" /&gt; &lt;property name="maxPoolPreparedStatementPerConnectionSize" value="$&#123;jdbc.maxPoolPreparedStatementPerConnectionSize&#125;" /&gt; &lt;!-- 配置监控统计拦截的filters --&gt; &lt;property name="filters" value="$&#123;jdbc.filters&#125;" /&gt;&lt;/bean&gt;&lt;!--配置JdbcTemplate--&gt;&lt;bean id="JdbcTemplate" class="org.springframework.jdbc.core.JdbcTemplate"&gt; &lt;constructor-arg name="dataSource" value="#&#123;DruidDataSource&#125;"&gt;&lt;/constructor-arg&gt;&lt;/bean&gt;&lt;!--Spring事务控制--&gt;&lt;!--1.配置事务管理器,本身事物管理器是需要我们写一个切面类通过AOP编程的方式来实现，但是Spring提供了我们就直接使用Spring提供的事物管理器--&gt;&lt;bean id="TransactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" value="#&#123;DruidDataSource&#125;"/&gt;&lt;/bean&gt;&lt;!--2.开启基于注解的事物管理--&gt;&lt;!--属性transaction-manager就是事物管理器--&gt;&lt;tx:annotation-driven transaction-manager="TransactionManager"&gt;&lt;/tx:annotation-driven&gt;&lt;!--3.在需要事物的地方用@Transactional来告诉Spring这个地方需要进行事物管理--&gt;&lt;/beans&gt; &nbsp;&nbsp;&nbsp;&nbsp;完成上面的操作后，我们就可以在需要事物管理的地方使用@Transactional注解标注在类或方法上，以此告诉Spring这里需要事物管理。当作用于类上时，该类的所有 public 方法将都具有该类型的事务属性。另外， @Transactional 注解应该只被应用到 public 方法上，这是由 Spring AOP 的本质决定的。如果你在 protected、private 或者默认可见性的方法上使用 @Transactional 注解，这将被忽略，也不会抛出任何异常。@Transactional注解的属性 属性 需要的参数的类型 描述 value String 指定使用的事务管理器(必须) propagation enum:Propagation 事务传播行为设置(可选) isolation enum: Isolation 事务隔离级别设置(可选) readOnly boolean 读写或只读事务，默认（false）读写 timeout int 事务超时时间设置,单位：秒 rollbackFor Class[]，必须继承自Throwable 指定发生异常后哪些异常要回滚 rollbackForClassName String[]，必须继承自Throwable 指定发生异常后哪些异常要回滚的异常类名字数组 noRollbackFor Class[]，必须继承自Throwable 指定发生异常后哪些异常不回滚 noRollbackForClassName String[]，必须继承自Throwable指定发生异常后哪些异常不回滚的异常类名字数组 DAO层，直接使用JdbcTemplate操作数据库，写3个方法分别用于：更新用户余额、更新图书库存、以及查询价格，具体如下： 123456789101112131415161718192021222324252627282930313233343536373839package com.xust.iot.dao;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.jdbc.core.JdbcTemplate;import org.springframework.stereotype.Repository;@Repositorypublic class BookDaoimp &#123; @Autowired JdbcTemplate jdbcTemplate; /** * 减库存 */ public void updateBookStock(Integer books,String isbn)&#123; String sql="update book_stock set stock=stock-? where isbn=?"; jdbcTemplate.update(sql,books,isbn); &#125; /** * 减用户对余额 */ public void updateUserBalance(Integer payment,String username)&#123; String sql="updatess account set balance=balance-? where username=?"; jdbcTemplate.update(sql,payment,username); &#125; /** * 查询图书的价格 * @param isbn * @return */ public Integer getBookPrice(String isbn)&#123; String sql="select price from book where isbn=?"; return jdbcTemplate.queryForObject(sql,Integer.class,isbn); &#125;&#125; 业务层，写一个结账的方法，使用@Transactional告诉Spring要帮我们控制事务 123456789101112131415161718192021222324252627282930313233package com.xust.iot.service;import com.xust.iot.dao.BookDao;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;import org.springframework.transaction.annotation.Transactional;@Servicepublic class BookService &#123; @Autowired BookDao bookDao; /** * 模拟结账 * @param username 用户姓名 * @param isbn 图书编号 * @param books 用户买了几本书 */ @Transactional public void cheockout(String username,String isbn,Integer books)&#123; //减库存 bookDao.updateBookStock(books,isbn); Integer price=bookDao.getBookPrice(isbn); Integer payment=price*books; //减账户余额 bookDao.updateUserBalance(payment,username); &#125;&#125; 基于XML的事物管理其他的步骤和使用注解一样，不同的核心操作在下面： 123456789101112131415161718&lt;!--基于XML的事物管理--&gt;&lt;!--1.配置事务管理器：这个和使用注解时一样--&gt;&lt;bean id="TransactionManager" class="org.springframework.jdbc.datasource.DataSourceTransactionManager"&gt; &lt;property name="dataSource" value="#&#123;DruidDataSource&#125;"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!--2.配置事物属性：使用&lt;tx:advice&gt;标签声明事物通知 --&gt;&lt;tx:advice id="myTransaction" transaction-manager="TransactionManager"&gt; &lt;!--事物属性--&gt; &lt;tx:attributes&gt; &lt;tx:method name="get*" propagation="REQUIRED" read-only="true"/&gt; &lt;tx:method name="cheockout" propagation="REQUIRED" isolation="REPEATABLE_READ"/&gt; &lt;/tx:attributes&gt;&lt;/tx:advice&gt;&lt;!--3.配置事物切入点，把事物切入点和事物属性关联起来--&gt;&lt;aop:config&gt; &lt;aop:pointcut id="pointCut" expression="execution(* com.xust.iot.service.*.*(..))"/&gt; &lt;aop:advisor advice-ref="myTransaction" pointcut-ref="pointCut"/&gt;&lt;/aop:config&gt; 测试在src/main/test包下新建测试类TxTest.java测试 12345678910111213141516171819202122232425262728package test;import com.alibaba.druid.pool.DruidDataSource;import com.xust.iot.service.BookService;import org.junit.Test;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;import org.springframework.jdbc.core.JdbcTemplate;import java.sql.Connection;import java.sql.SQLException;import java.util.Date;public class TxTest &#123; ApplicationContext ioc=new ClassPathXmlApplicationContext("ApplicationContext.xml"); private JdbcTemplate jdbcTemplate=ioc.getBean(JdbcTemplate.class); @Test public void txTest()&#123; BookService bookService=ioc.getBean(BookService.class); bookService.cheockout("Tom","ISBN-005",3); System.out.println("结账成功！"); &#125;&#125;]]></content>
      <categories>
        <category>Spring框架</category>
      </categories>
      <tags>
        <tag>Spring AOP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring和SpringMVC整合]]></title>
    <url>%2F2019%2F08%2F17%2FSpring%E5%92%8CSpringMVC%E6%95%B4%E5%90%88%2F</url>
    <content type="text"><![CDATA[看到这个标题有些同学有点奇怪，SpringMVC是基于Spring的框架，没有必要整合，关于Spring的IOC和bean在springmvc的配置文件里配置就可以了。如果真的这样，那我们的配置文件就面临着难以维护的致命缺点。 正常来说，我们应该将Spring的容器和SpringMVCc的配置文件分开来，在Spring的容器配置IOC和AOP的相关组件，让他只负责各个bean之间的依赖和横切逻辑，而在SpringMVC的配置文件中只负责handler的配置就完全可以了。 因此所谓的整合，实质上是让Spring和SpringMVC明确分工，各司其职。分工的目的总结来说就是： Spring配置文件：配置和业务有关的（事务控制、数据源.....） SpringMVC配置文件：配置和网站转发逻辑和网站功能有关的（视图解析、文件上传、支持ajax.....） 好了，废话不多说，下面直接来看看如何把他两有机的整合在一起。 导包首先，导入jar包这里使用Maven来管理项目，所需的Maven依赖写法如下: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121&lt;properties&gt; &lt;spring.version&gt;5.1.2.RELEASE&lt;/spring.version&gt;&lt;/properties&gt;&lt;dependencies&gt;&lt;!--单元测试--&gt;&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.12&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;!--Spring start--&gt;&lt;!--Core：spring-core、spring-beans、spring-content、spring-expression--&gt;&lt;!--Spring核心--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!--Spring IOC容器--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--Spring Bean工厂--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--SpEL(Spring表达式)--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-expression&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--AOP：spring-aop、spring-aspectj、spring-instrument、spring-instrument-tomcat--&gt;&lt;!--spring aop：外部依赖spring-core， (spring-beans，AOP Alliance， CGLIB，Commons Attributes)--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aop&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--提供对AspectJ的支持，以便可以方便的将面向切面的功能集成进IDE中--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--aspectj的runtime包(必须)--&gt;&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjrt&lt;/artifactId&gt; &lt;version&gt;1.9.1&lt;/version&gt;&lt;/dependency&gt;&lt;!--aspectjweaver是aspectj的织入包(必须)--&gt;&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.9.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;cglib&lt;/groupId&gt; &lt;artifactId&gt;cglib&lt;/artifactId&gt; &lt;version&gt;3.1&lt;/version&gt;&lt;/dependency&gt;&lt;!--Spring Data Access--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--Spring Web--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--spring-mvc--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--Spring Test：spring-test--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--Spring End--&gt;&lt;!--Servlet API--&gt;&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;javax.servlet.jsp&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet.jsp-api&lt;/artifactId&gt; &lt;version&gt;2.2.1&lt;/version&gt;&lt;/dependency&gt;&lt;/dependencies&gt; 写配置web.xml的配置web.xml应该是整个项目最重要的配置文件了，不过servlet3.0中已经支持注解配置方式了。在servlet3.0以前每个servlet必须要在web.xml中配置servlet及其映射关系。但是在spring框架中就不用了，因为Spring中是依赖注入（Dependency Injection）的也叫控制反转（Inversion of Control）。但是也要配置一个重要的servlet，就是前端控制器（DispatcherServlet）。配置方式与普通的servlet基本相似。 配置内容如下： 123456789101112131415&lt;!--配置前段控制器--&gt;&lt;servlet&gt; &lt;servlet-name&gt;Dispatcher&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:springmvc-config.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;!--web容器启动的时候就加载SpringMVC--&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;Dispatcher&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; springmvc-config.xml是SpringMVC的配置文件，稍后讨论他的配置。在web.xml中配置Spring容器： 12345&lt;!--加载Spring容器--&gt;&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt;&lt;/context-param&gt; 配置监听器： 1234&lt;!--配置监听器--&gt;&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;&lt;/listener&gt; 注意：如果你的项目里面不使用 WebApplicationContext 就可以不配置listener节点。但是正常情况下，都会配置ContentLoaderListener，具体参考这位老哥的博客：https://blog.csdn.net/qq_15037231/article/details/78743765。 配置字符编码过滤器： 1234567891011121314151617&lt;!--配置字符编码过滤器--&gt;&lt;filter&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 完整的web.xml配置如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;web-app xmlns="http://xmlns.jcp.org/xml/ns/javaee" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://xmlns.jcp.org/xml/ns/javaee http://xmlns.jcp.org/xml/ns/javaee/web-app_3_1.xsd" version="3.1"&gt;&lt;welcome-file-list&gt; &lt;welcome-file&gt;index.html&lt;/welcome-file&gt;&lt;/welcome-file-list&gt;&lt;!--配置前段控制器--&gt;&lt;servlet&gt; &lt;servlet-name&gt;Dispatcher&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:springmvc-config.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;!--web容器启动的时候就加载SpringMVC--&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;Dispatcher&lt;/servlet-name&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt;&lt;/servlet-mapping&gt;&lt;!--加载Spring容器--&gt;&lt;context-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:applicationContext.xml&lt;/param-value&gt;&lt;/context-param&gt;&lt;!--配置监听器--&gt;&lt;listener&gt; &lt;listener-class&gt;org.springframework.web.context.ContextLoaderListener&lt;/listener-class&gt;&lt;/listener&gt;&lt;!--配置字符编码过滤器--&gt;&lt;filter&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.CharacterEncodingFilter&lt;/filter-class&gt; &lt;init-param&gt; &lt;param-name&gt;encoding&lt;/param-name&gt; &lt;param-value&gt;UTF-8&lt;/param-value&gt; &lt;/init-param&gt; &lt;init-param&gt; &lt;param-name&gt;forceEncoding&lt;/param-name&gt; &lt;param-value&gt;true&lt;/param-value&gt; &lt;/init-param&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;characterEncodingFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt;&lt;/web-app&gt; springmvc-config.xml的配置配置自动扫描：只扫描Controller和ControllerAdvice 12345&lt;!--配置SpringMVC扫描的范围--&gt;&lt;context:component-scan base-package="com.xust.iot" use-default-filters="false"&gt; &lt;context:include-filter type="annotation" expression="org.springframework.stereotype.Controller"&gt;&lt;/context:include-filter&gt; &lt;context:include-filter type="annotation" expression="org.springframework.web.bind.annotation.ControllerAdvice"/&gt;&lt;/context:component-scan&gt; 注意：当使用&lt; context:component-scan /&gt;后，就可以将 &lt; context:annotation-config/&gt;移除。 配置视图解析器： 12345&lt;!--配置视图解析器--&gt;&lt;bean name="viewResolver" class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="prefix" value="WEB-INF/pages/"&gt;&lt;/property&gt; &lt;property name="suffix" value=".jsp"&gt;&lt;/property&gt; &lt;/bean&gt; 配置全局异常处理器：自己先写一个异常处理的类，然后用@ControllerAdvice标注，有啥异常后面开发的时候再写 12&lt;!--配置全局的异常处理器--&gt;&lt;bean id="exceptionHandler" class="com.xust.iot.exception.EntireExceptionHandler"/&gt; 如果项目中有上传文件的需求，那么还需要配置文件上传解析器，一般使用commons-fileupload来上传文件，需要导入的Maven依赖写法如下： 1234567891011121314&lt;!--文件上传--&gt;&lt;!-- https://mvnrepository.com/artifact/commons-fileupload/commons-fileupload --&gt;&lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;version&gt;1.4&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/commons-io/commons-io --&gt;&lt;!--comons-fileupload依赖commons-io,commons-io可以把它看成java IO的加强版--&gt;&lt;dependency&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt;&lt;/dependency&gt; 文件上传的配置如下： 12345&lt;!--文件上传解析器--&gt;&lt;bean id="multipartResolver" class="org.springframework.web.multipart.commons.CommonsMultipartResolver"&gt; &lt;property name="maxUploadSize" value="#&#123;1024*1024*20&#125;"&gt;&lt;/property&gt; &lt;property name="maxUploadSizePerFile" value="#&#123;1024*1024*5&#125;"&gt;&lt;/property&gt;&lt;/bean&gt; 注意：在使用CommonsMultipartResolver时一定要导入commons-fileupload的jar包，否者服务器一启动就会报错。 在上面web.xml中配置的前端控制器拦截了所有的请求，不做特殊处理就会导致部分静态资源无法使用。如果是这种情况就可以使用下面的配置来访问静态资源文件： 12&lt;!--配置默认对静态文件的处理--&gt;&lt;mvc:default-servlet-handler/&gt; 当然，也可以使用下面的配置方式来处理静态资源： 1234&lt;mvc:resources mapping="/images/**" location="/images/" /&gt;&lt;mvc:resources mapping="/css/**" location="/css/" /&gt; &lt;mvc:resources mapping="/js/**" location="/js/" /&gt;&lt;mvc:resources mapping="/imgdata/**" location="/imgdata/" /&gt; 对于静态资源处理如果问题，可以参照这位老哥的博客：https://www.cnblogs.com/dflmg/p/6393416.html。 完整的springmvc-config.xml文件的配置如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:mvc="http://www.springframework.org/schema/mvc" xsi:schemaLocation=" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd"&gt;&lt;!--配置SpringMVC扫描的范围--&gt;&lt;context:component-scan base-package="com.xust.iot" use-default-filters="false"&gt; &lt;context:include-filter type="annotation" expression="org.springframework.stereotype.Controller"&gt;&lt;/context:include-filter&gt; &lt;context:include-filter type="annotation" expression="org.springframework.web.bind.annotation.ControllerAdvice"/&gt;&lt;/context:component-scan&gt;&lt;!--配置默认对静态文件的处理--&gt;&lt;mvc:default-servlet-handler/&gt;&lt;!-- mvc的注解驱动 --&gt;&lt;mvc:annotation-driven/&gt;&lt;!--配置视图解析器--&gt;&lt;bean name="viewResolver" class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="prefix" value="WEB-INF/pages/"&gt;&lt;/property&gt; &lt;property name="suffix" value=".jsp"&gt;&lt;/property&gt;&lt;/bean&gt;&amp;lt;!&amp;ndash;文件上传解析器&amp;ndash;&amp;gt;&lt;bean id="multipartResolver" class="org.springframework.web.multipart.commons.CommonsMultipartResolver"&gt; &lt;property name="maxUploadSize" value="#&#123;1024*1024*20&#125;"&gt;&lt;/property&gt; &lt;property name="maxUploadSizePerFile" value="#&#123;1024*1024*5&#125;"&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!--配置全局的异常处理器--&gt;&lt;bean id="exceptionHandler" class="com.xust.iot.exception.EntireExceptionHandler"/&gt;&lt;/beans&gt; applicationContext.xml的配置配置自动扫描：Spring要扫描的是SpringMVC不扫描的，就是他两扫描的范围互补，因此这里只需要排除SpringMVC扫秒的范围即可。配置如下： 123456&lt;!--配置Spring自动扫描的范围--&gt;&lt;context:component-scan base-package="com.xust.iot"&gt; &lt;!--排除掉SpringMVC扫秒的外，Spring都取扫描--&gt; &lt;context:exclude-filter type="annotation" expression="org.springframework.stereotype.Controller"/&gt; &lt;context:exclude-filter type="annotation" expression="org.springframework.web.bind.annotation.ControllerAdvice"/&gt;&lt;/context:component-scan&gt; 完整的applicationContext.xml包的配置如下： 12345678910111213141516171819&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:aop="http://www.springframework.org/schema/aop" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd"&gt;&lt;!--配置Spring自动扫描的范围--&gt;&lt;context:component-scan base-package="com.xust.iot"&gt; &lt;!--排除掉SpringMVC扫秒的外，Spring都取扫描--&gt; &lt;context:exclude-filter type="annotation" expression="org.springframework.stereotype.Controller"/&gt; &lt;context:exclude-filter type="annotation" expression="org.springframework.web.bind.annotation.ControllerAdvice"/&gt;&lt;/context:component-scan&gt;&lt;/beans&gt; 测试最后写代码来测试一下Service层 12345678910111213141516package com.xust.iot.sevice;import org.springframework.stereotype.Service;@Servicepublic class UserService &#123; public UserService() &#123; System.out.println("初始化UserService......"); &#125; public String hello()&#123; return "Hello,Spring和SpringMVC整合成功！"; &#125;&#125; Controller层 123456789101112131415161718192021222324252627package com.xust.iot.controller;import com.xust.iot.sevice.UserService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.RequestMapping;@Controllerpublic class UserController &#123; @Autowired private UserService userService; public UserController() &#123; System.out.println("初始化UerController....."); &#125; @RequestMapping("/hello") public String hello(Model model)&#123; model.addAttribute("msg",userService.hello()); return "success"; &#125;&#125; 测试结果： 与此同时，控制台的打印的信息如下： 可以看到，两个类都被注册进了各自应该去的容器中。而且都只初始化了一遍。达到了最初的目的。 Spring与SpringMVC父子容器的关系&nbsp;&nbsp;&nbsp;&nbsp;最后，简单的说一下Spring与SpringMVC父子容器的关系&nbsp;&nbsp;&nbsp;&nbsp;Spring源码中默认规定，当Spring和SpringMVC两个容器共存的时候：1. Spring和SpringMVC的容器具有父子关系，Spring容器为父容器，SpringMVC为子容器，子容器可以引用父容器中的Bean，而父容器不可以引用子容器中的Bean;2. Spring容器导入的properties配置文件，只能在Spring容器中用而在SpringMVC容器中不能读取到。 需要在SpringMVC 的配置文件中重新进行导入properties文件，并且同样在父容器Spring中不能被使用，导入后使用@Value(“${key}”)在java类中进行读取。]]></content>
      <categories>
        <category>Spring框架</category>
      </categories>
      <tags>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC异常处理]]></title>
    <url>%2F2019%2F08%2F15%2FSpringMVC%E5%BC%82%E5%B8%B8%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[重要的接口和类HandlerExceptionResolver&nbsp; &nbsp; &nbsp; &nbsp;他是SpringMVC“九大组件”之一,SpringMVC异常处理核心接口。该接口定义了1个解析异常的方法： ExceptionHandlerExceptionResolver &nbsp; &nbsp; &nbsp; &nbsp;继承自AbstractHandlerMethodExceptionResolver，该类主要处理Controller中用@ExceptionHandler注解定义的方法。该类是&lt;annotation-driven/&gt;配置中定义的HandlerExceptionResolver实现类之一，大多数异常处理都是由该类操作。 在Controller中使用@ExceptionHandler 123456789101112131415161718192021222324252627282930313233343536373839package com.xust.iot.controller;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.ExceptionHandler;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.servlet.ModelAndView;import javax.servlet.http.HttpServletResponse;@Controllerpublic class ExceptionHandlerTest &#123;@RequestMapping("/handler1")public String handler1(Model model,@RequestParam(value = "value",required = false) int value)&#123; int i=10/value; model.addAttribute("msg","你好呀！"); model.addAttribute("msg1","10/"+value+"="); model.addAttribute("res",i); return "success";&#125;/** * 使用@ExceptionHandler注解可以告诉SpringMVC这是一个专门处理异常的方法 * 一个方法可处理多个异常，可以有多个处理异常的类 * @param e * @return */@ExceptionHandler(ArithmeticException.class)public ModelAndView exceptionHandler1(Exception e, HttpServletResponse response)&#123; System.out.println("在"+this.getClass().getName()+"中的异常处理方法"); ModelAndView mv=new ModelAndView("error"); mv.addObject("e",e); mv.addObject("statusCode",response.getStatus()); return mv;&#125;&#125; 异常后的页面： 12345678910&lt;%@ page contentType="text/html;charset=UTF-8" language="java" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;出错啦&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h3&gt;出错啦！响应代码：$&#123;status&#125;，错误信息:$&#123;e&#125;&lt;/h3&gt;&lt;/body&gt;&lt;/html&gt; 测试结果： &nbsp; &nbsp; &nbsp; &nbsp;像这样在Controller中借助@ExceptionHandler这个注解定义的异常处理方法只能在定义的那个Controller中使用，当Controller类十分多的时候，那么写异常处理方法就是个体力活了，因此SpringMVC就提供了@ControllerAdvice这个注解,它只能用在类上，而这个类中的异常处理方法都是全局范围，如下定义一个类专门集中处理异常： 1234567891011121314151617181920212223242526272829303132333435package com.xust.iot.handleException;import org.springframework.web.bind.annotation.ControllerAdvice;import org.springframework.web.bind.annotation.ExceptionHandler;import org.springframework.web.servlet.ModelAndView;import javax.servlet.http.HttpServletResponse;@ControllerAdvicepublic class MyExceptionHandler &#123;@ExceptionHandler(ArithmeticException.class)public ModelAndView handleArithmeticException(Exception e,HttpServletResponse response)&#123; ModelAndView mv=new ModelAndView("error"); mv.addObject("status", response.getStatus()); mv.addObject("e",e); return mv;&#125;@ExceptionHandler(NullPointerException.class)public ModelAndView handlerNulPointlException(Exception e,HttpServletResponse response)&#123; ModelAndView mv=new ModelAndView("error"); mv.addObject("status", response.getStatus()); mv.addObject("e",e); return mv;&#125;@ExceptionHandler(Exception.class)public ModelAndView handlerException(Exception e, HttpServletResponse response)&#123; ModelAndView mv=new ModelAndView("error"); mv.addObject("status", response.getStatus()); mv.addObject("e",e); return mv;&#125;&#125; 一个好的异常处理机制应该是这样的，有一个集中的处理点负责所有的异常处理，在真正的业务逻辑的处理过程中，我只会关心正常的业务流程，一旦遇到异常，我只管抛出对应的异常和相关的信息就行了。 DefaultHandlerExceptionResovler&nbsp; &nbsp; &nbsp; &nbsp;HandlerExceptionResolver接口的默认实现之一 ，基本上是Spring MVC内部使用，用来处理Spring定义的各种标准异常，将其转化为相对应的HTTP Status Code。其处理的异常类型有： 123456789101112handleNoSuchRequestHandlingMethodhandleHttpRequestMethodNotSupportedhandleHttpMediaTypeNotSupportedhandleMissingServletRequestParameterhandleServletRequestBindingExceptionhandleTypeMismatchhandleHttpMessageNotReadablehandleHttpMessageNotWritablehandleMethodArgumentNotValidExceptionhandleMissingServletRequestParameterhandleMissingServletRequestPartExceptionhandleBindException ResponseStatusExceptionResovler&nbsp; &nbsp; &nbsp; &nbsp;用来支持@ResponseStatus的使用，处理使用了ResponseStatus注解的异常，根据注解的内容，返回相应的HTTP Status Code和异常页面给客户端。如果Web应用程序中配置了ResponseStatusExceptionResolver，那么我们就可以使用ResponseStatus注解来注解我们自己编写的异常类，并在Controller中抛出该异常类，之后ResponseStatusExceptionResolver就会自动帮我们处理剩下的工作。&lt;annotation-driven/&gt;配置中定义的HandlerExceptionResolver实现类之一。 自定义一个异常 123456789package com.xust.iot.handleException;import org.springframework.http.HttpStatus;import org.springframework.web.bind.annotation.ResponseStatus;@ResponseStatus(reason = "用户不存在",value = HttpStatus.NOT_FOUND)public class UserNotFoundException extends RuntimeException &#123; //......&#125; 另一个自定义异常 12345678package com.xust.iot.handleException;import org.springframework.http.HttpStatus;import org.springframework.web.bind.annotation.ResponseStatus;@ResponseStatus(reason = "输入的登录参数不合法",value = HttpStatus.BAD_REQUEST)public class ParamterIllegalException extends RuntimeException &#123;&#125; 在Controller中主动抛出这个异常看看效果： 12345678910111213141516171819202122232425262728293031323334353637383940package com.xust.iot.controller;import com.xust.iot.beans.User;import com.xust.iot.handleException.ParamterIllegalException;import com.xust.iot.handleException.UserNotFoundException;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.MessageSource;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.ui.ModelMap;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.servlet.i18n.SessionLocaleResolver;import javax.servlet.http.HttpSession;import java.text.SimpleDateFormat;import java.util.Date;import java.util.Locale;@Controllerpublic class UserController &#123;@RequestMapping("/toLogin")public String checkLogIn(@RequestParam(value ="username",defaultValue = "")String username,Model model) throws Throwable &#123; if("".equals(username))&#123; System.out.println("用户登录失败"); throw new ParamaterIllegalException(); &#125;else if(!"admin".equals(username))&#123; System.out.println("用户登录失败"); throw new UserNotFoundException(); &#125; model.addAttribute("msg","欢迎你"+username+",现在是北京时间："+new SimpleDateFormat("hh:mm:ss").format(new Date())); System.out.println("用户登录成功"); return "success";&#125;&#125; 测试结果： ExceptionHandlerExceptionResolver、DefaultHandlerExceptionResolver和ResponseStatusExceptionResolver这三个类是&lt;mvc:annotation-driver&gt;配置后默认的3个实现类，他们的优先级是按书写的顺序由高到底。 SimpleMappingExceptionResovler提供了将异常映射为视图的能力，高度可定制化。其提供的能力有： 根据异常的类型，将异常映射到视图； 可以为不符合处理条件没有被处理的异常，指定一个默认的错误返回； 处理异常时，记录log信息； 指定需要添加到Modle中的Exception属性，从而在视图中展示该属性。在Springmvc配置文件中配置SimpleMappingExceptionResovler12345678910111213&lt;bean class="org.springframework.web.servlet.handler.SimpleMappingExceptionResolver"&gt;&lt;property name="exceptionMappings"&gt; &lt;!--在props标签中配置所有异常后对应的页面,其中: key表示异常，应该写异常的全类名 &lt;prop&gt;标签体写该异常映射的视图名，只写视图名即可，SpringMVC的视图处理器会自动拼串 --&gt; &lt;props&gt; &lt;prop key="java.lang.NullPointerException" &gt;error&lt;/prop&gt; &lt;/props&gt;&lt;/property&gt;&lt;/bean&gt;&lt;!--指定取出错误信息的key--&gt;&lt;property name="exceptionAttribute" value="ex"/&gt; 这样，我们把SimpleMappingExceptionResolver配置好了，这个类在配置的时候还有很多的属性可以配置，如下:]]></content>
      <categories>
        <category>Spring框架</category>
      </categories>
      <tags>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring MVC 资源国际化]]></title>
    <url>%2F2019%2F08%2F15%2FSpringMVC%E8%B5%84%E6%BA%90%E5%9B%BD%E9%99%85%E5%8C%96%2F</url>
    <content type="text"><![CDATA[国际化开发概述软件的国际化：软件开发时，要使它能同时应对世界不同地区和国家的访问，并针对不同地区和国家的访问，提供相应的、符合来访者阅读习惯的页面或数据。国际化(internationalization)又称为 i18n(读法为i 18 n，据说是因为internationalization(国际化)这个单词从i到n之间有18个英文字母，i18n的名字由此而来) 国际化的基本规则国际化信息”也称为“本地化信息”，一般需要两个条件才可以确定一个特定类型的本地化信息，它们分别是“语言类型”和“国家/地区的类型”。如中文本地化信息既有中国大陆地区的中文，又有中国台湾、中国香港地区的中文，还有新加坡地区的中文。Java通过java.util.Locale类表示一个本地化对象，它允许通过语言参数和国家/地区参数创建一个确定的本地化对象。 语言参数使用ISO标准语言代码表示，这些代码是由ISO-639标准定义的，每一种语言由两个小写字母表示。在许多网站上都可以找到这些代码的完整列表，下面的网址是提供了标准语言代码的信息：http://www.loc.gov/standards/iso639-2/php/English_list.php。 国家/地区参数也由标准的ISO国家/地区代码表示，这些代码是由ISO-3166标准定义的，每个国家/地区由两个大写字母表示。用户可以从以下网址查看ISO-3166的标准代码：http://www.iso.ch/iso/en/prods-services/iso3166ma/02iso-3166-code-lists/list-en1.html。下面是常用的国家/地区语言参数： 实现一个简单的国际化编写国际化资源文件国际化资源文件就是用一种key-value的形式把要显示的信息的不同语言的翻译版本写到properties资源文件中：针对美式英文的资源文件： 1234567login_en_US.properties:welcomeInfo=Welcome to my personal blog LoveITerusername=USERNAMEpassword=PASSWORDloginbtn=LOGINplaceholder_username=please input usernameplaceholder_password=please input password 针对简体中文的资源文件： 1234567login_zh_CN.propertieswelcomeInfo=欢迎访问我的个人博客LoveITerusername=用户名password=密码loginbtn=登录placeholder_username=请输入用户名placeholder_password=请输入密码 注意：一般情况下我们用._zh_CN.properties表示中文资源文件，.properties表示默认的资源文件。 在springmvc配置文件中简单的配置一下，把我们的资源文件交给SpringMVC管理 1234 &lt;!--配置国际化资源文件--&gt;&lt;bean id="messageSource" class="org.springframework.context.support.ResourceBundleMessageSource"&gt; &lt;property name="basename" value="login"/&gt;&lt;/bean&gt; 编写一个用户登录表单 12345678910111213141516171819&lt;%@ taglib prefix="fmt" uri="http://java.sun.com/jsp/jstl/fmt" %&gt;&lt;%@ page contentType="text/html;charset=UTF-8" language="java" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;登录&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h3&gt;&lt;fmt:message key="welcomeInfo"/&gt;&lt;/h3&gt;&lt;form action="checkLogin" method="post" &gt; &lt;table&gt; &lt;tr&gt;&lt;th&gt;&lt;fmt:message key="username"/&gt;&lt;/th&gt;&lt;td&gt;&lt;input type="text" placeholder="&lt;fmt:message key='placeholder_username'/&gt;"/&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;th&gt;&lt;fmt:message key="password"/&gt;&lt;/th&gt;&lt;td&gt;&lt;input type="password" placeholder="&lt;fmt:message key='placeholder_password'/&gt;"/&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;th&gt;&lt;input type="submit" value="&lt;fmt:message key="loginbtn"/&gt;"/&gt;&lt;/th&gt;&lt;/tr&gt; &lt;/table&gt;&lt;/form&gt;&lt;/body&gt;&lt;/html&gt; 上面的代码中用到了JSTL中的fmt标签&lt;fmt:message&gt;,因此需要导入对应的jar包。 测试结果：我的浏览器默认就是中文，因此显示的就是中文的欢迎信息： 在火狐浏览器中手动更改语言为英文 英文环境下就显示的是英文信息： 资源文件的编码问题一般我们采用properties文件来保存资源文件。properties文件是以key-value的形式来保存文件的。login_zh_CN.properties中保存的是经过utf-8编码字后的ASCII字符，Unicode字符中不允许出现中文、日文等其他字符的文字。但是Unicode编码后的文字阅读起来比较困难，在IDEA中，可以在File-&gt;Settings-&gt;Editor-&gt;File Encodings设置中勾选Transparent native-to-ascii conversion,如下图，设置好后点击Apply,然后回到刚才编写的中文资源文件发现中文字符全部乱码了，这时可以在编辑器中直接重新输入中文。虽然我们输入的是中文，但是IDEA已经帮我们做了中文转码。 在程序中获取国际化信息在程序中我们可以通过ResourceBundleMessageSource来获取资源文件的信息： 1234567891011121314151617181920212223242526272829303132package com.xust.iot.controller;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.MessageSource;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import java.util.Locale;@Controllerpublic class UserController &#123;@Autowiredprivate MessageSource messageSource;/** * SpringMVC会自动把locale信息注入 * @param locale * @return */@RequestMapping("/toLogin")public String logIn(Locale locale) &#123; System.out.println(locale); String welcomeInfo=messageSource.getMessage("welcomeInfo",null,locale); String userName=messageSource.getMessage("username",null,locale); String password=messageSource.getMessage("password",null,locale); System.out.println(welcomeInfo+"----"+userName+"----"+password); return "login";&#125;&#125; 执行结果：可以看到在不同对语言环境下使用了不同的资源文件。 自定义区域信息解析器3个步骤：1、写一个类实现LocaleResolver接口或他的子接口或继承他的实现类，最主要是要实现它的resolveLocale方法2、在springmvc的配置文件中把我们写的区域信息解析器注册给SpringMVC3、启动测试写一个类实现LocalResolver接口 1234567891011121314151617181920212223242526272829303132333435package com.xust.iot.LocaleResolver;import net.sf.cglib.core.Local;import org.springframework.web.servlet.LocaleResolver;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.util.Locale;public class MyLocaleResolver implements LocaleResolver &#123;/** * 解析locale信息 * @param request * @return */@Overridepublic Locale resolveLocale(HttpServletRequest request) &#123; Locale locale=null; //通过请求解析请求参数中的locale来让用户可以根据自己的习惯选择语言 String localeStr=null!=request.getParameter("locale")?request.getParameter("locale"):""; if(!"".equals(localeStr))&#123; locale=new Locale(localeStr.split("_")[0],localeStr.split("_")[1]); &#125;else&#123; locale=request.getLocale(); &#125; return locale;&#125;@Overridepublic void setLocale(HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse, Locale locale) &#123;&#125;&#125; 配置自定义的解析器 12&lt;!--自定义区域信息解析器--&gt;&lt;bean id="localeResolver" class="com.xust.iot.LocaleResolver.MyLocaleResolver"/&gt; 注意：解析器的id必须是localeResolver，如果写错了就没有效果了。至于为啥非要这么写请参考SpringMVC源码中的DispatcherServlet这个类。 在页面中加入可以切换语言的链接： 1234567891011121314151617181920&lt;%@ taglib prefix="fmt" uri="http://java.sun.com/jsp/jstl/fmt" %&gt;&lt;%@ page contentType="text/html;charset=UTF-8" language="java" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;登录&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h3&gt;&lt;fmt:message key="welcomeInfo"/&gt;&lt;/h3&gt;&lt;form action="checkLogin" method="post" &gt; &lt;table&gt; &lt;tr&gt;&lt;th&gt;&lt;fmt:message key="username"/&gt;&lt;/th&gt;&lt;td&gt;&lt;input type="text" placeholder="&lt;fmt:message key='placeholder_username'/&gt;"/&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;th&gt;&lt;fmt:message key="password"/&gt;&lt;/th&gt;&lt;td&gt;&lt;input type="password" placeholder="&lt;fmt:message key='placeholder_password'/&gt;"/&gt;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;th&gt;&lt;input type="submit" value="&lt;fmt:message key="loginbtn"/&gt;"/&gt;&lt;/th&gt;&lt;/tr&gt; &lt;/table&gt;&lt;/form&gt;&lt;a href="toLogin?locale=zh_CN"&gt;&lt;fmt:message key="Chinese"/&gt;&lt;/a&gt;|&lt;a href="toLogin?locale=en_US"&gt;&lt;fmt:message key="English"/&gt;&lt;/a&gt;&lt;/body&gt;&lt;/html&gt; 测试结果： SessionLocaleResolver 从SpringMVC的区域信息的继承图中我么看到了几个特别的区域信息解析器： 1、AcceptHeaderLocaleResolver：它是SpringMVC默认装配的区域信息解析器，他会默认从 accept-language请求头信息进行解析处理，通常这个头信息包含客户端操作信息的本地标示。它不支持通过链接的方式改变locale信息。 2、FixedLocaleResolver：从字面意思就可以知道，这也是一个不支持通过链接的方式改变locale信息的一个解析器，它默认会从操作系统拿locale信息。 3、SessionocaleResolver：从session中拿locale信息，允许设置区域信息。 4、CookieLocaleResolver：从Cookie中拿locale信息，允许设置区域信息。 下面我们借助SessionLocaleResolver来实现我们上面自定义区域信息解析器的功能： 123456789101112131415161718192021222324252627282930313233343536373839package com.xust.iot.controller;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.context.MessageSource;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.ui.ModelMap;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;import org.springframework.web.servlet.i18n.SessionLocaleResolver;import javax.servlet.http.HttpSession;import java.util.Locale;@Controllerpublic class UserController &#123;@Autowiredprivate MessageSource messageSource;@RequestMapping("/toLogin")public String logIn( @RequestParam(value = "locale",defaultValue = "zh_CN") String localeStr, Model model, Locale locale, HttpSession session) &#123; Locale l=null; if(null!=localeStr&amp;&amp;!"".equals(localeStr))&#123; l=new Locale(localeStr.split("_")[0],localeStr.split("_")[1]); &#125;else&#123; l=locale; &#125; session.setAttribute(SessionLocaleResolver.class.getName() + ".LOCALE",l); return "login";&#125;&#125; 测试结果： 使用LocaleChangeInterceptor通过配置LocaleChangeInterceptor，我们可以动态改变本地语言。从他的名字就可以知道他是一个可改变Locale信息的拦截器，熟悉Spring MVC拦截器的同学都知道，如果配置了拦截器，Spring MVC会在处理请求之前调用拦截器的preHandle方法，而LocaleChangeInterceptor就是在真正开启处理请求之前先调用LoacleResolver的方法setLocal()设置了本地化信息。 既然是拦截器，要使用他就需要在springmvc配置文件中配置它，配置也很简单： 123&lt;mvc:interceptors&gt; &lt;bean id="localeChangeInterceptor" class="org.springframework.web.servlet.i18n.LocaleChangeInterceptor"/&gt;&lt;/mvc:interceptors&gt; 然后在配合SessionLocaleResovler，实现动态的改变本地信息 1234567&lt;!--SessionLocaleResolver--&gt;&lt;bean id="localeResolver" class="org.springframework.web.servlet.i18n.SessionLocaleResolver"/&gt;&lt;!--资源国际化拦截器--&gt;&lt;mvc:interceptors&gt; &lt;bean id="localeChangeInterceptor" class="org.springframework.web.servlet.i18n.LocaleChangeInterceptor"/&gt;&lt;/mvc:interceptors&gt; 控制器层的代码瞬间变得极其简练，就一个跳转页面对返回语句 12345678910@Controllerpublic class UserController &#123;@RequestMapping("/toLogin")public String logIn() &#123; return "login";&#125;&#125; 测试结果：]]></content>
      <categories>
        <category>Spring框架</category>
      </categories>
      <tags>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC拦截器]]></title>
    <url>%2F2019%2F08%2F14%2FSpringMVC%E6%8B%A6%E6%88%AA%E5%99%A8(Interceptor)%2F</url>
    <content type="text"><![CDATA[拦截器概述什么是拦截器？Spring MVC中的拦截器（Interceptor）类似于Servlet中的过滤器（Filter），但是比过滤器的功能更加强大，它主要用于拦截用户请求并作相应的处理。例如通过拦截器可以进行权限验证、记录请求信息的日志、判断用户是否登录等。要使用Spring MVC中的拦截器，就需要对拦截器类进行定义和配置。通常拦截器类可以通过两种方式来定义：1.通过实现HandlerInterceptor接口，或继承HandlerInterceptor接口的实现类（如HandlerInterceptorAdapter）来定义。 2.通过实现WebRequestInterceptor接口，或继承WebRequestInterceptor接口的实现类来定义。 #### 实现第一个拦截器 以实现HandlerInterceptor接口方式为例，自定义拦截器类的代码如下： 123456789101112131415161718192021222324252627282930package com.xust.iot.interceptor;import org.springframework.web.servlet.HandlerInterceptor;import org.springframework.web.servlet.ModelAndView;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;public class MyFirstInterceptor implements HandlerInterceptor &#123;@Overridepublic boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; System.out.println("1.执行目标方法之前......"); //返回true表示放行，可以去执行目标方法，否者表示不允许执行目标方法 return true;&#125;@Overridepublic void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; System.out.println("3.执行目标方法之后......");&#125;@Overridepublic void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; System.out.println("5.来到页面之后......");&#125;&#125; 上述代码中，自定义拦截器实现了HandlerInterceptor接口，并实现了接口中的三个方法： preHandle()：在目标方法执行之前回执行，有个boolean类型的返回值，当返回true表示放行，即允许执行目标方法;当返回false，表示不放行，即不运行执行目标方法，此时会中断以后的所有过程 postHandle()：在目标方法执行结束后会执行，且解析视图之前执行 afterCompletion()：在请求到达页面，即视图渲染完成后执行 开发拦截器就像开发servlet或者filter一样，都需要在配置文件进行配置，配置代码如下： 12345&lt;!--拦截器--&gt;&lt;mvc:interceptors&gt; &lt;!--这样配置的拦截器默认拦截所有请求--&gt; &lt;bean id="myInterceptor" class="com.xust.iot.interceptor.MyFirstInterceptor"/&gt;&lt;/mvc:interceptors&gt; 上面的代码中，&lt;mvc:interceptors&gt;元素用于配置一组拦截器，子元素&lt;bean&gt;中定义的是全局拦截器，它会拦截所有的请求；而也可以使用&lt;mvc:interceptor&gt;元素中定义指定路径的拦截器，它会对指定路径下的请求生效。&lt;mvc:interceptor&gt;元素的子元素&lt;mvc:mapping&gt;用于配置拦截器作用的路径，该路径在其属性path 中定义。如果在请求路径中包含不需要拦截的内容，还可以通过&lt;mvc:exclude-mapping&gt;元素进行配置。注意：&lt;mvc:interceptor&gt;中的子元素必须按照上述代码中的配置顺序进行编写，即&lt;mvc:mapping&gt; &lt;mvc:exclude-mapping&gt; &lt;bean&gt;，否则文件会报错。 下面写一个控制器来测试一下正常情况下单个拦截器的工作流程： 123456789101112131415161718package com.xust.iot.controller;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.RequestMapping;@Controllerpublic class IntercrtorTestController &#123;@RequestMapping(value = "/test01")public String handler01(Model model)&#123; System.out.println("2.执行了目标方法......"); model.addAttribute("msg","你好啊！！!"); return "success";&#125;&#125; 目标页面success.jsp 1234567891011121314&lt;%@ page contentType="text/html;charset=UTF-8" language="java" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;成功&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;% System.out.println("4.来到了success.jsp页面");%&gt;$&#123;msg&#125;&lt;/body&gt;&lt;/html&gt; 测试结果 单个拦截器正常情况下的工作流程： 1. 拦截器preHandle方法执行，返回true继续以后的过程 2. 控制器目标方法执行 3. 拦截器postHandle方法执行 4. 页面渲染完成来到页面 5. 拦截器afterCompletion方法执行 单个拦截器非正常情况下的工作流程：单个拦截器的非正常情况分为两种情况：&nbsp;&nbsp;&nbsp;&nbsp;1、拦截器中的preHandler方法返回false;&nbsp;&nbsp;&nbsp;&nbsp;2、虽然preHandler方法返回了true，但是其中有一个过程“炸了”，比如发生了异常没有处理接下来通过代码来测试： 第一种情况：preHandler返回false123456789101112131415161718192021222324252627282930package com.xust.iot.interceptor;import org.springframework.web.servlet.HandlerInterceptor;import org.springframework.web.servlet.ModelAndView;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;public class MyFirstInterceptor implements HandlerInterceptor &#123;@Overridepublic boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; System.out.println("1.执行目标方法之前......"); //返回true表示放行，可以去执行目标方法，否者表示不允许执行目标方法 return false;&#125;@Overridepublic void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; System.out.println("3.执行目标方法之后......");&#125;@Overridepublic void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; System.out.println("5.来到页面之后......");&#125;&#125; 测试结果：可以看到，后面的过程直接无法执行 第二种情况：preHandle方法放行了，但是有一个过程“炸了”,比如我们在控制器目标方法中制造一个异常：12345678910111213141516171819package com.xust.iot.controller;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.RequestMapping;@Controllerpublic class IntercrtorTestController &#123;@RequestMapping(value = "/test01")public String handler01(Model model)&#123; int i=30/0; System.out.println("2.执行了目标方法......"); model.addAttribute("msg","你好啊！！!"); return "success";&#125;&#125; 测试结果： 可以看到，只要拦截器的prehandle方法放行了，拦截器的afterCompletion方法总会执行/font> 多个拦截器正常情况下的工作流程：第二个拦截器： 1234567891011121314151617181920212223242526package com.xust.iot.interceptor;import org.springframework.web.servlet.HandlerInterceptor;import org.springframework.web.servlet.ModelAndView;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;public class MySecondInterceptor implements HandlerInterceptor &#123;@Overridepublic boolean preHandle(HttpServletRequest request, HttpServletResponse response, Object handler) throws Exception &#123; System.out.println("1.执行目标方法之前......MySecondInterceptor"); return true;&#125;@Overridepublic void postHandle(HttpServletRequest request, HttpServletResponse response, Object handler, ModelAndView modelAndView) throws Exception &#123; System.out.println("3.执行目标方法之后......MySecondInterceptor");&#125;@Overridepublic void afterCompletion(HttpServletRequest request, HttpServletResponse response, Object handler, Exception ex) throws Exception &#123; System.out.println("5.来到页面之后......MySecondInterceptor");&#125;&#125; 配置第二个拦截器 12345678910111213&lt;!--拦截器--&gt;&lt;mvc:interceptors&gt; &lt;!--拦截器1--&gt; &lt;!--这样配置的拦截器默认拦截所有请求--&gt; &lt;bean id="myInterceptor" class="com.xust.iot.interceptor.MyFirstInterceptor"/&gt; &lt;!--拦截器2--&gt; &lt;!--使用&lt;mvc:interceptor&gt;可以具体配置拦截器拦截那些请求&gt;--&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path="/test01"/&gt; &lt;bean class="com.xust.iot.interceptor.MySecondInterceptor"/&gt; &lt;/mvc:interceptor&gt;&lt;/mvc:interceptors&gt; 执行结果： 交换拦截器在springmvc配置文件中的定义顺序： 12345678910111213&lt;!--拦截器--&gt;&lt;mvc:interceptors&gt; &lt;!--拦截器2--&gt; &lt;!--使用&lt;mvc:interceptor&gt;可以具体配置拦截器拦截那些请求&gt;--&gt; &lt;mvc:interceptor&gt; &lt;mvc:mapping path="/test01"/&gt; &lt;bean class="com.xust.iot.interceptor.MySecondInterceptor"/&gt; &lt;/mvc:interceptor&gt; &lt;!--拦截器1--&gt; &lt;!--这样配置的拦截器默认拦截所有请求--&gt; &lt;bean id="myInterceptor" class="com.xust.iot.interceptor.MyFirstInterceptor"/&gt;&lt;/mvc:interceptors&gt; 执行结果： 测试结果表明： 多个拦截器是有执行的先后顺序的，这个顺序就是定义的先后顺序 拦截器的preHandle方法：按照定义顺序顺序执行的 拦截器的postHandle方法：按照定义顺序逆序执行的 拦截器的preHandle方法：按照定义顺序顺逆序执行的 多个拦截器非正常情况下的工作流程：1、一个拦截器的preHandle方法返回false的情况： 2、所有拦截器的preHandle方法都返回true,但是中间有过程发生了异常： 小结单拦截器的执行顺序 正常情况下会按照：preHandle--->目标方法--->postHnadle--->页面渲染--->afterCompetion执行 当preHandle返回false,就没有以后流程的事儿了 当preHandler返回了true,但是中间过程发生异常，会直接结束以后的流程但是afterCompetion总会执行 多个拦截器的执行顺序正常情况 会按照配置中定义的顺序顺序执行所有拦截器的preHandle方法，然后执行控制器中目标方法，之后按照定义顺序的逆序执行postHandle方法，然后渲染页面，最后按照定义的顺序的逆序执行afterComprtion方法 有拦截器返回false 在多个拦截器中只要有一个拦截器的preHandle方法返回了false,那么以后的流程都没有了，会直接回按照这些拦截器配置的定义顺序的逆序执行afterCompetion方法]]></content>
      <categories>
        <category>Spring框架</category>
      </categories>
      <tags>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC文件下载和上传]]></title>
    <url>%2F2019%2F08%2F13%2FSpringMVC%E6%96%87%E4%BB%B6%E4%B8%8B%E8%BD%BD%E5%92%8C%E4%B8%8A%E4%BC%A0%2F</url>
    <content type="text"><![CDATA[文件下载文件下载的最重要的一点是设置响应头的Content-disposition为attachmen;filename=要下载的文件的名字,然后得到文件的输入流写入本地即可1. 常规方法 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758/** * 第一种文件下载的方法：使用原生的Servlet API * * @param filename 下载的文件名，SpringMVC会根据请求参数自动注入 * @param request * @param response * @throws UnsupportedEncodingException */@RequestMapping(value="/download1",method=RequestMethod.GET)public void download(@ResuestParam("filename")String fileName, HttpServletRequest request, HttpServletResponse response) throws UnsupportedEncodingException &#123; response.setContentType("text/html;charset=utf-8"); //解析文件在服务器中的真实路径 String filePath = request.getServletContext().getRealPath("/download/" + fileName); //System.out.println(filePath); BufferedInputStream bis = null; BufferedOutputStream bos = null; try &#123; //设置响应头告诉客户端浏览器，这个请求是要下载文件 long fileLength = new File(filePath).length(); response.setContentType("application/x-msdownload;"); response.setHeader("Content-disposition", "attachment;filename=" + fileName); response.setHeader("Content-Length", String.valueOf(fileLength)); //向客户端浏览器写文件数据 bis = new BufferedInputStream(new FileInputStream(filePath)); bos = new BufferedOutputStream(response.getOutputStream()); byte[] buff = new byte[1024]; int len; while (-1 != (len = bis.read(buff, 0, buff.length))) &#123; bos.write(buff, 0, len); &#125; &#125; catch (FileNotFoundException e) &#123; e.printStackTrace(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; finally &#123; if (null != bis) &#123; try &#123; bis.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; if (null != bos) &#123; try &#123; bos.close(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 2. 使用SpringMVC提供的 ResponseEntity&lt;T&gt;类型，使用它可以很方便地定义返回的HttpHeaders和HttpStatus。 123456789101112131415161718192021222324252627282930313233343536/** *第二种文件下载的方式：使用SpringMVC提供的esponseEntity类型 * @param filename 下载的文件的名字，通过前端页面的请求参数带过来后SpringMVC会自动注入 * @param request * @return * @throws IOException */@RequestMapping(value = "/download2",method = RequestMethod.GET)public ResponseEntity&lt;byte[]&gt; download(String filename, HttpServletRequest request) throws IOException &#123; System.out.println(filename); //得到文件在服务器上的真实物理路径 String filePath = request.getServletContext().getRealPath("/download/" + filename); /** * 两个把下载文件转成byte[]的办法：一种是把要下载的文件封装成一个File对象，把这个对象交给FileCopyUtils.copyToByteArray(file) */ File file = new File(filePath); /** * 另一种方法是：自己写一个转换的方法，如下 */ /*FileInputStream fis = new FileInputStream(filePath); byte[] file = new byte[fis.available()]; fis.read(); fis.close();*/ String downFileName = new String(filename.getBytes("utf-8"), "iso-8859-1"); HttpHeaders headers = new HttpHeaders(); //这是文件下载关键:设置contentDisposition为attachment headers.setContentDispositionFormData("attachment", downFileName); headers.setContentType(MediaType.APPLICATION_OCTET_STREAM); return new ResponseEntity&lt;byte[]&gt;(FileCopyUtils.copyToByteArray(file), headers, HttpStatus.OK);&#125; 下载页面 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;%@ page contentType="text/html;charset=UTF-8" language="java" %&gt;&lt;%pageContext.setAttribute("ctp",request.getContextPath());%&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;下载高清图片&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h2&gt;高清壁纸下载&lt;/h2&gt;&lt;table&gt;&lt;tr&gt; &lt;th&gt; &lt;img src="../..$&#123;ctp&#125;/download/18.jpg" width="420px" height="320px"&gt;&lt;br/&gt; &lt;button&gt;&lt;a href="download1?filename=18.jpg"&gt;使用Servlet API下载&lt;/a&gt;&lt;/button&gt; &lt;button&gt;&lt;a href="download2?filename=18.jpg"&gt;使用SpringMVC框架下载&lt;/a&gt;&lt;/button&gt; &lt;/th&gt; &lt;th&gt; &lt;img src="../..$&#123;ctp&#125;/download/13.jpg" width="420px" height="320px"&gt;&lt;br/&gt; &lt;button&gt;&lt;a href="download1?filename=13.jpg"&gt;使用Servlet API下载&lt;/a&gt;&lt;/button&gt; &lt;button&gt;&lt;a href="download2?filename=13.jpg"&gt;使用SpringMVC框架下载&lt;/a&gt;&lt;/button&gt; &lt;/th&gt; &lt;th&gt; &lt;img src="../..$&#123;ctp&#125;/download/14.jpg" width="420px" height="320px"&gt;&lt;br/&gt; &lt;button&gt;&lt;a href="download1?filename=14.jpg"&gt;使用Servlet API下载&lt;/a&gt;&lt;/button&gt; &lt;button&gt;&lt;a href="download2?filename=14.jpg"&gt;使用SpringMVC框架下载&lt;/a&gt;&lt;/button&gt; &lt;/th&gt;&lt;/tr&gt;&lt;tr&gt; &lt;th&gt; &lt;img src="../..$&#123;ctp&#125;/download/15.jpg" width="420px" height="320px"&gt;&lt;br/&gt; &lt;button&gt;&lt;a href="download1?filename=15.jpg"&gt;使用Servlet API下载&lt;/a&gt;&lt;/button&gt; &lt;button&gt;&lt;a href="download2?filename=15.jpg"&gt;使用SpringMVC框架下载&lt;/a&gt;&lt;/button&gt; &lt;/th&gt; &lt;th&gt; &lt;img src="../..$&#123;ctp&#125;/download/16.jpg" width="420px" height="320px"&gt;&lt;br/&gt; &lt;button&gt;&lt;a href="download1?filename=16.jpg"&gt;使用Servlet API下载&lt;/a&gt;&lt;/button&gt; &lt;button&gt;&lt;a href="download2?filename=16.jpg"&gt;使用SpringMVC框架下载&lt;/a&gt;&lt;/button&gt; &lt;/th&gt; &lt;th&gt; &lt;img src="../..$&#123;ctp&#125;/download/17.jpg" width="420px" height="320px"&gt;&lt;br/&gt; &lt;button&gt;&lt;a href="download1?filename=17.jpg"&gt;使用Servlet API下载&lt;/a&gt;&lt;/button&gt; &lt;button&gt;&lt;a href="download2?filename=17.jpg"&gt;使用SpringMVC框架下载&lt;/a&gt;&lt;/button&gt; &lt;/th&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/body&gt;&lt;/html&gt; 测试结果 文件上传文件上传这里使用的是commons-fileupload-1.4,他需要依赖commons-io,他们的Maven依赖如下： 12345678910111213&lt;!--文件上传--&gt;&lt;!-- https://mvnrepository.com/artifact/commons-io/commons-io --&gt;&lt;dependency&gt; &lt;groupId&gt;commons-io&lt;/groupId&gt; &lt;artifactId&gt;commons-io&lt;/artifactId&gt; &lt;version&gt;2.6&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/commons-fileupload/commons-fileupload --&gt;&lt;dependency&gt; &lt;groupId&gt;commons-fileupload&lt;/groupId&gt; &lt;artifactId&gt;commons-fileupload&lt;/artifactId&gt; &lt;version&gt;1.4&lt;/version&gt;&lt;/dependency&gt; 1. 单文件上传上传表单页面文件上传需要将表单的提交方法设置为post，将enctype的值设置为”multipart/form-data”。 1234567&lt;!--单文件上传--&gt;&lt;h3&gt;单文件上传&lt;/h3&gt;&lt;form action="$&#123;ctp&#125;/uploadImg" method="post" enctype="multipart/form-data"&gt; 头像： &lt;input type="file" name="headerImg"/&gt;&lt;br/&gt; 用户名：&lt;input type="text" name="username"/&gt;&lt;br/&gt; &lt;button type="submit"&gt;提交&lt;/button&gt;&lt;br/&gt;&lt;/form&gt; 控制器在Controller的处理方法中，使用MultipartFile对象作为参数接收前端上传过来的文件 12345678910111213141516171819202122232425262728293031323334353637383940//单个文件上传@RequestMapping("/uploadImg")public String ImgUpload( @RequestParam("username") String userName, @RequestParam("headerImg") MultipartFile file, HttpServletRequest request, Model model) &#123; String date = new SimpleDateFormat("yyyy-MM-dd").format(new Date()); try &#123; //得到服务器上传文件的文件夹物理路径 String realPath = request.getServletContext().getRealPath("/upload/"); File dir=new File(realPath+date+"//"); if(!dir.exists())&#123; boolean res=dir.mkdir(); if(!res)&#123; model.addAttribute("msg", "文件上传失败！请重试！"); return null; &#125; &#125; //解析文件后缀名 String fileName = file.getOriginalFilename(); String suffix = fileName.substring(fileName.lastIndexOf("."), fileName.length()); if(".jpg".equals(suffix)||".png".equals(suffix)||".gif".equals(suffix)||".jpeg".equals(suffix)||"bmp".equals(suffix)) &#123; //给上传的文件重新命名 File newFileName = new File(dir.toString() + "//" + System.currentTimeMillis() + suffix); //保存文件到服务器 file.transferTo(newFileName); model.addAttribute("msg", "文件上传成功！"); &#125;else&#123; model.addAttribute("msg","文件上传失败！只支持jpeg, jpg, png, gif, bmp 格式的图片文件"); &#125; &#125; catch (Exception e) &#123; model.addAttribute("msg", "文件上传失败！"); &#125; return "fileUpLoad";&#125; 在springmvc配置文件中注册文件上传组件使用MultipartFile对象接收前端上传过来的文件，还需要在springmvc的配置文件中进行如下配置： 12345678910111213141516171819202122&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:mvc="http://www.springframework.org/schema/mvc" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd"&gt;&lt;!--文件上传解析器的id是固定的，必须是multipartResolver--&gt;&lt;bean id="multipartResolver" class="org.springframework.web.multipart.commons.CommonsMultipartResolver"&gt; &lt;!--上传的文件总大小50M--&gt; &lt;property name="maxUploadSize" value="#&#123;1024*1024*50&#125;"/&gt; &lt;!--单个文件最大5M--&gt; &lt;property name="maxUploadSizePerFile" value="#&#123;1024*1024*5&#125;"/&gt; &lt;!--默认的字符编码：utf-8--&gt; &lt;property name="defaultEncoding" value="UTF-8"/&gt;&lt;/bean&gt;&lt;/beans&gt; 多文件上传其实多文件上传也很简单，单文件上传是在Controller的处理方法中使用MultipartFile对象作为参数接收前端上传过来的文件，而多文件上传则使用MultipartFile对象数组来接收。 页面该页面中有几个name值一样的file类型的input标签，其他跟单文件上传的页面没区别。 123456789&lt;h3&gt;一次选一个文件，一次提交上传多个文件&lt;/h3&gt;&lt;form action="$&#123;ctp&#125;/upload2" method="post" enctype="multipart/form-data"&gt; 头像： &lt;input type="file" name="headerImg"/&gt;&lt;br/&gt; 图片： &lt;input type="file" name="headerImg"/&gt;&lt;br/&gt; 资料： &lt;input type="file" name="headerImg"/&gt;&lt;br/&gt; 文件： &lt;input type="file" name="headerImg"/&gt;&lt;br/&gt; 用户名：&lt;input type="text" name="username"/&gt;&lt;br/&gt; &lt;button type="submit"&gt;提交&lt;/button&gt;&lt;br/&gt;&lt;/form&gt; 控制器 123456789101112131415161718192021222324252627282930313233343536373839404142434445@Controllerpublic class FileUpLoadController &#123;@RequestMapping("/upload2")public String upload(@RequestParam("username") String userName, @RequestParam("headerImg") MultipartFile[] files, HttpServletRequest request, Model model) &#123; String realPath = request.getServletContext().getRealPath("/upload/"); File dir = new File(realPath + date +"//"+userName+"//"); if (!dir.exists()) &#123; boolean res = dir.mkdirs(); if (!res) &#123; model.addAttribute("msg", "文件上传失败！请重试！"); return null; &#125; &#125; for (MultipartFile file : files) &#123; uploadFile(dir.toString(), file, model); &#125; return "fileUpLoad";&#125;public void uploadFile(String path, MultipartFile file, Model model) &#123; try &#123; if (!file.isEmpty()) &#123; String fileName = file.getOriginalFilename(); String suffix = fileName.substring(fileName.lastIndexOf("."), fileName.length()); //给上传的文件重新命名 File newFileName = new File(path + "//" + System.currentTimeMillis() + suffix); System.out.println(newFileName); //保存文件到服务器 file.transferTo(newFileName); model.addAttribute("msg", "文件上传成功！"); &#125; &#125; catch (Exception e) &#123; model.addAttribute("msg", "文件上传失败！" + e); &#125;&#125;&#125; 同样的，使用MultipartFile数组接收前端上传过来的多个文件，也需要在springmvc的配置文件进行配置，具体配置与上述单文件上传的springmvc.xml配置没差别。这样，就可以进行多文件上传了。 多种文件上传情景综合当然，项目开发中，场景可能并不是这么简单，上述的多文件上传是一个个文件选择后一起上传（即多个name相同的input标签），那要是我项目中只要一个input标签就可以一次性多个文件呢？又或者一个页面中既要一个个选择的多文件上传，又要一次性选择的多文件上传，还要有单文件上传呢？没问题，MultipartFile[]通吃，代码也很easy，下面直接上代码。 页面 1234567891011121314151617181920212223242526&lt;%@ page contentType="text/html;charset=UTF-8" language="java" %&gt;&lt;% pageContext.setAttribute("ctp",request.getContextPath());%&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;文件上传&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;form action="$&#123;ctp&#125;/upload3" method="post" enctype="multipart/form-data"&gt; &lt;!--一次选择一个文件的多文件上传--&gt; 头像： &lt;input type="file" name="headerImg"/&gt;&lt;br/&gt; &lt;!--一次选择一个文件的多文件上传 --&gt; &lt;input type="file" name="img"/&gt;&lt;br/&gt; &lt;input type="file" name="img"/&gt;&lt;br/&gt; &lt;input type="file" name="img"/&gt;&lt;br/&gt; &lt;!--一次选多个文件的多文件上传 --&gt; 图片：&lt;input type="file" name="pic" multiple/&gt;&lt;br/&gt; 用户名：&lt;input type="text" name="username"/&gt;&lt;br/&gt; &lt;button type="submit"&gt;提交&lt;/button&gt;&lt;br/&gt;&lt;/form&gt;$&#123;msg&#125;&lt;/body&gt;&lt;/html&gt; 控制器 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950@RequestMapping("/upload3")public String upload(@RequestParam("username") String userName, @RequestParam("headerImg") MultipartFile[] files1, @RequestParam("img") MultipartFile[] files2, @RequestParam("pic") MultipartFile[] files3, HttpServletRequest request, Model model) &#123; String realPath = request.getServletContext().getRealPath("/upload/"); File dir = new File(realPath + date +"//"+userName+"//"); if (!dir.exists()) &#123; boolean res = dir.mkdirs(); if (!res) &#123; model.addAttribute("msg", "文件上传失败！请重试！"); return null; &#125; &#125; for (MultipartFile file : files1) &#123; uploadFile(dir.toString(), file, model); &#125; for (MultipartFile file : files2) &#123; uploadFile(dir.toString(), file, model); &#125; for (MultipartFile file : files3) &#123; uploadFile(dir.toString(), file, model); &#125; return "fileUpLoad";&#125;public void uploadFile(String path, MultipartFile file, Model model) &#123; try &#123; if (!file.isEmpty()) &#123; String fileName = file.getOriginalFilename(); String suffix = fileName.substring(fileName.lastIndexOf("."), fileName.length()); //给上传的文件重新命名 File newFileName = new File(path + "//" + System.currentTimeMillis() + suffix); System.out.println(newFileName); //保存文件到服务器 file.transferTo(newFileName); model.addAttribute("msg", "文件上传成功！"); &#125; &#125; catch (Exception e) &#123; model.addAttribute("msg", "文件上传失败！" + e); &#125;&#125; 测试结果 MultipartFile[]就是如此强大，不管单个多个，逻辑处理一样，所以建议在项目开发中使用MultipartFile[]作为文件的接收参数。 拓展1、MutipartFile类的一些常用方法： String getContentType() //获取文件MIME类型 InputStream getInputStream() //获取文件流 String getName() //获取表单中文件组件的名字 String getOriginalFilename() //获取上传文件的原名 long getSize() //获取文件的字节大小，单位byte boolean isEmpty() //是否为空 void transferTo(File dest) //保存文件到服务器指定路径 2、CommonsMultipartResolver的属性解析 defaultEncoding：表示用来解析request请求的默认编码格式，当没有指定的时候根据Servlet规范会使用默认值ISO-8859-1。当request自己指明了它的编码格式的时候就会忽略这里指定的defaultEncoding。 uploadTempDir：设置上传文件时的临时目录，默认是Servlet容器的临时目录。 maxUploadSize：设置允许上传的总的最大文件大小，以字节为单位计算。当设为-1时表示无限制，默认是-1。 maxUploadSizePerFile：跟maxUploadSize差不多，不过maxUploadSizePerFile是限制每个上传文件的大小，而maxUploadSize是限制总的上传文件大小。 maxInMemorySize：设置在文件上传时允许写到内存中的最大值，以字节为单位计算，默认是10240。 resolveLazily：为true时，启用推迟文件解析，以便在UploadAction中捕获文件大小异常。]]></content>
      <categories>
        <category>Spring框架</category>
      </categories>
      <tags>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC对Ajax异步请求的支持]]></title>
    <url>%2F2019%2F08%2F11%2FSpringMVC%E5%AF%B9Ajax%E5%BC%82%E6%AD%A5%E8%AF%B7%E6%B1%82%E7%9A%84%E6%94%AF%E6%8C%81%2F</url>
    <content type="text"><![CDATA[Ajax异步请求概念AJAX: Ansyc Javascript And Xml (异步请求).异步是指基于Ajax的应用与服务器通信的方法。对于传统的Web应用，每次用户发送请求或向服务器请求获得新数据时，浏览器都会完全丢弃当前页面，而等待重新加载的页面。在服务器完全响应之前，用户浏览器将是一片空白，用户的动作必须中断。异步是指用户发送请求后，完全无须等待，请求在后台发送，不会阻塞用户的当前活动，用户无须等待第一次请求得到完全响应，就可以立即发送第二次请求。简单的说,异步请求不会刷新当前html页面。异步指的是服务器端响应数据的获取方式。 同步： 异步： 异步&amp;同步的区别1.同步请求： 请求的过程：浏览器(当前的html页面会丢弃) —&gt; http协议 —&gt; Web服务器(tomcat) 响应的过程：Web服务器(tomcat) —&gt; http协议 –&gt; 返回一个新html页面. 2.异步请求： 请求的过程：浏览器(当前的html页面不会丢弃) —&gt; Ajax引擎(http协议) —&gt; Web服务器(tomcat) 响应的过程：Web服务器(tomcat) —&gt; 准备部分数据 –&gt; Ajax引擎(http协议) –&gt; DOM编程. 总而言之，异步请求只是局部刷新页面，同步请求会全部刷新当前的页面 jQuery框架的异步请求和处理1.$.ajax([settings]) —jQuery核心处理异步请求的方法：语法： $.ajax([settings]) 最简单的情况下，$.ajax() 可以不带任何参数直接使用。具体语法格式都有哪些参数请参照：https://www.w3school.com.cn/jquery/ajax_ajax.asp 2.$.post() $.post() 方法通过 HTTP POST 请求从服务器上请求数据。语法： $.post(url, data, function(data, status){// status(状态码): success 、error// data : 响应数据}, dataType); 必需的 URL 参数规定您希望请求的 URL。可选的 data 参数规定连同请求发送的数据。可选的 function 参数是请求成功后所执行的函数名,其中data是响应的数据，status是状态码可选的dataType参数是服务器响应返回的数据 3.$.get() $.get() 方法通过 HTTP GET 请求从服务器上请求数据。 $.get(url, data, function(data, status){// status(状态码): success 、error// data : 响应数据}, dataType); 必需的 URL 参数规定您希望请求的 URL。可选的 data 参数规定连同请求发送的数据。可选的 function 参数是请求成功后所执行的函数名,其中data是响应的数据，status是状态码可选的dataType参数是服务器响应返回的数据 springMVC支持ajax异步请求和处理返回json数据数据绑定@RequestBody/@ResponseBody&lt;/font size=4&gt;@RequestBody&nbsp;&nbsp;&nbsp;&nbsp;功能 ：用于将HttpServletRequest的getInputStream()的内容绑定到方法入参例如： @RequestMapping(value = “/hello”) public String handleRequest(@RequestBody String body){ //body参数就被请求参数自动绑定} &lt;/font size=4&gt;@ResponseBody&nbsp;&nbsp;&nbsp;&nbsp;功能：被ResponseBody修饰的方法的返回值会被作为响应体 @RequestMapping(value = “/hello”)@ResponseBody public User handleRequest(Ueser user){ return User; //返回值会被作为响应体，而且如果返回值是对象时SpringMVC会自动转换成JSON给页面} 使用@RequestBody/@ResponseBody来支持Ajax可以使用@RequestBody来自动获取Ajax上传的数据，同时也可以使用@ResponseBody，把要返回的对象自动拼成JSON的格式返回。当然，需要加入几个jackson的包，这里加入了：jackson-core-2.9.3.jar、jackson-annotations-2.9.3.jar、jackson-databind-2.9.3.jar，Maven依赖如下： 12345678910111213141516171819 &lt;!--jackson的三个依赖包--&gt;&lt;!-- https://mvnrepository.com/artifact/com.fasterxml.jackson.core/jackson-databind --&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-databind&lt;/artifactId&gt; &lt;version&gt;2.9.3&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/com.fasterxml.jackson.core/jackson-core --&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-core&lt;/artifactId&gt; &lt;version&gt;2.9.3&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/com.fasterxml.jackson.core/jackson-annotations --&gt;&lt;dependency&gt; &lt;groupId&gt;com.fasterxml.jackson.core&lt;/groupId&gt; &lt;artifactId&gt;jackson-annotations&lt;/artifactId&gt; &lt;version&gt;2.9.3&lt;/version&gt;&lt;/dependency&gt; Controller 123456789101112131415161718192021222324252627282930313233343536373839 /** * ResponseBody:用于将ResponseBody方法的返回值作为响应体 * RequestBody:用于将HttpServletRequest的getInputStream()内容绑定到入参 * * @param users * @return */@ResponseBody@RequestMapping(value = "/getAllUserByAJAX", produces = "application/json;charset=UTF-8")public List&lt;User&gt; getAllUserByAJAX(@ModelAttribute("users") List&lt;User&gt; users) &#123; return users;&#125;/** * RequestBody：将请求体的数据绑定到入参 * * @param user * @return */@ResponseBody@RequestMapping("/testRequestBody")public User testRequestBody(@RequestBody User user, Model model) &#123; System.out.println("请求的数据："+user); model.addAttribute("requestInfo", user); return user;&#125;/** * 提前把全部信息查询好放在隐含模型中 * @param model */@ModelAttribute("users")public void getAll(Model model) &#123; IUserService userService = new IUserServiceImpl(); List&lt;User&gt; lists = userService.getUser(null, null, null); model.addAttribute("users", lists);&#125; 1. 通过AJAX获得服务器数据的页面： 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;%@ page import="java.util.Date" %&gt;&lt;%@ page contentType="text/html;charset=UTF-8" language="java" %&gt;&lt;% pageContext.setAttribute("ctp", request.getContextPath());%&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;ajax&lt;/title&gt;&lt;script src="https://cdn.staticfile.org/jquery/1.10.2/jquery.min.js"&gt;&lt;/script&gt;&lt;script type="text/javascript"&gt; $().ready(function () &#123; $("#first").click(function () &#123; alert("adacd"); $.ajax(&#123; url: "$&#123;ctp&#125;/getAllUserByAJAX", type: "GET", success: function (data) &#123; //console.log(data) $.each(data, function () &#123; var userInfo = this.name + "---" + this.age + "---" + this.email; $("#user").append(userInfo + "&lt;br/&gt;"); &#125;) &#125; &#125;); return false; &#125;);&#125;);&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;%=new Date()%&gt;&lt;div id="user"&gt;&lt;/div&gt;&lt;a id="first" href="$&#123;ctp&#125;/getAllUserByAJAX"&gt;获取全部用户信息&lt;/a&gt;&lt;/body&gt;&lt;/html&gt; 测试结果 2. 通过AJAX向服务器发JSON数据，服务器返回JSON数据 1234567891011121314151617181920212223242526272829303132333435363738394041&lt;%@ page contentType="text/html;charset=UTF-8" language="java" %&gt;&lt;% pageContext.setAttribute("ctp", request.getContextPath());%&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Title&lt;/title&gt;&lt;script src="https://cdn.staticfile.org/jquery/1.10.2/jquery.min.js"&gt;&lt;/script&gt;&lt;script type="text/javascript"&gt;$().ready(function () &#123; $("#first").click(function () &#123; //点击发送JSON数据给服务器 $.ajax(&#123; url: "$&#123;ctp&#125;/testRequestBody", type: "POST", contentType:"application/json", //请求的文本格式：json data: JSON.stringify(&#123;name: $("#username").val(), age: $("#userage").val(), email: $("#userEmail").val()&#125;), //给服务器提交的数据 dataType: "json", //服务器返回的数据类型 success: function (data) &#123; var userInfo = data.name + "---" + data.age + "---" + data.email; $("#users").append(userInfo + "&lt;br/&gt;"); &#125; &#125;); return false; &#125;);&#125;);&lt;/script&gt;&lt;/head&gt;&lt;body&gt;&lt;form action="$&#123;ctp&#125;/testRequestBody" method="post"&gt;&lt;input id="username" name="username" type="text"/&gt;&lt;input id="userage" name="age" type="text"/&gt;&lt;input id="userEmail" name="enail" type="email"/&gt;&lt;/form&gt;&lt;button type="button"&gt;&lt;a id="first" href="$&#123;ctp&#125;/testRequestBody"&gt;AJAX发送JSON数据给服务器&lt;/a&gt;&lt;/button&gt;&lt;div id="users"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 测试结果]]></content>
      <categories>
        <category>Spring框架</category>
      </categories>
      <tags>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC 数据绑定、数据格式化、数据校验]]></title>
    <url>%2F2019%2F08%2F09%2FSpringMVC%20%E6%95%B0%E6%8D%AE%E7%BB%91%E5%AE%9A%E3%80%81%E6%95%B0%E6%8D%AE%E6%A0%BC%E5%BC%8F%E5%8C%96%E3%80%81%E6%95%B0%E6%8D%AE%E6%A0%A1%E9%AA%8C%2F</url>
    <content type="text"><![CDATA[数据绑定流程 Spring MVC将ServletRequest对象及目标方法的入参实例传给WebDataBinderFactory实例，创建出DataBinder(数据绑定的核心部件) DataBinder调用转配在SpringMVC上下文中的ConversionService组件进行数据类型转换、数据格式化。并将servlet中的请求信息填充到入参对象中 调用Validator组件对已经绑定好的请求消息的入参进行数据合法性校验，并最终生成数据绑定结果BindingResult对象 Spring MVC抽取BindingResult中的入参对象和检验错误对象，将他们赋给处理方法的响应入参 Spring MVC通过反射机制对目标方法进行解析，将请求消息绑定到处理方法的入参中。 数据转换2.1 ConversionService Spring MVC 上下文中内建了很多转换器，可完成大多数 Java 类型的转换工作。 Spring3.0 添加了一个通用的类型转换模块，位于 org.springframework.core.convert 包中 ConversionService 接口是类型转换的核心接口 Modifier and Type Method and Description boolean canConvert(Class sourceType, Class targetType)判断是否可以将一个 java 类转换为另一个 java 类 boolean canConvert(TypeDescriptor sourceType, TypeDescriptor targetType) 需转换的类将以成员变量的方式出现在宿主类中，TypeDescriptor 不但描述了需转换类的信息，还描述了从宿主类的上下文信息，如成员变量 上的注解，成员是否是数组、集合或 Map 的方式呈现等 &lt;T&gt;&nbsp;T convert(Object source, Class&lt;T&gt; targetType) 将原类型对象转换为目标类型对象. Object convert(Object source, TypeDescriptor sourceType, TypeDescriptor targetType) 将对象从原类型对象转换为目标类型对象，此时往往会用到所在宿主类的上下文信息 2.2 自定义类型转换器Spring 在 org.springframework.core.convert.converter 包中定义了 3 种类型转换器接口，实现任意一个转换器接口都可以作为自定义转换器注册到 ConversionServiceFactroyBean 中： Converter&lt;S,T&gt;：将S类型对象转换为T类型对象 ConverterFactory：将相同系列多个Converter封装在一起.如果希望将一种类型的对象转换为另一种类型及其子类的对象（例如将 String 转换为 Number 及Number 子类（Integer、Long、Double 等）对象）可使用该转换器工厂类 GenericConverter：会根据源类对象及目标类对象所在的宿主类找那个的上下文信息进行类型转换 ConverstionServiceFactoryBean 的 converters 属性可以接受 Converter、ConverterFactory、GenericConverter 或 ConditionalGenericConverter 接口的实现类，并把这些转换器的转换逻辑统一封装到一个 ConverstionService 实例对象中(GenericConversionService),Spring 在 Bean属性配置及 Spring MVC 请求消息绑定时将利用这个 ConversionService 实例完成类型转换工作。 实际应用中常用的是Converter&lt;S,T&gt;，下面通过他实现一个自定义的类型转换器：关键步骤： 实现Converter接口，他有两个泛型，S:是转换前的了类型，T:是转换后的类型 ，实现Converter接口的conver方法，在方法中定制对S类型如何转换换成T类型的规则 在springmvc配置文件中将自定义的Converter配置在ConversionService中 告诉SpringMVC使用我们自定义的类型转换器 假设处理方法有一个 User 类型的入参，我们希望将一个格式化的请求字符串直接转为 User对象，该字符串格式如（小明:男:软件工程:软工3306班:1134556） 编写自定义类型转换器 1234567891011121314151617181920212223package com.xzy.converter;import com.xzy.bean.Student;import org.springframework.core.convert.converter.Converter;public class StringToStudentConverter implements Converter&lt;String, Student&gt; &#123; //在这个方法中定义转换的规则 @Override public Student convert(String param) &#123; Student student = new Student(); //param==&gt;小明:男:软件工程:软工3306班:17033309 if (null != param &amp;&amp; !"".equals(param)) &#123; String[] pa=param.split(":"); student.setName(pa[0]); student.setGender(pa[1]); student.setSclass(pa[2]); student.setMajor(pa[3]); student.setSid(pa[4]); &#125; return student; &#125;&#125; 在SpringMVC配置文件中将自定义的Converter方在IOC容器中交给Spring管理 1234567891011&lt;!--该 标 签 会 创 建 并 注 册 一 个 默 认 的 DefaultAnnotationHandlerMapping 和一个ReqeustMappingHandlerAdpter实现，除此之外&lt;mvc:annotaion-driven/&gt;标签还会注册一个默认的ConversionService（FormattingConversionServiceFactoryBean）以满足大多数类型转换 的需求 ，当用到自定义类型转换器时，需要用&lt;mvc:annotation-driven conversion-service=”xxx”/&gt;覆盖默认--&gt;&lt;!--配置自定义的类型转换器--&gt;&lt;bean id="conversionService" class="org.springframework.context.support.ConversionServiceFactoryBean"&gt; &lt;property name="converters"&gt; &lt;set&gt; &lt;bean class="com.xzy.converter.StringToStudentConverter"/&gt; &lt;/set&gt; &lt;/property&gt;&lt;/bean&gt; 用&lt;mvc:annotation-driven conversion-service=”xxx”/&gt;覆盖默认的类型转换器 12&lt;!--在&lt;mvc:annotation-driver中配置conversion-service覆盖默认的转换器&gt;--&gt;&lt;mvc:annotation-driven conversion-service="conversionService"/&gt; 控制器： 123456789101112131415161718package com.xzy.contorller;import com.xzy.bean.Student;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestParam;@Controllerpublic class StudentController &#123; @RequestMapping("/addStudent") public String addStudent(@RequestParam("stuInfo") Student student, Model model) &#123; System.out.println("封装的" + student); model.addAttribute("stuinfo",student); return "success"; &#125;&#125; 测试结果： 数据格式化Spring 使用转换器进行源类型对象到目标类型对象的转换，Spring 的转换不提供输入及输出信息格式化工作，像日期、时间、数字、货币等数据都具有一定格式的，在不同的本地化环境中，同一类型的数还会相应地呈现不同的显示格式。如何从格式化的数据中获取真正的数据以完成数据绑定，并将处理完成的数据输出为格式化的数据，是 spring 格式化框架要解决的问题，Spring 引入了一个新的格式化框架，这个框架位于 org.springframework.format 类包中，其中最重要的一个接口 FormatterSpring 的 org.springframework.format.datetime 包中提供了一个用于时间对象格式化的DateFormatter 实现类，而 org.springframework.format.number 包中提供了 3 个用于数字对象格式化的实现类。 NumberFormatter:用于数字类型对象的格式化 CurrencyFormatter:用于货币类型对象的格式化 PercentFormatter: 用于百分数数字类型对象的格式化 示例：有一个员工类employee.java 1234567891011121314151617181920212223242526272829303132package com.xzy.bean;import org.springframework.format.annotation.DateTimeFormat;import org.springframework.format.annotation.NumberFormat;import java.math.BigDecimal;import java.util.Date;public class employee &#123; private String mame; @DateTimeFormat(pattern = "yyyy-MM-dd") private Date birth; //生日 //表示3位一个逗号，保留两位小数 @NumberFormat(pattern = "#,###.##") private Double salary; //薪水 //省略getter、setter @Override public String toString() &#123; return "employee&#123;" + "mame='" + mame + '\'' + ", birth=" + birth + ", salary=" + salary + '&#125;'; &#125;&#125; 要使注解可以发挥作用还需要在注解中配置如下信息： 12345678&lt;mvc:annotation-driven conversion-service="conversionService"/&gt;&lt;bean id="conversionService" class="org.springframework.format.support.FormattingConversionServiceFactoryBean"&gt; &lt;property name="converters"&gt; &lt;set&gt; &lt;bean class="com.xzy.converter.StringToStudentConverter"/&gt; &lt;/set&gt; &lt;/property&gt;&lt;/bean&gt; &nbsp;&nbsp;&nbsp;&nbsp;对属性对象的输入/输出进行格式化，从其本质上讲依然属于 “类型转换” 的范畴。Spring 在格式化模块中定义了一个实现 ConversionService 接口的FormattingConversionService 实现类，该实现类扩展了GenericConversionService，因此它既具有类型转换的功能，又具有格式化的功能。&nbsp;&nbsp;&nbsp;&nbsp;FormattingConversionService 拥有FormattingConversionServiceFactroyBean 工厂类，后者用于在 Spring 上下文中构造前者FormattingConversionServiceFactroyBean 内部已经注册了 :NumberFormatAnnotationFormatterFactroy：支持对数字类型的属性使用 @NumberFormat 注解JodaDateTimeFormatAnnotationFormatterFactroy：支持对日期类型的属性使用 @DateTimeFormat 注解装配了 FormattingConversionServiceFactroyBean 后，就可 以在 Spring MVC 入参绑定及模型数据输出时使用注解驱动了。&lt;mvc:annotation-driven/&gt;默认创建的ConversionService 实例即为 FormattingConversionServiceFactroyBean. 数据校验应用程序在执行业务逻辑前，必须通过数据校验保证接收到的输入数据是正确合法的，如代表生日的日期应该是一个过去的时间、工资的数值必须是一个整数等。一般情况下，应用程序的开发时分层的，不同层的代码由不同的开发人员负责。很多时候，同样的数据验证会出现在不同的层中，这样就会导致代码冗余，违反了DRY原则。为了避免这样的情况，最好将验证逻辑和响应的域模型进行绑定，将代码验证的逻辑集中起来管理。 JSR-303 JSR-303是Java为Bean数据合法校验锁提供的标准框架，它已经包含在JavaEE 6.0中。JSR-303通过在Bean属性上标注类似于@NotNull、@Max等标准的注解指定校验规则，并通过标准的验证接口对Bean进行验证。可以通过http://jcp.org/en/jsr/detail?id=303了解更多详细内容。JSR-303定义了一套可标注在成员变量、属性方法上的校验注解： JSR-303 支持 XML 风格的和注解风格的验证，接下来我们首先看一下如何和 Spring 集成。 1. 导入jar包,此处使用 Hibernate-validator 实现（版本：hibernate-validator-6.0.17.Final-dist.zip），他的Maven依赖如下： 123456&lt;!-- https://mvnrepository.com/artifact/org.hibernate.validator/hibernate-validator --&gt;&lt;dependency&gt; &lt;groupId&gt;org.hibernate.validator&lt;/groupId&gt; &lt;artifactId&gt;hibernate-validator&lt;/artifactId&gt; &lt;version&gt;6.0.17.Final&lt;/version&gt;&lt;/dependency&gt; 在Spring配置中添加JSR-303验证框架支持 1234&lt;!--配置对JSR-303的支持--&gt;&lt;bean id="validator" class="org.springframework.validation.beanvalidation.LocalValidatorFactoryBean"&gt; &lt;property name="providerClass" value="org.hibernate.validator.HibernateValidator"/&gt;&lt;/bean&gt; 通过 ConfigurableWebBindingInitializer 注册 validator 12345&lt;!--注册validator--&gt;&lt;bean id="webBinding" class="org.springframework.web.bind.support.ConfigurableWebBindingInitializer"&gt; &lt;property name="conversionService" ref="conversionService"/&gt; &lt;property name="validator" ref="validator"/&gt;&lt;/bean&gt; 使用 JSR-303 验证框架注解为模型对象指定验证信息 123456789101112131415161718192021222324252627282930313233343536 package com.xzy.bean;import javax.validation.constraints.*;public class Student &#123;@NotEmptyprivate String name;@Size(min = 7,max=10)private String sid; //学号@Pattern(regexp = "/^(0|86|17951)?(13[0-9]|15[012356789]|166|17[3678]|18[0-9]|14[57])[0-9]&#123;8&#125;$/")private String phone; //手机号码@NotBlankprivate String sclass;@NotEmptyprivate String major; //省略getter、setter @Overridepublic String toString() &#123; return "Student&#123;" + "姓名：'" + name + '\'' + ", 学号：'" + sid + '\'' + ", 手机：'" +phone + '\'' + ", 班级：'" + sclass + '\'' + ", 专业：'" + major + '\'' + '&#125;'; &#125;&#125; 控制器 123456789101112131415161718192021222324252627//@Vaild就是告诉SpringMVC 把数据绑定好后要根据Bean里面的校验规则校验@RequestMapping(value = "/addStudent", method = RequestMethod.POST)public String addStudent2( @Valid @ModelAttribute Student student, Errors error, Model model) &#123; logger.info(student); model.addAttribute("student", student); if (error.hasErrors()) &#123; System.out.println(error); logger.error(error); return "add"; //如果有错误，就返回填写页面重新填写 &#125; return "success";&#125;@RequestMapping(value="/&#123;formName&#125;")public String loginForm( @PathVariable String formName, Model model)&#123; System.out.println(formName); Student student= new Student(); model.addAttribute("student",student); // 动态跳转页面 return formName;&#125; 通过在命令对象上注解@Valid 来告诉 Spring MVC 此命令对象在绑定完毕后需要进行 JSR-303验证，如果验证失败会将错误信息添加到 Errors 错误对象中。 验证失败后回到填写表单的页面（/WEB-INF/jsp/pages/add.jsp）123456789101112131415161718192021222324252627282930313233343536373839404142&lt;%@ taglib prefix="fmt" uri="http://java.sun.com/jsp/jstl/fmt" %&gt;&lt;%@ taglib prefix="form" uri="http://www.springframework.org/tags/form" %&gt;&lt;%@ page contentType="text/html;charset=UTF-8" language="java" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;form:form modelAttribute="student" method="post" action="addStudent.htm"&gt; &lt;table&gt; &lt;tr&gt; &lt;td&gt;姓名:&lt;/td&gt; &lt;td&gt;&lt;form:input path="name"/&gt;&lt;/td&gt; &lt;td&gt;&lt;form:errors path="name" cssStyle="color:red"/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;学号:&lt;/td&gt; &lt;td&gt;&lt;form:input path="sid"/&gt;&lt;/td&gt; &lt;td&gt;&lt;form:errors path="sid" cssStyle="color:red"/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;手机:&lt;/td&gt; &lt;td&gt;&lt;form:input path="phone"/&gt;&lt;/td&gt; &lt;td&gt;&lt;form:errors path="phone" cssStyle="color:red"/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;班级:&lt;/td&gt; &lt;td&gt;&lt;form:input path="sclass"/&gt;&lt;/td&gt; &lt;td&gt;&lt;form:errors path="sclass" cssStyle="color:red"/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;专业:&lt;/td&gt; &lt;td&gt;&lt;form:input path="major"/&gt;&lt;/td&gt; &lt;td&gt;&lt;form:errors path="major" cssStyle="color:red"/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;input type="submit" value="提交"/&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt;&lt;/form:form&gt;&lt;/body&gt;&lt;/html&gt; 测试结果： 自定义国际化错误消息提示在上面的程序中有一个不好的地方，错误消息不是 我们自定义的，而且都是英文的，下面我们来看看如何在通过国际化配置文件实现自定义国际化错误消息提示。使用 System.out.println(&quot;错误码：&quot;+fieldError.getCodes());可以得到错误的错误码，每种错误都定义了4中错误码，如下： 他们从上到下所包含的范围由小到大，我们在写国际化配置文件的时候，每条配置的key必须是4个code中的一个code。 error_en_US.properties 12345NotBlank.student.name=name must not be emptySize.student.sid=the length must between &#123;2&#125; and &#123;1&#125;Pattern.student.phone=please write a right phone numberNotBlank.student.sclass=class must not be emptyNotEmpty.student.major=major must not be empty error_zh_CN.properties 12345NotBlank.student.name=姓名不能为空!Size.student.sid=长度应该在&#123;2&#125;和&#123;1&#125;之间!Pattern.student.phone=请填写正确的手机号码!NotBlank.student.sclass=班级不能为空!NotEmpty.student.major=专业不能为空! 在springmvc.xml文件中配置国际化资源： 123456789101112131415161718&lt;!--配置国际化资源--&gt; &lt;bean id="messageSource" class="org.springframework.context.support.ResourceBundleMessageSource"&gt; &lt;property name="basenames" value="error"/&gt; &lt;!-- &lt;property name="basenames" value="message"/&gt;--&gt; &lt;property name="useCodeAsDefaultMessage" value="false"/&gt; &lt;property name="cacheSeconds" value="0"/&gt; &lt;!--配置字符编码为UTF-8：注意properties的编码格式也应该是UTF-8的，否者即使你设置了字符编码过滤器也会乱码--&gt; &lt;property name="defaultEncoding" value="UTF-8"/&gt; &lt;/bean&gt; &lt;!-- 主要用于获取请求中的locale信息，将其转为Locale对像，获取LocaleResolver对象--&gt; &lt;mvc:interceptors&gt; &lt;bean id="localeChangeInterceptor" class="org.springframework.web.servlet.i18n.LocaleChangeInterceptor"/&gt; &lt;/mvc:interceptors&gt; &lt;!-- 配置SessionLocaleResolver用于将Locale对象存储于Session中供后续使用 --&gt; &lt;bean id="SessionLocaleResolver" class="org.springframework.web.servlet.i18n.SessionLocaleResolver"/&gt; 测试结果：]]></content>
      <categories>
        <category>Spring框架</category>
      </categories>
      <tags>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC自定义视图和视图解析器]]></title>
    <url>%2F2019%2F08%2F08%2FSpringMVC%E8%87%AA%E5%AE%9A%E4%B9%89%E8%A7%86%E5%9B%BE%E5%92%8C%E8%A7%86%E5%9B%BE%E8%A7%A3%E6%9E%90%E5%99%A8%2F</url>
    <content type="text"><![CDATA[自定义视图解析器：123456789101112131415161718192021222324252627282930313233343536package com.xzy.view;import org.springframework.core.Ordered;import org.springframework.web.servlet.View;import org.springframework.web.servlet.ViewResolver;import java.util.Locale;/** * 自定义视图解析器 */public class MyViewResolver implements ViewResolver, Ordered &#123; private int order = 0; @Overridepublic View resolveViewName(String viewName, Locale locale) throws Exception &#123; if (viewName.startsWith("my:")) &#123; //返回自定义的视图对象 return new MyView(); &#125; else &#123; //不能处理就不要强行处理了，返回null让别的视图处理器来处理 return null; &#125; &#125;@Overridepublic int getOrder() &#123; return order;&#125;public void setOrder(int order) &#123; this.order = order; &#125;&#125; 自定义视图：1234567891011121314151617181920212223242526272829303132333435363738package com.xzy.view;import org.springframework.web.servlet.View;import javax.servlet.http.HttpServletRequest;import javax.servlet.http.HttpServletResponse;import java.io.PrintWriter;import java.util.List;import java.util.Map;/** * 自定义视图 */public class MyView implements View &#123; //返回的文本类型：text/html @Override public String getContentType() &#123; return "text/html"; &#125; // 渲染视图:在这个方法中写你对这个视图的渲染效果 @Override public void render(Map&lt;String, ?&gt; map, HttpServletRequest httpServletRequest, HttpServletResponse httpServletResponse) throws Exception &#123; System.out.println("方法中保存的数据：" + map); httpServletResponse.setContentType("text/html"); PrintWriter out = httpServletResponse.getWriter(); out.write("&lt;h3&gt;精彩内容即将呈现...Loading&lt;/h3&gt;"); List&lt;Object&gt; lists= (List&lt;Object&gt;) map.get("video"); out.write("&lt;ul&gt;"); for(Object object:lists)&#123; out.write("&lt;li&gt;&lt;a href='download'&gt;"+object+"&lt;/a&gt;&lt;/li&gt;"); &#125; out.write("&lt;/ul&gt;"); &#125;&#125; 好了，现在视图处理和视图都定义好，这样我们的视图解析器就可以工作了吗？非也！虽然我们实现了ViewRelover接口.但是对于SpringMVC来说他就是一个普通的java类，SpringMVC如何知道去哪里调用我们的视图解析器呢?解决的方法是：在springmvc配置文件中配置我们的视图解析器，交给Spring IOC容器管理。 1234567&lt;!--配置自定义的视图解析器: springmvc中视图解析器得到视图时优先级高的会先去尝试解析，order的数值越小，优先级越高 自定义的视图解析器需要实现Orderd接口，默认的视图解析器InternalResourceViewResolver的优先级最低 --&gt; &lt;bean class="com.xzy.view.MyViewResolver"&gt; &lt;property name="order" value="0"/&gt; &lt;/bean&gt; 注意：自定义的视图解析器必须要实现ordered接口，以给我们自定义的视图解析器指定优先级，优先级的规则是值越小，优先级高；SpringMVC默认的视图解析器InternalResourceViewResolver的优先级是最低的。 编写控制器123456789101112131415161718192021222324package com.xzy.contorller;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.RequestMapping;import java.util.ArrayList;import java.util.List;@Controllerpublic class MyViewController &#123; @RequestMapping("/viewhandler") public String myViewTest(Model model)&#123; List&lt;String&gt; vnames=new ArrayList&lt;String&gt;(); vnames.add("java疯狂讲义300集"); vnames.add("java从入门到如入土！！！"); vnames.add("Spring,SpringMVC从入门到放弃！！！"); vnames.add("MySql从删库到跑路！！！"); model.addAttribute("video",vnames); return "my:/hello"; &#125;&#125; 测试结果：总结自定义视图处理器和视图的步骤： 编写视图处理器（实现ViewReslover接口的resolveViewName方法）和视图（实现View接口的两个方法：getContentType()、render()） 视图解析器必须放在IOC容器中 视图处理器除了要实现ViewReslover接口，还应该实现ordered接口，已给我们定义的视图解析器指定优先级，这个很关键.]]></content>
      <categories>
        <category>Spring框架</category>
      </categories>
      <tags>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC视图解析]]></title>
    <url>%2F2019%2F08%2F07%2FSpringMVC%E8%A7%86%E5%9B%BE%E8%A7%A3%E6%9E%90%2F</url>
    <content type="text"><![CDATA[SpringMVC视图解析 &nbsp; &nbsp; &nbsp;对于控制器的目标方法，无论其返回值是String、View、ModelMap或是ModelAndView，SpringMVC都会在内部将它们封装为一个ModelAndView对象进行返回。 &nbsp; &nbsp; &nbsp; Spring MVC 借助视图解析器（ViewResolver）得到最终的视图对象（View），最终的视图可以是JSP也可是Excell、 JFreeChart等各种表现形式的视图。 视图（View） 视图的作用是渲染模型数据，将模型里的数据以某种形式呈现给客户。 为了实现视图模型和具体实现技术的解耦，Spring在org.springframework.web.servlet包中定义了一个高度抽象的View接口。 视图对象由视图解析器负责实例化。由于视图是无状态的，所以他们不会有线程安全的问题。所谓视图是无状态的，是指对于每一个请求，都会创建一个View对象。 JSP是最常见的视图技术。 视图解析器（ViewResolver）和视图（View） springMVC用于处理视图最重要的两个接口是ViewResolver和View。 所以视图解析器的作用就是通过视图名（处理方法的返回值）生成View对象，所有的视图解析器都必须实现ViewResolver接口。 SpringMVC为逻辑视图名的解析提供了不同的策略，可以在Spring WEB上下文中配置一种或多种解析策略，并指定他们之间的先后顺序。每一种映射策略对应一个具体的视图解析器实现类。程序员可以选择一种视图解析器或混用多种视图解析器。可以通过order属性指定解析器的优先顺序，order越小优先级越高，SpringMVC会按视图解析器顺序的优先顺序对逻辑视图名进行解析，直到解析成功并返回视图对象，否则抛出ServletException异常。在项目中可以配置InternalResourceViewResolver作为视图解析器,在springmvc.xml中可以做如下配置： 12345&lt;!--配置视图解析器--&gt;&lt;bean id="viewHandler" class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="prefix" value="WEB-INF/pages/"/&gt; &lt;property name="suffix" value=".jsp"/&gt;&lt;/bean&gt; forward: 和redirect:一般情况下，控制器方法返回字符串类型的值会被当成逻辑视图名处理，会经过视图解析器拼串，但如果返回的字符串中带forward:或redirect:前缀时，SpringMVC会对它们进行特殊处理：将forward: 和redirect: 当成指示符，其后的字符串作为URL 来处理。示例如下：index.html 123456789101112131415&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;SpringMVC给页面输出数据&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;center&gt; &lt;a href="handler1"&gt;handler1&lt;/a&gt;&lt;br/&gt; &lt;a href="handler2"&gt;handler2&lt;/a&gt;&lt;br/&gt; &lt;a href="handler3"&gt;handler3&lt;/a&gt;&lt;br/&gt; &lt;a href="handler4"&gt;handler4&lt;/a&gt;&lt;br/&gt;&lt;/center&gt;&lt;/body&gt;&lt;/html&gt; hello.jsp，在当前项目的根路径下，和index.html同级 1234567891011&lt;%@ page contentType="text/html;charset=UTF-8" language="java" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;Hello&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;center&gt; &lt;h1&gt;这是hello.jsp&lt;/h1&gt;&lt;/center&gt;&lt;/body&gt;&lt;/html&gt; ViewTestController.java 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package com.xzy.Contorller;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;@Controllerpublic class ViewTestController &#123; /** * handler1把请求转发到hello.jsp页面 * @return */ @RequestMapping("/handler1") public String handler1()&#123; System.out.println("handler1"); return "forward:/hello.jsp"; &#125; /** * handler把请求转发给handler1 * @return */ @RequestMapping("/handler2") public String handler2()&#123; System.out.println("handler2"); return "forward:handler1"; &#125; /** * 重定向到hello.jsp * @return */ @RequestMapping("/handler3") public String handler3()&#123; System.out.println("handler3"); return "redirect:/hello.jsp"; &#125; /** * 重定向到handler3 * @return */ @RequestMapping("/handler4") public String handler4()&#123; System.out.println("handler4"); return "redirect:handler3"; &#125;&#125; 测试结果: 按F12打开开发者工具，可以看到确实两次重定向 SpringMVC视图的解析流程(结合源码分析) 源码中把任何返回返回值封装为ModelAndView的实现：123456789101112131415161718192021222324 protected ModelAndView handleInternal(HttpServletRequest request, HttpServletResponse response, HandlerMethod handlerMethod) throws Exception &#123; this.checkRequest(request); ModelAndView mav; if (this.synchronizeOnSession) &#123; HttpSession session = request.getSession(false); if (session != null) &#123; Object mutex = WebUtils.getSessionMutex(session); synchronized(mutex) &#123; mav = this.invokeHandlerMethod(request, response, handlerMethod); &#125; &#125; else &#123; mav = this.invokeHandlerMethod(request, response, handlerMethod); &#125; &#125; else &#123; mav = this.invokeHandlerMethod(request, response, handlerMethod); &#125; if(!response.containsHeader("Cache-Control")) &#123;if (this.getSessionAttributesHandler(handlerMethod).hasSessionAttributes()) &#123; this.applyCacheSeconds(response,this.cacheSecondsForSessionAttributeHandlers); &#125; else &#123; this.prepareResponse(response); &#125; &#125; return mav; &#125; 这里以发出了一个GET请求为例：首先FrameworkServlet类会来处理这个GET请求doGet 123protected final void doGet(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; this.processRequest(request, response); &#125; processRequest 123456789101112131415protected final void processRequest(HttpServletRequest request, HttpServletResponse response) throws ServletException, IOException &#123; //省略..... try &#123; //它本类中的这个方法是个抽象方法，实现这个方法的类是DispatcherServlet this.doService(request, response); &#125; catch (IOException | ServletException var16) &#123; failureCause = var16; throw var16; &#125; catch (Throwable var17) &#123; //省略.....var17); &#125; finally &#123; //省略..... &#125; &#125; DispatcherServlet 类doService方法 12345678910111213protected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; protected void doService(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; //省略..... //给request域中设置了一些东西 try &#123; //调用doDispatch方法处理 this.doDispatch(request, response); &#125; finally &#123; ...... &#125; &#125; doDispatch方法 12345protected void doDispatch(HttpServletRequest request, HttpServletResponse response) throws Exception &#123; //省略...... this.processDispatchResult(processedRequest, response, mappedHandler, mv, dispatchException); //省略...... &#125; processDispatchResult方法,这个方法就是最终将数据交给页面的方法 12345678910111213141516171819202122232425 private void processDispatchResult(HttpServletRequest request, HttpServletResponse response, @Nullable HandlerExecutionChain mappedHandler, @Nullable ModelAndView mv, @Nullable Exception exception) throws Exception &#123; boolean errorView = false; //如果这里出现了异常就处理异常 if (exception != null) &#123; if (exception instanceof ModelAndViewDefiningException) &#123;this.logger.debug("ModelAndViewDefiningException encountered", exception); mv = ((ModelAndViewDefiningException)exception).getModelAndView(); &#125; else &#123; Object handler = mappedHandler != null ? mappedHandler.getHandler() : null; //如果自己配置了自定义的HandlerExceptionResolver将会在这个方法里处理 mv = this.processHandlerException(request, response, handler, exception); errorView = mv != null; &#125; &#125; if (mv != null &amp;&amp; !mv.wasCleared()) &#123; //调用render方法进行视图渲染 this.render(mv, request, response); if (errorView) &#123; WebUtils.clearErrorRequestAttributes(request); &#125; &#125; else if (this.logger.isTraceEnabled()) &#123; this.logger.trace("No view rendering, null ModelAndView returned."); &#125; //省略...... &#125; DispatcherServlet 类 的render方法并没有继承View接口的render,和View接口的render不是一回事，这个render仅仅是为了命名统一而起的一个名字 123456789101112131415161718192021222324252627protected void render(ModelAndView mv, HttpServletRequest request, HttpServletResponse response) throws Exception &#123; //省略...... //从ModelView中拿到视图名 String viewName = mv.getViewName(); View view; if (viewName != null) &#123; //这一步就是得到一个View对象，resolveViewName的实现看下边 view = this.resolveViewName(viewName, mv.getModelInternal(), locale, request); if (view == null) &#123; throw new ServletException("Could not resolve view with name '" + mv.getViewName() + "' in servlet with name '" + this.getServletName() + "'"); &#125; &#125; else &#123; view = mv.getView(); if (view == null) &#123; throw new ServletException("ModelAndView [" + mv + "] neither contains a view name nor a View object in servlet with name '" + this.getServletName() + "'"); &#125; &#125; //省略...... try &#123; //省略...... //调用了View接口的render方法，这里实际上调用的是视图在渲染时会把Model传入 view.render(mv.getModelInternal(), request, response); &#125; catch (Exception var8) &#123; //省略...... &#125;&#125; resolveViewName方法，循环遍历你配置的视图解析器，viewResolvers是进过order排序的，这一步就是ViewResolvers是如何通过视图名产生View对象的关键 1234567891011protected View resolveViewName(String viewName,Map&lt;String, Object&gt; model, Locale locale, HttpServletRequest request) throws Exception &#123; //遍历我们配置的视图解析器 for (ViewResolver viewResolver : this.viewResolvers) &#123; //ViewResolver根据方法的返回值，得到一个View对象，这块又有一个resolveViewName，具体的实现请往下看 View view = viewResolver.resolveViewName(viewName, locale); if (view != null) &#123; return view; &#125; &#125; return null;&#125; InternalResourceViewResolver继承了AbstractCachingViewResolver，resolveViewName方法首先会判断有没有缓存，要是有缓存，它会先去缓存中通过viewName查找是否有View对象的存在，要是没有，它会通过viewName创建一个新的View对象，并将View对象存入缓存中，这样再次遇到同样的视图名的时候就可以直接在缓存中取出View对象了 12345678910111213141516171819202122232425262728293031@Overridepublic View resolveViewName(String viewName, Locale locale) throws Exception &#123; //判断有缓存中有没有view对象，有就直接拿来用 if (!isCache()) &#123; return createView(viewName, locale); &#125; else &#123; Object cacheKey = getCacheKey(viewName, locale); View view = this.viewAccessCache.get(cacheKey); if (view == null) &#123; synchronized (this.viewCreationCache) &#123; view = this.viewCreationCache.get(cacheKey); if (view == null) &#123; //根据方法的返回值创建出View对象 view = createView(viewName, locale); if (view == null &amp;&amp; this.cacheUnresolved) &#123; view = UNRESOLVED_VIEW; &#125; if (view != null) &#123; this.viewAccessCache.put(cacheKey, view); this.viewCreationCache.put(cacheKey, view); if (logger.isTraceEnabled()) &#123; logger.trace("Cached view [" + cacheKey + "]"); &#125; &#125; &#125; &#125; &#125; return (view != UNRESOLVED_VIEW ? view : null); &#125;&#125; createView的实现细节： 12345678910111213141516171819202122232425protected View createView(String viewName, Locale locale) throws Exception &#123; if (!this.canHandle(viewName, locale)) &#123; return null; &#125; else &#123; String forwardUrl; //如果方法得到返回值是以redirect：开始的 if (viewName.startsWith("redirect:")) &#123; forwardUrl = viewName.substring("redirect:".length()); RedirectView view = new RedirectView(forwardUrl, this.isRedirectContextRelative(), this.isRedirectHttp10Compatible()); String[] hosts = this.getRedirectHosts(); if (hosts != null) &#123; view.setHosts(hosts); &#125; return this.applyLifecycleMethods("redirect:", view); //如果方法的返回值是以forward:开始的 &#125; else if (viewName.startsWith("forward:")) &#123; forwardUrl = viewName.substring("forward:".length()); InternalResourceView view = new InternalResourceView(forwardUrl); return this.applyLifecycleMethods("forward:", view); &#125; else &#123; //其他情况的处理,这里又有一个createView，它调用了父类的createView创建了一个默认的View对象 return super.createView(viewName, locale); &#125; &#125;&#125; 以下都是解析视图名的实现细节，感兴趣的可以看一下。 父类AbstractCachingViewResolver类的createView实现细节： 123protected View createView(String viewName, Locale locale) throws Exception &#123; return loadView(viewName, locale);&#125; InternalResourceViewResolver继承了UrlBasedViewResolverUrlBasedViewResolver类中loadView方法的实现： 12345protected View loadView(String viewName, Locale locale) throws Exception &#123; AbstractUrlBasedView view = buildView(viewName); View result = applyLifecycleMethods(viewName, view); return (view.checkResource(locale) ? result : null); &#125; UrlBasedViewResolver的buildView方法会获取一个View对象，这个对象会将视图以什么格式呈现给用户，例如如果是jsp显示呈现给用户的话，那这个view对象就是JstlView，默认的是JstlView。在这个方法中我们看到了getPrefix() + viewName + getSuffix()这样一段代码，这就是对视图路径的一个拼接了，getPrefix()方法获取前缀，也就是我们在配置文件中配置的&lt;property name=&quot;prefix&quot; value=&quot;/WEB-INF/PAGE/&quot;/&gt;的value中的值了,getSuffix()方法就是获取后缀值了，也就是我们在配置文件中配置的&lt;property name=&quot;suffix&quot; value=&quot;.jsp&quot;/&gt;的value中的值。这样就将将视图的物理路径找到了，并赋值到View的URL属性中去。 123456789101112131415161718192021222324252627protected AbstractUrlBasedView buildView(String viewName) throws Exception &#123; Class&lt;?&gt; viewClass = this.getViewClass(); Assert.state(viewClass != null, "No view class"); AbstractUrlBasedView view = (AbstractUrlBasedView)BeanUtils.instantiateClass(viewClass); view.setUrl(this.getPrefix() + viewName + this.getSuffix()); String contentType = this.getContentType(); if (contentType != null) &#123; view.setContentType(contentType); &#125; view.setRequestContextAttribute(this.getRequestContextAttribute()); view.setAttributesMap(this.getAttributesMap()); Boolean exposePathVariables = this.getExposePathVariables(); if (exposePathVariables != null) &#123; view.setExposePathVariables(exposePathVariables); &#125; Boolean exposeContextBeansAsAttributes = this.getExposeContextBeansAsAttributes(); if (exposeContextBeansAsAttributes != null) &#123; view.setExposeContextBeansAsAttributes(exposeContextBeansAsAttributes); &#125; String[] exposedContextBeanNames = this.getExposedContextBeanNames(); if (exposedContextBeanNames != null) &#123; view.setExposedContextBeanNames(exposedContextBeanNames); &#125; return view;&#125; 就这样我们得到了一个View对象，这个视图的name就是逻辑视图名，因为当将View对象放在缓存的时候，我们可以通过逻辑视图名在缓存中找出View对象。我们在获取到View对象的时候，我们还要将View进行渲染，并呈现给用户。 View是个接口,AbstractView实现了render方法: 1234567891011public void render(@Nullable Map&lt;String, ?&gt; model, HttpServletRequest request, HttpServletResponse response) throws Exception &#123; if (this.logger.isDebugEnabled()) &#123; this.logger.debug("View " + this.formatViewName() + ", model " + (model != null ? model : Collections.emptyMap()) + (this.staticAttributes.isEmpty() ? "" : ", static attributes " + this.staticAttributes)); &#125; //主要是将一些属性填充到Map中 Map&lt;String, Object&gt; mergedModel = this.createMergedOutputModel(model, request, response); //对response头进行了一些属性设置 this.prepareResponse(request, response); //渲染给页面输出的所有model数据 this.renderMergedOutputModel(mergedModel, this.getRequestToExpose(request), response);&#125; 最后一行的renderMergedOutputModel方法由AbstractView的孙子类InternalResourceView实现InternalResourceView的renderMergedOutputModel方法帮我们获取到视图的物理路径，然后将这段路径传给RequestDispatcher对象，再调用RequestDispatcher的forward方法将页面呈现给用户，这样就走完了视图的解析了。 12345678910111213141516171819202122232425262728293031@Overrideprotected void renderMergedOutputModel( Map&lt;String, Object&gt; model, HttpServletRequest request, HttpServletResponse response) throws Exception &#123; // Expose the model object as request attributes. exposeModelAsRequestAttributes(model, request); // Expose helpers as request attributes, if any. exposeHelpers(request); // Determine the path for the request dispatcher. String dispatcherPath = prepareForRendering(request, response); // Obtain a RequestDispatcher for the target resource (typically a JSP). RequestDispatcher rd = getRequestDispatcher(request, dispatcherPath); if (rd == null) &#123; throw new ServletException("Could not get RequestDispatcher for [" + getUrl() + "]: Check that the corresponding file exists within your web application archive!"); &#125; // If already included or response already committed, perform include, else forward. if (useInclude(request, response)) &#123; response.setContentType(getContentType()); if (logger.isDebugEnabled()) &#123; logger.debug("Including resource [" + getUrl() + "] in InternalResourceView '" + getBeanName() + "'"); &#125; rd.include(request, response); &#125;else &#123; // Note: The forwarded resource is supposed to determine the content type itself. if (logger.isDebugEnabled()) &#123; logger.debug("Forwarding to resource [" + getUrl() + "] in InternalResourceView '" + getBeanName() + "'"); &#125; //对请求进行转发，至此结束了视图解析解析过程 rd.forward(request, response); &#125;&#125; 最后一句话总结：视图解析器只是为了得到视图对象；视图对象才是真正的转发（将模型数据发在request域中数据）或重定向到页面（视图对象才是真正的渲染视图）。]]></content>
      <categories>
        <category>Spring框架</category>
      </categories>
      <tags>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC处理模型参数]]></title>
    <url>%2F2019%2F08%2F07%2FSpringMVC-%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[SpringMVC 提供了以下几种途径输出模型数据: ModelAndView: 处理方法返回值类型为 ModelAndView时, 方法体即可通过该对象添加模型数据 Map、Model以及ModelMap:入参为org.springframework.ui.Model、org.springframework.ui.ModelMap 或 Java.uti.Map 时，处理方法返回时，Map中的数据会自动添加到模型中。 @SessionAttributes: 将模型中的某个属性暂存到HttpSession 中，以便多个请求之间可以共享这个属性 @ModelAttribute: 方法入参标注该注解后, 入参的对象就会放到数据模型中。 当然，除了上面这些SpringMVC提供的几种方法，SpringMVC支持直接使用Servlet几个原生API来给页面传值: HttpServletRequest request、HttpservletResponse response、HttpSession session、InputStream/Reader 对应request.getInputStream()、OutputStream/Writer 对应response.getOutputStram() servlet原生API给页面传值123456789101112131415/** * 使用servlet原生API给页面输出数据 * @param request * @param session * @return */ @RequestMapping("handler01") public String handler01(HttpServletRequest request, HttpSession session) throws IOException &#123; request.setAttribute("msg","你好，这是HelloController"); session.setAttribute("msg","json123"); return "success"; &#125; 页面测试代码:success.jsp 1234567891011121314151617181920212223242526272829303132&lt;%@ page contentType="text/html;charset=UTF-8" language="java" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;成功&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;center&gt; &lt;table border="1px" width="70%" &gt; &lt;tr&gt; &lt;th&gt;域&lt;/th&gt; &lt;th&gt;值&lt;/th&gt; &lt;/tr&gt; &lt;tr&gt; &lt;th&gt;requestScope&lt;/th&gt; &lt;td&gt;$&#123;requestScope.msg&#125;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;th&gt;sessionScope&lt;/th&gt; &lt;td&gt;$&#123;sessionScope.msg&#125;&#125;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;th&gt;applicationScope&lt;/th&gt; &lt;td&gt;$&#123;applicationScope.msg&#125;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;th&gt;pageScope&lt;/th&gt; &lt;td&gt;$&#123;pageScope.msg&#125;&lt;/td&gt; &lt;/tr&gt; &lt;/table&gt;&lt;/center&gt;&lt;/body&gt;&lt;/html&gt; 测试结果： Model、Map、ModelMap首先通过通过源码看看他们三者的关系：ModelMap类 Model接口 ExtendModelMap类 BindingAwareModelMap类 通过打开源码，我们不难总结出如下继承关系 ： 接下来看看他们的用法：示例代码 123456789101112131415161718192021222324252627282930313233343536373839/** * 使用Model * @param model * @return */ @RequestMapping("/handler02") public String handler02(Model model)&#123; System.out.println("Model"+model.getClass()); model.addAttribute("msg","大家好！这是handler02"); model.addAttribute("id",18); return "success"; &#125; /** * 使用Map * @param map * @return */ @RequestMapping("/handler03") public String handler03(Map&lt;String,String&gt; map)&#123; System.out.println("Map:"+map.getClass()); map.put("msg","handler03"); map.put("logged","admin"); return "success"; &#125; /** * 使用ModelMap * @param modelMap * @return */ @RequestMapping("/handler04") public String handler04(ModelMap modelMap)&#123; System.out.println("ModelMap:"+modelMap.getClass()); modelMap.addAttribute("msg","handler04"); return "success"; &#125; 页面代码和上面样 测试结果：页面的显示： 控制台打印的信息: 从测试结果可以总结出：Model(SpringMVC接口)其中一个实现类是ExtendedModelMapModelMap是Map(JDK的接口)Map的一个实现类,并且ModelMap被ExtendedModelMapExtendedModelMap被BindingAwareModelMap继承Model、Map、ModelMap不论用哪个，最终工作的都是BindingAwareModelMap,而且从测试结果可以看到通过这三个设置的值，SpringMVC都把他们放在了request域中。 ModelAndView 目标方法的返回值可以是ModelAndView类型，从名字上就可以看到，这是一个既包括模型(Model)又有视图(View)的一个类， 然而事实也确实如此，他的model就可以理解为送给页面的数据，他的View可以理解为目标页面地址。但我们在他的model中放入值后，SpringMVC会把ModelAndView的model中数据放在request域对象中。 示例代码 123456789101112 /** * 方法的返回值可以是 ModelAndView类型，这样我们可以把值设置在model中 * 然后springmvc会把ModelAndView的model中数据放在request域对象中 * @return */@RequestMapping("/handler05")public ModelAndView handler05()&#123; ModelAndView mv=new ModelAndView("success"); mv.addObject("msg","handler05"); return mv;&#125; 测试结果： 使用@SessionAttributes注解如果希望在多个请求之间共用某个模型属性数据，则可以在控制器类标注一个 @SessionAttributes，SpringMVC 会将模型中对应的属性暂存到 HTTPSession 中。@SessionAttributes 除了可以通过属性名指定需要放到会话中的属性外，还可以通过模型属性的对象类型指定哪些模型属性需要放到会话中。 @SessionAttributes(types=User.class)会将隐含模型中所有类型为 User 的属性添加到会话中 @SessionAttributes(value={“user1”, “user2”})将名为 user1 和 user2 的模型属性添加到会话中 @SessionAttributes(types={“User.class”, “Dept.class”})将模型中所有类型为 User 及 Dept 的属性添加到会话中 @SessionAtributes(value={“user1”, “user2”}, types={Dept.class})将名为 user1 和 user2 的模型属性添加到会话中，同时将所有类型为 Dept 的模型属性添加到会话中总之：当使用@SessionAttributes注解时就是告诉SpringMVC,当@SessionAttributes中的value值和BindingAwareModelMap的key一样时，那么在session也你也给我保存一份相同的值示例代码：1234567891011121314//使用的时候一定要注意@SessionAttributes只能用在类上@SessionAttributes(value=&#123;"id","logged"&#125;)@Controllerpublic class HelloController &#123; @RequestMapping("/handler0") public String sessionAttributesTest(Model model)&#123; model.addAttribute("msg","handler0"); //这个会在request中显示 model.addAttribute("logged",new Date()); //会在session中显示 model.addAttribute("id","001"); //会在session中显示 return "success"; &#125;&#125; 页面代码对success.jsp中的sessionScope稍作修改： 1234 &lt;tr&gt; &lt;th&gt;sessionScope&lt;/th&gt; &lt;td&gt;$&#123;sessionScope.msg&#125; | $&#123;sessionScope.id&#125; |$&#123;sessionScope.logged&#125;&lt;/td&gt;&lt;/tr&gt; 测试结果： 使用@ModelAttribute注解先来看看ModelAttribute的定义：查看 @ModelAttribute注解定义可以看到这个注解可以用在方法和参数中。 在 SpringMVC 的 Controller 中使用 @ModelAttribute 时，应用情况包括下面几种：1、应用在方法上。2、应用在方法的参数上。3、应用在方法上，并且方法也使用了@RequestMapping 示例代码：修改图书信息的页面： 123456789101112131415161718192021222324252627&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;SpringMVC给页面输出数据&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;center&gt;&lt;!-- &lt;a href="handler01"&gt;原生API输出数据&lt;/a&gt;&lt;br/&gt; &lt;a href="handler02"&gt;Model输出数据&lt;/a&gt;&lt;br/&gt; &lt;a href="handler03"&gt;Map输出数据&lt;/a&gt;&lt;br/&gt; &lt;a href="handler04"&gt;ModelMap输出数据&lt;/a&gt;&lt;br/&gt; &lt;a href="handler05"&gt;ModelAndView带回返回值&lt;/a&gt;&lt;br/&gt;--&gt; &lt;h3&gt;更新图书信息&lt;/h3&gt; &lt;form action="update" method="post"&gt; 书名：&lt;label&gt;西游记&lt;/label&gt;&lt;br/&gt; 作者：&lt;label&gt;吴承恩&lt;/label&gt;&lt;br/&gt; 价格：&lt;input type="text" name="price" placeholder="输入价格..."/&gt;&lt;br/&gt; 库存：&lt;input type="text" name="stock" placeholder="输入库存..."/&gt;&lt;br/&gt; 销量：&lt;input type="text" name="sales" placeholder="输入销量..."/&gt;&lt;br/&gt; &lt;button type="submit"&gt;提交信息&lt;/button&gt; &lt;/form&gt;&lt;/center&gt;&lt;/body&gt;&lt;/html&gt; 提交图书修改信息后的页面： 12345678910111213141516171819202122232425262728&lt;%-- Created by IntelliJ IDEA. User: Administrator Date: 2019/8/7 Time: 10:34 To change this template use File | Settings | File Templates.--%&gt;&lt;%@ page contentType="text/html;charset=UTF-8" language="java" %&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;更新图书&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;center&gt; &lt;div style="height: 200px;width: 100%"&gt; &lt;h3&gt;提交的书籍的信息：&lt;/h3&gt; &lt;table border="1px" width="50%"&gt; &lt;tr&gt;&lt;th&gt;书名&lt;/th&gt;&lt;td&gt;$&#123;book.name&#125;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;th&gt;作者&lt;/th&gt;&lt;td&gt;$&#123;book.author&#125;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;th&gt;价格&lt;/th&gt;&lt;td&gt;$&#123;book.price&#125;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;th&gt;库存&lt;/th&gt;&lt;td&gt;$&#123;book.stock&#125;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;th&gt;销量&lt;/th&gt;&lt;td&gt;$&#123;book.sales&#125;&lt;/td&gt;&lt;/tr&gt; &lt;/table&gt; &lt;/div&gt;&lt;/center&gt;&lt;/body&gt;&lt;/html&gt; 如果没有使用@ModelAttribute，那么要更新数据信息，必须要全字段更新，即使你不需要更新的的字段，你也要填写，这显然不和常理，因为如果你不填写这个值，值就会为null。最主要是因为SpringMVC在封装提交的信息的时候只会new一个Book对象，里面的属性的值初始就是null。你没有填写也只会以null存到数据库。不使用@ModelAttribute进行非全字段更新 12345678@Controllerpublic class BookController &#123; @RequestMapping("/update") public String update(Book book)&#123; System.out.println("更新图书的信息......页面提交过来的图书信息："+book); return "updateBook"; &#125; &#125; 测试结果:页面的显示： 看看控制台的打印信息： 可以看到果然不出预料的出问题了，更新信息后书名和作者的信息没了。这就相当于你更改了一下你的QQ密码，然后你的QQ号没了！这是很可怕的事情。使用@ModelAttribute解决问题： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package com.xzy.Contorller;import bean.Address;import bean.Book;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.ModelAttribute;import org.springframework.web.bind.annotation.RequestMapping;import java.util.Map;@Controllerpublic class BookController &#123; /** * 用在方法上：这个方法就会优先于该类中的左右处理器方法先执行 * @param map */ @ModelAttribute public void getBook(Map&lt;String,Object&gt; map)&#123; //模拟从数据库中查询图书数据 Book book=new Book(); book.setName("西游记"); book.setPrice(9.98); book.setAuthor("吴承恩"); book.setSales(300); book.setStock(400); System.out.println("数据库中查询到Book的信息："+book); map.put("book",book); System.out.println("ModelAttribute将查询到的图书信息保存起来.......："); &#125;&#125; /** * 可以告诉SpringMVC,你不要去new Book对象了，我已经从数据库中查询到了，你直接拿过去用就好了。 * 问题是：如何告诉SpringMVC来用这个已经处理好的Book对象呢？ * 这就是@ModelAttribute在参数位置的用法： * 下面的@ModelAttribute("book")，就是告诉SpringMVC，去拿一个key为 * book的值，你不要重新new一个Book对象了，这样做的好处是可以只更改有更新的数据，没有更新的就保持原始值 * @param book * @return */ @RequestMapping("/update") public String update(@ModelAttribute("book") Book book)&#123; System.out.println("更新图书的信息......页面提交过来的图书信息："+book); return "updateBook"; &#125; 测试结果：页面展示的结果： 控制台打印的信息： 而且从控制台打印的信息来看，被@ModelAttribute标识的方法确实是在处理器方法之前执行了 @Modelattribute的原理废话不多说，直接看代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package com.xzy.Contorller;import bean.Address;import bean.Book;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.ModelAttribute;import org.springframework.web.bind.annotation.RequestMapping;import java.util.Map;/** * @Author: HuangXin * @Date: Created in 10:33 2019/8/7 * @Description: */@Controllerpublic class BookController &#123; private Object obj1; private Object b1; /** * 可以告诉SpringMVC,你不要去new Book对象了，我已经从数据库中查询到了，你直接拿过去用就好了。 * 问题是：如何告诉SpringMVC来用这个已经处理好的Book对象呢？ * 这就是@ModelAttribute在参数位置的用法： * 下面的@ModelAttribute("book")，就是告诉SpringMVC，你去拿一个key为book的值， * 你不要重新new一个Book对象了 * @param book * @return */ @RequestMapping("/update") public String update(@ModelAttribute("book") Book book, Map&lt;String,Object&gt; model)&#123; System.out.println("处理器方法的map:"+model.getClass()); System.out.println("book==b1=&gt;"+(book==b1)); System.out.println("obj1==model=&gt;"+(obj1==model)); System.out.println("更新图书的信息......页面提交过来的图书信息："+book); return "updateBook"; &#125; /** * 用在方法上：这个方法就会优先于该类中的左右处理器方法先执行 * * @param map */ @ModelAttribute public void getBook(Map&lt;String,Object&gt; map)&#123; //模拟从数据库中拿数据 Book book=new Book(); book.setName("西游记"); book.setPrice(9.98); book.setAuthor("吴承恩"); book.setSales(300); book.setStock(400); System.out.println("数据库中查询到Book的信息："+book); obj1=map; b1=book; map.put("book",book); System.out.println("@ModelAttribute中的map:"+map.getClass()); System.out.println("ModelAttribute将查询到的图书信息保存起来.......："); &#125;&#125; 测试结果： 最后总结为一张图：]]></content>
      <categories>
        <category>Spring框架</category>
      </categories>
      <tags>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC获取请求参数]]></title>
    <url>%2F2019%2F08%2F06%2FSpringmvc%2F</url>
    <content type="text"><![CDATA[第一种方式：方法的形参上给一个和请求参数同名的参数1.获得普通类型的参数值示例代码 123456789101112131415/** * 第1种获得请求参数的方式：在方法的形参上给一个和请求参数同名的参数， * 之后SpringMVC会帮我们自动注入参数值 * @param username * @param model * @return */@RequestMapping(value = "/welcome")public String welcome(String username, Model model)&#123; System.out.println("用户名："+username); model.addAttribute("username",username); return "success";&#125; 2.获得POJO类型的值示例代码：新建Book.java以及Address.java两个POJOBook.java 12345678910111213package com.xzy.bean;public class Book &#123; private String name; private Double price; private Integer stock; //库存 private Integer sales; //销量 private String author; private Address address; //地址 //省略getter、setter方法，并且重写toString()方法&#125; Address.java 123456789package com.xzy.bean;public class Address &#123; private String province; private String county; private String city; //省略getter、setter方法，并且重写toString()方法 写一个简单的表单：index.html 1234567891011121314151617181920212223&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;SpringMvc获取参数&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;center&gt; &lt;h3&gt;录入书籍信息&lt;/h3&gt; &lt;form action="book" method="post"&gt; 书名：&lt;input type="text" name="name" placeholder="输入书名..."/&gt;&lt;br/&gt; 作者：&lt;input type="text" name="author" placeholder="输入作者..."/&gt;&lt;br/&gt; 价格：&lt;input type="text" name="price" placeholder="输入价格..."/&gt;&lt;br/&gt; 库存：&lt;input type="text" name="stock" placeholder="输入库存..."/&gt;&lt;br/&gt; 销量：&lt;input type="text" name="sales" placeholder="输入销量..."/&gt;&lt;br/&gt; &lt;input type="text" name="address.province" /&gt;省&amp;nbsp; &lt;input type="text" name="address.city" /&gt;市&amp;nbsp; &lt;input type="text" name="address.county" /&gt;(区/县)&amp;nbsp;&lt;br/&gt; &lt;button type="submit"&gt;提交信息&lt;/button&gt; &lt;/form&gt;&lt;/center&gt;&lt;/body&gt;&lt;/html&gt; 提交后的页面：book.jsp 12345678910111213141516171819202122232425&lt;%@ taglib prefix="c" uri="http://java.sun.com/jsp/jstl/core" %&gt;&lt;%@ page contentType="text/html;charset=UTF-8" language="java" import="com.xzy.bean.*"%&gt;&lt;html&gt;&lt;head&gt; &lt;title&gt;SpringMVC获取参数&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;center&gt; &lt;div style="height: 200px;width: 100%"&gt; &lt;h3&gt;提交的书籍的信息：&lt;/h3&gt; &lt;table border="1px" width="50%"&gt; &lt;tr&gt;&lt;th&gt;书名&lt;/th&gt;&lt;td&gt;$&#123;book.name&#125;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;th&gt;作者&lt;/th&gt;&lt;td&gt;$&#123;book.author&#125;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;th&gt;价格&lt;/th&gt;&lt;td&gt;$&#123;book.price&#125;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;th&gt;库存&lt;/th&gt;&lt;td&gt;$&#123;book.stock&#125;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;th&gt;销量&lt;/th&gt;&lt;td&gt;$&#123;book.sales&#125;&lt;/td&gt;&lt;/tr&gt; &lt;tr&gt;&lt;th&gt;地区&lt;/th&gt;&lt;td&gt;$&#123;book.address&#125;&lt;/td&gt;&lt;/tr&gt; &lt;/table&gt; &lt;/div&gt;&lt;/center&gt;&lt;/body&gt;&lt;/html&gt; 提供一个控制器：BookContorller.java 1234567891011121314151617181920212223242526package com.xzy.controller;import com.xzy.bean.Book;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;import javax.servlet.http.HttpServletRequest;@Controllerpublic class BookContorller &#123; /** * SprningMVC帮我们自动注入参数到POJO类型中，而且还可以级联注入 * @param book * @param request * @return */ @RequestMapping("/book") public String addbook(Book book, HttpServletRequest request)&#123; //打印得到的book信息 System.out.println(book); request.setAttribute("book",book); return "book"; &#125;&#125; 测试结果： 第二种方式：使用Spring提供的注解1. 使用@RequestParam 获取参数分析@RequestParam的源码： 123456789101112131415public @interface RequestParam &#123; //默认值就是它，表示请求参数的key @AliasFor("name") String value() default ""; //请求参数的值 @AliasFor("value") String name() default ""; //设置这个参数是否必须，required=false表示这个参数不是必须的 boolean required() default true; //参数的默认值 String defaultValue() default "\n\t\t\n\t\t\n\ue000\ue001\ue002\n\t\t\t\t\n"; &#125; 示例代码： 12345678910111213141516171819/** * RequestParam设置获取参数的key为user,required=false表示这个参数不是必须的， * defaultValue是这个参数的默认值 * @RequestParam(value = "user", required = false, defaultValue = "") String username； * 等价于以前写的： * String user=null!=request.getParameter("user")?request.getParameter("user"):""; * @param username * @param model * @return */@RequestMapping("/welcome3")public String welocme3( @RequestParam(value = "user", required = false, defaultValue = "") String username, Model model) &#123; System.out.println("用户名：" + username); model.addAttribute("username", username); return "success";&#125; 2.使用@RequestHeader获得请求的头部信息@RequestHeader和@ReuqestParma的实现方式如出一辙，使用方法也基本相同。示例代码1：使用RequestHeader注解获得浏览器的信息 123456789101112131415161718192021/** * @RequestHeader(value = "User-Agent",required = false,defaultValue = "") String userAgent * 获取请求头中的值，相当于以前写的： * String header=null!=request.getHeader("User-Agent")? request.getHeader("User-Agent"):""; * @param username * @param userAgent * @param model * @return */ @RequestMapping("/welcome4") public String welocme4( @RequestParam(value = "user", required = false, defaultValue = "") String username, @RequestHeader(value = "User-Agent",defaultValue = "") String userAgent, Model model) &#123; System.out.println("用户名：" + username); System.out.println("User-Agent"+userAgent); model.addAttribute("userAgent",userAgent); model.addAttribute("username", username); return "success"; &#125; 示例代码2：使用RequestHeader注解获取请求头部的Cookie信息 123456789101112131415161718/** * 使用RequestHeader获得请求头中的Cookie的全部信息 * @param username * @param cookie * @param model * @return */ @RequestMapping("/welcome5") public String welocome5( @RequestParam(value = "user", required = false, defaultValue = "") String username, @RequestHeader(value = "Cookie",required = false,defaultValue = "") String cookie, Model model)&#123; System.out.println("用户名：" + username); model.addAttribute("cookie",cookie); model.addAttribute("username", username); return "success"; &#125; 3.使用CookieValue获得请求头部的JSESSIONID示例代码： 123456789101112131415161718192021/** * 使用SpringMVC提供的@CookieValue注解，可以只获的JSESSIONID的值 * @param username * @param cookie * @param model * @return */ @RequestMapping("/welcome6") public String welocome6( @RequestParam(value = "user", required = false, defaultValue = "") String username, @CookieValue(value = "JSESSIONID" ,required = false,defaultValue = "") String cookie, Model model)&#123; System.out.println("用户名：" + username); model.addAttribute("cookie",cookie); model.addAttribute("username", username); System.out.println("cookie："+cookie); return "success"; &#125;]]></content>
      <categories>
        <category>Spring框架</category>
      </categories>
      <tags>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC 对Ant风格和Rest风格支持]]></title>
    <url>%2F2019%2F08%2F04%2FSpringMVC%E6%94%AF%E6%8C%81%E7%9A%84%E5%87%A0%E7%A7%8D%E9%A3%8E%E6%A0%BC%E7%9A%84URL%E5%BD%A2%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Ant风格的URL形式Ant风格的URL指的是URL的路径可以写成模糊路径，然后Spring MVC会帮我们匹配， ?：匹配一个字符 *: 匹配多个字符以及一层URL路径 **:可以匹配多个字符以及多层路径 匹配的规则：以最精确的路径为准，就是说当有多个路径可以匹配的时候，以最精确的路径为目标去访问 示例代码：新建AntTestServlet.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package com.xzy.controller;import org.springframework.stereotype.Controller;import org.springframework.web.bind.annotation.RequestMapping;/** * * Ant风格的URL指的是URL的路径可以写成模糊路径，然后Spring MVC会帮我们匹配 * ?：匹配一个字符 * *: 匹配多个字符以及一层URL路径 * **:可以匹配多个字符以及多层路径 * 匹配的规则：以最精确的路径为准，就是说当有多个路径可以匹配的时候，以最精确的路径为目标去访问 */@RequestMapping("/ant")@Controllerpublic class AntTestServlet &#123; @RequestMapping("/handler1") public String handler1()&#123; System.out.println("访问了handler1()"); return "index"; &#125; //?可以匹配一个字符（“/”除外）,0个和多个都不行 @RequestMapping("/handler?") public String handler2()&#123; System.out.println("访问了handler2()"); return "index"; &#125; //*可以匹配任意多个字符 @RequestMapping("/handler*") public String handler3()&#123; System.out.println("访问了handler3()"); return "index"; &#125; /** * 匹配一层路径 * @return */ @RequestMapping("test/*/handler*") public String handler4()&#123; System.out.println("访问了handler4()"); return "index"; &#125; /** *匹配多层路径 * @return */ @RequestMapping("test/**/handler*") public String handler5()&#123; System.out.println("访问了handler5()"); return "index"; &#125;&#125; 测试结果: @PathVariable 路径占位符使用@PathVariable 注解可以获得路径中占位符的值示例代码: 测试结果： REST风格的URL形式编写一个控制器BooKContorller，模拟业务处理，里面写上增删改查的基本方法，然后定义不同的方法只有不同的请求才可以访问。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package com.xzy.controller;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.PathVariable;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RequestMethod;@Controllerpublic class BookContorller &#123; /** * 增加一本书 * @param model * @param bookId * @return */ @RequestMapping(value = "book/&#123;bookId&#125;",method = RequestMethod.PUT) public String addBook(Model model,@PathVariable String bookId)&#123; model.addAttribute("msg","添加了一本书,书的Id是："+bookId); return "index"; &#125; /** * 删除一本书 * @param model * @param bookId * @return */ @RequestMapping(value = "book/&#123;bookId&#125;",method = RequestMethod.DELETE) public String deleteBook(Model model,@PathVariable String bookId)&#123; model.addAttribute("msg","删除了一本书,书的Id是："+bookId); return "index"; &#125; /** * 更新一本书 * @param model * @param bookId * @return */ @RequestMapping(value = "book/&#123;bookId&#125;",method = RequestMethod.POST) public String updateBook(Model model,@PathVariable String bookId)&#123; model.addAttribute("msg","更新了一本书,书的Id是："+bookId); return "index"; &#125; /** * 查询一本书 * @param model * @param bookId * @return */ @RequestMapping(value = "book/&#123;bookId&#125;",method = RequestMethod.GET) public String getBook(Model model,@PathVariable String bookId)&#123; model.addAttribute("msg","查询了一本书,书的Id是："+bookId); return "index"; &#125;&#125; 但是页面上只能发出GET 和POST两种请求，如何解决delete和put请求呢？对于这个问题，SpringMVC中也给予了支持，即org.springframework.web.filter.HiddenHttpMethodFilter这个过滤器，只需要我们在web.xml中配置一个关于请求方法的过滤器： 123456789&lt;!--配置Http所有method的过滤器--&gt;&lt;filter&gt; &lt;filter-name&gt;HiddenHttpMethodFilter&lt;/filter-name&gt; &lt;filter-class&gt;org.springframework.web.filter.HiddenHttpMethodFilter&lt;/filter-class&gt;&lt;/filter&gt;&lt;filter-mapping&gt; &lt;filter-name&gt;HiddenHttpMethodFilter&lt;/filter-name&gt; &lt;url-pattern&gt;/*&lt;/url-pattern&gt;&lt;/filter-mapping&gt; 然后在一个带有POST请求的表单里加入&lt;input name=&quot;_method&quot; value=&quot;请求方法名&quot;&gt;，value后面就填写需要的请求方法名即可。 123456789101112131415161718192021222324252627&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;@RequestMapping测试&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;form action="book/1" method="get"&gt; &lt;input name="bookId"/&gt; &lt;button type="submit"&gt;查询一本书&lt;/button&gt; &lt;/form&gt; &lt;form action="book/1" method="post"&gt; &lt;input name="_method" value="delete"&gt; &lt;button type="submit"&gt;删除一本书&lt;/button&gt; &lt;/form&gt; &lt;form action="book/1" method="post"&gt; &lt;input name="_method" value="put"&gt; &lt;button type="submit"&gt;增加一本书&lt;/button&gt; &lt;/form&gt; &lt;form action="book/1" method="post"&gt; &lt;button type="submit"&gt;更新一本书&lt;/button&gt; &lt;/form&gt;&lt;/center&gt;&lt;/body&gt;&lt;/html&gt; 运行后会有一个问题：GET和POST的参数可以正常处理，但是当DELETE和PUT请求的时候，就会有下面的异常： 这是由于8.0以上的Tomcat不允许除了POST和GET以外的其他请求来访问JSP页面，解决的办法也很简单，如下： 解决这个问题后，最终的测试结果如下图：]]></content>
      <categories>
        <category>Spring框架</category>
      </categories>
      <tags>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RequestMapping注解]]></title>
    <url>%2F2019%2F08%2F04%2FSpringMVC%20RequestMapping%E6%B3%A8%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[@RequestMapping注解是一个十分强大的注解，Spring MVC使用@RequestMapping注解为控制器指定可以处理那些URL请求，在控制器的类上或类中的方法上均可以使用这个注解： 在类上使用可以提供初步的映射信息。相当于一个根路径 在方法上使用提供更进一步的细分映射信息。 这是一个只在方法上使用的例子： 1234567891011121314151617package com.xzy.controller;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.RequestMapping;@Controllerpublic class HelloServlet0 &#123; @RequestMapping("/hello") public String sayHello(Model model)&#123; System.out.println("收到请求，正在处理......."); model.addAttribute("msg","This is a Spring MVC Web"); return "success"; &#125;&#125; 这是一个在类和方法同时使用的例子： 1234567891011121314151617181920package com.xzy.controller;import com.xzy.bean.Teacher;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.RequestMapping;@Controller@RequestMapping("/welcome") //这个相当于是基准路径public class HelloServlet &#123; @RequestMapping("/hello") public String sayHello(Model model)&#123; System.out.println("收到请求，正在处理......"); model.addAttribute("msg","Welcome to SpringMVC!"); return "hello"; &#125;&#125; @Requestmapping的属性: 属性作用 value 默认的属性就是value,他就是一个URL路径，可以在一个方法上或类上给多个value值 method 用来定义接收浏览器发来的何种请求。在Spring中，使用枚举类RequestMethod来封装了HTTP协议的所有请求方式。最基本的有GET、POST、DELETE、PUT params 表示请求参数，也就是追加在URL上的键值对，多个请求参数以&隔开 headers 该属性表示请求头，通过 @RequestMapping 中的 headers 属性，可以限制客户端发来的请求 consumes 规定请求头的Content-Type produces 告诉浏览器返回的内容是什么，给响应头中加上Content-Type 示例代码：method:限定请求方法 12345678910111213141516171819202122232425262728HelloServlet.java /** * 指定只有GET请求才可一访问 * @param model * @return */ @RequestMapping(value="/handler1",method= RequestMethod.GET) public String handler1(Model model)&#123; System.out.println("收到请求，正在处理......"); model.addAttribute("msg","这是一个只有GET请求才可以访问页面"); return "success"; &#125; /** * 指定只有POST请求才可以来访问 * @param model * @return */ @RequestMapping(value = "/handler2",method = RequestMethod.POST) public String handler2(Model model)&#123; System.out.println("收到请求，正在处理......"); model.addAttribute("msg","这是一个只有POST请求才可以访问页面"); return "success"; &#125; 1234567891011121314151617&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;@RequestMapping测试&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;center&gt; &lt;a href="hello"&gt;1.只在方法方法上用@RequestMapping注解&lt;/a&gt;&lt;br/&gt; &lt;a href="home/hello"&gt;2.在类和方法上同时用@RequestMapping注解&lt;/a&gt;&lt;br/&gt; &lt;a href="home/handler1"&gt;3.通过GET方法来访问&lt;/a&gt;&lt;br/&gt; &lt;form action="home/handler2" method="post"&gt; &lt;button type="submit"&gt;4.POST提交&lt;/button&gt; &lt;/form&gt;&lt;/center&gt;&lt;/body&gt;&lt;/html&gt; parmars:限定参数parmars支持简单的表达式计算，例如:eg1:params = {“username”} ,表示请求的路径中必须要有username这个关键字，如果没有就会报异常 eg2:params = {“!username”} ,表示请求的路径中不能有username这个关键字，如果有这个参数就会报异常eg2:params = {“username”,”age=20”,”pwd”} ,表示请求的路径中必须要有username、age、pwd这三个关键字，并且age必须是20，如果没有或age的值不等就会报异常 12345678910111213141516171819&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;@RequestMapping测试&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;center&gt; &lt;a href="hello"&gt;1.只在方法方法上用@RequestMapping注解&lt;/a&gt;&lt;br/&gt; &lt;a href="home/hello"&gt;2.在类和方法上同时用@RequestMapping注解&lt;/a&gt;&lt;br/&gt; &lt;a href="home/handler1"&gt;3.通过GET方法来访问&lt;/a&gt;&lt;br/&gt; &lt;form action="home/handler2" method="post"&gt; &lt;button type="submit"&gt;4.POST提交&lt;/button&gt; &lt;/form&gt; &lt;a href="home/handler3?username=hx"&gt;5.限定请求参数1&lt;/a&gt;&lt;br/&gt; &lt;a href="home/handler4?username=hx&amp;age=20&amp;pwd=123456"&gt;5.限定请求参数2&lt;/a&gt;&lt;br/&gt;&lt;/center&gt;&lt;/body&gt;&lt;/html&gt; headers:限定请求头部示例一： 测试结果：]]></content>
      <categories>
        <category>Spring框架</category>
      </categories>
      <tags>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[SpringMVC的运行流程]]></title>
    <url>%2F2019%2F08%2F03%2FSpringMVC%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[Spring MVC体系结构：SpringMVC 是基于 Model2 实现的技术框架 一个请求在SpringMVC中经历的过程： 请求旅程的第一站是 Spring 的 DispatcherServlet。与大多数基于 Java 的 Web 框架一样，Spring MVC 所有的请求都会通过一个前端控制器（front controller）Servlet。前端控制器是常用的 Web 应用程序模式，在这里一个单实例的 Servlet 将请求委托给应用程序的其他组件来执行实际的处理。在 Spring MVC 中，DispatcherServlet 就是前端控制器。 DispatcherServlet 的任务是将请求发送给 Spring MVC 控制器（controller）。控制器是一个用于处理请求的 Spring 组件。在典型的应用程序中可能会有多个控制器，DispatcherServlet 需要知道应该将请求发送给哪个控制器。所以 DispatcherServlet 以会查询一个或多个处理器映射（handler mapping） 来确定请求的下一站在哪里。处理器映射会根据请求所携带的 URL 信息来进行决策。 一旦选择了合适的控制器，DispatcherServlet 会将请求发送给选中的控制器 。到了控制器，请求会卸下其负载（用户提交的信息）并耐心等待控制器处理这些信息。（实际上，设计良好的控制器本身只处理很少甚至不处理工作，而是将业务逻辑委托给一个或多个服务对象进行处理。） 控制器在完成逻辑处理后，通常会产生一些信息，这些信息需要返回给用户并在浏览器上显示。这些信息被称为模型（model）。不过仅仅给用户返回原始的信息是不够的——这些信息需要以用户友好的方式进行格式化，一般会是 HTML。所以，信息需要发送给一个视图（view），通常会是 JSP。 控制器所做的最后一件事就是将模型数据打包，并且标示出用于渲染输出的视图名。它接下来会将请求连同模型和视图名发送回 DispatcherServlet 。 这样，控制器就不会与特定的视图相耦合，传递给 DispatcherServlet 的视图名并不直接表示某个特定的 JSP。实际上，它甚至并不能确定视图就是 JSP。相反，它仅仅传递了一个逻辑名称，个名字将会用来查找产生结果的真正视图。DispatcherServlet 将会使用视图解析器（viewResolver）来将逻辑视图名匹配为一个特定的视图实现，它可能是也可能不是 JSP。 既然 DispatcherServlet 已经知道由哪个视图渲染结果，那请求的任务基本上也就完成了。它的最后一站是视图的实现（可能是 JSP） ，在这里它交付模型数据。请求的任务就完成了。视图将使用模型数据渲染输出，这个输出会通过响应对象传递给客户端（不会像听上去那样硬编码） 。 可以看到，请求要经过很多的步骤，最终才能形成返回给客户端的响应。大多数的步骤都是在 Spring 框架内部完成的，也就是上图所示的组件中。 第一个SpringMVC程序第一步：配置环境（新建Web工程+导包+配置Tomcat）在IDEA中新建MavenWeb工程，新建好后导包，使用SpringMVC所需要的基本的Maven依赖如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110pom.xml中的依赖&lt;properties &lt;spring.version&gt;5.1.4.RELEASE&lt;/spring.version&gt;&lt;/properties&gt;&lt;!--Servlet JSP依赖 --&gt;&lt;!-- https://mvnrepository.com/artifact/taglibs/standard --&gt;&lt;dependency&gt;&lt;groupId&gt;taglibs&lt;/groupId&gt; &lt;artifactId&gt;standard&lt;/artifactId&gt; &lt;version&gt;1.1.2&lt;/version&gt; &lt;type&gt;jar&lt;/type&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/javax.servlet/jstl --&gt;&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;jstl&lt;/artifactId&gt; &lt;version&gt;1.2&lt;/version&gt; &lt;type&gt;jar&lt;/type&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/javax.servlet/javax.servlet-api --&gt;&lt;dependency&gt; &lt;groupId&gt;javax.servlet&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet-api&lt;/artifactId&gt; &lt;version&gt;3.1.0&lt;/version&gt; &lt;scope&gt;provided&lt;/scope&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/javax.servlet.jsp/javax.servlet.jsp-api --&gt;&lt;dependency&gt; &lt;groupId&gt;javax.servlet.jsp&lt;/groupId&gt; &lt;artifactId&gt;javax.servlet.jsp-api&lt;/artifactId&gt; &lt;version&gt;2.2.1&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-core --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-context --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-beans --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-beans --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aop&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-web --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.springframework/spring-webmvc --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjrt&lt;/artifactId&gt; &lt;version&gt;1.7.4&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.7.4&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;cglib&lt;/groupId&gt; &lt;artifactId&gt;cglib&lt;/artifactId&gt; &lt;version&gt;3.1&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.slf4j/slf4j-api --&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.25&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.slf4j/slf4j-log4j12 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-log4j12&lt;/artifactId&gt; &lt;version&gt;1.7.25&lt;/version&gt;&lt;/dependency&gt; 第二步：配置DispatcherServlet通过DispatcherServlet这个名字可以大概了解到，这就是一个servlet,因此要想使一个sevlet起作用无非两种方法：一种是在servle类的头部加@WebServlet注解，二是在web.xml文件中配置&lt;servlet&gt;和servlet-mapping，第一种方法在这里显然不可行，人家源码肯定不能让改，那就需要在web.xml配置它，配置如下: 12345678910111213141516171819&lt;!--配置前段控制器DispatcherServlet到web.xml--&gt;&lt;servlet&gt; &lt;servlet-name&gt;app&lt;/servlet-name&gt; &lt;servlet-class&gt;org.springframework.web.servlet.DispatcherServlet&lt;/servlet-class&gt; &lt;!--初始化参数：是springMVC配置文件的类路径，也可以不配这个，在笔记最后有说明--&gt; &lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:springmvc.xml&lt;/param-value&gt; &lt;/init-param&gt; &lt;load-on-startup&gt;1&lt;/load-on-startup&gt;&lt;/servlet&gt;&lt;servlet-mapping&gt; &lt;servlet-name&gt;app&lt;/servlet-name&gt; &lt;!--url路径表示拦截所有的请求 /和/*都是拦截所有的请求 /*的拦截范围更大，会拦截*.jsp,而/不会拦截*.jsp --&gt; &lt;url-pattern&gt;/&lt;/url-pattern&gt;&lt;/servlet-mapping&gt; 接着在src/resources下新建springmvc.xml，配置springmvc： 123456789101112131415161718192021222324252627&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:mvc="http://www.springframework.org/schema/mvc" xsi:schemaLocation=" http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/mvc http://www.springframework.org/schema/mvc/spring-mvc.xsd"&gt;&lt;mvc:annotation-driven/&gt;&lt;context:annotation-config&gt;&lt;/context:annotation-config&gt;&lt;context:component-scan base-package="com.xzy.contorller"/&gt;&lt;!-- 当请求的中径没有对应的controller 那么就访问静态资源 --&gt;&lt;mvc:default-servlet-handler/&gt;&lt;!--配置一个视图解析器：会帮我们拼接页面地址--&gt;&lt;bean id="jspViewResolver" class="org.springframework.web.servlet.view.InternalResourceViewResolver"&gt; &lt;property name="prefix" value="/WEB-INF/pages/"/&gt; &lt;property name="suffix" value=".jsp"/&gt;&lt;/bean&gt;&lt;/beans&gt; 第三步：在webapp包下新建一个index.html以及hello.jsp，随便写点啥123456789101112&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;center&gt; &lt;a href="hello"&gt;hello&lt;/a&gt;&lt;/center&gt;&lt;/body&gt;&lt;/html&gt; 123456789101112131415161718&lt;%@ page language="java" contentType="text/html; charset=UTF-8" pageEncoding="UTF-8" %&gt;&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;title&gt;Insert title here&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1 align="center"&gt;第一个Spring mVC&lt;/h1&gt;&lt;center&gt; $&#123;msg&#125;&lt;br/&gt; $&#123;teacher.name&#125; &lt;hr/&gt; &lt;img src="img/a1.jpg"/&gt;&lt;/center&gt;&lt;/body&gt;&lt;/html&gt; 第四步：新建一个Controller，比如就叫HelloController1234567891011121314151617181920212223package com.xzy.controller;import com.xzy.bean.Teacher;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.stereotype.Controller;import org.springframework.ui.Model;import org.springframework.web.bind.annotation.RequestMapping;@Controllerpublic class HelloController &#123; @RequestMapping("/hello") public String sayHello(Model model)&#123; System.out.println("收到请求，正在处理......"); model.addAttribute("msg","Welcome to SpringMVC!"); /* &lt;property name="prefix" value="/WEB-INF/pages/"/&gt; &lt;property name="suffix" value=".jsp"/&gt; 在xml配置的视图解析器会自动帮我们拼接页面地址：prefix+返回值+suffix */ return "hello"; &#125;&#125; 测试结果： 总结在做的时候的几细节1. Spring MVC 下Web项目的运行流程：1).点击http://localhost/SpringMVC_01_war_exploded/后浏览器把请求给服务器2).服务器中由于配置了SpringMVC的Dispatcherservlet，他可以拦截到所有的请求3).Dispatcherservlet拦截到请求后查看请求地址和@RequestMapping()中的那个地址(对应的方法)匹配，如果没找到，又没有配置&lt;mvc:defalut-servlet-handler/&gt;那就“炸了”!4).如果前端控制器找到目标处理器和方法后，在执行目标方法前拦截器的preHnalde方法会执行，然后利用反射调用方法5).方法执行完成会有返回值（视图名），SpringMVC认为这就是方法执行完后要去的页面，最终会把它封装成一个ModelAndView对象6).拿到ModelAndView对象后，视图解析器(ViewResolver)会根据ModelAndView解析出实际的视图(View)对象7).得到视图对象后，调用该View对象的render方法来渲染视图，视图渲染完成后前段控制器就会使用转发的方式到目标页面，之后拦截器的afterCompletion方法会被调用 2.关于springmvc.xml配置文件的配置：在web.xml配置前段控制器又这么一段配置，他的作用是告诉服务器去哪里加载对于前端控制器的配置文件： 1234&lt;init-param&gt; &lt;param-name&gt;contextConfigLocation&lt;/param-name&gt; &lt;param-value&gt;classpath:springmvc.xml&lt;/param-value&gt;&lt;/init-param&gt; 如果我们没有写他会发生什么呢？会发生异常： 12345672019-08-03 15:07:16 [INFO]-[org.springframework.web.servlet.DispatcherServlet] Initializing Servlet 'app' 2019-08-03 15:07:16 [ERROR]-[org.springframework.web.servlet.DispatcherServlet] Context initialization failed org.springframework.beans.factory.BeanDefinitionStoreException: IOException parsing XML document from ServletContext resource [/WEB-INF/app-servlet.xml]; nested exception is java.io.FileNotFoundException: Could not open ServletContext resource [/WEB-INF/app-servlet.xml] at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:344) at org.springframework.beans.factory.xml.XmlBeanDefinitionReader.loadBeanDefinitions(XmlBeanDefinitionReader.java:304) at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:188) at org.springframework.beans.factory.support.AbstractBeanDefinitionReader.loadBeanDefinitions(AbstractBeanDefinitionReader.java:224) 一大堆异常信息反正就是告诉中我们启动的时候没有找不到配置文件的路径，SpringMVC默认会在/WEB-INF目录下默认加载一个文件叫app-servlet.xml的文件，然而也没有找到，从而无法完成初始化。从这里我们知道，在web.xml中配置前端控制器的时候也可以不写初始化参数，但是我们必须将springmvc配置文件放在WEB-INF目录下，并且文件的必须名字是：在web.xml中前端控制器的&lt;servlet-name&gt;+-servlet.xml,这是规定，不可随便来，你想节省一些操作就得按人家的要求来。]]></content>
      <categories>
        <category>Spring框架</category>
      </categories>
      <tags>
        <tag>SpringMVC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring AOP详细配置与使用]]></title>
    <url>%2F2019%2F08%2F03%2FSpring%20AOP%E8%AF%A6%E7%BB%86%E9%85%8D%E7%BD%AE%E4%B8%8E%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[AspectJ 通知类型 AOP 联盟定义通知类型，AOP联盟的jar都是接口，必须要有实现类。AspectJ通知类型只定义类型名称，以及方法格式，总共有6种；1.before：前置通知(应用：各种校验) 在方法执行前执行，如果通知抛出异常，将不会执行方法2.afterReturning：后置通知（应用：常规数据处理） 方法正常返回后执行，如果方法中抛出异常，通知将无法执行3. around：环绕通知（应用：十分强大，可以做任何事） 方法执行前后分别执行，可阻止方法执行4.afterThrowing：抛出异常通知（应用：包装异常信息） 方法抛出异常后执行，如果方法没有抛出异常，无法执行5.after：最终通知（应用：清理现场） 方法执行完毕后执行，无论方法中是否出现异常都会执行（类似于finally代码块） 基于XML配置AOP在上一篇笔记Spring AOP两种配置方式(半自动vs全自动)中讲了如何使用xml的方式配置和使用Spring的AOP，这里我们再回顾一下： 首先编写一个service接口,模拟要处理的业务 123456789101112131415161718192021package com.xzy.service;public interface UserSeviceBase &#123; /** * 增加用户 */ public void addUser(); /** * 删除用户 * @param id */ public int deleteUser(int id); /** * 更新用户 * @param id */ public void updateUser(int id);&#125; 实现service接口： 12345678910111213141516171819package com.xzy.service;public class UserSeviceImpl implements UserSeviceBase &#123; @Override public void addUser() &#123; System.out.println("增加了1个用户"); &#125; @Override public int deleteUser(int id) &#123; System.out.println("删除了id为"+id+"的用户"); return id; &#125; @Override public void updateUser(int id) &#123; System.out.println("id为"+id+"的用户更新了"); &#125;&#125; 编写切面类：写一个方法before()，他是在目标方法执行需要增强的功能 1234567891011121314package com.xzy.Aspect;import org.aspectj.lang.JoinPoint;public class MyAspect2 &#123; /* *前置通知 *JoinPoint：连接点 */ public void before(JoinPoint jp)&#123; System.out.println("前置通知........"+jp.getSignature().getName()); //得到方法的名字 &#125;&#125; applicationContext2.xml中的配置如下： 1234567891011121314151617181920212223242526&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:aop="http://www.springframework.org/schema/aop" xsi:schemaLocation="http://www.springframework.org/schema/beans https://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd"&gt; &lt;!--配置bean--&gt; &lt;bean id="userService" class="com.xzy.service.UserSeviceImpl"&gt;&lt;/bean&gt; &lt;!--配置切面类--&gt; &lt;bean id="aspect" class="com.xzy.Aspect.MyAspect2"&gt;&lt;/bean&gt; &lt;!--配置aop--&gt; &lt;aop:config&gt; &lt;!--指定切面--&gt; &lt;aop:aspect ref="aspect"&gt; &lt;!--指定切入点--&gt; &lt;aop:pointcut id="poincut1" expression="execution(* com.xzy.service.*.*(..))"/&gt; &lt;!--前置通知--&gt; &lt;aop:before method="before" pointcut-ref="poincut1"/&gt; &lt;/aop:aspect&gt; &lt;/aop:config&gt;&lt;/beans&gt; 测试： 12345678910111213141516171819package com.xzy;import com.xzy.service.UserSeviceBase;import org.junit.Test;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;public class AppTest &#123; @Test public void test()&#123; ApplicationContext context=new ClassPathXmlApplicationContext("ApplicationContext2.xml"); //从Spring容器中拿代理对象 UserSeviceBase userSevice= (UserSeviceBase) context.getBean("userService"); userSevice.deleteUser(23); userSevice.updateUser(3); &#125;&#125; 测试结果：如下图所示，前置通知确实起作用了，在目标方法执行之前就执行了 下面我们在来测测&lt;aop:advisor&gt;中的其他通知方式 &lt;aop:after-returning&gt;&nbsp;&nbsp;&nbsp;&nbsp;在切面类中增加方法：afterReturning(JoinPoint jp,Object obj),其中第一个参数是连接点，第二个参数是目标方法运行后的返回值。要获得返回返回值需要在配置中设置returning=”obj”，就是把这个第二个参数的名字放进去，Spring就会把返回值注入。 1234567891011121314151617181920212223package com.xzy.Aspect;import org.aspectj.lang.JoinPoint;public class MyAspect2 &#123; /* *方法执行前的通知 */ public void before(JoinPoint jp)&#123; System.out.println("前置通知........"+jp.getSignature().getName()); //得到方法的名字 &#125; /* *方法返回后的通知 */ public void afterReturning(JoinPoint jp,Object obj)&#123; System.out.println("后置通知........"+jp.getSignature().getName()); //得到方法的名字 System.out.println("方法的返回值是："+obj); System.out.println("----------------------------------"); &#125;&#125; 配置新增的切面类方法： 1234567891011121314151617181920&lt;!--配置bean--&gt; &lt;bean id="userService" class="com.xzy.service.UserSeviceImpl"&gt;&lt;/bean&gt; &lt;!--配置切面类--&gt; &lt;bean id="aspect" class="com.xzy.Aspect.MyAspect2"&gt;&lt;/bean&gt; &lt;!--配置aop--&gt; &lt;aop:config&gt; &lt;!--指定切面--&gt; &lt;aop:aspect ref="aspect"&gt; &lt;!--指定切入点--&gt; &lt;aop:pointcut id="poincut1" expression="execution(* com.xzy.service.UserServiceImpl.*(..))"/&gt; &lt;!--前置通知--&gt; &lt;aop:before method="before" pointcut-ref="poincut1"/&gt; &lt;!--后置通知--&gt; &lt;aop:after-returning method="afterReturning" pointcut-ref="poincut1" returning="obj"&gt;&lt;/aop:after-returning&gt; &lt;/aop:aspect&gt; &lt;/aop:config&gt; 测试代码不变，测试结果如下： &lt;aop: around&gt;around具有before和after-returning两者的功能，这里就不在重复测试了。所以一般使用了around就不在使用brfore和after-returning &lt;aop: after-throwing&gt;、&lt;aop: after&gt;切面类中增加方法afterThrowing和after 1234567891011121314/** * 抛出异常后通知 * @param jp 连接点 * @param e 异常 */public void afterThrowing(JoinPoint jp,Throwable e)&#123; System.out.println("抛出异常通知....."+jp.getSignature().getName()+e.getMessage());&#125;public void after(JoinPoint jp)&#123; System.out.println("最终通知......"+jp.getSignature().getName());&#125; 配置xml 12345678910111213141516&lt;!--配置aop--&gt; &lt;aop:config&gt; &lt;!--指定切面--&gt; &lt;aop:aspect ref="aspect"&gt; &lt;!--指定切入点--&gt; &lt;aop:pointcut id="poincut1" expression="execution(* com.xzy.service.UserSeviceImpl.*(..))"/&gt; &lt;!--环绕通知--&gt; &lt;aop:around method="around" pointcut-ref="poincut1"&gt;&lt;/aop:around&gt; &lt;!--异常通知:当目标方法发生异常后会执行 --&gt; &lt;aop:after-throwing method="afterThrowing" pointcut-ref="poincut1" throwing="e"/&gt; &lt;!--最终通知:无论方法有没有发生异常，都会执行--&gt; &lt;aop:after method="after" pointcut-ref="poincut1"/&gt; &lt;/aop:config&gt; 并在deleteUser方法中主动抛出异常： 12345@Overridepublic int deleteUser(int id) &#123; System.out.println("删除了id为" + id + "的用户"); throw new RuntimeException(new Exception("自定义异常...."));&#125; 测试结果如下： 如果去掉异常的测试结果如下： 基于Annotation配置AOP既然使用注解配置，那就全部用注解，包括配置文件都用注解+Java类来实现 编写配置类ApplicationConfig.java替代xml文件12345678910111213package com.xzy;import org.springframework.context.annotation.ComponentScan;import org.springframework.context.annotation.Configuration;import org.springframework.context.annotation.EnableAspectJAutoProxy;@Configuration //告诉spring这是配置文件@EnableAspectJAutoProxy //开启aop自动代理@ComponentScan(basePackages = &#123;"com.xzy"&#125;) //告诉spring去哪里扫描注解public class AppConfig &#123; //这里头以后可以写各种配置，这个类的作用就和XML文件的作用一样&#125; 当然这段java代码可以用下面这段XML配置文件替代 1234567891011121314151617181920&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:context="http://www.springframework.org/schema/context" xmlns:aop="http://www.springframework.org/schema/aop" xsi:schemaLocation="http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd http://www.springframework.org/schema/context http://www.springframework.org/schema/context/spring-context.xsd http://www.springframework.org/schema/aop http://www.springframework.org/schema/aop/spring-aop.xsd"&gt; &lt;!--开启注解功能--&gt; &lt;context:annotation-config/&gt; &lt;!--告诉Spring去哪里扫描注解--&gt; &lt;context:component-scan base-package="com.xzy"/&gt; &lt;!--配置aop自动代理--&gt; &lt;aop:aspectj-autoproxy/&gt; &lt;/beans&gt; 编写一个日志记录的切面类LoggerApsect.java在切面类中可以使用如下几个注解来定制一个切面： @Aspect：告诉Spring这是切面类 @Brfore：前置通知 @AfterRuning：返回后通知 @Around：环绕通知，是@Brfore和@AfterRuning的结合，功能十分强大 @After-Throwing：抛出异常后的通知，没有异常不会执行 @After：最终通知，无论有没有异常一定会执行的 @PointCut：定义切点 具体用法如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051package com.xzy.Aspect;import org.aspectj.lang.JoinPoint;import org.aspectj.lang.ProceedingJoinPoint;import org.aspectj.lang.annotation.*;import org.springframework.stereotype.Component;import java.util.Date;/** * 一个记录各种操作的日志切面类 */@Component //告诉Spring你要把这个类给我实例化了@Aspect //告诉Spring这是一个切面类public class LoggerAspect &#123; //声明一个公共的切点：将com.xzy.service包下的所有以Impl结尾的方法作为切入点，切入点中可以没有任何代码实现，只是让他在形式上存在即可 @Pointcut("execution(* com.xzy.service.*Impl.*(..))") public void pointcut() &#123; &#125; @Before("execution(* com.xzy.service.*Impl.*(..))") public void before(JoinPoint joinPoint) &#123; System.out.println("before给" + joinPoint.getSignature().getName() + "方法作前日志.........." + new Date()); &#125; @AfterReturning(pointcut = "pointcut()", returning = "retValue") public void afterReturning(JoinPoint joinPoint, Object retValue) &#123; System.out.println("afterReturning给" + joinPoint.getSignature().getName() + "方法作后日志.........." + new Date()); System.out.println("方法的返回值是：" + retValue); &#125; @Around("pointcut()") public Object around(ProceedingJoinPoint joinPoint) throws Throwable &#123; System.out.println("around给" + joinPoint.getSignature().getName() + "方法作前日志.........." + new Date()); Object retValue = joinPoint.proceed(); System.out.println("around给" + joinPoint.getSignature().getName() + "方法作前后志.........." + new Date()); return retValue; &#125; @AfterThrowing(pointcut = "pointcut()", throwing = "e") public void afterThrowing(JoinPoint joinPoint, Throwable e) &#123; System.out.println("给" + joinPoint.getSignature().getName() + "方法作异常日志：" + new Date() + "抛出" + e.getMessage()); &#125; @After("pointcut()") public void afterAll(JoinPoint joinPoint) &#123; System.out.println("给" + joinPoint.getSignature().getName() + "方法作最终日志.........." + new Date()); &#125;&#125; 测试类如下： 1234567891011121314151617181920212223242526package com.xzy;import com.xzy.service.UserSeviceBase;import org.apache.log4j.Logger;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.test.context.ContextConfiguration;import org.springframework.test.context.junit4.SpringJUnit4ClassRunner;@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(classes= &#123;AppConfig.class&#125;)public class AppTest &#123; private static Logger log= Logger.getLogger(AppTest.class); @Autowired UserSeviceBase userSevice; @Test public void test3()&#123; userSevice.deleteUser(12); userSevice.updateUser(34); &#125;&#125; 测试结果: 现在去掉before、after-return以及在deleteUser中抛出一个异常：]]></content>
      <categories>
        <category>Spring框架</category>
      </categories>
      <tags>
        <tag>Spring AOP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring AOP两种配置方式(半自动vs全自动)]]></title>
    <url>%2F2019%2F08%2F03%2FSpringAOP%E5%8D%8A%E8%87%AA%E5%8A%A8%E5%92%8C%E5%85%A8%E8%87%AA%E5%8A%A8%E9%85%8D%E7%BD%AE%E6%96%B9%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[Spring AOP半自动编程 核心步骤：1. 创建一个接口以及它的实现类2. 编写切面类，实现MethodInterceptor接口的invoke方法3. 配置Spring的配置文件，xml文件中的配置重要是：【重要】 &nbsp;&nbsp; 1).配置目标类的bean &nbsp;&nbsp;&nbsp;2).配置切面类的bean &nbsp;&nbsp;&nbsp;3).配置代理对象，其中代理对象中主要的配置如下’ &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;a.配置接口&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;b.配置目标类 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;c.配置切面类 &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;d.还可以用&lt;property name=&quot;optimize&quot; value=&quot;true&quot;/&gt;,指明使用cglib的代理对象 1.首先编写一个接口 123456789101112131415161718192021package com.xzy.service;public interface UserSeviceBase &#123; /** * 增加用户 */ public void addUser(); /** * 删除用户 * @param id */ public void deleteUser(int id); /** * 更新用户 * @param id */ public void updateUser(int id);&#125; 接口的实现类： 123456789101112131415161718package com.xzy.service;public class UserSeviceImpl implements UserSeviceBase &#123; @Override public void addUser() &#123; System.out.println("增加了1个用户"); &#125; @Override public void deleteUser(int id) &#123; System.out.println("删除了id为"+id+"的用户"); &#125; @Override public void updateUser(int id) &#123; System.out.println("id为"+id+"的用户更新了"); &#125;&#125; 编写一个切面类：让这个切面类实现MethodInvocation接口的invoke方法 1234567891011121314151617181920package com.xzy.Aspect;import org.aopalliance.intercept.MethodInterceptor;import org.aopalliance.intercept.MethodInvocation;import java.util.Date;//切面类public class MyAspect implements MethodInterceptor &#123; @Override public Object invoke(MethodInvocation methodInvocation) throws Throwable &#123; System.out.println("执行操作前日志......" + new Date()); Object obj = methodInvocation.proceed(); System.out.println("执行操作后日志......" + new Date()); return obj; &#125;&#125; 在Spring的配置文件Application.xml中注册代理对象 123456789101112131415&lt;!--注册目标对象UserService--&gt;&lt;bean id="userService" class="com.xzy.service.UserSeviceImpl"&gt;&lt;/bean&gt;&lt;!--注册切面类--&gt;&lt;bean id="myAspect" class="com.xzy.Aspect.MyAspect"&gt;&lt;/bean&gt;&lt;!--注册代理对象--&gt;&lt;bean id="proxyService" class="org.springframework.aop.framework.ProxyFactoryBean"&gt; &lt;!--接口--&gt; &lt;property name="interfaces" value="com.xzy.service.UserSeviceBase"/&gt; &lt;!--目标对象--&gt; &lt;property name="target" value="#&#123;userService&#125;"/&gt; &lt;!--切面类--&gt; &lt;property name="interceptorNames" value="myAspect"/&gt; &lt;!--配置使用cglib,当没有配置的时候默认是false,也就是使用JDk的Proxy--&gt; &lt;property name="optimize" value="true"/&gt;&lt;/bean&gt; 测试： 123456789101112131415161718192021222324package com.xzy;import com.xzy.service.UserSeviceBase;import org.junit.Test;import org.springframework.context.ApplicationContext;import org.springframework.context.support.ClassPathXmlApplicationContext;/** * Unit test for simple App. */public class AppTest &#123; @Test public void test()&#123; ApplicationContext context=new ClassPathXmlApplicationContext("ApplicationContext.xml"); //从Spring容器中拿代理对象 UserSeviceBase userSevice= (UserSeviceBase) context.getBean("proxyService"); userSevice.deleteUser(23); userSevice.updateUser(3); &#125;&#125; 测试结果： Spring AOP 全自动编程 主要步骤：1）.实现切面类2）.在bean配置文件中吧切点和切面关联起来 实现一个切面类,继承MethodInterceptor接口实现它的invoke方法 123456789101112131415161718192021package com.xzy.Aspect;import org.aopalliance.intercept.MethodInterceptor;import org.aopalliance.intercept.MethodInvocation;import java.util.Date;//切面类public class MyAspect implements MethodInterceptor &#123; @Override public Object invoke(MethodInvocation methodInvocation) throws Throwable &#123; System.out.println("执行操作前日志......" + new Date()); Object obj = methodInvocation.proceed(); System.out.println("执行操作后日志......" + new Date()); return obj; &#125;&#125; 接着在Spring配置文件Application.xml中配置aop的schema文件，如下红框的配置： 接着在配置文件中添加如下内容： 123456789101112131415&lt;!--配置UserService--&gt;&lt;bean id="userService" class="com.xzy.service.UserSeviceImpl"&gt;&lt;/bean&gt;&lt;!--配置切面类--&gt;&lt;bean id="myAspect" class="com.xzy.Aspect.MyAspect"&gt;&lt;/bean&gt;&lt;!--配置全自动AOP代理--&gt;&lt;aop:config &gt; &lt;!--配置切点expression：表达式，就是用来切入的业务类--&gt; &lt;aop:pointcut id="myPointcut" expression="execution(* com.xzy.service.*.*(..))"/&gt; &lt;!--配合通知 通知要关联切点和切面类 advice-ref:切面类 pointcut-ref:切点 --&gt; &lt;aop:advisor advice-ref="myAspect" pointcut-ref="myPointcut"&gt;&lt;/aop:advisor&gt;&lt;/aop:config&gt; 对于配置全自动AOP代理的一点说明，如下图所示&lt;aop:config&gt;标签中重要的三种元素：切点：&lt;aop:pointcut&gt;、切面：&lt;aop:aspect&gt;、通知：&lt;aop:advisor&gt; 其中通知：``又有一下5种： 测试： 1234567891011@Test public void test()&#123; ApplicationContext context=new ClassPathXmlApplicationContext("ApplicationContext.xml"); //从Spring容器中拿代理对象 UserSeviceBase userSevice= (UserSeviceBase) context.getBean("userService"); userSevice.deleteUser(23); userSevice.updateUser(3); &#125; 测试结果： 写在最后：&nbsp;&nbsp;&nbsp;&nbsp;通过实际的操作可以明显感受到第二种方式实现AOP是省事儿又简单的一种方式，然而第二种方式也是Spring中使用到AOP是常用到的一种配置方式。既然有全自动xml的配置方式，那么一定就会有对应对一套使用注解配置对方式。下一节就讲讲如何用注解配置使用Spring AOP。]]></content>
      <categories>
        <category>Spring框架</category>
      </categories>
      <tags>
        <tag>Spring AOP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring AOP原理与手撕AOP[重要]]]></title>
    <url>%2F2019%2F08%2F03%2FSpringAOP%E5%8E%9F%E7%90%86%2F</url>
    <content type="text"><![CDATA[AOP概述（Spring AOP是什么?AOP有什么用？） 1） 在软件行业，AOP为Aspect Oriented programming 的缩写，意为：面向切面编程，通过预编译方式和运行期动态代理实现程序功能的同一维护的一种技术。2） AOP是OOP（面向对象编程）的延续，是软件开发的一个热点，也是Spring框架中的一个重要内容，是函数式编程的一种衍生。3）利用AOP可以对业务逻辑的各个部分进行分离，从而使得业务逻辑各个部分之间的耦合度降低，Tiga程序的可重用性，同时提高了开发效率。4）AOP采用横向抽取机制，取代了传统继承体系的纵向机制。5）AOP的经典应用场景：事务管理、性能监视、安全、缓存、日志…..6）Spring AOP 使用纯Java代码实现，不需要专门的编译过程和类加载器，在运行期通过代理方式向目标类织入增强代码。7）AspectJ是一个基于Java的AOP框架，Spring2.0开始，Spring AOP引入AspectJ的支持，AspectJ扩展了Java语言，提供了一个专门的编译器，在编译时提供横向代码的织入。 AOP的一些术语【了解】&nbsp;&nbsp;&nbsp;&nbsp;AOP(Aspect Oriented Programming)像大多数技术一样形成了自己的术语，而且这些术语比较难理解，不论是理解还中不理解都对编程影响不太大。1）连接点（Joinpoint）&nbsp;&nbsp;&nbsp;&nbsp;程序执行的某个特定位置：如类开始初始化前、类初始化后、类某个方法调用前、调用后、方法抛出异常后。一个类或一段程序代码拥有一些具有边界性质的特定点，这些点中的特定点就称为“连接点”。Spring 仅支持方法的连接点，即仅能在方法调用前、方法调用后、方法抛出异常时以及方法调用前后这些程序执行点织入增强。2）切点（Pointcut）&nbsp;&nbsp;&nbsp;&nbsp;每个程序类都拥有多个连接点，如一个拥有两个方法的类，这两个方法都是连接点，即连接点是程序类中客观存在的事物。AOP 通过“切点”定位特定的连接点。连接点相当于数据库中的记录，而切点相当于查询条件。切点和连接点不是一对一的关系，一个切点可以匹配多个连接点。3）通知或增强（Advice）&nbsp;&nbsp;&nbsp;&nbsp;增强是织入到目标类连接点上的一段程序代码，在 Spring 中，增强除用于描述一段程序代码外，还拥有另一个和连接点相关的信息，这便是执行点的方位。结合执行点方位信息和切点信息，我们就可以找到特定的连接点。4）目标对象（Target）&nbsp;&nbsp;&nbsp;&nbsp;增强逻辑的织入目标类。如果没有 AOP，目标业务类需要自己实现所有逻辑，而在 AOP的帮助下，目标业务类只实现那些非横切逻辑的程序逻辑，而性能监视和事务管理等这些横切逻辑则可以使用 AOP 动态织入到特定的连接点上。5）引介（Introduction）&nbsp;&nbsp;&nbsp;&nbsp;引介是一种特殊的增强，它为类添加一些属性和方法。这样 ，即使一个业务类原本没有实现某个接口，通过 AOP 的引介功能，我们可以动态地为该业务类添加接口的实现逻辑，让业务类成为这个接口的实现类。6）织入（Weaving）&nbsp;&nbsp;&nbsp;&nbsp;织入是将增强添加对目标类具体连接点上的过程。AOP 像一台织布机，将目标类、增强或引介通过 AOP 这台织布机天衣无缝地编织到一起。根据不同的实现技术，AOP 有三种织入的方式： a、编译期织入，这要求使用特殊的 Java 编译器。b、类装载期织入，这要求使用特殊的类装载器。c、动态代理织入，在运行期为目标类添加增强生成子类的方式。Spring 采用动态代理织入，而 AspectJ 采用编译期织入和类装载期织入。 7）代理（Proxy）&nbsp;&nbsp;&nbsp;&nbsp;一个类被 AOP 织入增强后，就产出了一个结果类，它是融合了原类和增强逻辑的代理类。根据不同的代理方式，代理类既可能是和原类具有相同接口的类，也可能就是原类的子类，所以我们可以采用调用原类相同的方式调用代理类。8）切面（Aspect）&nbsp;&nbsp;&nbsp;&nbsp;切面由切点和增强（引介）组成，它既包括了横切逻辑的定义，也包括了连接点的定义，Spring AOP 就是负责实施切面的框架，它将切面所定义的横切逻辑织入到切面所指定的连接点中。 对于 Spring 中的 AOP 术语，确实不好理解，为了帮助大家理解这些术语，我们想象一 下这样的场景： 1、有 2 条高速公路可以通向北京，分别为 A,B（相当于 2 个目标个业务 Target（功能） 2、每条高速公路上有 3 个服务站（相当于每个业务上的连接点（Joinpoint）有 3 个） 3、在每条高速公路的第 2 个服务站需要测速（相当于一个切点（Pointcut），匹配了 3 个连接点） 4、在第一条(A)进入服务站之前进行测速，在第二条(b)进入服务站之后测速（通知或增强 Advice，其实也定义了调用测速功能进行测速，以及怎么测） 5、每条高速路第 2 个服务站加入测速功能，这件事情相当于切面 Aspect，它包含了测速功能的定义与切点的定义 6、将测速功能应用到服务站上，这个过程叫织入（Weaving） AOP的实现原理接下来是重点，我们来学习一下AOP的实现原理，并利用原理自己手动实现AOP。AOP底层采用代理机制进行实现，具体的实现方法有以下两种: 1）接口+实现类：采用jdk的动态代理 2）使用实现类：Spring采用了cglib字节码增强 接下来我们就用这两个原理分别自己手动实现AOP。 使用jdk的动态代理实现实现思路：使用jdk中的Proxy类的newProxyInstance方法来获得一个代理对象，在使用的时候就使用这个代理对象而不直接去new对象，关于方法的细节如下： 1234public static Object newProxyInstance( ClassLoader loader, 类加载器，写当前类的类加载器 Class&lt;?&gt;[] interfaces, 接口，就是你要增强的业务类的接口 InvocationHandler h)&#123;&#125; 处理器，可以自己实现InvocationHandler接口的invkoe方法实现一个处理器 步骤：1.写一个普通的接口以及这个接口的实现类2.写一个切面类（就是一个普通的java类，里面的方法写要增强的功能）3.上面的操作完成后，在工厂类（为了方便，当然也可以不写这个工厂类）中首先创建一个目标类对象（就是new一个业务类的对象），接着new一个切面类对象，使用动态代理把切面类中的增强功能织入到目标方法的前后，下面是示例代码：一个业务类接口：UserServiceBase.java 123456789101112131415161718192021package com.xzy.sevice;public interface UserSeviceBase &#123; /** * 增加用户 */ public void addUser(); /** * 删除用户 * @param id */ public void deleteUser(int id); /** * 更新用户 * @param id */ public void updateUser(int id);&#125; 业务类接口实现类：UserSeviceImpi.java 123456789101112131415161718package com.xzy.sevice;public class UserSeviceImpi implements UserSeviceBase &#123; @Override public void addUser() &#123; System.out.println("增加了1个用户"); &#125; @Override public void deleteUser(int id) &#123; System.out.println("删除了id为"+id+"的用户"); &#125; @Override public void updateUser(int id) &#123; System.out.println("id为"+id+"的用户更新了"); &#125;&#125; 写一个切面类：MyAspect.java 1234567891011121314151617package com.xzy.aspect;import java.util.Date;//切面类:就是一段增强功能的代码public class MyAspect &#123; public void before()&#123; System.out.println(".......执行操作前日志......."+new Date()); &#125; public void after()&#123; System.out.println(".......执行操作后日志......."+new Date()); &#125;&#125; 写一个工厂类，专门用于生产代理对象 123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.xzy.sevice;import com.xzy.aspect.MyAspect;import java.lang.reflect.InvocationHandler;import java.lang.reflect.Method;import java.lang.reflect.Proxy;public class ServiceFactory &#123; /** * 产生一个 UserSevice * * @return */ public static UserSeviceBase createUserService() &#123; //1.创建目标对象 final UserSeviceBase userSevice = new UserSeviceImpl(); //2.声明切面类 final MyAspect aspect = new MyAspect(); //3.使用动态代理来把切面类中的增强方法切入目标方法前后 UserSeviceBase proxyService = (UserSeviceBase) Proxy.newProxyInstance( ServiceFactory.class.getClassLoader(), userSevice.getClass().getInterfaces(), //InvocationHandler是一个接口，它里面只有一个invoke方法，这里也可以在外面单独写一个类实现InvocationHandler接口，然后在这里new这个类的对象也可以 new InvocationHandler() &#123; @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable &#123; //目标方法开始前的增强代码 aspect.before(); //通过反射调用目标方法 Object obj = method.invoke(userSevice, args); //目标方法执行后的增强代码 aspect.after(); return obj; &#125; &#125; ); return proxyService; //返回代理对象 &#125;&#125; 测试： 1234567891011121314151617181920212223package com.xzy;import com.xzy.sevice.ServiceFactory;import com.xzy.sevice.UserSeviceBase;import org.junit.Test;/** * Unit test for simple App. */public class AppTest &#123; /** * 使用Java的动态代理机制，手动实现AOP编程 */ @Test public void test1()&#123; //直接从工厂中拿代理对象 UserSeviceBase userSevice= ServiceFactory.createUserService(); userSevice.deleteUser(10); userSevice.updateUser(3); userSevice.addUser(); &#125;&#125; 测试结果： 使用Cglib实现&nbsp;&nbsp;&nbsp;&nbsp;在实际开发中，可能需要对没有实现接口的类增强，用JDK动态代理的方式就没法实现。采用Cglib动态代理可以对没有实现接口的类产生代理，实际上是生成了目标类的子类来增强。 首先，需要导入Cglib所需的jar包，Maven依赖写法如下： 12345&lt;dependency&gt; &lt;groupId&gt;cglib&lt;/groupId&gt; &lt;artifactId&gt;cglib&lt;/artifactId&gt; &lt;version&gt;3.1&lt;/version&gt;&lt;/dependency&gt; 还是需要一个业务类（这次不需要接口了）以及一个切面类，前面写过，这里就跳过了。接着在刚才的工厂类中再写一个方法createUserService2()，步骤还是那几步，只不过这次是用cglib提供的api来写，具体如下： 123456789101112131415161718192021222324252627282930/* *使用cglib实现AOP * */ public static UserSeviceBase createUserService2() &#123; //1.创建目标对象 final UserSeviceImpl userSevice = new UserSeviceImpl(); //2.声明切面类 final MyAspect aspect = new MyAspect(); //3.cglib核心类Enhancer Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(userSevice.getClass()); enhancer.setCallback(new MethodInterceptor() &#123; @Override public Object intercept(Object proxy, Method method, Object[] args, MethodProxy methodProxy) throws Throwable &#123; aspect.before(); /* *proxy代理是目标类的子类 */ Object obj = methodProxy.invoke(userSevice, args); aspect.after(); return obj; &#125; &#125;); UserSeviceImpl proxy = (UserSeviceImpl) enhancer.create(); return proxy; //返回代理对象 &#125; 测试： 1234567891011121314151617181920212223package com.xzy;import com.xzy.sevice.ServiceFactory;import com.xzy.sevice.UserSeviceBase;import org.junit.Test;/** * Unit test for simple App. */public class AppTest &#123; /** * 使用cglib手动实现AOP编程 */ @Test public void test2()&#123; UserSeviceBase userSevice= ServiceFactory.createUserService2(); userSevice.deleteUser(10); userSevice.updateUser(3); userSevice.addUser(); &#125;&#125; 测试结果： 可以看到结果和刚才用JDK动态代理的结果一样，但是这里要特别注意： jdk代理只能动态代理接口+实现类的形式； Cglib代理的优势是可以直接代理普通的类，但同时接口也可以]]></content>
      <categories>
        <category>Spring框架</category>
      </categories>
      <tags>
        <tag>Spring AOP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring IOC高级依赖注入]]></title>
    <url>%2F2019%2F08%2F02%2FSpringIOC%E9%AB%98%E7%BA%A7%E4%BE%9D%E8%B5%96%E6%B3%A8%E5%85%A5%2F</url>
    <content type="text"><![CDATA[环境与 Profile&nbsp;&nbsp;&nbsp;&nbsp;在开发中我们测试用一套数据库，开发用一套数据库，而且要将应用程序从一个环境迁移到 另一个环境，Spring 允许我们定义多套配置，可以配置声明应用哪套配置的 Bean 1 Profile Spring中的Profile是什么？ &nbsp;&nbsp;&nbsp;&nbsp;Spring中的Profile功能其实早在Spring 3.1的版本就已经出来，它可以理解为我们在Spring容器中所定义的Bean的逻辑组名称，只有当这些Profile被激活的时候，才会将Profile中所对应的Bean注册到Spring容器中。举个更具体的例子，我们以前所定义的Bean，当Spring容器一启动的时候，就会一股脑的全部加载这些信息完成对Bean的创建；而使用了Profile之后，它会将Bean的定义进行更细粒度的划分，将这些定义的Bean划分为几个不同的组，当Spring容器加载配置信息的时候，首先查找激活的Profile，然后只会去加载被激活的组中所定义的Bean信息，而不被激活的Profile中所定义的Bean定义信息是不会加载用于创建Bean的。 Profile有什么用？ &nbsp;&nbsp;&nbsp;&nbsp;由于我们平时在开发中，通常会出现在开发的时候使用一个开发数据库，测试的时候使用一个测试的数据库，而实际部署的时候需要一个数据库。以前的做法是将这些信息写在一个配置文件中，当我把代码部署到测试的环境中，将配置文件改成测试环境；当测试完成，项目需要部署到现网了，又要将配置信息改成现网的，真的好烦。。。而使用了Profile之后，我们就可以分别定义3个配置文件，一个用于开发、一个用户测试、一个用户生产，其分别对应于3个Profile。当在实际运行的时候，只需给定一个参数来激活对应的Profile即可，那么容器就会只加载激活后的配置文件，这样就可以大大省去我们修改配置信息而带来的烦恼。 方式一：用xml配置profile 123456789101112131415161718192021222324252627Application.xml&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;beans xmlns="http://www.springframework.org/schema/beans" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:jdbc="http://www.springframework.org/schema/jdbc" xmlns:jee="http://www.springframework.org/schema/jee" xmlns:p="http://www.springframework.org/schema/p" xsi:schemaLocation=" http://www.springframework.org/schema/jee http://www.springframework.org/schema/jee/spring-jee.xsd http://www.springframework.org/schema/jdbc http://www.springframework.org/schema/jdbc/spring-jdbc.xsd http://www.springframework.org/schema/beans http://www.springframework.org/schema/beans/spring-beans.xsd"&gt; &lt;beans profile="dev"&gt; &lt;jdbc:embedded-database id="dataSource" type="H2"&gt; &lt;jdbc:script location="classpath:schema.sql" /&gt; &lt;jdbc:script location="classpath:dev-data.sql" /&gt; &lt;/jdbc:embedded-database&gt; &lt;/beans&gt; &lt;beans profile="prod"&gt; &lt;jdbc:embedded-database id="dataSource" type="H2"&gt; &lt;jdbc:script location="classpath:schema.sql" /&gt; &lt;jdbc:script location="classpath:prod-data.sql" /&gt; &lt;/jdbc:embedded-database&gt; &lt;/beans&gt;&lt;/beans&gt; 方式二：用Annotation配置profile，这种方式配置和用xml配置是等价的 12345678910111213141516171819202122232425@Configurationpublic class DataSourceConfig &#123; //Spring 引入@Profile 制定某个bean属于哪个profile //在方法级别上使用@Profile注解 @Bean @Profile("dev") public DataSource embeddedDataSource() &#123; return new EmbeddedDatabaseBuilder() .setType(EmbeddedDatabaseType.H2) .addScript("classpath:schema.sql") .addScript("classpath:dev-data.sql") .build(); &#125; @Bean @Profile("prod") public DataSource embeddedDataSourceDev() &#123; return new EmbeddedDatabaseBuilder() .setType(EmbeddedDatabaseType.H2) .addScript("classpath:schema.sql") .addScript("classpath:prod-data.sql") .build(); &#125;&#125; 在同一个类的不同方法上使用@Profile注解与@Bean一起使用激活profileSpring在确定哪个profile处于激活状态时，需要依赖两个独立属性：sping.profiles.active和spring.profiles.default。Spring提供了@ActiveProfiles用来指定运行测试时要激活哪个profile,如果没有指定sping.profiles.active，会采用spring.profiles.default的默认值。 测试代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667package com.xzy;import static org.junit.Assert.*;import java.sql.ResultSet;import java.sql.SQLException;import java.util.List;import javax.sql.DataSource;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.jdbc.core.JdbcTemplate;import org.springframework.jdbc.core.RowMapper;import org.springframework.test.context.ActiveProfiles;import org.springframework.test.context.ContextConfiguration;import org.springframework.test.context.junit4.SpringJUnit4ClassRunner;import com.myapp.DataSourceConfig;public class DataSourceConfigTest &#123; @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration(classes=DataSourceConfig.class) @ActiveProfiles("dev") public static class DevDataSourceTest &#123; @Autowired private DataSource dataSource; @Test public void shouldBeEmbeddedDatasource() &#123; assertNotNull(dataSource); JdbcTemplate jdbc = new JdbcTemplate(dataSource); List&lt;String&gt; results = jdbc.query("select id, name from Things", new RowMapper&lt;String&gt;() &#123; @Override public String mapRow(ResultSet rs, int rowNum) throws SQLException &#123; return rs.getLong("id") + ":" + rs.getString("name"); &#125; &#125;); assertEquals(1, results.size()); assertEquals("1:A", results.get(0)); &#125; &#125; @RunWith(SpringJUnit4ClassRunner.class) @ContextConfiguration("classpath:datasource-config.xml") @ActiveProfiles("prod") public static class ProductionDataSourceTest_XMLConfig &#123; @Autowired private DataSource dataSource; @Test public void shouldBeEmbeddedDatasource() &#123; assertNotNull(dataSource); JdbcTemplate jdbc = new JdbcTemplate(dataSource); List&lt;String&gt; results = jdbc.query("select id, name from Things", new RowMapper&lt;String&gt;() &#123; @Override public String mapRow(ResultSet rs, int rowNum) throws SQLException &#123; return rs.getLong("id") + ":" + rs.getString("name"); &#125; &#125;); assertEquals(1, results.size()); assertEquals("1:B", results.get(0)); &#125; &#125;&#125; 条件化Bean&nbsp;&nbsp;&nbsp;&nbsp;Spring 4 引入了一个新的@Conditional 注解，它可以用到带@Bean 注解的方法上，如果条件计算结果为 true，就会创建个 Bean设置给@Conditional 的类可以是任意实现了 Condition 接口的类型,如果matches()方法返回true，那么就会创建带有@Conditional注解的bean。若返回false，将不会创建这些bean。其中: ConditionContext ： getRegistry()：返回的 BeanDefinitionRegistry 检查 Bean 定义： getBeanFactory()：返回 ConfigurableListableBeanFactory 检查 Bean 是否存在 getEnvironments()：返回 Environment 检查环境变量是否存在以及它的值是什么 getResourceLoader()：返回 ResourceLoader 所加载的瓷源 getClassLoader()：返回 ClassLoder 加载并检查是否存在 AnnotatedTypeMetadata ：可以让我们检查带@Bean 注解的方法上还有什么其它注解，它也是一个接口 举个栗子：写个条件类，实现Condition接口的matches方法，简单的判断一下当前的系统是不是Windows 7的，如果是返回true,否则返回false 12345678910111213141516171819package com.xzy.utils;import org.springframework.context.annotation.Condition;import org.springframework.context.annotation.ConditionContext;import org.springframework.core.env.Environment;import org.springframework.core.type.AnnotatedTypeMetadata;public class StudentCondition implements Condition &#123; @Override public boolean matches(ConditionContext context, AnnotatedTypeMetadata annotatedTypeMetadata) &#123; Environment env = context.getEnvironment(); System.out.println(env.toString()); if("Windows 7".equals(env.getProperty("os.name")))&#123; return true; &#125;else&#123; return false; &#125; &#125;&#125; 测试代码： 123456789101112131415161718192021package com.xzy.utils;import com.xzy.bean.Student;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Conditional;import org.springframework.context.annotation.Configuration;@Configurationpublic class ConditionTest &#123; //只用这个条件为true才能产生Student,否则spring压根就不会理他 @Bean @Conditional(StudentCondition.class) public Student appConfig()&#123; Student student=new Student(); student.setName("晓明"); student.setAge(34); return student; &#125;&#125; 测试代码： 程序运行结果： 如果把“Windows 7”改成“Windows 10”就是条件Bean就会返回false,由于无法正常的注入就会出现以下的异常： 1org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'com.xzy.AppTest': Unsatisfied dependency expressed through field 'student'; nested exception is org.springframework.beans.factory.NoSuchBeanDefinitionException: No qualifying bean of type 'com.xzy.bean.Student' available: expected at least 1 bean which qualifies as autowire candidate. Dependency annotations: &#123;@org.springframework.beans.factory.annotation.Autowired(required=true), @org.springframework.beans.factory.annotation.Qualifier(value=appConfig)&#125;]]></content>
      <categories>
        <category>Spring框架</category>
      </categories>
      <tags>
        <tag>Spring IOC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Spring IOC Container]]></title>
    <url>%2F2019%2F08%2F02%2FSpringIOC%2F</url>
    <content type="text"><![CDATA[什么是Spring IOC 和DI 控制反转（Inversion of Control，IoC） 所谓控制反转就是应用本身不负责依赖对象的创建及维护，依赖对象的创建及维护是由外部容器负责的。这样控制权就由应用转移到了外部容器，控制权的转移就是所谓反转。 依赖注入（Dependency Injection，DI） 在运行期，由外部容器动态地将依赖对象注入到组件中。换句话说，就是在运行时能 Bean对象设置属性值 bean标签 一个bean标签代表一个spring容器中的java对象，可以在bean中经常使用的属性如下:1. id 属性 ：起名称 不能包含特殊符号 根据id 获得配置对象 2. class属性：创建对象所在全路径 3. name属性：功能和id一样 ，id不能包含特殊符号，name可以（基本不用，为了满足struts1遗留问题） 4. scope属性：Bean的作用范围，scope常用的值有：-singleton 和 -prototype，分别表示单例和多例,如果没写默认就是单例 Bean的3种实例化方式 1.直接使用bean标签来实例化pojo，这中方法Spring默认调用的是这个pojo的无参构造器来实例化bean对象的 首先创建一个EmailDaoImpl.java 12345678910package com.xzy.dao.Impl;import com.xzy.dao.EmailDao;public class EmailDaoImpl implements EmailDao &#123; @Override public void sent() &#123; System.out.println("发送email&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;"); &#125;&#125; 在ApplicationContext.xml文件中使用&lt;bean id=“” class=”” /&amp;gt标签配置bean: 12 &lt;!--1.直接使用bean class来实例化--&gt;&lt;bean id="email" class="com.xzy.dao.Impl.EmailDaoImpl"/&gt; 经过这两步就配置好了一个bean,测试代码简单，就是调用了一下sent方法，下面是执行的结果： 2.使用静态工厂实例化pojo 首先新建一个静态工厂DaoFactory.java 12345678910111213package com.xzy.dao;import com.xzy.dao.Impl.EmailDaoImpl;public class DaoStaticFactory &#123; /** * 静态工厂实例化bean * @return */ public static EmailDao createInstance()&#123; return new EmailDaoImpl(); &#125;&#125; 接着在xml中配置如下： 1&lt;bean id="email1" class="com.xzy.dao.DaoStaticFactory" factory-method="createInstance"/&gt; 执行结果和上面的的一样，这里不再展示了。 3.使用实例化工厂实例化pojo 首先新建一个实例化工厂： 123456789101112package com.xzy.dao;import com.xzy.dao.Impl.EmailDaoImpl;/** * 实例工厂实例化bean */public class DaoInstanceFactory &#123; public EmailDao createInstance()&#123; return new EmailDaoImpl(); &#125;&#125; 在xml文件中配置如下： 123&lt;!--3.通过实例工厂实例化bean--&gt;&lt;bean id="factory" class="com.xzy.dao.DaoInstanceFactory"/&gt;&lt;bean id="email2" factory-bean="factory" factory-method="createInstance"/&gt; 依赖注入的2种常用方式 1. 构造方法注入2. setter方法注入 首先，新建学生实体类Student: 123456789101112131415161718192021222324252627package com.xzy.bean;import org.springframework.stereotype.Component;import java.util.Properties;public class Student &#123; private int age; private String name; private Teacher tea; private Properties info=null; public Student()&#123; System.out.println("默认调用无参构造方法实例化bean"); &#125; public Student(int age, String name) &#123; this.age = age; this.name = name; &#125; public Student(String name, Teacher tea) &#123; this.name = name; this.tea = tea; &#125; //省略getter,setter...... 1. 使用构造方法注入在xml中配置如下，正常情况下只用指定参数的名字和参数的值：&lt;constructor-arg name=”” value=”” /&gt;,name就是构造方法中的参数名，value即使这个参数的值 12345 &lt;!--1.构造方法注入--&gt;&lt;bean id="student" class="com.xzy.bean.Student"&gt; &lt;constructor-arg name="age" value="20" /&gt; &lt;constructor-arg name="name" value="小明" /&gt;&lt;/bean&gt; 程寻运行的结果： 当构造方法出现命名冲突的时候，可以使用type属性指定参数对java类型： 12345 &lt;!--当构造方法中出现命名冲突的时候，还可以使用type属性指定参数的类型--&gt;&lt;bean id="student" class="com.xzy.bean.Student"&gt; &lt;constructor-arg value="20" type="int"&gt;&lt;/constructor-arg&gt; &lt;constructor-arg value="小红" type="java.lang.String"&gt;&lt;/constructor-arg&gt;&lt;/bean&gt; 程寻运行的结果： 2. settrt方法注入,这种方法和实例化bean相同，都是用了property属性 1234567891011&lt;bean id="student" class="com.xzy.bean.Student"&gt; &lt;property name="age" value="#&#123;25*7-20*7&#125;"&gt;&lt;/property&gt; &lt;property name="name" value="#&#123;'aaaaaaa'.toUpperCase()&#125;"&gt;&lt;/property&gt; &lt;property name="tea" value="#&#123;teacher&#125;"&gt;&lt;/property&gt; &lt;property name="info"&gt; &lt;value&gt; jdbc.driver=com.mysql.jdbc.Driver jdbc.url=jdbc:mysql://localhost:3306/mydb &lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; 程寻运行的结果： SpEL（Spring表达式）&nbsp;&nbsp;&nbsp;&nbsp;SpEL（Spring Expression Language），即Spring表达式语言，是比JSP的EL更强大的一种表达式语言。为什么要总结SpEL，因为它可以在运行时查询和操作数据，尤其是数组列表型数据，因此可以缩减代码量，优化代码结构。个人认为很有用。&nbsp;&nbsp;&nbsp;&nbsp;SpEL有三种用法，一种是在注解@Value中；一种是XML配置；最后一种是在代码块中使用Expression。下面说一下它最基础最重要的一种用法：xml配置法。（使用注解的方式的语法和xml方式的语法一样的，只是使用注解会更方便）SpEL的基本语法有以下几条 语法格式`` #{123}、#{'字符串'} ：数字、字符串 #{beanId}：对另一个bean的引用，类似ref属性 #{beanId.propName}:：操作数据 #{beanId.toString()}：执行方法 #{T(类).字段|方法}：静态方法或字段 Spring表达式支持大多数的数学操作符、逻辑操作符、关系操作符。1.关系操作符包括：等于 (==, eq)，不等于 (!=, ne)，小于 (&lt;, lt),，小于等于(&lt;= ,le)，大于(&gt;, gt)，大于等于 (&gt;=, ge)2.逻辑操作符包括：and，or，and not(!)3.数学操作符包括：加 (+)，减 (-)，乘 (*)，除 (/)，取模 (%)，幂指数 (^)。 新建一个实体Customer 12345678910111213141516171819202122package com.xzy.bean;import java.util.Arrays;import java.util.List;import java.util.Map;import java.util.Set;public class Customer &#123; private String name; private String sex="男"; private double pi;@Override public String toString() &#123; return "Customer&#123;" + "name='" + name + '\'' + ", sex='" + sex + '\'' + ", pi=" + pi '&#125;'; &#125; 在配置文件中如下配置： 1234567&lt;bean id="customer" class="com.xzy.bean.Customer"&gt; &lt;!--操作字段：#&#123;ref.Field&#125;--&gt; &lt;property name="name" value="#&#123;student.name&#125;"&gt;&lt;/property&gt; &lt;!--静态字段：#&#123;T.(TYPE).staticField&#125;--&gt; &lt;property name="pi" value="#&#123;T(Math).PI&#125;"&gt;&lt;/property&gt; &lt;property name="sex" value="#&#123;'女'&#125;"&gt;&lt;/property&gt; &lt;/bean&gt; 程序的执行结果如下： 剩下的各种运算就不在这里试了，有兴趣的话可以自己尝试。 集合类型注入&nbsp;&nbsp;&nbsp;&nbsp;官方的一句话:In the &lt;list/&gt;, &lt;set/&gt;, &lt;map/&gt;, and &lt;props/&gt; elements, you set the properties and arguments of the Java Collection types List, Set, Map, and Properties, respectively.就是说，你可以用&lt;list&gt;、set、map、props来配置对应的Java集合类型：List、Set、Map、以及Array(数组),以及Properties也可以配置。举个栗子： 在上例Customer实体类的基础上修改，分别增加List属性、Set属性、Map属性和数组属性一个，具体代码如下： 1234567891011121314151617181920212223242526272829package com.xzy.bean;import java.util.Arrays;import java.util.List;import java.util.Map;import java.util.Set;public class Customer &#123; private String name; private String sex="男"; private List&lt;String&gt; shopCar; //购物车 private Set&lt;String&gt; price; //价格 private Map&lt;String,Double&gt; goods; //物品 private String[] address; //地址 //省略getter、setter.... @Override public String toString() &#123; return "Customer&#123;" + "name='" + name + '\'' + ", sex='" + sex + '\'' + ", shopCar=" + shopCar + ", price=" + price + ", goods=" + goods + ", address=" + Arrays.toString(address) + '&#125;'; &#125;&#125; 使用&lt;list&gt;标签给List类型注入初始值： 1234567891011121314&lt;!--bean的集合注入--&gt; &lt;bean id="customer" class="com.xzy.bean.Customer"&gt; &lt;property name="name" value="#&#123;student.name&#125;"&gt;&lt;/property&gt; &lt;property name="sex" value="#&#123;'女'&#125;"&gt;&lt;/property&gt; &lt;!--List注入使用&lt;list&gt;元素 --&gt; &lt;property name="shopCar"&gt; &lt;list&gt; &lt;value&gt;书&lt;/value&gt; &lt;value&gt;手机&lt;/value&gt; &lt;value&gt;衣服&lt;/value&gt; &lt;value&gt;电脑&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; 使用&lt;set&gt;标签给Set类型注入初始值： 123456789101112131415&lt;!--bean的集合注入--&gt; &lt;bean id="customer" class="com.xzy.bean.Customer"&gt; &lt;property name="name" value="#&#123;student.name&#125;"&gt;&lt;/property&gt; &lt;property name="sex" value="#&#123;'女'&#125;"&gt;&lt;/property&gt; &lt;!--Set注入使用&lt;set&gt;元素 --&gt; &lt;property name="price"&gt; &lt;set&gt; &lt;value&gt;"#&#123;3.5*6&#125;"&lt;/value&gt; &lt;value&gt;"#&#123;2000*2&#125;"&lt;/value&gt; &lt;value&gt;"#&#123;100*6&#125;"&lt;/value&gt; &lt;value&gt;"#&#123;5000*1&#125;"&lt;/value&gt; &lt;/set&gt; &lt;/property&gt; &lt;/bean&gt; 使用&lt;map&gt;标签给Map类型注入初始值： 12345678910111213141516&lt;!--bean的集合注入--&gt; &lt;bean id="customer" class="com.xzy.bean.Customer"&gt; &lt;property name="name" value="#&#123;student.name&#125;"&gt;&lt;/property&gt; &lt;property name="sex" value="#&#123;'女'&#125;"&gt;&lt;/property&gt; &lt;!--Map输注入 使用&lt;map&gt;元素，特别注意，使用&lt;entry&gt;来指定一条数据的key和value --&gt; &lt;property name="goods"&gt; &lt;map&gt; &lt;entry key="p1" value="23"&gt;&lt;/entry&gt; &lt;entry key="p2" value="24"&gt;&lt;/entry&gt; &lt;entry key="p3" value="25"&gt;&lt;/entry&gt; &lt;entry key="p4" value="26"&gt;&lt;/entry&gt; &lt;/map&gt; &lt;/property&gt; &lt;/bean&gt; 使用&lt;list&gt;标签给List类型注入初始值： 1234567891011121314&lt;!--bean的集合注入--&gt; &lt;bean id="customer" class="com.xzy.bean.Customer"&gt; &lt;property name="name" value="#&#123;student.name&#125;"&gt;&lt;/property&gt; &lt;property name="sex" value="#&#123;'女'&#125;"&gt;&lt;/property&gt; &lt;!--List注入使用&lt;list&gt;元素 --&gt; &lt;property name="shopCar"&gt; &lt;list&gt; &lt;value&gt;书&lt;/value&gt; &lt;value&gt;手机&lt;/value&gt; &lt;value&gt;衣服&lt;/value&gt; &lt;value&gt;电脑&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;/bean&gt; 使用&lt;list&gt;标签给List类型注入初始值： 1234567891011121314&lt;!--bean的集合注入--&gt; &lt;bean id="customer" class="com.xzy.bean.Customer"&gt; &lt;property name="name" value="#&#123;student.name&#125;"&gt;&lt;/property&gt; &lt;property name="sex" value="#&#123;'女'&#125;"&gt;&lt;/property&gt; &lt;!--数组注入使用&lt;array&gt;元素 --&gt; &lt;property name="address"&gt; &lt;array&gt; &lt;value&gt;西安&lt;/value&gt; &lt;value&gt;北京&lt;/value&gt; &lt;value&gt;南京&lt;/value&gt; &lt;value&gt;广州&lt;/value&gt; &lt;/array&gt; &lt;/property&gt; &lt;/bean&gt; 最后，对于customer的DI配置如下： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849&lt;!--bean的集合注入--&gt; &lt;bean id="customer" class="com.xzy.bean.Customer"&gt; &lt;property name="name" value="#&#123;student.name&#125;"&gt;&lt;/property&gt; &lt;property name="sex" value="#&#123;'女'&#125;"&gt;&lt;/property&gt; &lt;!--List注入 使用&lt;list&gt;元素 --&gt; &lt;property name="shopCar"&gt; &lt;list&gt; &lt;value&gt;书&lt;/value&gt; &lt;value&gt;手机&lt;/value&gt; &lt;value&gt;衣服&lt;/value&gt; &lt;value&gt;电脑&lt;/value&gt; &lt;/list&gt; &lt;/property&gt; &lt;!--Set注入 使用&lt;set&gt;元素 --&gt; &lt;property name="price"&gt; &lt;set&gt; &lt;value&gt;"#&#123;3.5*6&#125;"&lt;/value&gt; &lt;value&gt;"#&#123;2000*2&#125;"&lt;/value&gt; &lt;value&gt;"#&#123;100*6&#125;"&lt;/value&gt; &lt;value&gt;"#&#123;5000*1&#125;"&lt;/value&gt; &lt;/set&gt; &lt;/property&gt; &lt;!--Map输注入 使用&lt;map&gt;元素，特别注意，使用&lt;entry&gt;来指定一条数据的key和value --&gt; &lt;property name="goods"&gt; &lt;map&gt; &lt;entry key="p1" value="23"&gt;&lt;/entry&gt; &lt;entry key="p2" value="24"&gt;&lt;/entry&gt; &lt;entry key="p3" value="25"&gt;&lt;/entry&gt; &lt;entry key="p4" value="26"&gt;&lt;/entry&gt; &lt;/map&gt; &lt;/property&gt; &lt;!--数组注入 使用&lt;array&gt;元素 --&gt; &lt;property name="address"&gt; &lt;array&gt; &lt;value&gt;西安&lt;/value&gt; &lt;value&gt;北京&lt;/value&gt; &lt;value&gt;南京&lt;/value&gt; &lt;value&gt;广州&lt;/value&gt; &lt;/array&gt; &lt;/property&gt; &lt;/bean&gt; 程序执行结果： 使用Annotation自动装配扫描要使用Anntation配置spring容器，首先需要在ApplicationContext.xml文件中配置如下信息： 1234&lt;!--开启注解--&gt;&lt;context:annotation-config/&gt;&lt;!--告诉Spring去扫描哪里--&gt;&lt;context:component-scan base-package="com.xzy"&gt;&lt;/context:component-scan&gt; 设置组件与bean命名 1.@Repository, @Service, and @Controller,@Component 这 四 个 Annotation 功 能 相 同都是声明一个bean组件，不同的是 @Repository 用于持久层，也就是Dao层。 @Service 用于服务层（业务层）。 @controller 用于控制器层。 @Component 泛指组件，当组件不好归类的时候，我们可以使用这个注解进行标注。例如对pojo实体可以使用他 都是用在类上的 Annotation，说明让Spring 实例化此类的对像，并放入 spring 容器中 2.@componet(“id”)其中 id 声明 bean 对像的名字 举个栗子：新建Student.java 12345678910111213141516171819202122232425package com.xzy.bean;import org.springframework.stereotype.Component;@Component //这一句就是告诉Spring这是个普通的组件public class Student &#123; private int age; private String name; public Student() &#123; System.out.println("1.实例化了bean。。。。。"); &#125; //省略getter、setter @Override public String toString() &#123; return "Student&#123;" + "age=" + age + ", name='" + name + '\'' + '&#125;'; &#125;&#125; 测试代码： 12345678910111213141516171819202122232425262728package com.xzy;import com.xzy.bean.Student;import org.apache.log4j.Logger;import org.junit.Test;import org.junit.runner.RunWith;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.test.context.ContextConfiguration;import org.springframework.test.context.junit4.SpringJUnit4ClassRunner;/** * Unit test for simple App. */@RunWith(SpringJUnit4ClassRunner.class)@ContextConfiguration(value=&#123;"/ApplicationContext.xml"&#125;)public class AppTest &#123; private static Logger log=Logger.getLogger(AppTest.class); @Autowired //自动注入，Spring会为我们自动从容器中找到student的对象然后注入这里的变量 private Student student; @Test public void test01()&#123; System.out.println(student); &#125;&#125; 程序运行结果： @Repository, @Service, and @Controller新建StudentDao以及StudentDaoImpl 1234567891011121314StudentDaopackage com.xzy.Dao;import com.xzy.bean.Student;public interface StudentDao &#123; /** * 增加一个学生 * @param stu * @return */ public void addStudent(Student stu);&#125; 写一个StudentDaoImpi，模拟DAO层，并使用@Respositiry告诉Spring这是DAO层的组件 1234567891011121314151617181920212223StudentDaoImplpackage com.xzy.Dao.DaoImpi;import com.xzy.Dao.StudentDao;import com.xzy.bean.Student;import org.springframework.stereotype.Repository;@Repositorypublic class StudentDaoImpi implements StudentDao &#123; public StudentDaoImpl() &#123; System.out.println("Repository层实例化"); &#125; @Override public void addStudent(Student stu) &#123; System.out.print("3.Dao层处理数据："); System.out.println("向数据库发一条insert语句添加一个学生:"+stu.getName()); &#125;&#125; 新建StudentService.java，模拟Service层，使用@Service注解告诉Spring这是一个Service的组件 1234567891011121314151617181920212223StudentService.javapackage com.xzy.Service;import com.xzy.Dao.StudentDao;import com.xzy.bean.Student;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Service;@Servicepublic class StudentService &#123; public StudentService() &#123; System.out.println("Service层实例化"); &#125; @Autowired private StudentDao stuImp; public void add(Student stu)&#123; System.out.println("2.service层收到控制层的数据后发给Dao层"); stuImp.addStudent(stu); &#125;&#125; 新建StudentServlet.java，模拟控制器层，并使用@Controller注解告诉Spring这是控制器。 123456789101112131415161718192021222324252627StudentServlet.javapackage com.xzy.Servlet;import com.xzy.Service.StudentService;import com.xzy.bean.Student;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Controller;@Controllerpublic class StudentServlet &#123; public StudentServlet() &#123; System.out.println("Controller层实例化"); &#125; @Autowired private StudentService stuService; @Autowired private Student stu; public void addAction() &#123; System.out.println("1.控制层发数据给sevice层"); stu.setAge(23); stu.setName("狗子"); stuService.add(stu); &#125;&#125; 最终的执行结果： 注意注入的顺序：把DAO实现类注入到service实现类中，把service的接口(注意不要是service的实现类)注入到controller中 设置组件扫描的base-packages @Configuration@ComponentScan(“基包名”)Public class AppConfig{} @Configuration@ComponentScan(basepackages=“基包名”)Public class AppConfig{} @Configuration@ComponentScan(basepackages={“基包名”,”…”})Public class AppConfig{} @Configuration@ComponentScan(basePackageClasses={App1Config.class,App2Config.class})Public class AppConfig{}以上 App1Config 与 App2Config 所在的包作为组件扫描的基础包 Annotation 自动装配 1.@Autowired 自动装配和 JSR 330’s @Inject 对应，可用在构造方法、属性 setter 方法，有属性@Autowired(required=false)@Primary 用于声明 bean 的首先，用在多个 bean，无法选择装配谁的情况可以指明使用哪个 2.@Required 声明依赖必须提供 用在 setter 方法@Requiredpublic void setMovieFinder(MovieFinder movieFinder) {this.movieFinder = movieFinder;} 3.@Qualifiers 注明要装配 bean 的标识，用于多个 bean 无法确定装配哪个的情况 处理自动装配的歧义Spring提供的自动装配是非常好用，可是用这么个问题：比如，一个接口有三个实现类，当要将接口类型自动装配置时，就出现不唯一的问题，Spring 会抛出 NoUniqueBeanDefinitionException。正如下面这种情况：写一个接口： 123456789package com.xzy.utils;import org.springframework.stereotype.Component;@Componentpublic interface ReadData &#123; public void read();&#125; 接口的三个实现类： 1234567891011package com.xzy.utils;import org.springframework.stereotype.Component;@Componentpublic class USBRead implements ReadData &#123; @Override public void read() &#123; System.out.println("USB读取数据....."); &#125;&#125; 1234567891011package com.xzy.utils;import org.springframework.stereotype.Component;@Componentpublic class SSDRead implements ReadData &#123; @Override public void read() &#123; System.out.println("SSD读取数据......"); &#125;&#125; 1234567891011package com.xzy.utils;import org.springframework.stereotype.Component;@Componentpublic class BlueRead implements ReadData &#123; @Override public void read() &#123; System.out.println("蓝牙读取数据......."); &#125;&#125; 这时如果让Spring给我们自动装配，他都懵逼了，因为这个接口有3个实现类，都可以装配，他不知道装配那个，如下图所示： 此时如果直接运行就会发生如下异常： 122019-08-01 21:49:51 [ERROR]-[org.springframework.test.context.TestContextManager] Caught exception while allowing TestExecutionListener [org.springframework.test.context.support.DependencyInjectionTestExecutionListener@685cb137] to prepare test instance [com.xzy.AppTest@50a638b5] org.springframework.beans.factory.UnsatisfiedDependencyException: Error creating bean with name 'com.xzy.AppTest': Unsatisfied dependency expressed through field 'read'; nested exception is org.springframework.beans.factory.NoUniqueBeanDefinitionException: No qualifying bean of type 'com.xzy.utils.ReadData' available: expected single matching bean but found 3: blueRead,SSDRead,USBRead 解决办法解决方法1：在实现类的头上使用@Primary注解告诉Spring首选哪个装配，比如在USBRead类的头上加上@Primary： 解决方法2：使用@Qualifier 注解限定自动装配的 Bean]]></content>
      <categories>
        <category>Spring框架</category>
      </categories>
      <tags>
        <tag>Spring IOC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[认识Spring框架]]></title>
    <url>%2F2019%2F08%2F01%2F%E8%AE%A4%E8%AF%86Spring%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[Spring 框架是 Java 应用最广的框架，它的成功来源于理念，而不是技术本身，它的理念包括 IoC (Inversion of Control，控制反转) 和 AOP(Aspect Oriented Programming，面向切面编程)。 什么是 Spring?1). Spring 是一个轻量级的 DI / IoC 和 AOP 容器的开源框架，来源于 Rod Johnson 在其著作《Expert one on one J2EE design and development》中阐述的部分理念和原型衍生而来。2).Spring 提倡以“最少侵入”的方式来管理应用中的代码，这意味着我们可以随时安装或者卸载 Spring3).适用范围：任何 Java 应用4).Spring 的根本使命：简化 Java 开发 Spring 中常用术语：框架：是能完成一定功能的半成品。框架能够帮助我们完成的是：项目的整体框架、一些基础功能、规定了类和对象如何创建，如何协作等，当我们开发一个项目时，框架帮助我们完成了一部分功能，我们自己再完成一部分，那这个项目就完成了。 非侵入式设计： 从框架的角度可以理解为：无需继承框架提供的任何类这样我们在更换框架时，之前写过的代码几乎可以继续使用。 轻量级和重量级： 轻量级是相对于重量级而言的，轻量级一般就是非入侵性的、所依赖的东西非常少、资源占用非常少、部署简单等等，其实就是比较容易使用，而重量级正好相反。 JavaBean： 即符合 JavaBean 规范的 Java 类 POJO：即 Plain Old Java Objects，简单老式 Java 对象它可以包含业务逻辑或持久化逻辑，但不担当任何特殊角色且不继承或不实现任何其它Java框架的类或接口。 > 注意：bean 的各种名称——虽然 Spring 用 bean 或者 JavaBean 来表示应用组件，但并不意味着 Spring 组件必须遵循 JavaBean 规范，一个 Spring 组件可以是任意形式的 POJO。 容器： 在日常生活中容器就是一种盛放东西的器具，从程序设计角度看就是装对象的的对象，因为存在放入、拿出等操作，所以容器还要管理对象的生命周期。 Spring 的优势低侵入 / 低耦合 （降低组件之间的耦合度，实现软件各层之间的解耦） 声明式事务管理（基于切面和惯例） 方便集成其他框架（如MyBatis、Hibernate） 降低 Java 开发难度 Spring 框架中包括了 J2EE 三层的每一层的解决方案（一站式） Spring能帮我们做什么?①.Spring 能帮我们根据配置文件创建及组装对象之间的依赖关系。②.Spring 面向切面编程能帮助我们无耦合的实现日志记录，性能统计，安全控制。③.Spring 能非常简单的帮我们管理数据库事务。④.Spring 还提供了与第三方数据访问框架（如Hibernate、JPA）无缝集成，而且自己也提供了一套JDBC访问模板来方便数据库访问。⑤.Spring 还提供与第三方Web（如Struts1/2、JSF）框架无缝集成，而且自己也提供了一套Spring MVC框架，来方便web层搭建。⑥.Spring 能方便的与Java EE（如Java Mail、任务调度）整合，与更多技术整合（比如缓存框架）。 Spring的框架体系结构： Data Access/Integration层包含有JDBC、ORM、OXM、JMS和Transaction模块。 Web层包含了Web、Web-Servlet、WebSocket、Web-Porlet模块。 AOP模块提供了一个符合AOP联盟标准的面向切面编程的实现。 Core Container(核心容器)：包含有Beans、Core、Context和SpEL模块。 Test模块支持使用JUnit和TestNG对Spring组件进行测试。 下面介绍这5个部分的jar以及依赖关系 Core core部分包含4个模块: spring-core：这个jar 文件包含Spring 框架基本的核心工具类。Spring 其它组件要都要使用到这个包里的类，是其它组件的基本核心。外部依赖Commons Logging， (Log4J)。 spring-beans：这个jar 文件是所有应用都要用到的，它包含访问配置文件、创建和管理bean 以及进行Inversion ofControl / Dependency Injection（IoC/DI）操作相关的所有类。如果应用只需基本的IoC/DI 支持，引入spring-core.jar 及spring-beans.jar 文件就可以了。 spring-context：spring的context上下文即IoC容器 spring-expression：一个强大的表达式语言，用于在运行时查询和处理对象图。该语言支持设置和获取属性值；属性赋值，方法调用，访问数组的内容，收集和索引器，逻辑和算术运算，命名变量，并从Spring的IOC容器的名字对象检索，它也支持列表选择和投影以及常见的列表聚合。 它们的依赖关系 Maven依赖写法如下： 12345678910111213141516171819202122232425262728293031&lt;!--Core：spring-core、spring-beans、spring-content、spring-expression--&gt;&lt;!--Spring核心--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-core&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;commons-logging&lt;/groupId&gt; &lt;artifactId&gt;commons-logging&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!--Spring IOC容器--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--Spring Bean工厂--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-beans&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--SpEL(Spring表达式)--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-expression&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt; AOP aop部分包含4个模块: spring-aop：这个jar 文件包含在应用中使用Spring 的AOP 特性时所需的类和源码级元数据支持。使用基于AOP 的Spring特性，如声明型事务管理（Declarative Transaction Management），也要在应用里包含这个jar包。外部依赖spring-core， (spring-beans，AOP Alliance， CGLIB，Commons Attributes) spring-aspects：提供对AspectJ的支持，以便可以方便的将面向切面的功能集成进IDE中，比如Eclipse AJDT。 spring-instrument：提供一些类级的工具支持和ClassLoader级的实现，用于服务器 spring-instrument-tomcat：针对tomcat的instrument实现 它们的依赖关系 Maven依赖写法如下： 1234567891011121314151617181920212223242526272829303132333435&lt;!--AOP：spring-aop、spring-aspectj、spring-instrument、spring-instrument-tomcat--&gt;&lt;!--spring aop：外部依赖spring-core， (spring-beans，AOP Alliance， CGLIB，Commons Attributes)--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aop&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--提供对AspectJ的支持，以便可以方便的将面向切面的功能集成进IDE中--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-aspects&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;!--aspectj的runtime包(必须)--&gt;&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjrt&lt;/artifactId&gt; &lt;version&gt;1.9.1&lt;/version&gt;&lt;/dependency&gt;&lt;!--aspectjweaver是aspectj的织入包(必须)--&gt;&lt;dependency&gt; &lt;groupId&gt;org.aspectj&lt;/groupId&gt; &lt;artifactId&gt;aspectjweaver&lt;/artifactId&gt; &lt;version&gt;1.9.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;cglib&lt;/groupId&gt; &lt;artifactId&gt;cglib&lt;/artifactId&gt; &lt;version&gt;3.1&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-instrument&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt; Data Accessdata access部分包含5个模块 spring-jdbc：这个jar 文件包含对Spring 对JDBC 数据访问进行封装的所有类。 spring-tx：为JDBC、Hibernate、JDO、JPA、Beans等提供的一致的声明式和编程式事务管理支持。 spring-orm：包含Spring对DAO特性集进行了扩展，使其支持iBatis(MyBatis)、JDO、OJB、TopLink， 因为Hibernate已经独立成包了，现在不包含在这个包里了。这个jar文件里大部分的类都要依赖spring-dao.jar里的类，用这个包时你需要同时包含spring-dao.jar包。 spring-oxm：Spring 对Object/XMl的映射支持,可以让Java与XML之间来回切换。 spring-jms：这个jar包提供了对JMX 1.0/1.2的支持类。java消息服务与Spring-massaging对应。外部依赖spring-beans，spring-aop， JMXAPI。 它们的依赖关系 Maven依赖写法如下： 12345678910111213141516171819202122232425&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jdbc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-tx&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-orm&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-oxm&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-jms&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt; Webweb部分包含4个模块 spring-web：这个jar 文件包含Web 应用开发时，用到Spring 框架时所需的核心基础类，包括自动载入Web ApplicationContext 特性的类、Struts 与JSF 集成类、文件上传的支持类、Filter 类和大量工具辅助类。 spring-webmvc：这个jar 文件包含Spring MVC 框架相关的所有类。包括框架的Servlets，Web MVC框架，控制器和视图支持。当然，如果你的应用使用了独立的MVC 框架，则无需这个JAR 文件里的任何类。外部依赖spring-web, (spring-support，Tiles，iText，POI)。 spring-webmvc-portlet：基于portlet的mvc实现 spring-websocket：Spring4以后为web应用提供的高效通信工具 spring-messaging：Spring4以后提供用于构建基于消息的应用程序 spring-struts：与struts的集成，不推荐，spring4不再提供 它们的依赖关系 Maven依赖写法如下： 1234567891011&lt;!--Spring Web：spring-web、spring-webmvc、spring-webmvc-portlet--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-web&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-webmvc&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt; Testtest部分只有一个模块，我将spring-context-support也放在这吧 spring-test：Spring-test支持spring组建junit或TestNG的集成测试和单元测试。它提供了一致spring ApplicationContext的加载和上下文的缓存。他还提供了可以用来测试代码隔离的模拟对象。 spring-context-support：包含支持缓存Cache（ehcache）、JCA、JMX、 邮件服务（Java Mail、COS Mail）、任务计划Scheduling（Timer、Quartz）方面的类。 它们的依赖关系 Maven依赖写法如下： 1234567891011&lt;!--Spring Test：spring-test--&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-context-support&lt;/artifactId&gt; &lt;version&gt;$&#123;spring.version&#125;&lt;/version&gt;&lt;/dependency&gt;]]></content>
      <categories>
        <category>Spring框架</category>
      </categories>
      <tags>
        <tag>Spring</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis分页插件PageHelper]]></title>
    <url>%2F2019%2F07%2F29%2FMybatis%E5%88%86%E9%A1%B5%E6%8F%92%E4%BB%B6PageHelper%2F</url>
    <content type="text"><![CDATA[PageHelper简介这是一个基于MyBatis开源的分页插件，使用非常方便，支持各种复杂的单表、多表分页查询，让你在写sql时无需考虑分页问题，PageHelper帮你搞定。项目托管在github上https://github.com/pagehelper/Mybatis-PageHelper。 在项目中引入PageHelperPageHelper是一个通用的MyBatis分页插件,在使用的时候除了要导入MyBatis和数据库驱动的jar包外，还要导入PageHelper的jar包。 123456789101112&lt;!--MyBatis通用分页插件pageHelper--&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.pagehelper&lt;/groupId&gt; &lt;artifactId&gt;pagehelper&lt;/artifactId&gt; &lt;version&gt;5.1.6&lt;/version&gt;&lt;/dependency&gt;&lt;!--分页插件依赖的包--&gt;&lt;dependency&gt; &lt;groupId&gt;com.github.jsqlparser&lt;/groupId&gt; &lt;artifactId&gt;jsqlparser&lt;/artifactId&gt; &lt;version&gt;0.9.5&lt;/version&gt;&lt;/dependency&gt; 分页插件的配置配置PageHepler拦截器插件对方法有很多种，可以在mybatis-config.xml全局配置文件来配置。也可以在Spring配置文件中配置，配置都很简单，具体如下： 在 MyBatis 配置 xml 中配置拦截器插件123456789101112&lt;!--配置拦截器插件--&gt;&lt;plugins&gt; &lt;plugin interceptor="com.github.pagehelper.PageInterceptor"&gt; &lt;property name="dialect" value="com.github.pagehelper.PageHelper"/&gt; &lt;property name="offsetAsPageNum" value="false"/&gt; &lt;property name="rowBoundsWithCount" value="false"/&gt; &lt;property name="pageSizeZero" value="false"/&gt; &lt;property name="reasonable" value="false"/&gt; &lt;property name="supportMethodsArguments" value="false"/&gt; &lt;property name="returnPageInfo" value="none"/&gt; &lt;/plugin&gt;&lt;/pligins&gt; 在 Spring 配置文件中配置拦截器插件1234567891011121314151617&lt;bean id="sqlSessionFactory" class="org.mybatis.spring.SqlSessionFactoryBean"&gt; &lt;property name="plugins"&gt; &lt;array&gt; &lt;bean class="com.github.pagehelper.PageInterceptior"&gt; &lt;property name="properties"&gt; &lt;value&gt; &lt;!--一行一个参数，可以写多个--&gt; pageSizeZero=false helperDialect=mysql reasonable=true &lt;/value&gt; &lt;/property&gt; &lt;/bean&gt; &lt;/array&gt; &lt;/property&gt; &lt;!--其他配置--&gt;&lt;/bean&gt; 分页插件参数介绍&nbsp;&nbsp;&nbsp;&nbsp;dialect：默认情况下会使用PageHelper类进行分页，如果想要实现自己的分页逻辑，可以实现Dialect接口,然后配置这个属性未实现类的全限定名。下面的参数都是在默认dialect情况下的参数。使用自定义dialect实现时下面的参数没有任何作用。&nbsp;helpDialect：配置helperDialect属性来指定分页插件使用哪种方言。配置时，可以使用下面的缩写值：oracle,mysql,mariadb,sqlite,hsqldb,postgresql,db2,sqlserver,informix,h2,sqlserver2012,derby。一般情况下，分页插件会自动检测当前的数据库链接，自动选择合适的分页方式。&nbsp;offsetAspageNum：默认值为 false，该参数对使用 RowBounds 作为分页参数时有效。 当该参数设置为 true 时，会将 RowBounds 中的 offset 参数当成 pageNum 使用，可以用页码和页面大小两个参数进行分页。&nbsp;rowBoundsWithCount：默认值为false，该参数对使用 RowBounds 作为分页参数时有效。 当该参数设置为true时，使用 RowBounds 分页会进行 count 查询。&nbsp;pageSizeZero：默认值为 false，当该参数设置为 true 时，如果 pageSize=0 或者 RowBounds.limit = 0 就会查询出全部的结果&nbsp;reasonable：分页合理化参数，默认值为false。当该参数设置为 true 时，pageNum&lt;=0 时会查询第一页， pageNum&gt;pages（超过总数时），会查询最后一页。&nbsp;params：为了支持startPage(Object params)方法，增加了该参数来配置参数映射，用于从对象中根据属性名取值， 可以配置 pageNum,pageSize,count,pageSizeZero,reasonable，不配置映射的用默认值， 默认值为pageNum=pageNum;pageSize=pageSize;count=countSql;reasonable=reasonable;pageSizeZero=pageSizeZero。&nbsp;supportMethodsArguments：支持通过 Mapper 接口参数来传递分页参数，默认值false，分页插件会从查询方法的参数值中，自动根据上面 params 配置的字段中取值，查找到合适的值时就会自动分页&nbsp;autoRuntimeDialect：默认值为 false。设置为 true 时，允许在运行时根据多数据源自动识别对应方言的分页&nbsp;closeConn：默认值为 true。当使用运行时动态数据源或没有设置 helperDialect 属性自动获取数据库类型时，会自动获取一个数据库连接， 通过该属性来设置是否关闭获取的这个连接，默认true关闭 在代码中使用PageHelper完成上面的操作后对分页插件的配置就完成了，使用方法也很简单：使用PageHelper.statPage静态方法来分页，使用PageInfo来获取分页信息 123456789101112131415161718@RequestMapping("/showAll") public String showAllBook(@RequestParam(value = "pageNo",defaultValue = "1") Integer pageNo,Model model) &#123; //官方推荐的两种使用方式 //1.使用PageHelper.startPage(pageNo,10)进行分页，第一个参数是页码，第二个参数是每页的大小,startPage有几个重载的方法，具体下面有说道 PageHelper.startPage(pageNo,20); List&lt;Book&gt; lists = bookService.getAll(); /**2.使用PageHelper.offsetPage(pageNo,20) *PageHelper.offsetPage(pageNo,20); *List&lt;Book&gt; lists = bookService.getAll(); */ //可以有两个参数，第一个参数是查询到的结果、第二个参数是连续显示的页码数 PageInfo&lt;Book&gt; info=new PageInfo&lt;Book&gt;(lists,10); model.addAttribute("info", info); return "bookInfo"; &#125; 使用的时应注意：&nbsp;&nbsp;&nbsp;&nbsp;1.只有紧跟在PageHelper.startPage方法后的第一个Mybatis的查询（Select）方法会被分页。&nbsp;&nbsp;&nbsp;&nbsp;2.请不要在系统中配置多个分页插件(使用Spring时,mybatis-config.xml和Spring配置方式，请选择其中一种，不要同时配置多个分页插件)！&nbsp;&nbsp;&nbsp;&nbsp;3.对于带有for update的sql，会抛出运行时异常，对于这样的sql建议手动分页，毕竟这样的sql需要重视。&nbsp;&nbsp;&nbsp;&nbsp;4.由于分页插件是通过拦截器，在原有SQL上进行追加约束条件，所以使用分页插件时，应保证原有SQL不会 受后面追加的条件的影响。给出一个反例:原有SQL中使用变量计算排名时,如果在后面追加了LIMIT的话，那么排名就会受到影响，因为SELECT的优先级在LIMIT之后。&nbsp;&nbsp;&nbsp;&nbsp;5.PageInfo是比Page信息更丰富的一个类;我们可以直接返回Page,也可以使用PageInfo包装一下返回PageInfo，甚至也可以自定义一个类来存放结果信息(只需将返回的Page中的信息取出来,再setter放入我们自己的类即可)。 PageHelper常用的APIPageMethod的APIPageHelper类继承了PageMethod抽象类，而使用PageHelper类进行分页操作的方法实际用的是PageMethod中的方法，具体如下： 1234567891011121314151617/**startPage方法都有下面几个内存pageNum int类型，当前页码pageSize int类型，每页的大小count boolean类型，是否在分页的时候统计记录数 reasonable boolean类型， isReasonable分页合理化,null时用默认配置pageSizeZero boolean类型，isPageSizeZero是否支持PageSize为0，true且pageSize=0时返回全部结果，false时分页,null时用默认配置*/public static &lt;E&gt; Page&lt;E&gt; startPage(Object params)public static &lt;E&gt; Page&lt;E&gt; startPage(int pageNum, int pageSize)public static &lt;E&gt; Page&lt;E&gt; startPage(int pageNum, int pageSize, boolean count)public static &lt;E&gt; Page&lt;E&gt; startPage(int pageNum, int pageSize, String orderBy)public static &lt;E&gt; Page&lt;E&gt; startPage(int pageNum, int pageSize, boolean count, Boolean reasonable, Boolean pageSizeZero)//offsetPage方法和startPage一样都是用来分页的，参数中offset相当于pageNum,limit相当于PageSizepublic static &lt;E&gt; Page&lt;E&gt; offsetPage(int offset, int limit)public static &lt;E&gt; Page&lt;E&gt; offsetPage(int offset, int limit, boolean count)//设置排序规则public static void orderBy(String orderBy) PageInfo类中的成员变量每一个成员变量都有对应的get和set方法，使用这些方法可以获得分页的任何信息，这个类十分强大 1234567891011121314151617181920212223242526272829303132333435//两个重要的构造方法，list是查询到的结果，navigatePages是下方显示的导航页码个数public PageInfo(List&lt;T&gt; list)public PageInfo(List&lt;T&gt; list, int navigatePages)//当前页private int pageNum;//每页的数量private int pageSize;//当前页的数量private int size;//当前页面第一个元素在数据库中的行号private int startRow;//当前页面最后一个元素在数据库中的行号private int endRow;//总记录数private long total;//总页数private int pages;//结果集private List&lt;T&gt; list;//第一页private int firstPage;//前一页private int prePage;//是否为第一页private boolean isFirstPage;//是否为最后一页private boolean isLastPage;//是否有前一页private boolean hasPreviousPage;//是否有下一页private boolean hasNextPage;//导航页码数private int navigatePages;//所有导航页号private int[] navigatepageNums;]]></content>
      <categories>
        <category>MyBatis框架</category>
      </categories>
      <tags>
        <tag>MyBatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MyBatis集成EhCache缓存]]></title>
    <url>%2F2019%2F07%2F29%2FMyBatis%E9%9B%86%E6%88%90EhCache%E7%BC%93%E5%AD%98%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;Encache是一个纯粹的Java进程内的缓存框架，具有快速、精干等特点。具体来说，Encache主要特点如下。 快速 简单 多种缓存策略 缓存数据有内存和磁盘两级，无需担心容量问题 缓存数据会在虚拟机重启的过程写入磁盘 可以通过RMI、可插入API等方式进行分布式缓存 具有缓存和缓存接口的侦听接口 &nbsp;因为以上诸多优点，MyBatis项目开发者最早提供了EnCache的MyBatis二级缓存实现，该项目名encache-cache，EhCache官方网址是http://www.mybatis.org/ehcache-cache/。下面，按照如下步骤集成EhCache框架。 添加项目依赖除了基本的MyBatis依赖、数据库驱动以外还需要在pom.xml中添加如下依赖： 123456789101112&lt;!--EnCache缓存核心包--&gt;&lt;dependency&gt; &lt;groupId&gt;net.sf.ehcache&lt;/groupId&gt; &lt;artifactId&gt;ehcache-core&lt;/artifactId&gt; &lt;version&gt;2.6.6&lt;/version&gt;&lt;/dependency&gt;&lt;!--mybatis-ehcache整合包--&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis.caches&lt;/groupId&gt; &lt;artifactId&gt;mybatis-ehcache&lt;/artifactId&gt; &lt;version&gt;1.0.3&lt;/version&gt;&lt;/dependency&gt; 配置encache.xml和MyBatis一样，EnCache也需要外部的配置文件，而且要求这个文件的名字必须是encache.xml，并且必须放在类路径的根目录下，即src/main/resources目录下 1234567891011121314151617181920&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;ehcache xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="http://ehcache.org/ehcache.xsd"&gt; &lt;!-- 磁盘保存路径 --&gt; &lt;diskStore path="E:\ehcache"/&gt; &lt;defaultCache maxElementsInMemory="1" maxElementsOnDisk="10000000" eternal="false" overflowToDisk="true" copyOnRead="true" copyOnWrite="true" timeToIdleSeconds="120" timeToLiveSeconds="120" diskExpiryThreadIntervalSeconds="120" memoryStoreEvictionPolicy="LRU"&gt; &lt;/defaultCache&gt;&lt;/ehcache&gt; 如果想增加一个针对某个Mapper映射文件的缓存配置，可以在ehcache.xml文件中添加一个和映射文件命名空间一致的缓存配置，例如针对UserMapper,可以进行如下配置： 12345678910&lt;cache name="com.xust.iot.mapper.UserMapper" maxElementsInMemory="3000" maxElementsOnDisk="1000000" eternal="false" overflowToDisk="true" copyOnWrite="true" copyOnRead="true" timeToIdleSeconds="3600" timeToLiveSeconds="3600" diskPersistent="true"/&gt; EhCache的配置信息 nameCache的名称，必须是唯一的(ehcache会把这个cache放到HashMap里)。 maxElementsInMemory在内存中缓存的element的最大数目 maxElementsOnDisk在磁盘上缓存的element的最大数目，默认值为0，表示不限制。 eternal设定缓存的elements是否永远不过期。如果为true，则缓存的数据始终有效，如果为false那么还要根据timeToIdleSeconds，timeToLiveSeconds判断。 overflowToDisk 如果内存中数据超过内存限制，是否要缓存到磁盘上。 copyOnRead判断从缓存中读取数据是否是返回对象的引用还是赋值一个对象返回。默认是false，即返回数据的引用，这种情况和MyBatis默认的缓存中只读对象是相同的。如果为true，那就是可读写缓存，每次读取缓存是都赋值一个新的实例。 copyOnWrite判断写入缓存时直接缓存对象的引用还是赋值一个对象后缓存，默认值也是false。如果想使用可读写缓存，就需要将这两个属性配置为true，如果使用只读缓存，可以不配置这两个属性。 timeToIdleSeconds 对象空闲时间，指对象在多长时间没有被访问就会失效。只对eternal为false的有效。默认值0，表示一直可以访问。 timeToLiveSeconds 对象存活时间，指对象从创建到失效所需要的时间。只对eternal为false的有效。默认值0，表示一直可以访问。 diskPersistent 是否在磁盘上持久化。指重启jvm后，数据是否有效。默认为false。 diskExpiryThreadIntervalSeconds 对象检测线程运行时间间隔。标识对象状态的线程多长时间运行一次。 diskSpoolBufferSizeMB DiskStore使用的磁盘大小，默认值30MB。每个cache使用各自的DiskStore。 memoryStoreEvictionPolicy 如果内存中数据超过内存限制，向磁盘缓存时的策略。默认值LRU，可选FIFO、LFU。 缓存清空策略 : １、FIFO ，first in first out (先进先出). ２、LFU ， Less Frequently Used (最少使用).意思是一直以来最少被使用的。缓存的元素有一个hit 属性，hit 值最小的将会被清出缓存。 ３、LRU ，Least Recently Used(最近最少使用). (ehcache 默认值).缓存的元素有一个时间戳，当缓存容量满了，而又需要腾出地方来缓存新的元素的时候，那么现有缓存元素中时间戳离当前时间最远的元素将被清出缓存。 修改Mapper映射文件chcache-cache提供了如下两个可选的缓存实现： org.mybatis.caches.ehcache.EhcacheCache org.mybatis.caches.ehcache.LoggingEhcache 这两个缓存中，第二个是带日志的缓存，由于MyBatis初始化时，如果Cache不是继承自LoggingEhcache，MyBatis便会使用LoggingEhcache装饰代理缓存，所以上面两个缓存使用时并没有区别，都会输出命中率的日志。修改后的UserMapper.xml配置如下： 12345678910111213141516&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;mapper namespace="com.xust.iot.mapper.UserMapper"&gt; &lt;!--在UserMapper中开启二级缓存,MyBatis支持集成第三方缓存,方法是使用type属性指定--&gt; &lt;cache type="org.mybatis.caches.ehcache.EhcacheCache"/&gt; &lt;select id="getUserByName" parameterType="string" resultType="user"&gt; select * from user &lt;where&gt; name=#&#123;username&#125; &lt;/where&gt; &lt;/select&gt;&lt;/mapper&gt; 在src/main/test目录下新建测试类AppTest.java测试是否用上了EhCache： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package test;import com.xust.iot.beans.User;import com.xust.iot.mapper.UserMapper;import net.sf.ehcache.CacheEntry;import net.sf.ehcache.Element;import org.apache.ibatis.io.Resources;import org.apache.ibatis.session.SqlSession;import org.apache.ibatis.session.SqlSessionFactory;import org.apache.ibatis.session.SqlSessionFactoryBuilder;import org.apache.log4j.Logger;import org.junit.Before;import org.junit.Test;import org.mybatis.caches.ehcache.EhcacheCache;import java.io.IOException;import java.io.InputStream;import java.util.Date;import java.util.List;public class AppTest &#123; private static SqlSessionFactory sqlSessionFactory; private static Logger log = Logger.getLogger(AppTest.class); @Before public void init() &#123; String resource = "mybatis-config.xml"; try &#123; InputStream inputStream = Resources.getResourceAsStream(resource); sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; @Test public void test02() &#123; //第一个会话 SqlSession session = sqlSessionFactory.openSession(true); UserMapper sm = session.getMapper(UserMapper.class); List&lt;User&gt; user1 = sm.getUserByName("小明"); if (null != user1 &amp;&amp; user1.size() &gt; 0) &#123; for (User u : user1) &#123; System.out.println(u.toString()); &#125; &#125; session.close(); //第二个会话 System.out.println("开启新的会话......"); SqlSession session2 = sqlSessionFactory.openSession(true); UserMapper sm2 = session2.getMapper(UserMapper.class); List&lt;User&gt; user2 = sm2.getUserByName("小明"); if (null != user2 &amp;&amp; user2.size() &gt; 0) &#123; for (User u : user2) &#123; System.out.println(u.toString()); &#125; &#125; session2.close(); &#125;&#125; 测试结果： 在配置的磁盘路径下确实有缓存文件：]]></content>
      <categories>
        <category>MyBatis框架</category>
      </categories>
      <tags>
        <tag>MyBatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[深入理解MyBatis高级结果映射]]></title>
    <url>%2F2019%2F07%2F28%2F%E6%B7%B1%E7%90%86%E8%A7%A3MyBatis%E9%AB%98%E7%BA%A7%E7%BB%93%E6%9E%9C%E6%98%A0%E5%B0%84%2F</url>
    <content type="text"><![CDATA[搭建实验环境 1).新建数据库mybatis6 2). 新建表：sys_user、sys_role、sys_user_role,sys_privilege、sys_role_privilege sql脚本如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657create table sys_user( id bigint not null primary key auto_increment, user_name varchar(255) , user_password varchar(255), user_email varchar(255), user_info text comment '用户简介', head_img blob comment '头像', create_time datetime);create table sys_role( id bigint not null primary key auto_increment, role_name varchar(255) , enable int comment '有效标志', create_by bigint comment '创建人', create_time datetime);create table sys_privilege( id bigint not null primary key auto_increment, privilege_name varchar(50) comment '权限名称', privilege_url varchar(255));create table sys_user_role( user_id bigint , role_id bigint);create table sys_role_privilege( role_id bigint, privilege bigint);insert into sys_user values('1','admin','123456','adimin@mybatis.tk','管理员',null,'2019-7-30 10:05:56');insert into sys_user values('1002','testuser','123456','test@mybatis.tk','测试用户',null,'2019-7-30 10:05:56');insert into sys_role values('1','管理员','1','1','2019-7-30 10:05:56');insert into sys_role values('2','普通用户','1','1','2019-7-30 10:05:56');insert into sys_user_role values ('1','1');insert into sys_user_role values ('1','2');insert into sys_user_role values ('1001','2');insert into sys_privilege values('1','用户管理','/user');insert into sys_privilege values('2','角色管理','/roles');insert into sys_privilege values('3','系统管理','/system');insert into sys_privilege values('4','系统维护','/system-a');insert into sys_privilege values('5','单位管理','/company');insert into sys_role_privilege values('1','1');insert into sys_role_privilege values('1','2');insert into sys_role_privilege values('1','3');insert into sys_role_privilege values('2','4');insert into sys_role_privilege values('2','5'); 3).新建每个 表对应的实体JavaBean SysUser.java 1234567891011121314151617package com.orecal.bean;import java.util.Date;import java.util.List;public class SysUser &#123; private Long id; private String userName; private String userPassword; private String userEmail; private String userInfo; private String headImg; private Date createTime; private SysRole role; //用户的角色 private List&lt;SysRole&gt; roleList; //用户角色结合和 //省略getter、setter.... SysRole.java 1234567891011121314package com.orecal.bean;import java.util.Date;import java.util.List;public class SysRole &#123; private Long id; private String roleName; private int enable; private int createBy; private Date createTime; private List&lt;SysPrivilege&gt; privilegeList; //省略getter、setter.... SysUserRole.java 12345678package com.orecal.bean;public class SysUserRole &#123; private Long userId; private Long roleId; //省略getter、setter.... SysPrivilege.java 123456789package com.orecal.bean;public class SysPrivilege &#123; private Long id; private String privilegeName; private String privilegeUrl; //省略getter、setter.... SysRolePrivilege.java 12345678package com.orecal.bean;public class SysRolePrivilege &#123; private Long roleId; private Long privilegeId; //省略getter、setter.... 4).新建SysUserMapper接口 5). 新建mybaits配置文件 一对一映射Mybatis中的映射方式有两种，一种是通过resultType自动映射，另一种是通过resultMap自己设置映射规则。resultMap又有两种映射方式：嵌套结果映射和嵌套查询映射。 嵌套结果映射:给数据库发一条复杂的sql语句把查询到的结果根据映射规则映射到不同的对象中 嵌套查询映射：会发多条sql简单的语句，Mybatis会把多条sql语句的查询据结果封装到一个对象中。如果在mybatis全局配置中设置了延迟加载：` ` 那么还可以按需给数据库发sql语句，即当没有用到这个表中的数据的时候，Mybatis压根就不会给数据库法sql语句，即使已在xml文件中已经配置了sql语句，这是MyBatis中非常强大的一个功能。 配置xml文件：通过resultMap一对一映射，在SysUser实体类中新增一个属性private SysRole role 标识用户的角色，然后在SysUserMapper.xml中写如下映射userRoleMap： 123456789101112131415161718192021222324252627SysUserMapper.xml&lt;resultMap type="com.orecla.bean.SysUser" id="userRoleMap"&gt; &lt;!--sys_user表中原有的属性--&gt; &lt;!-- id:id元素是一个很特殊的元素，如果设置了它，MyBayis会比较每次返回来的数据的id,如果id相同，MyBatis就会认为这是同一条数据，然后就会把这两条数据合并；如果没有设置id,MyBatis会比较resultMap下所有的字段属性，只要有一个不同就不会合并。 --&gt; &lt;id property="id" column="id"/&gt; &lt;result property="userName" column="user_name"/&gt; &lt;result property="userPassword" column="user_password"/&gt; &lt;result property="userEmail" column="user_email"/&gt; &lt;result property="userInfo" column="user_info"/&gt; &lt;result property="headImg" column="head_img"/&gt; &lt;result property="createTime" column="create_time"/&gt; &lt;!--role字段在sys_user表中没有，而且role他是一个复杂的类型，没法直接映射，最简单的可以通过如下这种方式来映射--&gt; &lt;result property="role.roleName" column="role_name"/&gt; &lt;result property="role.enable" column="enable"/&gt; &lt;result property="role.createTime" column="create_time"/&gt; &lt;result property="role.createBy" column="create_by"/&gt; &lt;/resultMap&gt; &lt;select id="selectUserAndRoleById" resultMap="userRoleMap"&gt; select sys_user.*,sys_role.role_name from sys_user,sys_role where sys_user.id=#&#123;id&#125; and sys_role.role_name=sys_user.user_info&lt;/select&gt; 在SysUserMapper接口中增加方法：public SysUser selectUserAndRoleById(Long id);测试方法： 1234567891011121314@Test public void test1() &#123; SqlSession session = sqlSessionFactory.openSession(true); try &#123; SysUserMapper sum = session.getMapper(SysUserMapper.class); SysUser user = sum.selectUserAndRoleById(1002L); System.out.println(user); //log.info(sum); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; session.close(); &#125; &#125; 这是日志的打印结果： 123456 2019-07-31 10:16:52 [DEBUG]-[com.orecal.mapper.SysUserMapper.selectUserAndRoleById] ==&gt; Preparing: select sys_user.*,sys_role.role_name from sys_user,sys_role where sys_user.id=? and sys_role.role_name=sys_user.user_info 2019-07-31 10:16:52 [DEBUG]-[com.orecal.mapper.SysUserMapper.selectUserAndRoleById] ==&gt; Parameters: 1002(Long) 2019-07-31 10:16:53 [DEBUG]-[com.orecal.mapper.SysUserMapper.selectUserAndRoleById] &lt;== Total: 1 SysUser&#123;id=1002, userName=&apos;testuser&apos;, userPassword=&apos;123456&apos;, userEmail=&apos;test@mybatis.tk&apos;, userInfo=&apos;普通用户&apos;, headImg=&apos;null&apos;, createTime=Tue Jul 30 10:05:56 CST 2019, role=SysRole&#123;id=null, roleName=&apos;普通用户&apos;, enable=0, createBy=0, createTime=Tue Jul 30 10:05:56 CST 2019, privilegeList=null&#125;, roleList=null&#125;2019-07-31 10:16:53 [DEBUG]-[org.apache.ibatis.transaction.jdbc.JdbcTransaction] Closing JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@2ed0fbae] 2019-07-31 10:16:53 [DEBUG]-[org.apache.ibatis.datasource.pooled.PooledDataSource] Returned connection 785447854 to pool. &nbsp;&nbsp;&nbsp;&nbsp;改进上面的映射方法：上面的映射方法虽然可以使用，但是耦合性太高，而且最大的问题是配置文件不能复用，啥意思?就是说，如果我现在需要一个单独查用户的方法，那我还得专门为查用户写一个sql配置，这样做非常的糟糕，当项目非常大的时候，配置文件的重复配置代码将会非常的多，那么如何解决这个问题呢?我们接着往下看:在SysUserMapper.xml中增加一个专门为查用户的映射userMap： 12345678910111213SysUserMapper.xml&lt;resultMap type="com.orecal.bean.SysUser" id="userMap"&gt; &lt;id property="id" column="id"/&gt; &lt;result property="userName" column="user_name"/&gt; &lt;result property="userPassword" column="user_password"/&gt; &lt;result property="userEmail" column="user_email"/&gt; &lt;result property="userInfo" column="user_info"/&gt; &lt;result property="headImg" column="head_img"/&gt; &lt;result property="createTime" column="create_time"/&gt; &lt;/resultMap&gt; &lt;select id="selectUser" resultMap="userMap"&gt; select * from sys_user where id=#&#123;id&#125;; &lt;/select&gt; 然后刚才的上面的userRoleMap就可以修改成下面的样子： 123456789101112131415161718192021SysUserMapper.xml &lt;!-- 使用resultMap可以自定义结果集的映射关系 type:这个样映射到那个pojo id：给这个映射关系起的一个唯一的标识 extends:resultMap可以继承别的map已经定义好的关系，比如下面的userMap在上门已经定义了，在下面可以继承后直接使用 --&gt; &lt;resultMap type="com.orecal.bean.SysUser" id="userRoleMap" extends="userMap"&gt; &lt;result property="role.roleName" column="role_name"/&gt; &lt;result property="role.enable" column="enable"/&gt; &lt;result property="role.createTime" column="create_time"/&gt; &lt;result property="role.createBy" column="create_by"/&gt; &lt;/resultMap&gt; &lt;select id="selectUserAndRoleById" resultMap="userRoleMap"&gt; select sys_user.*,sys_role.role_name from sys_user,sys_role where sys_user.id=#&#123;id&#125; and sys_role.role_name=sys_user.user_info &lt;/select&gt; 使用association元素替代上面的role.XXX: 1234567891011121314151617SysUserMapper.xml &lt;!--使用association和一个复杂的类型进行关联 property:pojo中对应的属性名，必填 javaType:这个属性对应的pojo类型 resultMap:可以使用这个属性配置已有的map， 如果要引用当前mapper中的resultMap，直接引用 如果引用别的mapper中的resultMap，要指定namespace以及引用的那个map的id --&gt;&lt;resultMap id="userRoleMap2" type="com.orecal.bean.SysUser" extends="userMap"&gt; &lt;association property="role" javaType="com.orecal.bean.SysRole"&gt; &lt;result property="id" column="id"/&gt; &lt;result property="roleName" column="role_name"/&gt; &lt;result property="enable" column="enable"/&gt; &lt;result property="createTime" column="create_time"/&gt; &lt;result property="createBy" column="create_by"/&gt; &lt;/association&gt;&lt;/resultMap&gt; 可是这样还是不行，实际的开发中，肯定会有关于单独查询sys_role的需求，而且人家sys_role肯定也会有单独的mapper,这样就又会存在重复配置的问题，解决这个问题需要用到association元素的另一个功能,具体看代码：新建SysRoleMapper.xml,并配置roleMap如下： 123456789101112SysRoleMapper.xml&lt;!--根据id查询角色--&gt;&lt;resultMap type="com.orecal.bean.SysRole" id="roleMap"&gt; &lt;result property="id" column="id"/&gt; &lt;result property="roleName" column="role_name"/&gt; &lt;result property="enable" column="enable"/&gt; &lt;result property="createTime" column="create_time"/&gt; &lt;result property="createBy" column="create_by"/&gt;&lt;/resultMap&gt;&lt;select id="selectRoleById" resultMap="roleMap"&gt; select * from sys_role where id=#&#123;id&#125;;&lt;/select&gt; 这样我们在SysUserMapper.xml就可以把刚才的配置彻底抽取了出来： 1234567SysUserMapper.xml&lt;resultMap id="userRoleMap" type="com.orecal.bean.SysUser" extends="userMap"&gt; &lt;!--在association中使用resultMap属性指定要关联的Map resultMap=目标map的namespace.目标map的id 在同一个mapper中也可以这么使用，但是只用指定id就够了 --&gt; &lt;association property="role" resultMap="com.orecal.mapper.SysRoleMapper.roleMap"/&gt;&lt;/resultMap&gt; 这样就彻底把模块与模块分开了,当然我们也可以顺便实现以下selectRoleById,下面是配置后的运行时打印的日志的部分： 12345678 2019-07-31 10:57:08 [DEBUG]-[com.orecal.mapper.SysUserMapper.selectUserAndRoleById2] ==&gt; Preparing: select sys_user.*,sys_role.role_name from sys_user,sys_role where sys_user.id=? and sys_role.role_name=sys_user.user_info 2019-07-31 10:57:08 [DEBUG]-[com.orecal.mapper.SysUserMapper.selectUserAndRoleById2] ==&gt; Parameters: 1002(Long) 2019-07-31 10:57:08 [DEBUG]-[com.orecal.mapper.SysUserMapper.selectUserAndRoleById2] &lt;== Total: 1 SysUser&#123;id=1002, userName=&apos;testuser&apos;, userPassword=&apos;123456&apos;, userEmail=&apos;test@mybatis.tk&apos;, userInfo=&apos;普通用户&apos;, headImg=&apos;null&apos;, createTime=Tue Jul 30 10:05:56 CST 2019, role=SysRole&#123;id=1002, roleName=&apos;普通用户&apos;, enable=0, createBy=0, createTime=Tue Jul 30 10:05:56 CST 2019, privilegeList=null&#125;, roleList=null&#125;2019-07-31 10:57:08 [DEBUG]-[org.apache.ibatis.transaction.jdbc.JdbcTransaction] Closing JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@2ed0fbae] 2019-07-31 10:57:08 [DEBUG]-[org.apache.ibatis.datasource.pooled.PooledDataSource] Returned connection 785447854 to pool. Process finished with exit code 0 可以看到，日志的打印结果相同，但是修改后的方式肯定比一开始的方法要好，因为这样就把各个查询模块化了，就像搭积木，一个个简单的“积木块”最后通过合理的组织，就可以实现不同的复杂查询。一对一的嵌套查询映射上面这种方法是嵌套结果映射，就是直接给数据库发一条sql语句，数据库返回数据后Mybatis根据映射规则，把数据映射到不同的对象中。而嵌套查询映射则是多次给数据库发简单的sql语句，然后把不同的数据映射到一个对象中。 1.association元素的嵌套查询： &nbsp; &nbsp; select :另一个映射查询map的id &nbsp; &nbsp; column：将主查询的那个列的结果作为嵌套查询的参数传给嵌套查询方法 &nbsp; &nbsp; fetchType:数据加载的方式[lazy或eager],即延迟加载或积极加载, &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 配置这个属性会覆盖全局配置中飞lazyLoadingEnabled 2.MyBatis的嵌套查询可以实现懒加载，简单点的说就是不用的时候就不给你加载，等用的时候才去给你加载,这样做的好处是可以降低数据库的压力，做到按需响应。那么要用懒加载必须在全局配置文件中设置如下：&lt;settings&gt; &lt;setting name=&quot;aggressiveLazyLoading&quot; value=&quot;false&quot;/&gt; &lt;!--vallue=false时按需加载-，否者全部加载-&gt; &lt;setting name=&quot;lazyLoadingEnabled&quot; value=&quot;true&quot;/&gt; &lt;!--是否开启懒加载，true表示开启--&gt; &lt;setting name=&quot;lazyLoadTriggerMethods&quot; value=&quot;equals,clone,hashCode,toString&quot;/&gt; &lt;!--懒加载模式下如果调用value后的方法将全部加载--&gt; &lt;/settings&gt; 在SysUserMapper.xml中写一个id为userRoleMapSelecct的新的映射关系，并写SQL查询语句如下： 123456789101112131415161718192021222324252627SysUserMapper.xml&lt;resultMap id="userRoleMapSelect" extends="userMap" type="com.orecal.bean.SysUser"&gt; &lt;!-- association的select元素中指定另一个嵌套的子查询 select=子查询Mapper接口中对应方法的全类名 --&gt; &lt;association property="role" select="com.orecal.mapper.SysRoleMapper.selectRoleById" column="&#123;id=role_id&#125;"/&gt;&lt;/resultMap&gt;&lt;select id="selectUserAndRoleById3" resultMap="userRoleMapSelect"&gt;SELECT sys_user.id, sys_user.user_name, sys_user.user_password, sys_user.user_email, sys_user.user_info, sys_user.head_img, sys_user.create_time, sys_user_role.role_id FROM sys_user, sys_user_role WHERE sys_user.id = sys_user_role.user_id AND sys_user.id = #&#123;id&#125;&lt;/select&gt; 配置好后我们在SysUserMapper接口中增加selectUserAndRoleById3方法,然后写测试： 1234567891011121314151617 @Testpublic void test4() &#123; SqlSession session = sqlSessionFactory.openSession(true); try &#123; SysUserMapper sum = session.getMapper(SysUserMapper.class); List&lt;SysUser&gt; user = sum.selectUserAndRoleById3(1002L); for (SysUser u : user) &#123; System.out.println(u); //System.out.println(u.getUserName() + "," + u.getUserEmail() + "," + u.getCreateTime()); &#125; log.info(sum); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; session.close(); &#125;&#125; 日志的打印结果： 123456789101112131415 2019-07-31 11:29:54 [DEBUG]-[org.apache.ibatis.transaction.jdbc.JdbcTransaction] Opening JDBC Connection 2019-07-31 11:29:54 [DEBUG]-[org.apache.ibatis.datasource.pooled.PooledDataSource] Created connection 785447854. 2019-07-31 11:29:54 [DEBUG]-[com.orecal.mapper.SysUserMapper.selectUserAndRoleById3] ==&gt; Preparing: select sys_user.id, sys_user.user_name, sys_user.user_password, sys_user.user_email, sys_user.user_info, sys_user.head_img, sys_user.create_time, sys_user_role.role_id from sys_user,sys_user_role where sys_user.id=sys_user_role.user_id and sys_user.id=? 2019-07-31 11:29:54 [DEBUG]-[com.orecal.mapper.SysUserMapper.selectUserAndRoleById3] ==&gt; Parameters: 1002(Long) 2019-07-31 11:29:54 [WARN]-[org.apache.ibatis.session.AutoMappingUnknownColumnBehavior] Unknown column is detected on &apos;com.orecal.mapper.SysUserMapper.selectUserAndRoleById3&apos; auto-mapping. Mapping parameters are [columnName=role_id,propertyName=role_id,propertyType=null] 2019-07-31 11:29:54 [DEBUG]-[com.orecal.mapper.SysUserMapper.selectUserAndRoleById3] &lt;== Total: 1 2019-07-31 11:29:54 [DEBUG]-[com.orecal.mapper.SysRoleMapper.selectRoleById] ==&gt; Preparing: select * from sys_role where id=?; 2019-07-31 11:29:54 [DEBUG]-[com.orecal.mapper.SysRoleMapper.selectRoleById] ==&gt; Parameters: 2(Long) 2019-07-31 11:29:54 [DEBUG]-[com.orecal.mapper.SysRoleMapper.selectRoleById] &lt;== Total: 1 SysUser&#123;id=1002, userName=&apos;testuser&apos;, userPassword=&apos;123456&apos;, userEmail=&apos;test@mybatis.tk&apos;, userInfo=&apos;普通用户&apos;, headImg=&apos;null&apos;, createTime=Tue Jul 30 10:05:56 CST 2019, role=SysRole&#123;id=2, roleName=&apos;普通用户&apos;, enable=1, createBy=1, createTime=Tue Jul 30 10:05:56 CST 2019, privilegeList=null&#125;, roleList=null&#125;2019-07-31 11:29:54 [INFO]-[com.orecal.AppTest] org.apache.ibatis.binding.MapperProxy@6580cfdd 2019-07-31 11:29:54 [DEBUG]-[org.apache.ibatis.transaction.jdbc.JdbcTransaction] Closing JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@2ed0fbae] 2019-07-31 11:29:54 [DEBUG]-[org.apache.ibatis.datasource.pooled.PooledDataSource] Returned connection 785447854 to pool. Process finished with exit code 0 可以看到，MyBatis分别给数据库发了两条sql语句，这是因为直接打印，在配置文件的setting中有一个元素lazyLoadTriggerMethods 默认值value=&quot;equals,clone,hashCode,toString&quot;，当程序中调用这些方法的时就会全部加载。但是如果我们在程序中只是用到User的一些属性，那么Mybatis就只发查user的sql语句,把测试代码中的System.out.println(u);改成System.out.println(u.getUserName() + &quot;,&quot; + u.getUserEmail() + &quot;,&quot; + u.getCreateTime()); 再次运行打印的日志部分如下： 12345678910 2019-07-31 11:27:13 [DEBUG]-[com.orecal.mapper.SysUserMapper.selectUserAndRoleById3] ==&gt; Preparing: select sys_user.id, sys_user.user_name, sys_user.user_password, sys_user.user_email, sys_user.user_info, sys_user.head_img, sys_user.create_time, sys_user_role.role_id from sys_user,sys_user_role where sys_user.id=sys_user_role.user_id and sys_user.id=? 2019-07-31 11:27:13 [DEBUG]-[com.orecal.mapper.SysUserMapper.selectUserAndRoleById3] ==&gt; Parameters: 1002(Long) 2019-07-31 11:27:13 [WARN]-[org.apache.ibatis.session.AutoMappingUnknownColumnBehavior] Unknown column is detected on &apos;com.orecal.mapper.SysUserMapper.selectUserAndRoleById3&apos; auto-mapping. Mapping parameters are [columnName=role_id,propertyName=role_id,propertyType=null] 2019-07-31 11:27:13 [DEBUG]-[com.orecal.mapper.SysUserMapper.selectUserAndRoleById3] &lt;== Total: 1 testuser,test@mybatis.tk,Tue Jul 30 10:05:56 CST 20192019-07-31 11:27:13 [INFO]-[com.orecal.AppTest] org.apache.ibatis.binding.MapperProxy@6a400542 2019-07-31 11:27:13 [DEBUG]-[org.apache.ibatis.transaction.jdbc.JdbcTransaction] Closing JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@2ed0fbae] 2019-07-31 11:27:13 [DEBUG]-[org.apache.ibatis.datasource.pooled.PooledDataSource] Returned connection 785447854 to pool. Process finished with exit code 0 可以看到，只发了一条sql语句。这就是MyBatis的延迟加载（懒加载），也就是说，当你没用到的时候，MyBatis压根不会帮你去查这个数据。这样一来的好处是会减轻数据库的压力。 一对多映射使用collection实现一对多映射,collection的属性和用法与association基本是一样的，只是collection是专门用来映射数据库中一对多的多方元素的一个集合。比如现在有这样的需求：查询所有用户以及每个用户在本系统中所拥有的角色。这是一个很典型的一对多的例子，一个用户在系统中有多个角色。举个栗子：在SysUser.java中增加属性List&lt;SysRole&gt; roleList 12345678910//其他的属性不变private List&lt;SysRole&gt; roleList; //用户角色结合public List&lt;SysRole&gt; getRoleList() &#123; return roleList;&#125;public void setRoleList(List&lt;SysRole&gt; roleList) &#123; this.roleList = roleList;&#125; 在SysUserMapper.xml中增加reultMapuserRoleListMap,由于roleMap在前面已经定义过了，这里就可以直接使用 12345678910111213141516SysUserMapper.xml&lt;resultMap id="userRoleListMap" extends="userMap" type="com.orecal.bean.SysUser"&gt; &lt;collection property="roleList" resultMap="com.orecal.mapper.SysRoleMapper.roleMap"/&gt;&lt;/resultMap&gt;&lt;select id="selectAllUserAndRole" resultMap="userRoleListMap"&gt;SELECT sys_user.*, sys_role.* FROM sys_user, sys_role, sys_user_role WHERE sys_user_role.user_id = sys_user.id AND sys_user_role.role_id = sys_role.id;&lt;/select&gt; 测试代码： 1234567891011121314151617181920@Testpublic void test5() &#123; SqlSession session = sqlSessionFactory.openSession(true); try &#123; SysUserMapper sum = session.getMapper(SysUserMapper.class); List&lt;SysUser&gt; user = sum.selectAllUserAndRole(); System.out.println("用户数：" + user.size()); for (SysUser u : user) &#123; System.out.println("用户名：" + u.getUserName()); for (SysRole role : u.getRoleList()) &#123; System.out.println("角色名：" + role.getRoleName()); &#125; &#125; log.info(sum); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; session.close(); &#125;&#125; 程序运行打印的日志： 12345678910111213141516 2019-07-31 14:47:06 [DEBUG]-[org.apache.ibatis.transaction.jdbc.JdbcTransaction] Opening JDBC Connection 2019-07-31 14:47:06 [DEBUG]-[org.apache.ibatis.datasource.pooled.PooledDataSource] Created connection 741669172. 2019-07-31 14:47:06 [DEBUG]-[com.orecal.mapper.SysUserMapper.selectAllUserAndRole] ==&gt; Preparing: select sys_user.*,sys_role.*,sys_privilege.* from sys_user, sys_role,sys_user_role,sys_privilege,sys_role_privilege where sys_user_role.user_id=sys_user.id and sys_user_role.role_id=sys_role.id and sys_role_privilege.role_id=sys_role.id and sys_privilege.id=sys_role_privilege.privilege_id; 2019-07-31 14:47:06 [DEBUG]-[com.orecal.mapper.SysUserMapper.selectAllUserAndRole] ==&gt; Parameters: 2019-07-31 14:47:06 [DEBUG]-[com.orecal.mapper.SysUserMapper.selectAllUserAndRole] &lt;== Total: 7 用户数：2用户名：admin角色名：管理员角色名：普通用户用户名：testuser角色名：普通用户2019-07-31 14:47:06 [INFO]-[com.orecal.AppTest] org.apache.ibatis.binding.MapperProxy@38c5cc4c 2019-07-31 14:47:06 [DEBUG]-[org.apache.ibatis.transaction.jdbc.JdbcTransaction] Closing JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@2c34f934] 2019-07-31 14:47:06 [DEBUG]-[org.apache.ibatis.datasource.pooled.PooledDataSource] Returned connection 741669172 to pool. Process finished with exit code 0 前面这个实现了一层嵌套，就是一个主查询下面只有一个层子查询然后就结束了，下面我们尝试来实现一个两层嵌套：比如现在有这样的需求：查询所有的用户的角色，以及每个角色拥有的权限。很好想，就是一个用户可以有多个角色，每个角色又有不同的权限。 实现： 首先在SysRole中增加一个属性private List&lt;SysPrivilege&gt; privilegeList 12345678910//其他的属性不变private List&lt;SysPrivilege&gt; privilegeList;public List&lt;SysPrivilege&gt; getPrivilegeList() &#123; return privilegeList;&#125;public void setPrivilegeList(List&lt;SysPrivilege&gt; privilegeList) &#123; this.privilegeList = privilegeList;&#125; 新建SysPrivilegeMapper.xml文件，增加一个resultMapprivilegeMap 12345678910111213 &lt;resultMap type="com.orecal.bean.SysPrivilege" id="privilegeMap"&gt; &lt;result property="privilegeName" column="privilege_name"/&gt; &lt;result property="privilegeUrl" column="privilege_url"/&gt; &lt;/resultMap&gt; SELECT sys_privilege.* FROM sys_privilege, sys_role_privilege WHERE sys_role_privilege.privilege_id = sys_privilege.id AND sys_role_privilege.role_id = #&#123;roleId&#125; &lt;/select&gt; 在SysRoleMapper.xml中增加一个resultMaprolePrivilegeListMap，由于roleMap在上面已经定义过了，，用extends继承他就可以直接使用了。 123456789101112131415SysRoleMapper.xml&lt;resultMap id="rolePrivilegeListMap" extends="roleMap" type="com.orecal.bean.SysRole"&gt; &lt;collection property="privilegeList" resultMap="com.orecal.mapper.SysPrivilegeMapper.privilegeMap"/&gt;&lt;/resultMap&gt;&lt;select id="selectAllRoleAndPrivilege" resultMap="rolePrivilegeListMap"&gt; select sys_role.*, sys_privilege.* from sys_role, sys_privilege, sys_role_privilege where sys_role_privilege.role_id=sys_role.id and sys_privilege.id=sys_role_privilege.privilege_id; &lt;/select&gt; 在SysUserMapper.xml中增加reusltMap:userRoleListMapSelect 12345678910111213141516171819202122SysUserMapper.xml&lt;resultMap id="userRoleListMapSelect" extends="userMap" type="com.orecal.bean.SysUser"&gt; &lt;collection property="roleList" resultMap="com.orecal.mapper.SysRoleMapper.rolePrivilegeListMap"/&gt; &lt;/resultMap&gt; &lt;select id="selectAllUserAndRole2" resultMap="userRoleListMap"&gt; SELECT sys_user.*, sys_role.*, sys_privilege.* FROM sys_user, sys_role, sys_user_role, sys_privilege, sys_role_privilege WHERE sys_user_role.user_id = sys_user.id AND sys_user_role.role_id = sys_role.id AND sys_role_privilege.role_id = sys_role.id AND sys_privilege.id = sys_role_privilege.privilege_id; &lt;/select&gt; 在SysUserMapper接口中增加方法selectAllUserAndRole2，并且编写测试代码： 1234567891011121314151617181920212223@Test public void test6() &#123; SqlSession session = sqlSessionFactory.openSession(true); try &#123; SysUserMapper sum = session.getMapper(SysUserMapper.class); List&lt;SysUser&gt; user = sum.selectAllUserAndRole(); System.out.println("用户数：" + user.size()); for (SysUser u : user) &#123; System.out.println("用户名：" + u.getUserName()); for (SysRole role : u.getRoleList()) &#123; System.out.println("角色名：" + role.getRoleName()); for (SysPrivilege privilege : role.getPrivilegeList()) &#123; System.out.println("权限：" + privilege.getPrivilegeName()); &#125; &#125; System.out.println("--------------------------------------------------------"); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; session.close(); &#125; &#125; 程寻运行打印的日志的一部分： 1234567891011121314151617181920212223242019-07-31 15:11:27 [DEBUG]-[org.apache.ibatis.datasource.pooled.PooledDataSource] Created connection 741669172. 2019-07-31 15:11:27 [DEBUG]-[com.orecal.mapper.SysUserMapper.selectAllUserAndRole] ==&gt; Preparing: select sys_user.*,sys_role.*,sys_privilege.* from sys_user, sys_role,sys_user_role,sys_privilege,sys_role_privilege where sys_user_role.user_id=sys_user.id and sys_user_role.role_id=sys_role.id and sys_role_privilege.role_id=sys_role.id and sys_privilege.id=sys_role_privilege.privilege_id; 2019-07-31 15:11:27 [DEBUG]-[com.orecal.mapper.SysUserMapper.selectAllUserAndRole] ==&gt; Parameters: 2019-07-31 15:11:27 [DEBUG]-[com.orecal.mapper.SysUserMapper.selectAllUserAndRole] &lt;== Total: 7 用户数：2用户名：admin角色名：管理员权限：用户管理权限：角色管理权限：系统管理角色名：普通用户权限：系统维护权限：单位管理--------------------------------------------------------用户名：testuser角色名：普通用户权限：系统维护权限：单位管理--------------------------------------------------------2019-07-31 15:11:27 [INFO]-[com.orecal.AppTest] org.apache.ibatis.binding.MapperProxy@38c5cc4c 2019-07-31 15:11:27 [DEBUG]-[org.apache.ibatis.transaction.jdbc.JdbcTransaction] Closing JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@2c34f934] 2019-07-31 15:11:27 [DEBUG]-[org.apache.ibatis.datasource.pooled.PooledDataSource] Returned connection 741669172 to pool. Process finished with exit code 0 这样，我们就算是实现了一对多的两层嵌套结果映射的一个查询，这种方式在日常非常常见，也是MyBatis中非常强大的地方。最后我们看一下一对多的嵌套查询映射，和一对一的实现方法是类似的：前面我们写过一个resultMaprolePrivilegeListMap，但是还没有为他写接口方法，这里我们首先来实现这个： 123456789public interface SysPrivilegeMapper &#123; /** * 通过角色ID获得它的权限 * @return */ public List&lt;SysPrivilege&gt; selectPrivilegeByRoleId(Long id);&#125; 在SysRoleMapper.xml增加一个resultMap:rolePrivilegeListMap2 123456789101112131415&lt;resultMap id="rolePrivilegeListMap2" extends="roleMap" type="com.orecal.bean.SysRole"&gt; &lt;collection property="privilegeList" select="com.orecal.mapper.SysPrivilegeMapper.selectPrivilegeByRoleId" column="&#123;roleId=id&#125;"&gt; &lt;/collection&gt; &lt;/resultMap&gt; &lt;select id="selectRoleByUserId" resultMap="rolePrivilegeListMap2"&gt; SELECT sys_role.* FROM sys_role, sys_user_role WHERE sys_user_role.user_id = sys_role.id AND sys_user_role.user_id = 1; &lt;/select&gt; 在SysRoleMapper接口中增加一个方法selectRoleByUserId 123456/** * 根据用户id查他的权限 * @param userId * @return */public List&lt;SysRole&gt; selectRoleByUserId(Long userId); 最后在SysUserMapper.xml中增加一个resultMap:userRoleListMap2 12345678 &lt;resultMap id="userRoleListMap2" extends="userMap" type="com.orecal.bean.SysUser"&gt; &lt;collection property="roleList" select="com.orecal.mapper.SysRoleMapper.selectRoleByUserId" column="&#123;userId=id&#125;"/&gt;&lt;/resultMap&gt;&lt;select id="selectAllUserAndRole2" resultMap="userRoleListMap2"&gt; select sys_user.* from sys_user where sys_user.id=#&#123;id&#125;&lt;/select&gt; 在SysUserMapper接口中增加一个方法selectAllUserAndRole2: 1234567 /** * 根据用户的Id查询他拥有的角色和对应的权限 * @param id * @return */public SysUser selectAllUserAndRole2(Long id); 测试代码： 1234567891011121314151617181920212223@Test public void test10() &#123; SqlSession session = sqlSessionFactory.openSession(true); try &#123; SysUserMapper sum = session.getMapper(SysUserMapper.class); SysUser user = sum.selectAllUserAndRole2(1002L); System.out.println("-------------------------------------------"); System.out.println("用户名：" + user.getUserName()); for (SysRole role : user.getRoleList()) &#123; System.out.println("角色名：" + role.getRoleName()); for (SysPrivilege privilege : role.getPrivilegeList()) &#123; System.out.println("权限：" + privilege.getPrivilegeName()); &#125; System.out.println("$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$"); &#125; System.out.println("-------------------------------------------"); log.info(sum); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; session.close(); &#125; &#125; 程寻运行打印的日志: 123456789101112131415161718192021222324252627282019-07-31 15:40:08 [DEBUG]-[org.apache.ibatis.datasource.pooled.PooledDataSource] Created connection 785447854. 2019-07-31 15:40:08 [DEBUG]-[com.orecal.mapper.SysUserMapper.selectAllUserAndRole2] ==&gt; Preparing: select sys_user.* from sys_user where sys_user.id=? 2019-07-31 15:40:08 [DEBUG]-[com.orecal.mapper.SysUserMapper.selectAllUserAndRole2] ==&gt; Parameters: 1(Long) 2019-07-31 15:40:08 [DEBUG]-[com.orecal.mapper.SysUserMapper.selectAllUserAndRole2] &lt;== Total: 1 -------------------------------------------用户名：admin2019-07-31 15:40:08 [DEBUG]-[com.orecal.mapper.SysRoleMapper.selectRoleByUserId] ==&gt; Preparing: select sys_role.* from sys_role,sys_user_role where sys_user_role.user_id=sys_role.id and sys_user_role.user_id=? 2019-07-31 15:40:08 [DEBUG]-[com.orecal.mapper.SysRoleMapper.selectRoleByUserId] ==&gt; Parameters: 1(Long) 2019-07-31 15:40:08 [DEBUG]-[com.orecal.mapper.SysRoleMapper.selectRoleByUserId] &lt;== Total: 2 角色名：管理员2019-07-31 15:40:08 [DEBUG]-[com.orecal.mapper.SysPrivilegeMapper.selectPrivilegeByRoleId] ==&gt; Preparing: select sys_privilege.* from sys_privilege,sys_role_privilege where sys_role_privilege.privilege_id=sys_privilege.id and sys_role_privilege.role_id=? 2019-07-31 15:40:08 [DEBUG]-[com.orecal.mapper.SysPrivilegeMapper.selectPrivilegeByRoleId] ==&gt; Parameters: 1(Long) 2019-07-31 15:40:08 [DEBUG]-[com.orecal.mapper.SysPrivilegeMapper.selectPrivilegeByRoleId] &lt;== Total: 3 权限：用户管理权限：角色管理权限：系统管理$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$角色名：管理员权限：用户管理权限：角色管理权限：系统管理$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$-------------------------------------------2019-07-31 15:40:08 [INFO]-[com.orecal.AppTest] org.apache.ibatis.binding.MapperProxy@63355449 2019-07-31 15:40:08 [DEBUG]-[org.apache.ibatis.transaction.jdbc.JdbcTransaction] Closing JDBC Connection [com.mysql.cj.jdbc.ConnectionImpl@2ed0fbae] 2019-07-31 15:40:08 [DEBUG]-[org.apache.ibatis.datasource.pooled.PooledDataSource] Returned connection 785447854 to pool. Process finished with exit code 0 可以看到，程寻运行时，MyBatis给数据库发了多条sql语句，最终通过预定的映射集合，把这些查出来的数据放进去，之后打包组合成一个List&lt;SysRole&gt;对象返回。]]></content>
      <categories>
        <category>MyBatis框架</category>
      </categories>
      <tags>
        <tag>MyBatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MyBatis缓存配置]]></title>
    <url>%2F2019%2F07%2F28%2FMyBatis%E7%BC%93%E5%AD%98%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;使用缓存可以是应用更快的获取数据，避免频繁的数据库交互，尤其是在查询越多、缓存命中率越高的情况下，使用缓存的作用就越明显。MyBatis作为持久层框架，提供了强大的查询缓存特性，可非常方便的配置和使用。&nbsp;&nbsp;&nbsp;&nbsp;MyBatis系统中默认定义了两级缓存：一级缓存和二级缓存。&nbsp;&nbsp;&nbsp;&nbsp;1、默认情况下，一级缓存（SqlSession级别的缓存，也称为本地缓存）是开启的，但是不能控制。&nbsp;&nbsp;&nbsp;&nbsp;2、二级缓存需要手动开启和配置，他是和命名空间绑定的，即二级缓存需要配置在Mepper,xml文件中获配置在Mapper..java接口中&nbsp;&nbsp;&nbsp;&nbsp;3、为了提高扩展性。MyBatis定义了缓存接口Cache。我们可以通过实现Cache接口来自定义二级缓存（或者使用第三方缓存） 一级缓存先通过一个简单的演示看看MyBati一级缓存是如何起作用的。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package test;import com.xust.iot.beans.User;import com.xust.iot.mapper.StudentMapper;import org.apache.ibatis.io.Resources;import org.apache.ibatis.session.SqlSession;import org.apache.ibatis.session.SqlSessionFactory;import org.apache.ibatis.session.SqlSessionFactoryBuilder;import org.apache.log4j.Logger;import org.junit.Before;import org.junit.Test;import java.io.IOException;import java.io.InputStream;import java.util.Date;import java.util.List;public class AppTest &#123;private static SqlSessionFactory sqlSessionFactory;private static Logger log = Logger.getLogger(AppTest.class);@Beforepublic void init() &#123;String resource = "mybatis-config.xml";try &#123; InputStream inputStream = Resources.getResourceAsStream(resource); sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);&#125; catch (IOException e) &#123; e.printStackTrace();&#125;&#125;/*** 测试MyBatis一级缓存的特性*/@Testpublic void test01() &#123;SqlSession session = sqlSessionFactory.openSession(true);try &#123; StudentMapper sm = session.getMapper(StudentMapper.class); List&lt;User&gt; user1 = sm.getUserByName("小明"); if (null != user1 &amp;&amp; user1.size() &gt; 0) &#123; for (User u : user1) &#123; System.out.println(u.toString()); &#125; &#125; System.out.println("第二次查询\"小明\"............"); List&lt;User&gt; user2 = sm.getUserByName("小明"); if (null != user1 &amp;&amp; user1.size() &gt; 0) &#123; for (User u : user1) &#123; System.out.println(u.toString()); &#125; &#125; System.out.println("user1==user?==&gt;" + (user1 == user2));&#125; catch (Exception e) &#123; log.error(e + "---" + new Date());&#125; finally &#123; session.close();&#125;&#125;&#125; 测试结果如下： &nbsp;&nbsp;&nbsp;&nbsp;可以看到，两次查询值MyBatis只给数据库发送了一次SQL语句，但是两次查询的结果都是一样的，而且再往下发现两个List&lt;User&gt;对象竟然是同一个对象，之所以这样就是MyBatis的一级缓存在起作用。&nbsp;&nbsp;&nbsp;&nbsp;在同一个SqlSession中查询是MyBatis会把执行的方法和参数通过算法生成缓存的键值，将键值和查询结果存入PerpetualCache 的 HashMap本地缓存对象中。如果同一个SqlSession中执行的方法和参数完全一致，闹通过算法就会生成相同的键值，当Map缓存对象中已经存在该键值时，就会返回缓存中的对象，而不会再给数据库发sql语句了。&nbsp;&nbsp;&nbsp;&nbsp;但是要注意，下面几种情况发生会使一级缓存会失效： 1. 不同的SqlSession用不同的一级缓存，他们之间的数据不能共享 2. 就算是同一个SqlSession对象，但是如果执行的方法和参数不同也不行 3. 默认情况下，在SqlSession期间执行任何一次增删改操作，一级缓存会被清空 4. 手动清空一级缓存，一级缓存也会失效 下面分别举例说明： 由于MyBatis的一级缓存存在于SqlSession生命周期中，一次不同的SqlSession当然会有不同的一级缓存。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869package test;import com.xust.iot.beans.User;import com.xust.iot.mapper.StudentMapper;import org.apache.ibatis.io.Resources;import org.apache.ibatis.session.SqlSession;import org.apache.ibatis.session.SqlSessionFactory;import org.apache.ibatis.session.SqlSessionFactoryBuilder;import org.apache.log4j.Logger;import org.junit.Before;import org.junit.Test;import java.io.IOException;import java.io.InputStream;import java.util.Date;import java.util.List;public class AppTest &#123;private static SqlSessionFactory sqlSessionFactory;private static Logger log = Logger.getLogger(AppTest.class);@Beforepublic void init() &#123;String resource = "mybatis-config.xml";try &#123; InputStream inputStream = Resources.getResourceAsStream(resource); sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);&#125; catch (IOException e) &#123; e.printStackTrace();&#125;&#125;/*** MyBatis的一级缓存存在于SqlSession生命周期中，在同一个SqlSession中查询是MyBatis会把* 执行的方法和参数通过算法生成缓存的键值，将键值和查询结果存入一个Map中。*/@Testpublic void test02() &#123;//第一个会话SqlSession session = sqlSessionFactory.openSession(true);StudentMapper sm = session.getMapper(StudentMapper.class);List&lt;User&gt; user1 = sm.getUserByName("小明");if (null != user1 &amp;&amp; user1.size() &gt; 0) &#123; for (User u : user1) &#123; System.out.println(u.toString()); &#125;&#125;//第二个会话System.out.println("开启新的会话......");SqlSession session2 = sqlSessionFactory.openSession(true);StudentMapper sm2 = session2.getMapper(StudentMapper.class);List&lt;User&gt; user2 = sm2.getUserByName("小明");if (null != user2 &amp;&amp; user2.size() &gt; 0) &#123; for (User u : user2) &#123; System.out.println(u.toString()); &#125;&#125;session.close();session2.close();&#125;&#125; 测试结果如下： MyBatis的&lt;insert&gt;、&lt;delete&gt;、&lt;update&gt;和&lt;select&gt;标签都中有一个属性：flushCache,在默认情况下，对于增删改操作这个标签默认值是true,也就是每次操作后要清空缓存，而对于&lt;select&gt;操作这个属性默认值是false，也即不刷新缓冲。也就是下面这段代码要说明的： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364package test;import com.xust.iot.beans.User;import com.xust.iot.mapper.StudentMapper;import org.apache.ibatis.io.Resources;import org.apache.ibatis.session.SqlSession;import org.apache.ibatis.session.SqlSessionFactory;import org.apache.ibatis.session.SqlSessionFactoryBuilder;import org.apache.log4j.Logger;import org.junit.Before;import org.junit.Test;import java.io.IOException;import java.io.InputStream;import java.util.Date;import java.util.List;public class AppTest &#123;private static SqlSessionFactory sqlSessionFactory;private static Logger log = Logger.getLogger(AppTest.class);@Beforepublic void init() &#123;String resource = "mybatis-config.xml";try &#123; InputStream inputStream = Resources.getResourceAsStream(resource); sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);&#125; catch (IOException e) &#123; e.printStackTrace();&#125;&#125;@Testpublic void test03() &#123;SqlSession session = sqlSessionFactory.openSession(true);StudentMapper sm = session.getMapper(StudentMapper.class);List&lt;User&gt; user1 = sm.getUserByName("小明");if (null != user1 &amp;&amp; user1.size() &gt; 0) &#123; for (User u : user1) &#123; System.out.println(u.toString()); &#125;&#125;//执行任意一次增删改操作，当前SqlSession的一级缓存立即被清空System.out.println("删除一个用户......");sm.deleteUserById(14);System.out.println("删除完成.......");//由于缓存被清了，因此还得给数据库发sql语句查询StudentMapper sm2 = session.getMapper(StudentMapper.class);List&lt;User&gt; user2 = sm2.getUserByName("小明");if (null != user2 &amp;&amp; user2.size() &gt; 0) &#123; for (User u : user2) &#123; System.out.println(u.toString()); &#125;&#125;session.close();&#125;&#125; 测试结果如下： 下面的这种情况就更直观了，但本质上和上面那种情况是一样的——都是一级缓存被清空了。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package test;import com.xust.iot.beans.User;import com.xust.iot.mapper.StudentMapper;import org.apache.ibatis.io.Resources;import org.apache.ibatis.session.SqlSession;import org.apache.ibatis.session.SqlSessionFactory;import org.apache.ibatis.session.SqlSessionFactoryBuilder;import org.apache.log4j.Logger;import org.junit.Before;import org.junit.Test;import java.io.IOException;import java.io.InputStream;import java.util.Date;import java.util.List;public class AppTest &#123;private static SqlSessionFactory sqlSessionFactory;private static Logger log = Logger.getLogger(AppTest.class);@Beforepublic void init() &#123;String resource = "mybatis-config.xml";try &#123; InputStream inputStream = Resources.getResourceAsStream(resource); sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);&#125; catch (IOException e) &#123; e.printStackTrace();&#125;&#125;@Testpublic void test03() &#123;SqlSession session = sqlSessionFactory.openSession(true);StudentMapper sm = session.getMapper(StudentMapper.class);List&lt;User&gt; user1 = sm.getUserByName("小明");if (null != user1 &amp;&amp; user1.size() &gt; 0) &#123; for (User u : user1) &#123; System.out.println(u.toString()); &#125;&#125;//清除缓存System.out.println("手动清除缓存......");session.clearCache();StudentMapper sm2 = session.getMapper(StudentMapper.class);List&lt;User&gt; user2 = sm2.getUserByName("小明");if (null != user2 &amp;&amp; user2.size() &gt; 0) &#123; for (User u : user2) &#123; System.out.println(u.toString()); &#125;&#125;session.close();&#125;&#125; 测试结果如下： 二级缓存 二级缓存默认也是采用 PerpetualCache，HashMap存储； 二级缓存的存储作用域为 Mapper(确切说是namespace)，即一个Mapper执行了insert、update或delete操作，不影响另外一个Mapper（不同namespace）； 二级缓存可自定义存储实现，如 Ehcache、redis； 二级缓存开启后，需要对应的java Bean实现，并且这个java Bean要实现Serializable接口进行序列化 配置二级缓存&nbsp;&nbsp;&nbsp;&nbsp;二级缓存有两种配置方法，一种是基于Mapper.xml文件来配置；另一种就是基于Mapper.java接口来配置。下面分别来看看如何配置使用MyBatis的二级缓存：&nbsp;&nbsp;&nbsp;&nbsp;首先，无论是通过Mapper.xml文件来配置，还是通过Mapper.java接口来配置，都需要在mybatis-config.xml文件中通过settings设置显式地开启二级缓存： 123456&lt;!--一些有关于mybatis运行行为的设置--&gt;&lt;settings&gt; &lt;!--开启二级缓存--&gt; &lt;setting name="cacheEnabled" value="true"/&gt; &lt;!--其他的设置--&gt;&lt;/settings&gt; 在Mapper.xml中配置二级缓存在xml文件中配置的方法很简单，在保证二级缓存的全局配置开启的情况下，在UserMapper.xml中只需要添加&lt;cache&gt;&lt;/cache&gt;即可。 123456789101112131415161718192021222324&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE mapperPUBLIC "-//mybatis.org//DTD Mapper 3.0//EN""http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;mapper namespace="com.xust.iot.mapper.StudentMapper"&gt;&lt;!--在UserMapper中开启二级缓存--&gt;&lt;cache&gt;&lt;/cache&gt;&lt;select id="getUserByName" parameterType="string" resultType="user"&gt;select * from user&lt;where&gt; name=#&#123;username&#125;&lt;/where&gt;&lt;/select&gt;&lt;delete id="deleteUserById" parameterType="integer" &gt;delete from user&lt;where&gt; id=#&#123;userId&#125;&lt;/where&gt;&lt;/delete&gt;&lt;/mapper&gt; &lt;cacha&gt;标签的属性： eviction：缓存回收策略：flushInterval：缓存多长时间清空一次，默认不清空，单位毫秒 ms&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;LRU——最少使用的，移除最长时间不适用的对象；&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;FIFO——先进先出&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;WEAK——弱引用，更积极的移除基于垃圾回收器状态和弱引用规则的对象&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;SOFT——软引用，更积极的移除基于垃圾回收器状态和弱引用规则的对象 flushInterval：缓存多久清空一次，默认不清空，时间毫秒 ms readOnly：缓存是否只读 size：缓存觉存放元素个数，默认1024 type：自定义缓存的全类名 在Mapper接口中配置二级缓存在接口中配置主要是借助@CacheNamespace这个注解，但是要注意：配置文件和接口注释是不能够配合使用的。只能通过全注解的方式或者全部通过xml配置文件的方式使用。也就是说你用了配置文件就不要用这种方式，用了接口配置的方式就别用xml配置文件的方式。如下： 1234567891011121314151617181920212223242526package com.xust.iot.mapper;import com.xust.iot.beans.User;import org.apache.ibatis.annotations.*;import java.util.List;@CacheNamespacepublic interface StudentMapper &#123; /** * 查询所有姓名为name的用户 * @param name * @return */ @Select("select * from user where name=#&#123;username&#125;") @Options(useCache = true) public List&lt;User&gt; getUserByName(@Param("username") String name); /** * 删除id=userId的用户 * @param id */ @Delete("delete from user where id=#&#123;userId&#125;") public void deleteUserById(@Param("userId") Integer id);&#125; 并在mybatis-config.xml中重新配置Mapper映射文件： 1234&lt;mappers&gt; &lt;!-- &lt;mapper resource="mapper/StudentMapper.xml"&gt;&lt;/mapper&gt;--&gt; &lt;mapper class="com.xust.iot.mapper.StudentMapper"/&gt; &lt;/mappers&gt; 使用二级缓存：&nbsp;&nbsp;&nbsp;&nbsp;配置Mybatis二级缓存的方法有两种，只要配置好,二级缓存就可以工作了。但是在使用前需要注意的是，由于MyBatis使用SerializedCache序列化缓存来实现可读写缓存类，并通过序列化和反序列化来保证通过缓存获取数据时，得到的是一个新的实例。因此，如果配置了只读缓存，MyBatis就会使用Map来存储缓存值。而这个缓存类要求所有被序列化的对象必须实现Serializable接口 。因此我们的java Bean需要实现Serializable接口。 12345678910package com.xust.iot.beans;import java.io.Serializable;public class User implements Serializable &#123; private static final long serialVersionUID = -8963153814502574628L; //其他属性&#125; 做好所有准备后，编写一个测试类来看看二级缓存的效果： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package test;import com.xust.iot.beans.User;import com.xust.iot.mapper.StudentMapper;import org.apache.ibatis.io.Resources;import org.apache.ibatis.session.SqlSession;import org.apache.ibatis.session.SqlSessionFactory;import org.apache.ibatis.session.SqlSessionFactoryBuilder;import org.apache.log4j.Logger;import org.junit.Before;import org.junit.Test;import java.io.IOException;import java.io.InputStream;import java.util.Date;import java.util.List;public class AppTest &#123; private static SqlSessionFactory sqlSessionFactory; private static Logger log = Logger.getLogger(AppTest.class); @Before public void init() &#123; String resource = "mybatis-config.xml"; try &#123; InputStream inputStream = Resources.getResourceAsStream(resource); sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; @Test public void testL2Cache() &#123; //第一个会话 SqlSession session = sqlSessionFactory.openSession(true); StudentMapper sm = session.getMapper(StudentMapper.class); List&lt;User&gt; user1 = sm.getUserByName("小明"); if (null != user1 &amp;&amp; user1.size() &gt; 0) &#123; for (User u : user1) &#123; System.out.println(u.toString()); &#125; &#125; session.close(); //第二个会话 System.out.println("开启新的会话......"); SqlSession session2 = sqlSessionFactory.openSession(true); StudentMapper sm2 = session2.getMapper(StudentMapper.class); List&lt;User&gt; user2 = sm2.getUserByName("小明"); if (null != user2 &amp;&amp; user2.size() &gt; 0) &#123; for (User u : user2) &#123; System.out.println(u.toString()); &#125; &#125; session2.close(); &#125;&#125; 测试结果： MyBatis缓存的执行逻辑&nbsp;&nbsp;&nbsp;&nbsp;1.当一个SqlSession第一次执行一次select后，查到数据后会首先把查询到的结果保存到一级缓存中&nbsp;&nbsp;&nbsp;&nbsp;2.当该SqlSession被关闭或者提交后，保存在一级缓存中的数据会转移到二级缓存中（前提是正确开启并配置了二级缓存）&nbsp;&nbsp;&nbsp;&nbsp;3.当另一个SqlSession第一次执行同样select时，首先会在二级缓存中找，如果没找到，就去自己的一级缓存中找，找到了就返回，如果没找到就去数据库查，MyBatis就是通过这样的机制从而减少了数据库压力提高了性能。MyBatis的执行流程总结起来就是：二级缓存–&gt;一级缓存–&gt;数据库 注意事项：&nbsp;&nbsp;&nbsp;&nbsp;1.如果SqlSession执行了DML操作（insert、update、delete），并commit了，那么mybatis就会清空当前mapper缓存中的所有缓存数据，这样可以保证缓存中的存的数据永远和数据库中一致，避免出现脏读&nbsp;&nbsp;&nbsp;&nbsp;2.mybatis的缓存是基于[namespace:sql语句:参数]来进行缓存的，意思就是，SqlSession的HashMap存储缓存数据时，是使用[namespace:sql:参数]作为key，查询返回的语句作为value保存的。]]></content>
      <categories>
        <category>MyBatis框架</category>
      </categories>
      <tags>
        <tag>MyBatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis XML映射文件的配置]]></title>
    <url>%2F2019%2F07%2F27%2FMybatis%20XML%E6%98%A0%E5%B0%84%E6%96%87%E4%BB%B6%E7%9A%84%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[MyBatis中的SQL 映射文件只有很少的几个顶级元素（按照它们应该被定义的顺序）： cache – 给定命名空间的缓存配置。cache-ref – 其他命名空间缓存配置的引用。resultMap – 是最复杂也是最强大的元素，用来描述如何从数据库结果集中来加载对象。sql – 可被其他语句引用的可重用语句块。insert – 映射插入语句update – 映射更新语句delete – 映射删除语句select – 映射查询语句 select元素select元素就是用来查询的，在select里嵌入SQL select查询语句,就象下边这样： 123&lt;select id="get" resultType="Employee" parameterType="int"&gt; select * from employee where id=#&#123;id&#125;;&lt;/select&gt; 其中 select元素中的id属性是必须的，它的值是对应Mapper接口中的一个方法，当调用这个接口就是调用这个sql。关于select元素常用的属性具体如下： 属性 描述 id 在命名空间中唯一的标识符，可以被用来引用这条语句。这个是必须的属性 parameterType 将会传入这条语句的参数类的完全限定名或别名。这个属性是可选的，因为 MyBatis 可以通过 TypeHandler 推断出具体传入语句的参数，默认值为 unset。 resultType 返回的期望类型的类的完全限定名或别名。这个属性是可选的 resultMap 返回值类型是是个map集合，可用于多表联查后的结果MyBatis会封装成一个map返回，这个属性是可选的 flushCache 将其设置为 true，任何时候只要语句被调用，都会导致本地缓存和二级缓存都会被清空，默认值：false。这个属性是可选的 useCache 将其设置为 true，将会导致本条语句的结果被二级缓存，默认值：对 select 元素为 true。这个属性是可选的 timeout 这个设置是在抛出异常之前，驱动程序等待数据库返回请求结果的秒数。默认值为 unset（依赖驱动）。这个属性是可选的 insert update delete&nbsp;&nbsp;&nbsp;&nbsp;insert update delete元素分别对应SQL语句中的insert、update、delete，分别实现对数据库记录的插入、更新和删除。他们可以有的属性值如下： 属性 描述 id 在命名空间中唯一的标识符，可以被用来引用这条语句。这个是必须的属性 parameterType 将会传入这条语句的参数类的完全限定名或别名。这个属性是可选的，因为 MyBatis 可以通过 TypeHandler 推断出具体传入语句的参数，默认值为 unset。 useGeneratedKeys （仅对 insert 和 update 有用）这会令 MyBatis 使用 JDBC 的 getGeneratedKeys 方法来取出由数据库内部生成的主键，默认值为false，这个属性是可选的。 keyProperty （仅对 insert 和 update 有用）唯一标记一个属性，MyBatis 会通过 getGeneratedKeys 的返回值或者通过 insert 语句的 selectKey 子元素设置它的键值，他和useGeneratedKeys配合起来才能工作 flushCache 将其设置为 true，任何时候只要语句被调用，都会导致本地缓存和二级缓存都会被清空，默认值：true。这个属性是可选的 useCache 将其设置为 true，将会导致本条语句的结果被二级缓存，默认值：对增删改元素为false。这个属性是可选的 timeout 这个设置是在抛出异常之前，驱动程序等待数据库返回请求结果的秒数。默认值为 unset（依赖驱动）。这个属性是可选的 keyColumn （仅对 insert 和 update 有用）通过生成的键值设置表中的列名，这个设置仅在某些数据库（像 PostgreSQL）是必须的，当主键列不是表中的第一列的时候需要设置。如果希望得到多个生成的列，也可以是逗号分隔的属性名称列表。 Result MapsresultMap 元素是 MyBatis 中最重要最强大的元素。 ResultMap 的设计就是简单语句不需要明确的结果映射,而很多复杂语句确实需要描述它们的关系。 简单映射例如下面这个例子：： 123&lt;select id="getById" resultType="Employee" paramaterType="int"&gt; select * from employee where id=#&#123;id&#125;&lt;/select&gt; JavaBean是这样的： 1234567891011121314151617181920212223242526package com.xzy.bean;public class Employee &#123; /** * JavaBean基本类型最好使用他的包装类型！！！ */ private Long id; private String empId; private String empName; private Integer empAge; private String empSex; //省略getter、setter.... @Override public String toString() &#123; return "Employee&#123;" + "id=" + id + ", empId='" + empId + '\'' + ", empName='" + empName + '\'' + ", empAge=" + empAge + ", empSex='" + empSex + '\'' + '&#125;'; &#125;&#125; Mybatis会将基于 JavaBean 的规范,这些 在 select 语句中会精确匹配到列名。这样一个语句简单作用于所有列被自动映射到 HashMap 的键上,这由 resultType 属性 指定。也就是说，对于resultType MyBatis会结果封装一个map返回。 高级映射有时候我们避免不了多表联查，这样带来的问题是返回的结果类型中的一个字段在resultType中的不存在，这就会造成问题。MyBatis中使用resultMap来解决这个问题。resultMap 元素有很多子元素和一个值得讨论的结构。 下面是 resultMap 标签中可以使用的属性如下： resultMap:constructor - 类在实例化时,用来注入结果到构造方法中idArg - ID 参数;标记结果作为 ID 可以帮助提高整体效能arg - 注入到构造方法的一个普通结果id – 一个 ID 结果;标记结果作为 ID 可以帮助提高整体效能result – 注入到字段或 JavaBean 属性的普通结果association – 一个复杂的类型关联;许多结果将包成这种类型嵌入结果映射 – 结果映射自身的关联,或者参考一个collection – 复杂类型的集嵌入结果映射 – 结果映射自身的集,或者参考一个discriminator – 使用结果值来决定使用哪个结果映射case – 基于某些值的结果映射嵌入结果映射 – 这种情形结果也映射它本身,因此可以包含很多相 同的元素,或者它可以参照一个外部的结果映射。 描述描述 id 当前命名空间中的一个唯一标识，用于标识一个result map. type 类的全限定名, 或者一个类型别名 autoMapping 如果设置这个属性，MyBatis将会为这个ResultMap开启或者关闭自动映射。这个属性会覆盖全局的属性autoMappingBehavior。默认值为：unset。 下面是一个例子： 12345678910111213141516171819202122&lt;!--StudentMapper.xml--&gt;&lt;?xml version="1.0" encoding="UTF-8"?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;mapper namespace="com.xzy.mapper.StudentMapper"&gt; &lt;!--第一种多表联查的映射方式--&gt; &lt;resultMap type="student" id="queryCName"&gt; &lt;id property="id" column="id"/&gt; &lt;result property="sid" column="sid"/&gt; &lt;result property="sname" column="sname"/&gt; &lt;result property="majorIn" column="major_in"/&gt; &lt;result property="sclass" column="sclass"/&gt; &lt;result property="course.cname" column="cname"/&gt; &lt;/resultMap&gt; &lt;!--查询某个同学所选的课程--&gt; &lt;select id="getAll" parameterType="string" resultMap="queryCName"&gt; select student.*,course.cname from student,course where student.cid=course.cid and student.sname=#&#123;sname&#125; &lt;/select&gt;&lt;/mapper&gt; 学生实体：Student.java 123456789101112131415161718192021222324252627//JavaBean Studentpackage com.xzy.bean;public class Student &#123; private Long id; private String sid; private String sname; private String majorIn; private String sclass; private Course course; //getter、setter... @Override public String toString() &#123; return "Student&#123;" + "id=" + id + ", sid='" + sid + '\'' + ", sname='" + sname + '\'' + ", majorIn='" + majorIn + '\'' + ", sclass='" + sclass + '\'' + ", cname=" + course.getCname() + '&#125;'; &#125;&#125; 课程实体:Course.java 1234567891011121314151617181920//JavaBean Coursepackage com.xzy.bean;public class Course &#123; private Long id; private String cid; private String cname; private Student student; //省略getter、setter..... @Override public String toString() &#123; return "Course&#123;" + "id=" + id + ", cid='" + cid + '\'' + ", cname='" + cname + '\'' + '&#125;'; &#125;&#125; 测试类AppTest.java 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960package com.xzy;import com.xzy.bean.Course;import com.xzy.bean.Student;import com.xzy.mapper.CourseMapper;import com.xzy.mapper.StudentMapper;import org.apache.ibatis.io.Resources;import org.apache.ibatis.session.SqlSession;import org.apache.ibatis.session.SqlSessionFactory;import org.apache.ibatis.session.SqlSessionFactoryBuilder;import org.apache.log4j.Logger;import org.junit.Before;import org.junit.Test;import java.io.IOException;import java.io.InputStream;import java.util.Date;import java.util.List;import java.util.Scanner;/** * Unit test for simple App. */public class AppTest &#123; private static Logger log = Logger.getLogger(AppTest.class); private static SqlSessionFactory sqlSessionFactory; @Before public void initLoad() throws IOException &#123; String resource = "mybatis-config.xml"; InputStream inputStream = Resources.getResourceAsStream(resource); sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); &#125; @Test public void selectAll() &#123; SqlSession session = sqlSessionFactory.openSession(true); try&#123; StudentMapper sm=session.getMapper(StudentMapper.class); List&lt;Student&gt; lists= sm.getAll("OKOK2"); if(null!=lists&amp;&amp;lists.size()&gt;0) &#123; System.out.println("OKOK2同学选的课："); for (Student list : lists) &#123; System.out.println(list.toString()); &#125; System.out.println("OK..."); &#125;else&#123; System.out.println("没有这个人或该同学没有选课...."); &#125; &#125;catch (Exception e)&#123; System.out.println("查询失败。。。。"); &#125;finally&#123; session.close(); &#125; &#125;&#125; 运行结果： cache 和cache-ref 的用法参考另一篇笔记MyBatis缓存配置]]></content>
      <categories>
        <category>MyBatis框架</category>
      </categories>
      <tags>
        <tag>MyBatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis 动态SQL]]></title>
    <url>%2F2019%2F07%2F26%2FMybatis%E5%8A%A8%E6%80%81SQL%2F</url>
    <content type="text"><![CDATA[&nbsp;&nbsp;&nbsp;&nbsp;MyBatis 的强大特性之一便是它的动态 SQL。动态 SQL 元素和使用 JSTL 或其他类似基于 XML 的文本处理器相似。在 MyBatis 之前的版本中,有很多的元素需要来了解。MyBatis 3 大大提升了它们,现在用不到原先一半的元素就可以了。MyBatis 采用功能强大的基于 OGNL 的表达式来消除其他元素。主要的有以下几个： if choose (when, otherwise) trim (where, set) liforeach if使用if可以用条件的筛选SQL语句分支，只有条件满足的时候才会执行。实例： 12345678&lt;select id="get" resultType="Employee"&gt; select * from employee &lt;where&gt; &lt;if test="empSex!=null"&gt;and emp_sex=#&#123;empSex&#125; &lt;/if&gt; &lt;if test="empAge!=null"&gt;and emp_age=#&#123;empAge&#125;&lt;/if&gt; &lt;if test="empName!=null"&gt;or emp_name=#&#123;empName&#125;&lt;/if&gt; &lt;/where&gt;&lt;/select&gt; 这条sql语句就会动态的根据传入的参数值来查询，比如当只传了empAge=23，其他都为空，那么生成的sql语句就是：select * from employee where emp_age=23，where元素是很强大的，他会自动帮我们把sql中多余的and或or去掉 choose、when、otherwiseMyBatis 提供了 choose 元素，它有点像 Java 中的 switch 语句。实例; 12345678910&lt;!--下面的条件分支中只会有一条被执行--&gt;&lt;select id="getBycondition" resultType="Employee"&gt;select * from employee where&lt;choose&gt; &lt;when test="empId!=null"&gt;emp_id=#&#123;empId&#125;&lt;/when&gt; &lt;when test="empAge!=null"&gt;emp_age=#&#123;empAge&#125;&lt;/when&gt; &lt;when test="empName!=null"&gt;emp_name=#&#123;empName&#125;&lt;/when&gt; &lt;otherwise&gt;emp_sex='女'&lt;/otherwise&gt;&lt;/choose&gt;&lt;/select&gt; java代码这么写： 123456789101112131415161718192021222324252627282930313233public class AppTest&#123;SqlSessionFactory sqlSessionFactory;private static final Logger log=Logger.getLogger(AppTest.class);@Beforepublic void createSqlSession() throws IOException &#123;String resource="mybatis-config.xml";try (InputStream inputStream = Resources.getResourceAsStream(resource)) &#123; sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream);&#125;&#125;@Testpublic void get2()&#123;SqlSession session=sqlSessionFactory.openSession(true);try&#123; Employee employee=new Employee(); employee.setEmpAge(34); employee.setEmpId("3343"); EmployeeMapper mapper=session.getMapper(EmployeeMapper.class); List&lt;Employee&gt;lists=mapper.getBycondition(employee); for(Employee list:lists)&#123; System.out.println(list.toString()); &#125; log.info(mapper);&#125;catch (Exception e)&#123; System.out.println("查询数据异常..."+e); session.rollback();&#125;finally &#123; session.close();&#125;&#125;&#125; 可以看到，即使在条件中给了两个不为空的，但是由于EmpId在最前面，因此首先匹配上后就不在往下找了，和switch很像。最终的运行结果： trim, where看看下面的这条这种情况： 123456&lt;select id="getEmp" resultType="Employee"&gt; select * from employee where &lt;if test="empAge!=null"&gt;emp_age=#&#123;empAge&#125;&lt;/if&gt; &lt;if test="empAge!=null"&gt; and emp_age=#&#123;empAge&#125;&lt;/if&gt; &lt;if test="empAge!=null"&gt;and emp_age=#&#123;empAge&#125;&lt;/if&gt;&lt;/selsct&gt; 如果三个分之没有一条分支匹配上，那么最终的sql语句会变成： 1select * from employee where 这显然是会导致查询失败的。如果仅仅第二条或第三条匹配，那么sql语句会变成这样: 123select * from employee where and emp_age=#&#123;empAge&#125;/*或者是下面的样子*/select * from employee where and emp_age=#&#123;empAge&#125; 不论是那种情况，都会导致由于sql语句错误而查询失败。MyBatis 有一个简单的处理，这在90%的情况下都会有用。那就是使用where元素，where 元素知道只有在一个以上的if条件有值的情况下才去插入“WHERE”子句。而且，若最后的内容是“AND”或“OR”开头的，where 元素也知道如何将他们去除。例如： 12345678&lt;select id="getEmp" resultType="Employee"&gt; select * from employee &lt;where&gt; &lt;if test="empAge!=null"&gt;emp_age=#&#123;empAge&#125;&lt;/if&gt; &lt;if test="empAge!=null"&gt; and emp_age=#&#123;empAge&#125;&lt;/if&gt; &lt;if test="empAge!=null"&gt;and emp_age=#&#123;empAge&#125;&lt;/if&gt; &lt;/where&gt;&lt;/selsct&gt; &nbsp;&nbsp;&nbsp;&nbsp;这样即使三条语句都不满足条件，那么最终的sql语句是：select * from employee，也不会影响正常的查询。 &nbsp;&nbsp;&nbsp;&nbsp;如果 where 元素没有按正常套路出牌，我们还是可以通过自定义 trim 元素来定制我们想要的功能。比如，和 where 元素等价的自定义 trim 元素为： 123&lt;trim prefix="WHERE" prefixOverrides="AND |OR "&gt; ... &lt;/trim&gt; &nbsp;&nbsp;&nbsp;&nbsp;prefixOverrides 属性会忽略通过管道分隔的文本序列（注意此例中的空格也是必要的）。它带来的结果就是所有在 prefixOverrides 属性中指定的内容将被移除，并且插入 prefix 属性中指定的内容。类似的用于动态更新语句的解决方案叫做 set。set 元素可以被用于动态包含需要更新的列，而舍去其他的. set&nbsp;&nbsp;&nbsp;&nbsp;set用于动态更新语句的解决方案叫做 set。set 元素可以被用于动态包含需要更新的列，而舍去其他的.示例： 123456789101112131415161718&lt;update id="updateByConditon"&gt;update employee&lt;set&gt; &lt;if test="param1.empId!=null"&gt; emp_id=#&#123;param1.empId&#125;, &lt;/if&gt; &lt;if test="param1.empName!=null"&gt; emp_name=#&#123;param1.empName&#125;, &lt;/if&gt; &lt;if test="param1.empSex!=null"&gt; emp_sex=#&#123;param1.empSex&#125;, &lt;/if&gt; &lt;if test="param1.empAge!=null"&gt; emp_age=#&#123;param1.empAge&#125; &lt;/if&gt;&lt;/set&gt;where emp_age=#&#123;param2&#125;&lt;/update&gt; java代码： 123456789101112131415 @Testpublic void updateByConditon()&#123; SqlSession session=sqlSessionFactory.openSession(true); try&#123; EmployeeMapper em=session.getMapper(EmployeeMapper.class); List&lt;Employee&gt; lists=em.getAll(); for(Employee list:lists)&#123; list.setEmpName("蔡徐坤"); em.updateByConditon(list,22); &#125; log.info(em); &#125;finally &#123; session.close(); &#125;&#125; &nbsp;&nbsp;&nbsp;&nbsp;set 元素会动态前置 SET 关键字，同时也会消除无关的逗号，因为用了条件语句之后很可能就会在生成的赋值语句的后面留下这些逗号 foreach&nbsp;&nbsp;&nbsp;&nbsp;动态 SQL 的另外一个常用的必要操作是需要对一个集合进行遍历，通常是在构建 in 条件语句的时候: 1234567&lt;select id="selectPostIn" resultType="Employee"&gt; SELECT * FROM POST P WHERE ID in &lt;foreach collection="lists" item="list" open="(" separator="," close=")"&gt; #&#123;list&#125; &lt;/foreach&gt;&lt;/select&gt; foreach标签中可以使用的属性如下：1. collection ：collection属性的值有三个分别是list、array、map三种，分别对应的java类型为：List、数组、map集合2. item ： 表示在迭代过程中每一个元素的别名3. index ：遍历过程的索引值4. open ：前缀5. close ：后缀6. separator ：分隔符，表示迭代时每个元素之间以什么分隔7. foreach标签主要用于构建in条件，他可以在sql中对集合进行迭代。]]></content>
      <categories>
        <category>MyBatis框架</category>
      </categories>
      <tags>
        <tag>MyBatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Mybatis 全局XML文件的配置]]></title>
    <url>%2F2019%2F07%2F26%2FMybatis%E5%85%A8%E5%B1%80XML%E6%96%87%E4%BB%B6%E7%9A%84%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[properties properties提供了一个通过外部配置文件(例如数据库配置文件)来动态配置环境的方法。以动态配置数据库为例： 数据库配置文件jdbc.properties的详细配置如下： 1234driver=com.mysql.cj.jdbc.Driverurl=jdbc:mysql://127.0.0.1:3306/xust?autoReconnect=true&amp;useSSL=false&amp;allowPublicKeyRetrieval=true&amp;set global time_zone=&apos;+8:00&apos; username=rootpassword=95162437 那么我们可以在mybatis-config.xml中这么写： 1234567891011121314151617181920212223242526272829&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;configuration&gt; &lt;!--配置外部数据库文件的位置，把它加载进来--&gt; &lt;properties resource="jdbc.properties"&gt; &lt;/properties&gt; &lt;environments default="development"&gt; &lt;environment id="development"&gt; &lt;transactionManager type="JDBC"/&gt; &lt;dataSource type="POOLED"&gt; &lt;!--通过在外部动态配置的方式来配置--&gt; &lt;!--需要注意的是value后面的值如果没有自定义，必须和外部配置文件中的名字一致--&gt; &lt;property name="driver" value="$&#123;driver&#125;"/&gt; &lt;property name="url" value="$&#123;url&#125;"/&gt; &lt;property name="username" value="$&#123;username&#125;"/&gt; &lt;property name="password" value="$&#123;password&#125;"/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;mappers&gt; &lt;mapper resource="mapper/StudentMapper.xml"/&gt; &lt;/mappers&gt;&lt;/configuration&gt; settingssetting可以调整MyBatis的一些分长重要的配置，它们会改变 MyBatis 的运行时的行为，具体都有哪些配置可以设置可以参考官网，这里不再赘述，这里说几个常用的： 设置参数 描述 有效值 默认值 cacheEnabled 该配置影响的所有映射器中配置的缓存的全局开关。 true | false true lazyLoadingEnabled 延迟加载的全局开关。当开启时，所有关联对象都会延迟加载。 特定关联关系中可通过设置fetchType属性来覆盖该项的开关状态。 true | false false mapUnderscoreToCamelCase 是否开启自动驼峰命名规则（camel case）映射，即从经典数据库列名 A_COLUMN 到经典 Java 属性名 aColumn 的类似映射。 true | false false logImpl 指定 MyBatis 所用日志的具体实现，未指定时将自动查找。 SLF4J | LOG4J | LOG4J2 | JDK_LOGGING | COMMONS_LOGGING | STDOUT_LOGGING | NO_LOGGING Not set logPrefix 指定 MyBatis 增加到日志名称的前缀。 Any String Not set L2Dwidget.init({"pluginRootPath":"live2dw/","pluginJsPath":"lib/","pluginModelPath":"assets/","tagMode":false,"model":{"jsonPath":"/live2dw/assets/wanko.model.json"},"display":{"position":"left","width":150,"height":300},"mobile":{"show":false},"log":false});!function(e){var r=Array.prototype.slice.call(document.querySelectorAll("img[data-original]"));function t(){for(var c=0;c]]></content>
      <categories>
        <category>MyBatis框架</category>
      </categories>
      <tags>
        <tag>MyBatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[认识MyBatis]]></title>
    <url>%2F2019%2F07%2F25%2F%E8%AE%A4%E8%AF%86Mybatis%2F</url>
    <content type="text"><![CDATA[什么是MyBatis?MyBatis 是一款优秀的java持久层框架，它支持定制化 SQL、存储过程以及高级映射。MyBatis 避免了几乎所有的 JDBC 代码和手动设置参数以及获取结果集。MyBatis 可以使用简单的 XML 或注解来配置和映射原生类型、接口和 Java 的 POJO（Plain Old Java Objects，普通老式 Java 对象）为数据库中的记录。 MyBatis的历史原是Apache的一个开源项目iBatis, 2010年6月这个项目由Apache Software Foundation 迁移到了Google Code，随着开发团队转投Google Code旗下， iBatis3.x正式更名为MyBatis ，代码于2013年11月迁移到Github（下载地址见后）。iBatis一词来源于“internet”和“abatis”的组合，是一个基于Java的持久层框架。 iBatis提供的持久层框架包括SQL Maps和Data Access Objects（DAO） 为什么要使用MyBatis? MyBatis是一个半自动化的持久化层框架。 JDBC的不足： -SQL夹在Java代码块里，耦合度高导致硬编码内伤 -维护不易且实际开发需求中sql是有变化，频繁修改的情况多见 Hibernate和JPA -长难复杂SQL，对于Hibernate而言处理也不容易 -内部自动生产的SQL，不容易做特殊优化。 -基于全映射的全自动框架，大量字段的POJO进行部分映射时比较困难。导致数据库性能下降。 对开发人员而言，核心sql还是需要自己优化 sql和java编码分开，功能边界清晰，一个专注业务、一个专注数据。 去哪里找MyBatis?MyBatis：https://github.com/mybatis/mybatis-3 简单的配置让MyBatis跑起来创建Maven项目在IDEA中打开【File】->【New】->【New Project】,然后选择【Maven】，创建一个【webapp】工程，如图所示 填写【GroupId】和【ArtifactId】,填好后点击【Next】 完成上面的操作后，等待片刻，一个基于Maven的基本结构就创建完成了，得到的Maven项目的目录结构如下图： 打开Mavne项目的pom.xml配置文件，向文件中添加MyBatis依赖、数据库JDBC驱动和Log4j等依赖 1234567891011121314151617181920212223242526272829&lt;dependency&gt; &lt;groupId&gt;junit&lt;/groupId&gt; &lt;artifactId&gt;junit&lt;/artifactId&gt; &lt;version&gt;4.11&lt;/version&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/org.mybatis/mybatis --&gt;&lt;!--mybatis的依赖包--&gt;&lt;dependency&gt; &lt;groupId&gt;org.mybatis&lt;/groupId&gt; &lt;artifactId&gt;mybatis&lt;/artifactId&gt; &lt;version&gt;3.5.2&lt;/version&gt;&lt;/dependency&gt;&lt;!-- https://mvnrepository.com/artifact/mysql/mysql-connector-java --&gt;&lt;!--数据库驱动的依赖包--&gt;&lt;dependency&gt; &lt;groupId&gt;mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-java&lt;/artifactId&gt; &lt;version&gt;8.0.11&lt;/version&gt; &lt;/dependency&gt;&lt;!--日志记录--&gt;&lt;dependency&gt; &lt;groupId&gt;log4j&lt;/groupId&gt; &lt;artifactId&gt;log4j&lt;/artifactId&gt; &lt;version&gt;1.2.17&lt;/version&gt;&lt;/dependency&gt; 完成以上操作后，MyBatis的基本开发环境就已经搭建好了，接下来我们开始实现衣蛾简单的查询功能。 准备数据库创建Student表 123456create table student( sid varchar(255) primary key not null, sname varchar(255) not null, major_in varchar(255), sclass varchar(255) ); 创建实体类和Mapper文件在【main】下新建一个文件夹【java】,并标记为【Source Root】，然后在src/main/java下新建一个基础包com.xzy,在这个包下在创建一个beans包，在这个包中创建一个实体类Student,代码如下： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859package com.xzy.beans;import java.io.Serializable;public class Student implements Serializable &#123; private String sid; private String sname; private String majorIn; private String sclass; public Student()&#123; &#125; public String getSid() &#123; return sid; &#125; public void setSid(String sid) &#123; this.sid = sid; &#125; public String getSname() &#123; return sname; &#125; public void setSname(String sname) &#123; this.sname = sname; &#125; public String getMajorIn() &#123; return majorIn; &#125; public void setMajorIn(String majorIn) &#123; this.majorIn = majorIn; &#125; public String getSclass() &#123; return sclass; &#125; public void setSclass(String sclass) &#123; this.sclass = sclass; &#125; @Override public String toString() &#123; return "Student&#123;" + "sid='" + sid + '\'' + ", sname='" + sname + '\'' + ", major_in='" + majorIn + '\'' + ", sclass='" + sclass + '\'' + '&#125;'; &#125;&#125; 再在【com.xzy】包下新建一个包【dao.mapper】,在里面新建一个接口StudentMapper 1234567891011package com.xzy.dao.mapper;import com.xzy.beans.Student;import java.util.List;public interface StudentMapper &#123; public List&lt;Student&gt; getAll();&#125; 在【main】下新建一个文件夹【resoources】,并标记为【Resources Root】,然后在src/main/resources下创建目录【mapper】,在mapper目录中创建StudentMapper.xml文件，添加如下内容： 12345678910&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE mapper PUBLIC "-//mybatis.org//DTD Mapper 3.0//EN" "http://mybatis.org/dtd/mybatis-3-mapper.dtd"&gt;&lt;mapper namespace="com.xzy.dao.mapper.StudentMapper"&gt; &lt;!--查询学生表中的所有学生--&gt; &lt;select id="getAll" resultType="com.xzy.beans.Student"&gt; select * from student &lt;/select&gt;&lt;/mapper&gt; 配置MyBatisMyBatis有多种配置方式，这里使用最基础最常用的XML配置方式。首先在【src/main/resources】下创建【MyBatis-config.xml】文件，输入如下内容： 1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?xml version="1.0" encoding="UTF-8" ?&gt;&lt;!DOCTYPE configuration PUBLIC "-//mybatis.org//DTD Config 3.0//EN" "http://mybatis.org/dtd/mybatis-3-config.dtd"&gt;&lt;configuration&gt; &lt;properties resource="jdbc.properties"&gt; &lt;/properties&gt; &lt;!--一些有关于mybatis运行是行为的设置--&gt; &lt;settings&gt; &lt;setting name="cacheEnabled" value="true"/&gt; &lt;setting name="lazyLoadingEnabled" value="true"/&gt; &lt;setting name="multipleResultSetsEnabled" value="true"/&gt; &lt;setting name="useColumnLabel" value="true"/&gt; &lt;setting name="useGeneratedKeys" value="false"/&gt; &lt;setting name="autoMappingBehavior" value="PARTIAL"/&gt; &lt;setting name="autoMappingUnknownColumnBehavior" value="WARNING"/&gt; &lt;setting name="defaultExecutorType" value="SIMPLE"/&gt; &lt;setting name="defaultStatementTimeout" value="25"/&gt; &lt;setting name="defaultFetchSize" value="100"/&gt; &lt;setting name="safeRowBoundsEnabled" value="false"/&gt; &lt;setting name="mapUnderscoreToCamelCase" value="true"/&gt; &lt;!--设置数据库字段的下换线自动映射到java的驼峰模式--&gt; &lt;setting name="localCacheScope" value="SESSION"/&gt; &lt;setting name="jdbcTypeForNull" value="OTHER"/&gt; &lt;setting name="lazyLoadTriggerMethods" value="equals,clone,hashCode,toString"/&gt; &lt;/settings&gt; &lt;!--配置数据库连接，可以配置多个数据库--&gt; &lt;environments default="development"&gt; &lt;environment id="development"&gt; &lt;transactionManager type="JDBC"/&gt; &lt;dataSource type="POOLED"&gt; &lt;!--通过在外部动态配置的方式来配置--&gt; &lt;property name="driver" value="$&#123;driver&#125;"/&gt; &lt;property name="url" value="$&#123;url&#125;"/&gt; &lt;property name="username" value="$&#123;username&#125;"/&gt; &lt;property name="password" value="$&#123;password&#125;"/&gt; &lt;/dataSource&gt; &lt;/environment&gt; &lt;/environments&gt; &lt;mappers&gt; &lt;mapper resource="mapper/StudentMapper.xml"/&gt; &lt;/mappers&gt;&lt;/configuration&gt; 上面的配置文件中需要一个jdbbc.properties的配置文件，同样在【src/main/resources】下新建jdbc,properties文件 ，然后输入如下内容： 1234driver=com.mysql.cj.jdbc.Driverurl=jdbc:mysql://localhost:3306/xust?autoReconnect=true&amp;useSSL=false&amp;allowPublicKeyRetrieval=true&amp;set global time_zone='+8:00' username=rootpassword=123456 配置Log4j一遍查看MyBatis操作数据库的过程在src/main/resources中添加log4j.properties配置文件，输入一下内容： 123456789101112131415161718192021222324### set log levels ### log4j.rootLogger = DEBUG , console , debug , error ### console ### log4j.appender.console = org.apache.log4j.ConsoleAppender log4j.appender.console.Target = System.out log4j.appender.console.layout = org.apache.log4j.PatternLayout log4j.appender.console.layout.ConversionPattern = %-d&#123;yyyy-MM-dd HH\:mm\:ss&#125; [%p]-[%c] %m%n ### log file ### log4j.appender.debug = org.apache.log4j.DailyRollingFileAppender log4j.appender.debug.File = redcmsv6.log log4j.appender.debug.Append = true log4j.appender.debug.Threshold = INFO log4j.appender.debug.layout = org.apache.log4j.PatternLayout log4j.appender.debug.layout.ConversionPattern = %-d&#123;yyyy-MM-dd HH\:mm\:ss&#125; [%p]-[%c] %m%n ### exception ### log4j.appender.error = org.apache.log4j.DailyRollingFileAppender log4j.appender.error.File = redcms.log log4j.appender.error.Append = true log4j.appender.error.Threshold = ERROR log4j.appender.error.layout = org.apache.log4j.PatternLayout log4j.appender.error.layout.ConversionPattern = %-d&#123;yyyy-MM-dd HH\:mm\:ss&#125; [%p]-[%c] %m%n 编写测试代码然MyBatis跑起来12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152package test;import java.io.IOException;import java.io.InputStream;import java.util.List;import com.xzy.beans.Student;import com.xzy.dao.mapper.StudentMapper;import org.apache.ibatis.io.Resources;import org.apache.ibatis.session.SqlSession;import org.apache.ibatis.session.SqlSessionFactory;import org.apache.ibatis.session.SqlSessionFactoryBuilder;import org.junit.Before;import org.junit.Test;/** * Unit test for simple App. */public class AppTest&#123; SqlSessionFactory sqlSessionFactory; @Before public void before() &#123; try &#123; String resource = "MyBatis-CONFIG.xml"; InputStream inputStream = Resources.getResourceAsStream(resource); sqlSessionFactory = new SqlSessionFactoryBuilder().build(inputStream); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; @Test public void testselectAll()&#123; SqlSession session=sqlSessionFactory.openSession(); //接口 try &#123; StudentMapper sm = session.getMapper(StudentMapper.class); List&lt;Student&gt; stus = sm.getAll(); for (Student stu : stus) System.out.println(stu.toString()); System.out.println("Ok"); &#125;finally &#123; session.close(); &#125; &#125;&#125; 测试结果：]]></content>
      <categories>
        <category>MyBatis框架</category>
      </categories>
      <tags>
        <tag>MyBatis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx配置实例—反向代理]]></title>
    <url>%2F2019%2F01%2F29%2FNginx%E9%85%8D%E7%BD%AE%E5%AE%9E%E4%BE%8B%E2%80%94%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86%2F</url>
    <content type="text"><![CDATA[1、配置示例1：： 要求：在浏览器地址栏中输入www.123.com，跳转到Linux服务器中的tomcat主页面 声明：本次实验在我电脑的Linux虚拟机上进行的，Linux系统信息如下： 图1 实验系统信息 1.1 准备工作（1）安装nginx(参考：Nginx快速入门—基本概念以及在Linux上安装Nginx（2）启动一个tomcat（注意：在启动之前一定要配置好Java环境变量，参考：记一次在云服务器上部署项目的实践经历)（3）tomcat启动后在本地host文件中配置域名映射： 1192.168.92.128 www.123.com 配置完成后在浏览器中输入www.123.com:8080 如果能看到tomcat的页面，就说明配置的没有问题。 图2 host配置测试 1.2 nginx配置反向代理接下来我们来配置nginx，nginx一入门我们都知道在nginx的安装目录下的conf/nginx.conf是nginx的默认配置文件，因此打开它默认配置文件并简单配置如下内容（当然，你也可以使用nginx -c指定配置文件），简单配置如下： 123456789101112server &#123; listen 80; server_name 192.168.92.128; #server 代理域名 charset utf-8; location / &#123; #location / 通配所有请求路径 root html; proxy_pass http://127.0.0.1:8080; #请求会转发到Linux系统的127.0.0.1：8080端口 index index.html index.htm; proxy_connect_timeout 600; proxy_read_timeout 600; &#125;&#125; 测试结果：配置完成后重新加载配置文件后，直接访问www.123.com，如果可以看到tomcat的首页那就大功告成啦！ 图2 nginx反向代理配置示例1测试 2、配置示例2：： 要求：在浏览器地址栏中输入www.123.com/login，请求跳转到127.0.0.1:8080在浏览器地址栏中输入www.123.com/user，请求跳转到127.0.0.1:8081 2.1 准备工作启动两个tomcat，并在监听8080端口的tomcat的webapps目录下新建文件夹login以及文件index.html;在监听8081端口的tomcat的webapps目录下新建文件夹user以及文件index.html; 2.2 配置nginx按照要求，nginx服务器要根据不同的请求路径把不同的请求转发到不同的tomcat中处理，这里就需要用到正则表达式来匹配路径，具体的配置如下： 123456789101112131415161718192021server &#123; listen 80; server_name 192.168.92.128; charset utf-8; location ~ /login &#123; #正则表达式匹配login请求 root html; proxy_pass http://127.0.0.1:8080; #forward to tomcat 8080 index index.html index.htm; proxy_connect_timeout 600; proxy_read_timeout 600; &#125; location ~ /user&#123; #正则表达式匹配user请求 root html; proxy_pass http://127.0.0.1:8081; proxy_connect_timeout 600; proxy_read_timeout 600; &#125; error_page 404 /404.html;&#125; 测试结果： 图3 nginx反向代理配置示例2测试 3、location匹配规则详解在上面的配置中使用到了正则匹配，nginx官方文档给出location语法如下： location语法：location [=||*|^~] /uri/ { … } 其中，方括号中的四种标识符是可选项，用来改变请求字符串和uri的匹配方式。uri是待匹配的请求字符串，可以是不包含正则的字符串，这种模式被称为“标准的uri”；也可以包含正则，这种模式被称为”正则uri”，具体可用的标识符如下： *= * ：必须与指定的模式严格匹配，如果匹配成功就停止向下搜索，并立即处理代理逻辑 ~：必须以指定模式开始，并且区分大小写 ~* ：必须以指定模式开始，并且不区分大小写 *^~ *：前缀匹配，不支持正则，如果模式匹配，那么就停止搜索其他模式了。 无：普通匹配（最长字符匹配）；与location顺序无关，是按照匹配的长短来取匹配结果。若完全匹配，就停止匹配。 备注：1、如果uri里面包含正则表达式，就必须使用或标识符；2、针对和*匹配标识符，可以在前面加上!来取反，如下：&lt;span style=”color=”rgb(192, 0, 0)”&gt;!~ 表示正则不匹配，区分大小写。&lt;span style=”color=”rgb(192, 0, 0)”&gt;!~ 表示正则不匹配，不区分大小写。 3.1 精确匹配（=）示例123location = /login&#123; #严格匹配 /login（多一个字母少一个字母或多一级少一级路径都不行） ，匹配成功后，立即结束&#125; 3.2 区分大小写正则匹配（~）示例123location ~ /login/&#123; #正则匹配，区分大小写（/LOGIN/、、/Login/都是不可以的），匹配成功后，立即结束&#125; 3.3 不区分大小写正则匹配（~*）示例123location ~* /login/&#123;#正则匹配，不区分大小写（/LOGIN/、/Login/都是可以的），匹配成功后，立即结束&#125; 3.4 标准匹配（^~）示例123location ^~ /login/&#123; # 匹配任何以 /login/ 开头的地址，匹配符合以后，停止往下搜索正则&#125; 3.5 普通匹配（最长字符匹配）示例1234location /login/&#123; # 与location顺序无关 # 若完全匹配成功，就不在继续匹配，否则还会进行正则匹配&#125; 4、location匹配优先级1、如果有精确匹配，会先进行精确匹配，匹配成功，立刻返回结果。2、普通匹配与顺序无关，因为按照匹配的长短来取匹配结果。3、正则匹配与顺序有关，因为是从上往下匹配。(首先匹配，就结束解析过程)。4、在location中，location /可以匹配所有的请求，但是他的优先级是最低的。 总结匹配规则如下：&lt;span style=”color=”rgb(192, 0, 0)”&gt; (location =) &gt; (location 完整路径) &gt; (location ^~ 路径) &gt; (location ,* 正则顺序) &gt; (location 部分起始路径) &gt; (location /)即&lt;span style=”color=”rgb(192, 0, 0)”&gt;（精确匹配）&gt; (最长字符串匹配，但完全匹配) &gt;（非正则匹配）&gt;（正则匹配）&gt;（最长字符串匹配，不完全匹配）&gt;（location通配）]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>Nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Java获取请求URL以及服务器根路径的方法]]></title>
    <url>%2F2019%2F01%2F02%2FJava%E8%8E%B7%E5%8F%96%E8%AF%B7%E6%B1%82URL%E4%BB%A5%E5%8F%8A%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%A0%B9%E8%B7%AF%E5%BE%84%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[一、 获取此次请求的URL123456String requestUrl = request.getScheme() //当前链接使用的协议 +"://" + request.getServerName()//服务器地址 + ":" + request.getServerPort() //端口号 + request.getContextPath() //应用名称，如果应用名称为 + request.getServletPath() //请求的相对url + "?" + request.getQueryString(); //请求参数 举例：http://127.0.0.1:8080/world/index.jsp?name=lilei&amp;sex=1 123456789101112131415161718&lt;Context path=&quot;world&quot; docBase=&quot;/home/webapps&quot; debug=&quot;0&quot; reloadable=&quot;true&quot;/&gt; request.getScheme() = &quot;http&quot;;request.getServerName() = &quot;127.0.0.1&quot;;request.getServerPort() = &quot;8080&quot;;request.getContextPath() = &quot;world&quot;;request.getServletPath() = &quot;index.jsp&quot;;request.getQueryString() = &quot;name=lilei&amp;sex=1&quot;; http://127.0.0.1:8080/world/index.jsp?name=lilei&amp;sex=1&lt;Context path=&quot;&quot; docBase=&quot;/home/webapps&quot; debug=&quot;0&quot; reloadable=&quot;true&quot;/&gt; request.getScheme() = &quot;http&quot;;request.getServerName() = &quot;127.0.0.1&quot;;request.getServerPort() = &quot;8080&quot;;request.getContextPath() = &quot;&quot;;request.getServletPath() = &quot;world/index.jsp&quot;;request.getQueryString() = &quot;name=lilei&amp;sex=1&quot;; 二、获取服务器根路径1234&lt;% String path = request.getContextPath(); String basePath = request.getScheme()+"://"+request.getServerName()+":"+request.getServerPort()+path+"/"; %&gt; 在JSP中使用方法如下： 123456789&lt;head&gt;&lt;link rel="stylesheet" type="text/css" href="&lt;%=basePath%&gt;static/css/framework/themes/default/easyui.css"&gt;&lt;link rel="stylesheet" type="text/css" href="&lt;%=basePath%&gt;static/css/framework/themes/icon.css"&gt;&lt;link rel="stylesheet" type="text/css" href="&lt;%=basePath%&gt;static/css/base.css"&gt;&lt;script src="&lt;%=basePath%&gt;static/javascript/framework/jquery.min.js"&gt;&lt;/script&gt;&lt;script src="&lt;%=basePath%&gt;static/javascript/framework/jquery.easyui.min.js"&gt;&lt;/script&gt;&lt;script src="&lt;%=basePath%&gt;static/javascript/framework/easyui-lang-zh_CN.js"&gt;&lt;/script&gt;&lt;script src="&lt;%=basePath%&gt;static/javascript/framework/easyui-util.js"&gt;&lt;/script&gt;&lt;/head&gt;]]></content>
      <categories>
        <category>Java</category>
      </categories>
      <tags>
        <tag>Java</tag>
      </tags>
  </entry>
</search>
